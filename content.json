{"meta":{"title":"RookieYin's Note","subtitle":"","description":"","author":"Yin Peng","url":"http://rookieyin.github.io","root":"/"},"pages":[{"title":"friends","date":"2021-12-07T09:16:04.043Z","updated":"2021-06-04T09:28:08.022Z","comments":true,"path":"friends/index.html","permalink":"http://rookieyin.github.io/friends/index.html","excerpt":"","text":""},{"title":"About me","date":"2021-12-07T09:16:04.043Z","updated":"2021-06-04T09:57:51.569Z","comments":false,"path":"about-me/2021.html","permalink":"http://rookieyin.github.io/about-me/2021.html","excerpt":"","text":"敬请期待！！！！"},{"title":"tags","date":"2021-06-04T05:28:17.000Z","updated":"2021-06-04T05:57:01.623Z","comments":true,"path":"tags/index.html","permalink":"http://rookieyin.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-06-04T05:27:43.000Z","updated":"2021-06-04T05:56:41.150Z","comments":true,"path":"categories/index.html","permalink":"http://rookieyin.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"快排的3种实现方式","slug":"4 算法/快排的3种实现方式","date":"2022-06-11T07:48:05.000Z","updated":"2022-06-11T07:49:24.962Z","comments":true,"path":"b991887dca39/","link":"","permalink":"http://rookieyin.github.io/b991887dca39/","excerpt":"本文循序渐进的总结一下：单路、双路和三路，三种快排实现方式。大家可以去912. 排序数组验证自己代码的正确性。","text":"本文循序渐进的总结一下：单路、双路和三路，三种快排实现方式。大家可以去912. 排序数组验证自己代码的正确性。 单路快排 思路：以p = arr[right]作为基准值，指针i = left表示第一个大于等于基准值的下标，指针j = left 如果arr[j] &lt; p，交换index和p处的值，i++且j++ 否则j++，i不变 跳出循环后，交换right和i处的值即可。 注：这里选择arr[right]作为基准值很重要，如果选择arr[left]作为基准值，当所有元素都小于基准值时就比较麻烦。 下面是java的简单实现： 123456789101112131415161718public void quickSort(int[] nums, int left, int right)&#123; if(left &gt;= right) return; //终点和随机位置交换值 int temp = rand.nextInt(left, right+1); swap(nums, right, temp); int i = left, j = left, p = nums[right]; while(j &lt; right)&#123; if(nums[j] &lt; p)&#123; swap(nums, i, j); i++; &#125; j++; &#125; //交换i和right处的值，这样[left, i-1]都是小于p的值，[i+1, right]都是大于等于p的值 swap(nums, i, right); quickSort(nums, left, i-1); quickSort(nums, i+1, right);&#125; 双路快排 思路：以p=arr[left]作为基准值，i = left， j= right 如果i &lt; j &amp;&amp; arr[j] &gt;= p，重复j-- 注：第一步必须先让j走，否则如果所有元素都小于等于p，就会出错。 如果i &lt; j &amp;&amp; arr[i] &lt;= p，重复i++ 交换i和j处的值，重复上述步骤 跳出循环后，交换left和i处的值即可。 注：上面第1、2步中都带等号，即&lt;=和&gt;=，这样可以让基准值在两边分布均匀。 下面是java的简单实现： 1234567891011121314151617public void quickSort(int[] nums, int left, int right)&#123; if(left &gt;= right) return; //起点和随机位置交换值 int temp = rand.nextInt(left, right+1); swap(nums, left, temp); int i = left, j = right, p = nums[left]; while(i &lt; j)&#123; //先让j走 while(i &lt; j &amp;&amp; nums[j] &gt;= p) --j; while(i &lt; j &amp;&amp; nums[i] &lt;= p) ++i; swap(nums, i, j); &#125; //交换i和left处的值，这样[left, i-1]都是小于p的值，[i+1, right]都是大于等于p的值 swap(nums, i, left); quickSort(nums, left, i-1); quickSort(nums, i+1, right);&#125; 三路快排 思路：以p = arr[left]作为基准值，i = left作为左侧存放小于基准值元素的位置，j = right + 1作为右侧存放大于基准值元素的位置，index = left + 1遍历所有元素。 如果arr[index] &lt; p，交换i+1和index处的值，i++，index++ 如果arr[index] &gt; p，交换j-1和index处的值，j-- 否则，index++ 跳出循环后，交换left和i处的值即可 下面是java的简单实现： 1234567891011121314151617181920212223public void quickSort(int[] nums, int left, int right)&#123; if(left &gt;= right) return; //起点和随机位置交换值 int temp = rand.nextInt(left, right); swap(nums, left, temp); int i = left, j = right+1, index = left + 1, p = nums[left]; while(index &lt; j)&#123; if(nums[index] &lt; p)&#123; swap(nums, i + 1, index); i++; index++; &#125;else if(nums[index] &gt; p)&#123; swap(nums, j - 1, index); j--; &#125;else&#123; index++; &#125; &#125; //交换i和left处的值，这样[left, i-1]都是小于p的值，[j, right]都是大于p的值 swap(nums, i, left); quickSort(nums, left, i-1); quickSort(nums, j, right);&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"MySQL连接查询","slug":"2 后端/MySQL/14. MySQL连接查询","date":"2022-06-11T06:28:18.000Z","updated":"2022-06-11T06:31:56.532Z","comments":true,"path":"b20020a2ff1b/","link":"","permalink":"http://rookieyin.github.io/b20020a2ff1b/","excerpt":"本文简单总结一下MySQL中常用的连接查询，以及连接查询的底层原理。","text":"本文简单总结一下MySQL中常用的连接查询，以及连接查询的底层原理。 常用的连接查询 连接的本质 我们先建立两张简单的表t1和t2： 1234CREATE TABLE t1 (m1 int, n1 char(1));CREATE TABLE t2 (m2 int, n2 char(2));INSERT INTO t1 VALUES (1, &#x27;a&#x27;), (2, &#x27;b&#x27;), (3, &#x27;c&#x27;);INSERT INTO t2 VALUES (2, &#x27;b&#x27;), (3, &#x27;c&#x27;), (4, &#x27;d&#x27;); 如上图所示，连接的本质就是：把t1表中的记录和t2表中的记录连起来组成一个新的更大的记录，这个查询过程称之为连接查询。 在MySQL中连接的使用非常简单，把两个表同时放到FROM关键字后面即可。比如，把t1和t2连接起来可以写成这样： 从前文我们可以看出，如果不加条件进行表连接，可能产生非常巨大的笛卡尔乘积。比如，3个100行记录的表连接到一起就是1 000 000行记录！因此在连接时，我们通常需要加过滤条件。过滤条件可以分为两类： 涉及单表的过滤条件：比如t1.m1 &gt; 1和t2.n2 &lt; 'd' 涉及两表的过滤条件：比如t1.m1 = t2.m2 以select * from t1, t2 where t1.m1 = t2.m2为例，这种带过滤条件的连接查询，执行过程大致如下： 步骤1：首先确定第一个需要查询的表，称之为驱动表 选择最优查询方法，按照过滤条件，执行单表查询语句。 步骤2：步骤1从驱动表中每获取到一条记录，都需要到t2表（被驱动表）中查找匹配的记录 整个连接查询的执行过程大致如下： 内连接 内连接，使我们经常使用的一种连接，前文提到的“将所有表添加到FROM关键字后面”就是内连接的一种实现方式。 内连接的特点是：若驱动表中的记录在被驱动表中没有找到与之匹配的记录，则该记录不会加入到最后的结果集。 内连接的语法格式如下： 1SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件] INNER和CROSS可有可无，即INNER JOIN == CROSS JOIN == JOIN ON后面添加连接条件，等价于WHERE中添加普通条件，即下面两条语句等价 123SELECT * FROM t1 INNER JOIN t2 ON t1.m1 = t2.m2;--等价于SELECT * FROM t1 INNER JOIN t2 WHERE t1.m1 = t2.m2; 外连接 有了内连接，为什么还有搞个外连接呢？前面提到过“对于内连接，若驱动表中的记录在被驱动表中没有找到与之匹配的记录，则该记录不会加入到最后的结果集”。 但是，有时候我们希望把驱动表中没匹配到的记录页加到结果集中，这时候就需要外连接了。下面举个简单例子： 创建两张表，并填充数据，如下图所示： 现在要查询每位学生的得分信息，使用内连接查询，结果如下图所示： 观察上图结果，我们发现：王五同学因为某些原因没有参加考试，所以score表中没有他的成绩。 如果老师想要查看所有同学的考试成绩，即使是缺考的学生，它们的成绩也应该展现出来。这样内连接就无法完成该任务了，需要使用外连接。 MySQL中，根据选取的驱动表的不同，外连接可以细分为2种： 左外连接：LEFT [OUTER] JOIN，选取左侧的表作为驱动表 右外连接：RIGHT [OUTER] JOIN，选取右侧的表作为驱动表 在内连接中，我们提到ON中的连接条件和WHERE中的过滤条件，效果是等价的。但是在外连接中，两者是有区别的： WHERE中的过滤条件 不论是内连接还是外连接，凡是不符合条件的记录都不会加入结果集 ON中的连接条件 对于外连接，如果在被驱动表中无法找到匹配ON子句中过滤条件的记录，那么这条驱动表记录会被加到结果集中，对应被驱动表的各个字段用NULL填充。 为了更直观的对比内、左外、右外三种连接方式，下图展示了将t1和t2以这三种连接方式查询的结果： 其他 前面提到的3种连接方式是最常用的，还有一些不常用的连接： 自然连接：一种特殊的等值连接， 要求两个关系表中进行比较的属性组必须是名称相同的属性组，并且在结果中把重复的属性列去掉 。 交叉连接： 用于生成两张表的笛卡尔结果集， select * from A , B语句就是返回笛卡尔结果集，等同于 select * from A cross join B 。 连接查询底层原理 嵌套循环连接 前面提到过，对于两表连接查询，驱动表只会访问一遍，但是被驱动表却要访问好多遍，具体访问多少遍取决于驱动表中有多少条符合条件的记录。 查询过程大致为：每从驱动表中找到一条符合条件的记录，就遍历一次被驱动表，查找被驱动表中符合条件的记录。 这个过程称之为“嵌套循环连接”。 使用索引加快连接速度 在嵌套循环连接中可能要多次访问被驱动表。如果访问被驱动表的方式都是全表扫描，那得扫描好多次。 我们可以利用索引来加快查询速度，即在连接条件和过滤条件上建立索引。 这样在扫描被驱动表时，就可以利用索引加快查询速度。 基于块的嵌套循环连接 如果我们不能使用索引加快被驱动表的扫描速度，还有其他方法减少被驱动表全表扫描次数吗？ 答案是有的，即基于块的嵌套循环连接。 具体来说，在InnoDB中设计了一个名为Join Buffer的缓冲区，先把若干条驱动表结果集中的记录装在这个Join Buffer中，然后开始扫描被驱动表，每一条被驱动表记录一次性地与Join Buffer中的多条驱动表记录进行匹配。这样可以显著减少被驱动表的I/O代价。 大致过程如下图所示： Join Buffer默认大小为256KB，最小可以设置成128字节。 当我们要优化对被驱动表的查询时，最好是为被驱动表加上高效率索引。如果实在不能使用索引，并且机器内存比较大，则可以尝试调大Join Buffer的大小。 不过需要注意的是，Join Buffer不会存放驱动表记录的所有列，只有查询列表中的列和过滤条件中的列才会被放到Join Buffer中。因此，最好不要把*作为查询列表，这样Join Buffer中可以存放更多的记录。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"Hyperloglog算法","slug":"4 算法/Hyperloglog算法","date":"2022-06-10T11:50:48.000Z","updated":"2022-06-10T11:54:52.656Z","comments":true,"path":"956d20e7408c/","link":"","permalink":"http://rookieyin.github.io/956d20e7408c/","excerpt":"在Redis中有一种叫作Hyperloglog的数据结构，用于基数统计，其背后原理就是Hyperloglog算法，本文介绍下HyperLogLog算法的原理和具体实现方式。主要包括LLC算法原理及实现，HLLC算法原理及实现，Redis中HeperLogLog的具体实现。","text":"在Redis中有一种叫作Hyperloglog的数据结构，用于基数统计，其背后原理就是Hyperloglog算法，本文介绍下HyperLogLog算法的原理和具体实现方式。主要包括LLC算法原理及实现，HLLC算法原理及实现，Redis中HeperLogLog的具体实现。 基数统计概述 基数统计通常用来统计一个集合中不重复元素的个数，例如统计某个网站的UV，或者用户搜索网站的关键词数量等等。当数据量比较少的时候，我们用一个set或者性能更高的bitmap就能轻松解决。但是当数据量非常大，比如上亿级别，这时用set就不切实际了。 实际上目前还没有发现更好的在大数据场景中准确计算基数的高效算法，因此在不追求绝对准确的情况下，使用概率算法算是一个不错的解决方案。概率算法不直接存储数据集合本身，通过一定的概率统计方法预估基数值，这种方法可以大大节省内存，同时保证误差控制在一定范围内。目前用于基数计数的概率算法包括: Linear Counting(LC)：早期的基数估计算法，LC在空间复杂度方面并不算优秀，实际上LC的空间复杂度与简单bitmap方法是一样的（但是有个常数项级别的降低），都是O(Nmax)； LogLog Counting(LLC)：LogLog Counting相比于LC更加节省内存，空间复杂度只有O(log2(log2(Nmax))) HyperLogLog Counting(HLL)：HyperLogLog Counting是基于LLC的优化和改进，在同样空间复杂度情况下，能够比LLC的基数估计误差更小。 本文重点介绍后两种算法，即LLC和HLL。 LLC 算法思想 LLC算法的思想其实来源于伯努利实验，下面我们以抛硬币实验为例，简单介绍下伯努利。 硬币拥有正反两面，一次的上抛至落下，最终出现正反面的概率都是50%。假设一直抛硬币，直到它出现正面为止，我们记录为一次完整的试验，间中可能抛了一次就出现了正面，也可能抛了4次才出现正面。无论抛了多少次，只要出现了正面，就记录为一次试验。这个试验就是伯努利试验。 那么对于多次的伯努利试验，假设这个多次为n次。就意味着出现了n次的正面。假设每次伯努利试验所经历了的抛掷次数为k。第一次伯努利试验，次数设为k1k_1k1​，以此类推，第n次对应的是knk_nkn​。 其中，对于这n次伯努利试验中，必然会有一个最大的抛掷次数k，例如抛了12次才出现正面，那么称这个为kmaxk_{max}kmax​，代表抛了最多的次数。 伯努利试验容易得出有以下结论： n 次伯努利过程的投掷次数都不大于 kmaxk_{max}kmax​。 n 次伯努利过程，至少有一次投掷次数等于 kmaxk_{max}kmax​。 最终结合极大似然估算的方法，发现在nnn和kmaxk_{max}kmax​中存在估算关联：n=2kmaxn = 2^{k_{max}}n=2kmax​ 。这种通过局部信息预估整体数据流特性的方法似乎有些超出我们的基本认知，需要用概率和统计的方法才能推导和验证这种关联关系。 例如下面的样子： 1234第一次试验: 抛了3次才出现正面，此时 k&#x3D;3，n&#x3D;1第二次试验: 抛了2次才出现正面，此时 k&#x3D;2，n&#x3D;2第三次试验: 抛了6次才出现正面，此时 k&#x3D;6，n&#x3D;3第n 次试验：抛了12次才出现正面，此时我们估算， n &#x3D; 2^12 假设上面例子中实验组数共3组，那么 k_max = 6，最终 n=3，我们放进估算公式中去，明显： 3 ≠ 2^6 。也即是说，当试验次数很小的时候，这种估算方法的误差是很大的。 下面我们尝试从数学角度，来解释：为什么可以用2kmax2^{k_{max}}2kmax​来估算实验次数n。 现在考虑下面两个问题： 进行n次伯努利实验，所有投掷次数都不大于k的概率是多少？ 进行n次伯努利实验，至少有一次投掷次数等于k的概率是多少？ 首先看第一个问题，在一次伯努利实验中，投掷次数大于k的概率是1/2k1/2^k1/2k，即前k次都投出了反面。因此，问题1的答案是Pn(X≤k)=(1−1/2k)nP_n(X\\leq k) = (1-1/2^k)^nPn​(X≤k)=(1−1/2k)n。那么第二个问题的答案显然是，Pn(X≥k)=1−(1−1/2k)nP_n(X\\geq k) = 1-(1-1/2^k)^nPn​(X≥k)=1−(1−1/2k)n。 从上述分析，我们可以得出这样的结论：当n&lt;&lt;2kn &lt;&lt; 2^kn&lt;&lt;2k时，Pn(X≥k)P_n(X\\geq k)Pn​(X≥k)的概率几乎为0，同时，当n&gt;&gt;2kn &gt;&gt; 2^kn&gt;&gt;2k时，Pn(X≤k)P_n(X\\leq k)Pn​(X≤k)的概率也几乎为0。 用自然语言描述就是：当实验次数远远小于2k2^k2k时，至少有一次实验投掷次数等于k的概率几乎为0；当实验次数远远大于2k2^k2k时，没有一次实验投掷次数大于k的概率也几乎为0。 如果将上面描述作一个对应：一次伯努利实验对应一个比特串，反面对应0，正面对应1，投掷次数k对应第一个“1”出现的位置，我们就得出如下结论： 假设一个集合基数为n，kmaxk_{max}kmax​为所有比特串中，首个“1”出现位置最大的位置，如果n远远小于2kmax2^{k_{max}}2kmax​，那么我们得到kmaxk_{max}kmax​为当前只的概率几乎为0，同样的，如果n远远大于2kmax2^{k_{max}}2kmax​，则我们得到kmaxk_{max}kmax​的概率也几乎为0，因此2kmax2^{k_{max}}2kmax​可以作为基数n的一个粗糙估计。 总结来说就是： 进行n次抛硬币实验，每次分别记录第一次抛出正面的次数k，假设n个k中最大值为kmaxk_{max}kmax​，那么我们可以用2kmax2^{k_{max}}2kmax​来估计实验次数n。 回到基数统计的问题，我们需要统计一组数据中不重复元素的个数， 集合中每个元素的经过hash函数后可以表示成0和1构成的二进制数串，一个二进制串可以类比为一次抛硬币实验，1是抛到正面，0是反面。 二进制串中从低位开始第一个1出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数k， 那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验， 同样可以可以通过第一个1出现位置的最大值kmaxk_{max}kmax​来预估总共有多少个不同的数字（整体基数）。 具体实现 LogLogCounting算法伪代码如上图所示，主要包含哈希和分桶两部分。 哈希 在使用LLC之前，需要选取一个合适的哈希函数，将所有元素映射成一个二进制串。哈希函数需要满足一下性质： 均匀分布 哈希碰撞可以忽略不计 哈希结果长度固定 分桶 基于前文的分析，如果使用单一估计量进行基数估计会由于偶然性而存在较大误差。因此，LLC采用了分桶平均的思想来消除误差。 具体来说，就是把哈希空间平均分成m份，每份称之为一个桶。对于每个元素，根据其哈希值的前k比特作为桶编号，其余比特作为基数估计的比特串。 桶编号相同的元素被分配到同一个桶，在进行基数估计时，首先计算每个桶内元素最大的第一个“1”的位置，设为M[i]M[i]M[i]，然后对这m个值取平均后再进行估计，即： n^=21/m∑M[i]\\hat n=2^{1/m}\\sum M[i]n^=21/m∑M[i]。 这其实相当于我们熟知的多次试验取平均的做法，可以有效消减因偶然性带来的误差。 设一个元素哈希值的比特串为“0001001010001010”，由于m为32，因此前5个bit为桶编号，所以这个元素应该归入“00010”即2号桶（桶编号从0开始，最大编号为m-1） 而剩下部分是“01010001010”且显然k(01010001010)=2，所以桶编号为“00010”的元素最大的k即为M[2]的值。 偏差修正 上述经过分桶平均后的估计量看似已经很不错了，不过通过数学分析可以知道这并不是基数n的无偏估计。因此需要修正成无偏估计。这部分的具体数学分析在“Loglog Counting of Large Cardinalities”中，过程过于艰涩这里不再具体详述，有兴趣的朋友可以参考原论文。 通过数学推导，可以得到如下的渐进五篇估计量： n^=αm21/m∑M[i]αm=(Γ(−1/m)1−21/mlog⁡2)−mΓ(s)=1s∫0∞e−ttsdt\\begin{aligned} \\hat{n}&amp;=\\alpha_{m} 2^{1 / m} \\sum M[i]\\\\ \\alpha_{m}&amp;=\\left(\\Gamma(-1 / m) \\frac{1-2^{1 / m}}{\\log 2}\\right)-m \\\\ \\Gamma(s)&amp;=\\frac{1}{s} \\int_{0}^{\\infty} e^{-t} t^{s} d t \\end{aligned} n^αm​Γ(s)​=αm​21/m∑M[i]=(Γ(−1/m)log21−21/m​)−m=s1​∫0∞​e−ttsdt​ 该估计量的偏差为：Std⁡Error⁡(n^/n)≈1.30m\\operatorname{Std} \\operatorname{Error}(\\hat{n} / n) \\approx \\frac{1.30}{\\sqrt{m}}StdError(n^/n)≈m​1.30​。 因此在实际应用中，如果我们想将误差控制在ϵ\\epsilonϵ内，那么m&gt;(1.30/ϵ)2m&gt;(1.30/\\epsilon)^2m&gt;(1.30/ϵ)2。 内存使用分析 内存使用与m的大小及哈希值长度有关，假设哈希值长度为32，由于kmax≤32k_{max} \\leq 32kmax​≤32，因此每个桶需要5bit空间来存储这个桶的kmaxk_{max}kmax​，m个桶就需要5×m/85\\times m/85×m/8个字节。 举个例子，加入基数上限为一亿（约2272^{27}227），当分桶数m=1024时，每个桶的基数上限约为2172^{17}217，而log2(log2(217))=4.09log_2(log_2(2^{17}))=4.09log2​(log2​(217))=4.09，因此每个桶需要5bit存储kmaxk_{max}kmax​，需要的字节数就是5×1024/8=6405\\times 1024/8=6405×1024/8=640，误差为1.30/1024=0.0406251.30/\\sqrt {1024}=0.0406251.30/1024​=0.040625，约等于4%。 HLLC HLLC是对LLC的一种改进。 HLLC的第一个改进是使用调和平均数替代几何平均数。注意LLC是对各个桶取算数平均数，而算数平均数最终被应用到2的指数上，所以总体来看LLC取得是几何平均数。由于几何平均数对于离群值（例如这里的0）特别敏感，因此当存在离群值时，LLC的偏差就会很大，这也从另一个角度解释了为什么n不太大时LLC的效果不太好。这是因为n较小时，可能存在较多空桶，而这些特殊的离群值强烈干扰了几何平均数的稳定性。 因此，HLLC使用调和平均数来代替几何平均数，调和平均数的定义如下： H=n1x1+1x2+…+1xn=n∑i=1n1xiH=\\frac{n}{\\frac{1}{x_{1}}+\\frac{1}{x_{2}}+\\ldots+\\frac{1}{x_{n}}}=\\frac{n}{\\sum_{i=1}^{n} \\frac{1}{x_{i}}} H=x1​1​+x2​1​+…+xn​1​n​=∑i=1n​xi​1​n​ 调和平均数可以有效抵抗离群值的扰动。使用调和平均数代替几何平均数后，估计公式变为如下： n^=αmm2∑2−Mαm=(m∫0∞(log⁡2(2+u1+u))mdu)−1\\begin{aligned} \\hat{n}&amp;=\\frac{\\alpha_{m} m^{2}}{\\sum 2^{-M}}\\\\ \\alpha_{m}&amp;=\\left(m \\int_{0}^{\\infty}\\left(\\log _{2}\\left(\\frac{2+u}{1+u}\\right)\\right)^{m} d u\\right)^{-1} \\end{aligned} n^αm​​=∑2−Mαm​m2​=(m∫0∞​(log2​(1+u2+u​))mdu)−1​ 该估计的误差期望为：Shllc (n^/n)=1.04/mS_{\\text {hllc }}(\\hat{n} / n)=1.04 / \\sqrt{m}Shllc ​(n^/n)=1.04/m​。 因此在存储空间相同的情况下，HLLC比LLC具有更高的精度。例如，对于分桶数m为2^13（8k字节）时，LLC的标准误差为1.4%，而HLLC为1.1%。 Redis中的HyperLogLog 在 Redis 中，HyperLogLog 是它的一种高级数据结构。提供有包含但不限于下面两条命令： pfadd key value，将 key 对应的一个 value 存入 pfcount key，统计 key 的 value 有多少个 在Redis中，设有 16384 个桶，即：2^14 = 16384，每个桶有 6 位，每个桶可以表达的最大数字是：2^5+2^4+…+1 = 63 ，二进制为： 111 111 。因为每个value（哈希值）为64位，去掉前14位，还剩50，因此kmaxk_{max}kmax​最大为50，用每个桶用6bit空间足够表示50了。 因此，Redis中一个HyperLogLog，只需要(6 * 16384)/8/1024 K=12K的空间，就能统计最多2642^{64}264个数，统计误差大约为1.04/16384=0.0081251.04/\\sqrt{16384}=0.0081251.04/16384​=0.008125。 参考资料 https://juejin.cn/post/6844903785744056333 https://zhuanlan.zhihu.com/p/77289303 http://algo.inria.fr/flajolet/Publications/DuFl03-LNCS.pdf","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"统计","slug":"统计","permalink":"http://rookieyin.github.io/tags/%E7%BB%9F%E8%AE%A1/"}]},{"title":"Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations","slug":"3 论文笔记/图学习/对比学习/23.Bringing Your Own View Graph Contrastive Learning without Prefabricated Data Augmentations","date":"2022-06-10T11:26:03.000Z","updated":"2022-06-10T11:46:25.528Z","comments":true,"path":"b1598f2ddb56/","link":"","permalink":"http://rookieyin.github.io/b1598f2ddb56/","excerpt":"https://arxiv.org/pdf/2201.01702 https://github.com/Shen-Lab/GraphCL_Automated Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations ，2022，WSDM","text":"https://arxiv.org/pdf/2201.01702 https://github.com/Shen-Lab/GraphCL_Automated Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations ，2022，WSDM 1. 简介 1.1 摘要 Self-supervision is recently surging at its new frontier of graph learning. It facilitates graph representations beneficial to down-stream tasks; but its success could hinge on domain knowledge for handcraft or the often expensive trials and errors. Even its state-of-the-art representative, graph contrastive learning (GraphCL), is not completely free of those needs as GraphCL uses a prefabricated prior reflected by the ad-hoc manual selection of graph data augmentations. Our work aims at advancing GraphCL by answering the following questions: How to represent the space of graph augmented views? What principle can be relied upon to learn a prior in that space? And what framework can be constructed to learn the prior in tandem with contrastive learning? Accordingly, we have extended the prefabricated discrete prior in the augmentation set, to a learnable continuous prior in the parameter space of graph generators, assuming that graph priors per se, similar to the concept of image manifolds, can be learned by data generation. Furthermore, to form contrastive views without collapsing to trivial solutions due to the prior learnability, we have lever-aged both principles of information minimization (InfoMin) and information bottleneck (InfoBN) to regularize the learned priors. Eventually, contrastive learning, InfoMin, and InfoBN are incorporated organically into one framework of bi-level optimization. Our principled and automated approach has proven to be competitive against the state-of-the-art graph self-supervision methods, including GraphCL, on benchmarks of small graphs; and shown even better generalizability on large-scale graphs, without resorting to human expertise or downstream validation. Our code is publicly released at https://github.com/Shen-Lab/GraphCL_Automated. 近来自监督在图学习领域火速发展。它有利于下游任务中的图表示学习，但是他的成功依赖于一些手工的领域知识或者代价昂贵的试错。尽管是SOTA方法，GraphCL也存在这些问题，它基于一些先验知识来选择图增强方法。我们的工作致力于通过回答下列问题来提高GraphCL：如何表示图增强视角空间？在这个空间可以依赖哪些原则来学习先验知识？在对比学习的同时可以构建什么样的框架来学习先验知识？因此，我们假设图先验知识类似于image manifolds的概念，可以通过data generation来学习，并将增强集合中预制的离散先验知识拓展成图生成器参数空间中可学习的连续知识。另外，由于先验知识的可学习性，生成对比视角不会崩溃成琐碎的解决方案，我们同时利用InfoMin和InfoBN来正则化学习到的先验知识。最后，将对比学习、infoMin和infoBN有机地整合到一个双侧优化框架中。在small graphs的标准数据集上，我们的方法已经被证明和SOTA 图自监督方法相比，具有竞争力，在大规模数据集上的泛化能力也更好。 1.2 本文工作 背景： 现有自监督方法并没有完全解决图结构数据中异质性的挑战，它们的成功依赖于基于领域知识，去精心设计predictive pretext任务。也就是说，以前那些方法为了完成某种任务，比如上下文预测、元路径提取、图补全等任务，会去精心设计自己的模型，通用性不高。最近比较火的图对比学习方法一定程度上解决了这个问题，但是GCL也存在依赖人工先验知识的部分，即图增强。 动机：“ help close the gap is to turn the prefabricated self-supervised prior into a learnable one”，将依赖人工先验知识的图增强变成可学习的。 本文工作：“ What is the space, principle and framework that one can rely on, to define and pursue the learnable self-supervised prior ”，解决“用什么样的空间、原则、框架来定义和实现可学习自监督先验知识”这一问题。具体来说： 定义了一个参数化可学习先验函数 用InfoMin和InfoBN来regularize生成器的优化。 2. 方法 先回顾下GraphCL的整体框架： 2.1 对prior进行learnable 建模 在GCL中唯一用到预定义先验的地方就是图增强那块，因此对prior进行建模，其实就是对图增强进行可学习建模。最近图生成模型上升速度很快，给图先验知识参数化提供了一种平滑的解决方案。 本文作者利用VGAE，对GCL中的图增强进行建模。 这里也就是本文和其他Automated GCL方法核心区别所在，之前的自适应增强方法，都是预定义一个增强策略集合，然后从这个集合里面选取最优组合。而本文直接使用图生成模型来生成增强视角。 然后接下来的一个问题就是如何将可学习先验模型和对比模型结合到一起。一种直接的方式就是双层优化： min⁡θEPGLCL(G,ϕ1,ϕ2,θ) s.t. ϕ1,ϕ2∈arg⁡min⁡ϕ1′,ϕ2′EPGG{LGen(G,ϕ1′)+LGen(G,ϕ2′)}\\begin{aligned} &amp;\\min _{\\theta} \\mathbb{E}_{P_{\\mathrm{G}}} \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right) \\\\ &amp;\\text { s.t. } \\phi_{1}, \\phi_{2} \\in \\arg \\min _{\\phi_{1}^{\\prime}, \\phi_{2}^{\\prime}} \\mathbb{E}_{\\mathrm{PG}_{\\mathrm{G}}}\\left\\{\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{1}^{\\prime}\\right)+\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{2}^{\\prime}\\right)\\right\\} \\end{aligned} ​θmin​EPG​​LCL​(G,ϕ1​,ϕ2​,θ) s.t. ϕ1​,ϕ2​∈argϕ1′​,ϕ2′​min​EPGG​​{LGen​(G,ϕ1′​)+LGen​(G,ϕ2′​)}​ 此时两部分模型相当于各搞各的，独立优化，上下层之间没有交互，容易出现平凡解。为了解决这个问题，作者向图生成模型中添加了一个“reward”信号，这个信号来自于上层的对比模型。这样新的双层优化模型公式如下： min⁡θEPGLCL(G,ϕ1,ϕ2,θ) s.t. ϕ1,ϕ2∈arg⁡min⁡ϕ1′,ϕ2′EPGr(G,ϕ1′,ϕ2′,θ){LGen(G,ϕ1′)+LGen(G,ϕ2′)}\\begin{aligned} \\min _{\\theta} &amp; \\mathbb{E}_{P_{\\mathrm{G}}} \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right) \\\\ \\text { s.t. } &amp; \\phi_{1}, \\phi_{2} \\in \\arg \\min _{\\phi_{1}^{\\prime}, \\phi_{2}^{\\prime}} \\mathbb{E}_{\\mathbb{P}_{\\mathrm{G}}} r\\left(\\mathrm{G}, \\phi_{1}^{\\prime}, \\phi_{2}^{\\prime}, \\theta\\right)\\left\\{\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{1}^{\\prime}\\right)+\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{2}^{\\prime}\\right)\\right\\} \\end{aligned} θmin​ s.t. ​EPG​​LCL​(G,ϕ1​,ϕ2​,θ)ϕ1​,ϕ2​∈argϕ1′​,ϕ2′​min​EPG​​r(G,ϕ1′​,ϕ2′​,θ){LGen​(G,ϕ1′​)+LGen​(G,ϕ2′​)}​ 其中优化信号计算方式为：r(G,ϕ1,ϕ2,θ)={1, given some condition δ≪1, otherwise r\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right)=\\left\\{\\begin{array}{cc} 1, &amp; \\text { given some condition } \\\\ \\delta \\ll 1, &amp; \\text { otherwise } \\end{array}\\right.r(G,ϕ1​,ϕ2​,θ)={1,δ≪1,​ given some condition otherwise ​。整个模型架构如下图所示： 2.2 具体实现 在2.1中介绍了模型的整体框架，和双层优化公式，但是并没有具体实现（reward signal）。 可以看到，为了具体实现前文提到的模型，作者提出了两个Principle：InfoBN和InfoMin InfoMin Principle 和其他GCL方法一样，最小化两个视角之间的互信息，作者这里采用GraphCL中的对比损失： min⁡θEPGLCL(G,A1, A2,θ)=min⁡θEPG{−EP(A1, A2)sim⁡(Tθ,1(G),Tθ,2(G))⏞positive pairs +EPA1log⁡(EPG′×PA2exp⁡(sim⁡(Tθ,1(G),Tθ,2(G′))⏟negative pairs ))},\\begin{aligned} &amp; \\min _{\\theta} \\mathbb{E P}_{\\mathrm{G}} \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right) \\\\ =&amp; \\min _{\\theta} \\mathbb{E P}_{\\mathrm{G}}\\left\\{-\\mathbb{E P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)} \\operatorname{sim}(\\overbrace{\\left.\\mathrm{T}_{\\theta, 1}(\\mathrm{G}), \\mathrm{T}_{\\theta, 2}(\\mathrm{G})\\right)}^{\\text {positive pairs }}\\right.\\\\ &amp;+\\mathbb{E}_{\\mathrm{P}_{\\mathrm{A}_{1}}} \\log \\left(\\mathrm{EP}_{\\mathrm{G}^{\\prime}} \\times \\mathrm{P}_{\\mathrm{A}_{2}} \\exp \\left(\\operatorname{sim}(\\underbrace{\\left.\\mathrm{T}_{\\theta, 1}(\\mathrm{G}), \\mathrm{T}_{\\theta, 2}\\left(\\mathrm{G}^{\\prime}\\right)\\right)}_{\\text {negative pairs }})\\right)\\right\\}, \\end{aligned} =​θmin​EPG​LCL​(G,A1​, A2​,θ)θmin​EPG​⎩⎪⎨⎪⎧​−EP(A1​, A2​)​sim(Tθ,1​(G),Tθ,2​(G))​positive pairs ​+EPA1​​​log⎝⎜⎛​EPG′​×PA2​​exp⎝⎜⎛​sim(negative pairs Tθ,1​(G),Tθ,2​(G′))​​)⎠⎟⎞​⎭⎪⎬⎪⎫​,​ 作者定义InfoMin下的reward signal为：rInfoMin⁡(G,ϕ1ϕ2,θ)={1, if LCL(G,ϕ1,ϕ2,θ)&gt; threshold δ≪1, otherwise r_{\\operatorname{InfoMin}}\\left(\\mathrm{G}, \\phi_{1}\\right.\\left.\\phi_{2}, \\theta\\right)=\\left\\{\\begin{array}{cc} 1, &amp; \\text { if } \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right)&gt;\\text { threshold } \\\\ \\delta \\ll 1, &amp; \\text { otherwise } \\end{array}\\right.rInfoMin​(G,ϕ1​ϕ2​,θ)={1,δ≪1,​ if LCL​(G,ϕ1​,ϕ2​,θ)&gt; threshold otherwise ​。 InfoBN Principle 作者通过减少每个对比视图及其潜在表示之间的信息重叠来引入InfoBN： LInfoBN(G,ϕ1,ϕ2,θ,π)=−sim⁡(Tπ,ϕ1(G),Tθ,ϕ1(G))+log⁡(EPG′exp⁡(sim⁡(Tπ,ϕ1(G),Tθ,ϕ1(G′))))−sim⁡(Tπ,ϕ2(G),Tθ,ϕ2(G))+log⁡(EPG′exp⁡(sim⁡(Tπ,ϕ2(G),Tθ,ϕ2(G′))))\\begin{aligned} &amp;\\mathcal{L}_{\\mathrm{InfoBN}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta, \\pi\\right)= \\\\ &amp;-\\operatorname{sim}\\left(\\mathrm{T}_{\\pi, \\phi_{1}}(\\mathrm{G}), \\mathrm{T}_{\\theta, \\phi_{1}}(\\mathrm{G})\\right)+\\log \\left(\\mathbb{E}_{\\mathrm{P}_{\\mathrm{G}^{\\prime}}} \\exp \\left(\\operatorname{sim}\\left(\\mathrm{T}_{\\pi, \\phi_{1}}(\\mathrm{G}), \\mathrm{T}_{\\theta, \\phi_{1}}\\left(\\mathrm{G}^{\\prime}\\right)\\right)\\right)\\right) \\\\ &amp;-\\operatorname{sim}\\left(\\mathrm{T}_{\\pi, \\phi_{2}}(\\mathrm{G}), \\mathrm{T}_{\\theta, \\phi_{2}}(\\mathrm{G})\\right)+\\log \\left(\\mathbb{E}_{\\mathrm{P}_{\\mathrm{G}^{\\prime}}} \\exp \\left(\\operatorname{sim}\\left(\\mathrm{T}_{\\pi, \\phi_{2}}(\\mathrm{G}), \\mathrm{T}_{\\theta, \\phi_{2}}\\left(\\mathrm{G}^{\\prime}\\right)\\right)\\right)\\right) \\end{aligned} ​LInfoBN​(G,ϕ1​,ϕ2​,θ,π)=−sim(Tπ,ϕ1​​(G),Tθ,ϕ1​​(G))+log(EPG′​​exp(sim(Tπ,ϕ1​​(G),Tθ,ϕ1​​(G′))))−sim(Tπ,ϕ2​​(G),Tθ,ϕ2​​(G))+log(EPG′​​exp(sim(Tπ,ϕ2​​(G),Tθ,ϕ2​​(G′))))​ 因此，InfoBN的reward signal可以定义为rInfoBN⁡(G,ϕ1,ϕ2,θ,π)={1, if Lln⁡foBN(C,ϕ1,ϕ2,θ,π)&gt; threshold δ⇔1, otherwise r_{\\operatorname{InfoBN}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta, \\pi\\right)=\\left\\{\\begin{array}{cc} 1, &amp; \\text { if } \\mathcal{L}_{\\ln f o B N}\\left(C, \\phi_{1}, \\phi_{2}, \\theta, \\pi\\right)&gt;\\text { threshold } \\\\ \\delta \\Leftrightarrow 1, &amp; \\text { otherwise } \\end{array}\\right.rInfoBN​(G,ϕ1​,ϕ2​,θ,π)={1,δ⇔1,​ if LlnfoBN​(C,ϕ1​,ϕ2​,θ,π)&gt; threshold otherwise ​。 这样带有InfoBN-reward learned prior的GraphCL可以写成： min⁡θEPGLCL(G,ϕ1,ϕ2,θ), s.t. ϕ1,ϕ2∈arg⁡min⁡ϕ1′,ϕ2′EPGrInfoBN⁡(G,ϕ1′,ϕ2′,θ,π){LGen(G,ϕ1′)+LGen(G,ϕ2′)},π∈arg⁡min⁡π′EPGLInfoBN(G,ϕ1,ϕ2,θ,π′).\\begin{aligned} &amp;\\min _{\\theta} \\mathbb{E}_{P_{\\mathrm{G}}} \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right), \\\\ &amp;\\text { s.t. } \\phi_{1}, \\phi_{2} \\in \\arg \\min _{\\phi_{1}^{\\prime}, \\phi_{2}^{\\prime}} \\mathbb{E}_{\\mathrm{P}_{\\mathrm{G}}} r_{\\operatorname{InfoBN}}\\left(\\mathrm{G}, \\phi_{1}^{\\prime}, \\phi_{2}^{\\prime}, \\theta, \\pi\\right)\\left\\{\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{1}^{\\prime}\\right)\\right. \\\\ &amp;\\left.+\\mathcal{L}_{\\mathrm{Gen}}\\left(\\mathrm{G}, \\phi_{2}^{\\prime}\\right)\\right\\}, \\pi \\in \\arg \\min _{\\pi^{\\prime}} \\mathbb{E}_{\\mathrm{P}_{\\mathrm{G}}} \\mathcal{L}_{\\mathrm{InfoBN}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta, \\pi^{\\prime}\\right) . \\end{aligned} ​θmin​EPG​​LCL​(G,ϕ1​,ϕ2​,θ), s.t. ϕ1​,ϕ2​∈argϕ1′​,ϕ2′​min​EPG​​rInfoBN​(G,ϕ1′​,ϕ2′​,θ,π){LGen​(G,ϕ1′​)+LGen​(G,ϕ2′​)},π∈argπ′min​EPG​​LInfoBN​(G,ϕ1​,ϕ2​,θ,π′).​ Mixed 最后作者提出了一种混合模式，即将InfoMin和InfoBN整合到一起，这样reward signal定义为： rInfo⁡(Min⁡&amp;BN)(G,ϕ1,ϕ2,θ,π)={1,δ≪1, if γLCL(G,ϕ1,ϕ2,θ)+(1−γ)LlnfoBN (G,ϕ1,ϕ2,θ,π)&gt; threshold \\begin{aligned} &amp;r_{\\operatorname{Info}(\\operatorname{Min} \\&amp; \\mathrm{BN})}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta, \\pi\\right)=\\\\ &amp;\\left\\{\\begin{array}{c} 1, \\\\ \\delta \\ll 1, \\end{array} \\text { if } \\gamma \\mathcal{L}_{\\mathrm{CL}}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta\\right)+(1-\\gamma) \\mathcal{L}_{\\text {lnfoBN }}\\left(\\mathrm{G}, \\phi_{1}, \\phi_{2}, \\theta, \\pi\\right)&gt;\\right.\\text { threshold } \\end{aligned} ​rInfo(Min&amp;BN)​(G,ϕ1​,ϕ2​,θ,π)={1,δ≪1,​ if γLCL​(G,ϕ1​,ϕ2​,θ)+(1−γ)LlnfoBN ​(G,ϕ1​,ϕ2​,θ,π)&gt; threshold ​ 3. 实验 3.1 半监督 作者的方法和GraphCL相比，性能差不多，时好时坏。然后，不同原则在不同数据集上的表现也不一样。 3.2 迁移学习 3.3 分析型实验 Graph generation quality usually aligns with downstream performance. Molecule-specific generator alone does not significantly benefit molecular datasets. Tuning principled-reward hyper-parameters could strengthen the competitive performance even more. Generative graphs connections are sparse to capture patterns","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation","slug":"3 论文笔记/图学习/对比学习/24.SimGRACE A Simple Framework for Graph Contrastive Learning without Data Augmentation","date":"2022-06-10T11:26:03.000Z","updated":"2022-06-10T11:47:45.295Z","comments":true,"path":"36ea8234990f/","link":"","permalink":"http://rookieyin.github.io/36ea8234990f/","excerpt":"https://arxiv.org/pdf/2202.03104 https://github.com/junxia97/simgrace SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation，2022，WWW","text":"https://arxiv.org/pdf/2202.03104 https://github.com/junxia97/simgrace SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation，2022，WWW 1. 简介 1.1 摘要 Graph contrastive learning (GCL) has emerged as a dominant technique for graph representation learning which maximizes the mutual information between paired graph augmentations that share the same semantics. Unfortunately, it is difficult to preserve semantics well during augmentations in view of the diverse nature of graph data. Currently, data augmentations in GCL that are designed to preserve semantics broadly fall into three unsatisfactory ways. First, the augmentations can be manually picked per dataset by trial-and-errors. Second, the augmentations can be selected via cumber some search. Third, the augmentations can be obtained by introducing expensive domain-specific knowledge as guidance. All of these limit the efficiency and more general applicability of existing GCL methods. To circumvent these crucial issues, we propose a Simple framework for GRAph Contrastive lEarning, SimGRACE for brevity, which does not require data augmentations. Specifically, we take original graph as input and GNN model with its perturbed version as two encoders to obtain two correlated views for contrast. SimGRACE is inspired by the observation that graph data can preserve their semantics well during encoder perturbations while not requiring manual trial-and-errors, cumbersome search or expensive domain knowledge for augmentations selection. Also, we explain why SimGRACE can succeed. Furthermore, we devise adversarial training scheme, dubbed AT-SimGRACE, to enhance the robustness of graph contrastive learning and theoretically explain the reasons. Albeit simple, we show that SimGRACE can yield competitive or better performance compared with state-of-the-art methods in terms of generalizability, transferability and robustness, while enjoying unprecedented degree of flexibility and efficiency. 图对比学习最近成了图表示学习的主流方法之一，通过最大化两个共享相同语义信息的增强视角之间的互信息来学习节点嵌入。不幸的是，考虑到图数据存在天然的差异性，因此在图增强过程中很难保留语义信息。目前，GCL中的数据增强策略的选取方式主要有3种类型：第1种是通过人工进行试错式选取。第2种，通过繁琐的搜索来寻找最适合的增强策略。第3种是通过引入大量领域相关知识作为指导来选取。这些方法都限制了现有GCL方法的有效性和通用性。为了解决这个问题，我们提出了SimGRACE，一个不需要数据增强的GCL框架。具体来说，将原始图作为输入，GNN模型的2个perturbed版本作为两个编码器，用来获得两个视角进行对比。SIMGRACE的ideal来自于： the observation that graph data can preserve their semantics well during encoder perturbations，从而避免了前面提到的3种缺陷。当然，我们解释了为什么SIMGRACE能取得成功。另外，我们设计了对抗训练模式AT-SIMGRACE，来提高图对比学习的鲁棒性，并从理论上进行了解释。尽管方法简单，和SOTA方法相比，我们发现SimGRACE无论是性能、鲁棒性还是迁移能力都具有竞争力或更好表现，同时效率和灵活性都更高。 1.2 本文工作 背景： 现有GCL方法对于增强策略的选取方式主要有3种：人工选择、grid search或者引入领域相关信息作为指导。这些方式限制了GCL方法的性能和通用性。 注：这里作者说的不准，很多自适应增强或者自动增强方法，没有提到。（可能可以糊弄下大同行） 动机： 图增强的核心在于：在保留原始图语义信息的前提下，生成两个具有一定差异的增强视角。作者的ideal来自于：the observation that graph data can preserve their semantics well during encoder perturbations。那为什么不直接去掉图增强，用两个pertubated graph encoder的输出作为对比对象呢？（方法很讨巧） 本文工作： 1. 首先，作者提出了SimGRACE，一种不需要图增强的GCL框架，并给出理论解释；2. 其次，还设计了一个对抗训练版本AT-SimGRACE，进一步提高模型鲁棒性，并给出了理论解释。 2. 方法 模型细节 Encoder perturbation f(⋅;θ)f(\\cdot;\\theta)f(⋅;θ)表示GNN编码器，f(⋅;θ′)f(\\cdot;\\theta&#x27;)f(⋅;θ′)表示其扰动版本，hhh和h′h&#x27;h′表示两个编码器学习到的节点嵌入。扰动编码器参数计算方式如下： θl′=θl+η⋅Δθl;Δθl∼N(0,σl2)\\theta_{l}^{\\prime}=\\theta_{l}+\\eta \\cdot \\Delta \\theta_{l} ; \\quad \\Delta \\theta_{l} \\sim \\mathcal{N}\\left(0, \\sigma_{l}^{2}\\right) θl′​=θl​+η⋅Δθl​;Δθl​∼N(0,σl2​) 其实就是将原始GNN每一层的参数加上一个高斯噪声。 Projection head 这个属于常规操作，将节点嵌入用一个非线性函数映射到对比空间。 z=g( h),z′=g( h′)z=g(\\mathrm{~h}), z^{\\prime}=g\\left(\\mathrm{~h}^{\\prime}\\right) z=g( h),z′=g( h′) Contrastive loss 这个也很常规，和其他GCL方法没什么区别： ℓn=−log⁡exp⁡(sim⁡(zn,zn′))/τ)∑n′=1,n′≠nNexp⁡(sim⁡(zn,zn′)/τ)\\ell_{n}=-\\log \\frac{\\left.\\exp \\left(\\operatorname{sim}\\left(z_{n}, z_{n}^{\\prime}\\right)\\right) / \\tau\\right)}{\\sum_{n^{\\prime}=1, n^{\\prime} \\neq n}^{N} \\exp \\left(\\operatorname{sim}\\left(z_{n}, z_{n^{\\prime}}\\right) / \\tau\\right)} ℓn​=−log∑n′=1,n′​=nN​exp(sim(zn​,zn′​)/τ)exp(sim(zn​,zn′​))/τ)​ 理论证明 作者基于“ Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere”这篇文章，尝试解释SIMGRACE为什么有效。在这篇文章里，作者给出了两个评价对比学习获取到的节点嵌入质量的指标：alignment和uniformity。 alignment：正样本对之间的距离 ℓalign (f;α)≜E(x,y)∼ppos [∥f(x)−f(y)∥2α],α&gt;0\\ell_{\\text {align }}(f ; \\alpha) \\triangleq \\underset{(x, y) \\sim p_{\\text {pos }}}{\\mathbb{E}}\\left[\\|f(x)-f(y)\\|_{2}^{\\alpha}\\right], \\quad \\alpha&gt;0 ℓalign ​(f;α)≜(x,y)∼ppos ​E​[∥f(x)−f(y)∥2α​],α&gt;0 其中pposp_{pos}ppos​表示所有的正样本对。这个指标其实适合对比学习的目标相对应的，即正样本在嵌入空间中的距离应该很近。 在SimGRACE里面，alignment计算方式可以转换成： ℓalign (f;α)≜Ex∼pdata [∥f(x;θ)−f(x;θ′)∥2α],α&gt;0\\ell_{\\text {align }}(f ; \\alpha) \\triangleq \\mathbb{E}_{x \\sim p_{\\text {data }}}\\left[\\left\\|f(x ; \\theta)-f\\left(x ; \\theta^{\\prime}\\right)\\right\\|_{2}^{\\alpha}\\right], \\quad \\alpha&gt;0 ℓalign ​(f;α)≜Ex∼pdata ​​[∥f(x;θ)−f(x;θ′)∥2α​],α&gt;0 其中pdatap_{data}pdata​表示数据分布，其实就是输入图的所有节点。 uniform： the logarithm of the average pairwise Gaussian potential ℓuniform (f;α)≜log⁡Ex,yi.i.d.pdata [e−t∥f(x;θ)−f(y;θ)∥22]\\ell_{\\text {uniform }}(f ; \\alpha) \\triangleq \\log \\underset{x, y^{i . i . d .} p_{\\text {data }}}{\\mathbb{E}}\\left[e^{-t\\|f(x ; \\theta)-f(y ; \\theta)\\|_{2}^{2}}\\right] ℓuniform ​(f;α)≜logx,yi.i.d.pdata ​E​[e−t∥f(x;θ)−f(y;θ)∥22​] uniform对应于对比学习的另一个目标：随机样本的嵌入应该分散在嵌入空间中。 作者在训练过程中每2个epochs，记录下lalignl_{align}lalign​和luniforml_{uniform}luniform​值。作者对比了SimGRACE、GraphCL和MoCL三种方法，如下图所示： 从上图可以看出，GraphCL的alignment和uniformity值要大于SimGRACE和MoCL，这说明他不能让正样本对保持比较近的距离（因为图增强破坏了原始图的语义信息）。相反，MoCL通过引入领域知识作为指导来选取增强策略，可以在增强过程中保留语义信息，因此alignment指标下，表现较好。但是在uniformity指标下，其表现不如SimGRACE，因此最终的表现也不如SimGRACE。 AT-SimGRACE 在GraphCL中，其作者提到过它们的框架能够提高模型鲁棒性，但是并没有进行解释。这里作者希望利用对抗训练提升SimGRACE的对抗攻击鲁棒性。 一个通用的AT框架公式如下： min⁡θL′(θ), where L′(θ)=1n∑i=1nmax⁡∥xi′−xi∥p≤ϵℓi′(f(xi′;θ),yi), \\min _{\\theta} \\mathcal{L}^{\\prime}(\\theta), \\quad \\text { where } \\quad \\mathcal{L}^{\\prime}(\\theta)=\\frac{1}{n} \\sum_{i=1}^{n} \\max _{\\|\\mathrm{x}_{i}^{\\prime}-\\mathbf{x}_{i} \\|_{p} \\leq \\epsilon} \\ell_{i}^{\\prime}\\left(f\\left(\\mathrm{x}_{i}^{\\prime} ; \\theta\\right), y_{i}\\right) \\text {, } θmin​L′(θ), where L′(θ)=n1​i=1∑n​∥xi′​−xi​∥p​≤ϵmax​ℓi′​(f(xi′​;θ),yi​), 但是这个框架不能直接用于GCL，存在以下问题： AT需要标签信息，但是GCL中没有 对数据集中的每个图都进行perturbation，计算量过大，这个问题在GROC已经被指出。 为了解决第一个问题，作者用对比损失代替监督分类中的交叉熵损失。 为了解决第2个问题，作者对encoder进行对抗扰动，而不是图数据。具体来说，假设Θ\\ThetaΘ表示GNNs的权重空间，对于任意的www和任意正数ϵ\\epsilonϵ，可定义如下norm ball： R(w;ϵ):={θ∈Θ:∥θ−w∥≤ϵ}\\mathrm{R}(\\mathrm{w} ; \\epsilon):=\\{\\theta \\in \\Theta:\\|\\theta-\\mathrm{w}\\| \\leq \\epsilon\\} R(w;ϵ):={θ∈Θ:∥θ−w∥≤ϵ} 这样AT-SimGRACE的优化目标定义为： min⁡θL(θ+Δ), where L(θ+Δ)=1M∑i=1Mmax⁡Δ∈R(0;ϵ)ℓi(f(Gi;θ+Δ),f(Gi;θ))\\min _{\\theta} \\mathcal{L}(\\theta+\\Delta) \\text {, } \\\\ where\\ \\mathcal{L}(\\theta+\\Delta)=\\frac{1}{M} \\sum_{i=1}^{M} \\max _{\\Delta \\in \\mathrm{R}(0 ; \\epsilon)} \\ell_{i}\\left(f\\left(\\mathcal{G}_{i} ; \\theta+\\Delta\\right), f\\left(\\mathcal{G}_{i} ; \\theta\\right)\\right) θmin​L(θ+Δ), where L(θ+Δ)=M1​i=1∑M​Δ∈R(0;ϵ)max​ℓi​(f(Gi​;θ+Δ),f(Gi​;θ)) 理论证明 基础1：大部分人都认同“flatter loss landscape can bring robustness”。 因此要证明AT-SimGRACE能提高鲁棒性，只需要证明它能带来跟平滑的loss变化即可。 基础:2：已经有工作证明了loss landscape和PAC-Bayes之间存在关联。 E{Gi}i=1M,Δ[L(θ+Δ)]≤EΔ[L(θ+Δ)]+4KL(θ+Δ∥P)+ln⁡2MδM\\mathbb{E}_{\\left\\{\\mathcal{G}_{i}\\right\\}_{i=1}^{M}, \\Delta}[\\mathcal{L}(\\theta+\\Delta)] \\leq \\mathbb{E}_{\\Delta}[\\mathcal{L}(\\theta+\\Delta)]+4 \\sqrt{\\frac{K L(\\theta+\\Delta \\| P)+\\ln \\frac{2 M}{\\delta}}{M}} E{Gi​}i=1M​,Δ​[L(θ+Δ)]≤EΔ​[L(θ+Δ)]+4MKL(θ+Δ∥P)+lnδ2M​​​ E{Gi}i=1M,Δ[L(θ+Δ)]≤L(θ)+{EΔ[L(θ+Δ)]−L(θ)}⏟Expected sharpness +41M(12α+ln⁡2Mδ)\\begin{aligned} \\mathbb{E}_{\\left\\{\\mathcal{G}_{i}\\right\\}_{i=1}^{M}, \\Delta}[\\mathcal{L}(\\theta+\\Delta)] \\leq \\mathcal{L}(\\theta) &amp;+\\underbrace{\\left\\{\\mathbb{E}_{\\Delta}[\\mathcal{L}(\\theta+\\Delta)]-\\mathcal{L}(\\theta)\\right\\}}_{\\text {Expected sharpness }} \\\\ &amp;+4 \\sqrt{\\frac{1}{M}\\left(\\frac{1}{2 \\alpha}+\\ln \\frac{2 M}{\\delta}\\right)} \\end{aligned} E{Gi​}i=1M​,Δ​[L(θ+Δ)]≤L(θ)​+Expected sharpness {EΔ​[L(θ+Δ)]−L(θ)}​​+4M1​(2α1​+lnδ2M​)​​ 最终得出一个结论：AT-SimGRACE可以优化sharpness of loss landscape的最差情况，即减小maxΔ[L(θ+Δ)]−L(θ)max_\\Delta[L(\\theta+\\Delta)]-L(\\theta)maxΔ​[L(θ+Δ)]−L(θ)的上界。 这块涉及到的数学公式，我也不太懂，可以大概了解下作者的证明思路：首先把鲁棒性问题转化成loss平滑性，然后用PAC-Bayes框架算出AT-SimGRACE的loss平滑性优于原来的。 实验 主要关注5个问题： 通用性：无监督、半监督设定下，模型在下游任务的表现是否优于竞争对手？ 2. 迁移性：预训练模式下的Sim-GRACE是否优于竞争对手？ 鲁棒性：Sim-GRACE在不同对抗攻击下是否优于竞争对手？ 性能：时间、空间占用情况是否优于对手？ 超参敏感性：扰动参数、epoch和batch大小等等。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/25.RoSA A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning","date":"2022-06-10T11:26:03.000Z","updated":"2022-06-10T11:45:45.836Z","comments":true,"path":"5ac7bfb92e9a/","link":"","permalink":"http://rookieyin.github.io/5ac7bfb92e9a/","excerpt":"https://arxiv.org/pdf/2204.13846 https://github.com/zhuyun97/rosa RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning，2022，IJCAI","text":"https://arxiv.org/pdf/2204.13846 https://github.com/zhuyun97/rosa RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning，2022，IJCAI 1. 简介 1.1 摘要 Graph contrastive learning has gained significant progress recently. However, existing works have rarely explored non-aligned node-node contrasting. In this paper, we propose a novel graph contrastive learning method named RoSA that focuses on utilizing non-aligned augmented views for node-level representation learning. First, we leverage the earth mover’s distance to model the minimum effort to transform the distribution of one view to the other as our contrastive objective, which does not require alignment between views. Then we introduce adversarial training as an auxiliary method to increase sampling diversity and enhance the robustness of our model. Experimental results show that RoSA outperforms a series of graph contrastive learning frameworks on homophilous, non-homophilous and dynamic graphs, which validates the effectiveness of our work. To the best of our awareness, RoSA is the first work focuses on the non-aligned node-node graph contrastive learning problem. 1.2 本文工作 背景： 有研究指出对于node-level任务，使用node-node对比，获得的收益最大。 动机： 现有node-node GCL方法基本都是对比aligned views 一方面，这限制了模型的灵活性和视角的多样性； 另一方面，某些场景下视角必须是non-aligned的，比如随机游走采样和时空网络中。 什么是aligned view和non-aligned view，下图展示了几个例子： aligned view：两个视角中包含的节点集合是一样的，可能在结构和节点属性上有所差异； 对应于丢边或者mask feature等增强策略 non-aligned view：两个视角中包含的节点集合不同 对应丢节点等增强策略 为什么现有GCL中没有考虑non-aligned view？存在2个难点： 对于N-N类型GCL，如果对比non-aligned view，现有GCL框架就会存在一些问题 对于某个节点i，可能在视角1中存在，但是视角2中不存在。这导致完全没法对比这两个视角，因为节点i不存在正样本。 正负样本间距离的计算也不能采用传统的余弦相似度。 使用什么样的增强策略来生成non-aligned views？ 需要最大化视角差异的同时，不破坏原有语义信息 本文工作： 作者提出了RoSA框架，解决了前文提到的non-aligned下GCL存在的两个挑战。 2. 方法 整个框架比较核心的点有3个：生成对比视角、视角对比和对抗训练，下面详细介绍下这3块内容。 生成图视角 一个好的对比视角具有这样的特性：存在差异的同时，保留原始语义信息。 本文作者利用随机游走来生成对比视角。具体来说，对于每个central节点vvv，给定step size sss，restart概率α\\alphaα,利用随机游走生成一个subgraph。每个节点游走2次，这样就能生成2个view。 这种策略下，不仅可以保留原始语义，正负样本也能很好确定： 对于节点v，利用随机游走生成了两个子图G1v,G2v\\mathcal G_1^v,\\mathcal G_2^vG1v​,G2v​，这两个子图以vvv为中心节点的子图就是一个正样本对。 以v节点为中心的子图和以其他所有节点为中心的子图，构成所有的负样本对。 对比损失 得到unaligned view和正负样本后，最后一个核心问题就是对比损失的定义。因为两个视角是unaligned，传统的基于余弦相似度的对比损失就没办法用了。本文作者提出了一种基于EMD算法的对比目标g-EMD，这也是本文最核心的创新点。 EMD是一种度量两个分布之间相似度的算法，用于图像相似度度量，早期时候多用于图像检索。 EMD，earth mover‘s distance，从字面理解就是，把一个分布搬运到另一个分布的代价。对应到本文，可以理解成把一个子图搬运到另一个子图的代价。g-EMD的公式定义如下： min⁡Γ∑iM∑jNDijΓij s.t. Γij≥0,i=1,2,…,M,j=1,2,…,N∑iMΓij=rj,j=1,2,…,N∑jNΓij=ti,i=1,2,…,M\\begin{gathered} \\min _{\\Gamma} \\sum_{i}^{M} \\sum_{j}^{N} \\mathbf{D}_{i j} \\boldsymbol{\\Gamma}_{i j} \\\\ \\text { s.t. } \\boldsymbol{\\Gamma}_{i j} \\geq 0, i=1,2, \\ldots, M, j=1,2, \\ldots, N \\\\ \\sum_{i}^{M} \\boldsymbol{\\Gamma}_{i j}=r_{j}, j=1,2, \\ldots, N \\\\ \\sum_{j}^{N} \\boldsymbol{\\Gamma}_{i j}=t_{i}, i=1,2, \\ldots, M \\end{gathered} Γmin​i∑M​j∑N​Dij​Γij​ s.t. Γij​≥0,i=1,2,…,M,j=1,2,…,Ni∑M​Γij​=rj​,j=1,2,…,Nj∑N​Γij​=ti​,i=1,2,…,M​ 其中D\\mathbf DD和Γ\\GammaΓ分别是搬运代价矩阵和权重矩阵。下面详细介绍下这两个矩阵： 假设X∈RM×d\\mathbf X\\in\\mathbb R^{M\\times d}X∈RM×d和Y∈RN×d\\mathbf Y \\in \\mathbb R^{N\\times d}Y∈RN×d表示两个增强视角，其实就是两个随机游走生成的子图，两个子图分别包含M个节点和N个节点 xi∈Rdx_i\\in \\mathbb R^dxi​∈Rd和yi∈Rdy_i\\in \\mathbb R^dyi​∈Rd表示连个子图中的节点嵌入。 对于代价矩阵D\\mathbf DD，作者定义了连个方面的代价 维度1：节点的相似度，将xi\\mathbf {x_i}xi​搬运到yj\\mathbf {y_j}yj​的代价，定义为： Dij=1−xiTyj∥xi∥∥yj∥\\mathbf{D}_{i j}=1-\\frac{\\boldsymbol{x}_{i}^{T} \\boldsymbol{y}_{j}}{\\left\\|\\boldsymbol{x}_{i}\\right\\|\\left\\|\\boldsymbol{y}_{j}\\right\\|} Dij​=1−∥xi​∥∥∥∥​yj​∥∥∥​xiT​yj​​ ​ 其实就是1减去节点相似度，两个节点越相似，搬运代价越低。 维度2：拓扑距离，即两个节点之间的跳数，表示为Ψ∈RM×N\\Psi \\in \\mathbb{R}^{M \\times N}Ψ∈RM×N。其思想在于，两个节点在空间上距离越近，越相似，搬运代价越低。 Si,j=S(Ψi,j)=11+e−Ψi,j/τ\\mathbf{S}_{i, j}=S\\left(\\Psi_{i, j}\\right)=\\frac{1}{1+e^{-\\Psi_{i, j} / \\tau}} Si,j​=S(Ψi,j​)=1+e−Ψi,j​/τ1​ 这样最终拓扑距离的范围控制在S∈[0.5,1]M×N\\mathbf{S} \\in[0.5,1]^{M \\times N}S∈[0.5,1]M×N。 这样，最终的距离矩阵定义为 D=D∘S\\mathbf{D}=\\mathrm{D} \\circ \\mathrm{S} D=D∘S 对于Γ\\mathbf \\GammaΓ矩阵，需要依赖于两个向量t∈RM\\mathbf t\\in\\mathbb R^Mt∈RM和r∈RN\\mathbf r\\in\\mathbb R^Nr∈RN，计算方式如下： Π(t,r)={Γ∈RM×N∣Γ1M=t,ΓT1N=r}\\Pi(\\mathbf{t}, \\mathbf{r})=\\left\\{\\boldsymbol{\\Gamma} \\in \\mathbb{R}^{M \\times N} \\mid \\boldsymbol{\\Gamma} \\mathbf{1}_{M}=\\mathbf{t}, \\boldsymbol{\\Gamma}^{T} \\mathbf{1}_{N}=\\mathbf{r}\\right\\} Π(t,r)={Γ∈RM×N∣Γ1M​=t,ΓT1N​=r} ​ 这里的向量t和r可以分别理解成视角1中每个节点的搬运概率和视角2中每个节点的接收概率，它们的计算法如下： ti=max⁡{xiT⋅∑j=1NyjN,0}rj=max⁡{yjT⋅∑i=1MxiM,0}\\begin{aligned} \\boldsymbol{t}_{i} &amp;=\\max \\left\\{\\boldsymbol{x}_{i}^{T} \\cdot \\frac{\\sum_{j=1}^{N} \\boldsymbol{y}_{j}}{N}, 0\\right\\} \\\\ \\boldsymbol{r}_{j} &amp;=\\max \\left\\{\\boldsymbol{y}_{j}^{T} \\cdot \\frac{\\sum_{i=1}^{M} \\boldsymbol{x}_{i}}{M}, 0\\right\\} \\end{aligned} ti​rj​​=max{xiT​⋅N∑j=1N​yj​​,0}=max{yjT​⋅M∑i=1M​xi​​,0}​ ​ 其实就是两个节点越相似，权重越大。这里还有一点内容没介绍，就是Γ\\GammaΓ的具体计算方法，上面那个公式其实是给了一个方程 组，需要求解Γ\\GammaΓ矩阵，感兴趣可以自己去看原文。 得到g-EMD的具体定义后，对比损失定义如下： ℓ(Z1(i),Z2(i))=−log⁡(es(Z1(i),Z2(i)))/τ∑k=1Nes(Z1(i),Z2(k)))/τ+∑k=1N1[k≠i]es(Z1(i),Z1(k)))/τ)\\begin{gathered} \\quad \\ell\\left(\\mathbf{Z}_{1}^{(i)}, \\mathbf{Z}_{2}^{(i)}\\right)= \\\\ -\\log \\left(\\frac{e^{\\left.\\mathrm{s}\\left(\\mathbf{Z}_{1}^{(i)}, \\mathbf{Z}_{2}^{(i)}\\right)\\right) / \\tau}}{\\sum_{k=1}^{N} e^{\\left.\\mathrm{s}\\left(\\mathbf{Z}_{1}^{(i)}, \\mathbf{Z}_{2}^{(k)}\\right)\\right) / \\tau}+\\sum_{k=1}^{N} \\mathbf{1}_{[k \\neq i]} e^{\\left.\\mathrm{s}\\left(\\mathbf{Z}_{1}^{(i)}, \\mathbf{Z}_{1}^{(k)}\\right)\\right) / \\tau}}\\right) \\end{gathered} ℓ(Z1(i)​,Z2(i)​)=−log⎝⎜⎛​∑k=1N​es(Z1(i)​,Z2(k)​))/τ+∑k=1N​1[k​=i]​es(Z1(i)​,Z1(k)​))/τes(Z1(i)​,Z2(i)​))/τ​⎠⎟⎞​​ J=12N∑i=1N[ℓ(Z1(i),Z2(i))+ℓ(Z2(i),Z1(i))]\\mathcal{J}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left[\\ell\\left(\\mathbf{Z}_{1}^{(i)}, \\mathbf{Z}_{2}^{(i)}\\right)+\\ell\\left(\\mathbf{Z}_{2}^{(i)}, \\mathbf{Z}_{1}^{(i)}\\right)\\right] J=2N1​i=1∑N​[ℓ(Z1(i)​,Z2(i)​)+ℓ(Z2(i)​,Z1(i)​)] 整体格式和传统GCL方法没什么区别，唯一一点区别就是函数s(⋅)s(\\cdot)s(⋅)，以前的方法都是采用余弦相似度函数，这里改成了g-EMD函数。 对抗训练 这个没什么好说的，感觉是作者拉过来凑数的，让工作显得更丰富一些： min⁡θ,ωE(X1(i),X2(i))∼D[1M∑t=0M−1max⁡δt∈ItJ(X1(i)+δt,X2(i))]\\min _{\\theta, \\omega} \\mathbb{E}_{\\left(\\mathbf{X}_{1}^{(i)}, \\mathbf{X}_{2}^{(i)}\\right) \\sim \\mathbb{D}}\\left[\\frac{1}{M} \\sum_{t=0}^{M-1} \\max _{\\delta_{t} \\in \\mathcal{I}_{t}} \\mathcal{J}\\left(\\mathbf{X}_{1}^{(i)}+\\delta_{t}, \\mathbf{X}_{2}^{(i)}\\right)\\right] θ,ωmin​E(X1(i)​,X2(i)​)∼D​[M1​t=0∑M−1​δt​∈It​max​J(X1(i)​+δt​,X2(i)​)] 这个也不是本文的重点，这里就不细说了。 3. 实验 同构图 异构图 大规模图 动态图 消融实验 可视化1 可视化2","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Augmentations in Graph Contrastive Learning: Current Methodological Flaws & Towards Better Practices","slug":"3 论文笔记/图学习/对比学习/26.Augmentations in Graph Contrastive Learning Current Methodological Flaws & Towards Better Practices","date":"2022-06-10T11:26:03.000Z","updated":"2022-06-10T11:45:36.354Z","comments":true,"path":"9409fcf95bcf/","link":"","permalink":"http://rookieyin.github.io/9409fcf95bcf/","excerpt":"https://dl.acm.org/doi/pdf/10.1145/3485447.3512200 Augmentations in Graph Contrastive Learning: Current Methodological Flaws &amp; Towards Better Practices ，2022，WWW 总结： 第一次看到这种全是实验的文章，个人觉得这篇文章有两个点比较有启发性： 除了accuracy 之外，我们需要关注一些其他指标，比如affinity等，帮助我们更好的评价一个模型。 context-aware augmentation，之前一直没有关注过这一点，结合领域知识设计一个增强策略。 不过这篇文章，也有一些点是有待商榷的： 文章中实验的通用性，这篇文章作者只关注了图分类数据集，然后使用的DAGAs策略也比较有限 作者虽然提到了context-aware augmentation，但是没有提出更具体的设计方案。使用的两个case也比较特殊。","text":"https://dl.acm.org/doi/pdf/10.1145/3485447.3512200 Augmentations in Graph Contrastive Learning: Current Methodological Flaws &amp; Towards Better Practices ，2022，WWW 总结： 第一次看到这种全是实验的文章，个人觉得这篇文章有两个点比较有启发性： 除了accuracy 之外，我们需要关注一些其他指标，比如affinity等，帮助我们更好的评价一个模型。 context-aware augmentation，之前一直没有关注过这一点，结合领域知识设计一个增强策略。 不过这篇文章，也有一些点是有待商榷的： 文章中实验的通用性，这篇文章作者只关注了图分类数据集，然后使用的DAGAs策略也比较有限 作者虽然提到了context-aware augmentation，但是没有提出更具体的设计方案。使用的两个case也比较特殊。 1. 简介 1.1 摘要 Graph classification has a wide range of applications in bioinformatics, social sciences, automated fake news detection, web document classification, and more. In many practical scenarios, including webscale applications, labels are scarce or hard to obtain. Unsupervised learning is thus a natural paradigm for these settings, but its performance often lags behind that of supervised learning. However, recently contrastive learning (CL) has enabled unsupervised computer vision models to perform comparably to supervised models. Theoretical and empirical works analyzing visual CL frameworks find that leveraging large datasets and task relevant augmentations is essential for CL framework success. Interestingly, graph CL frameworks report high performance while using orders of magnitude smaller data, and employing domain-agnostic graph augmentations (DAGAs) that can corrupt task relevant information. Motivated by these discrepancies, we seek to determine why existing graph CL frameworks continue to perform well, and identify flawed practices in graph data augmentation and popular graph CL evaluation protocols. We find that DAGA can destroy task-relevant information and harm the model’s ability to learn discriminative representations. We also show that on small benchmark datasets, the inductive bias of graph neural networks can significantly compensate for these limitations, while on larger graph classification tasks commonly-used DAGAs perform poorly. Based on our findings, we propose better practices and sanity checks for future research and applications, including adhering to principles in visual CL when designing context-aware graph augmentations. For example, in graph-based document classification, which can be used for better web search, we show task-relevant augmentations improve accuracy by up to 20%. 图分类被广泛用于生物、社交科学、假新闻检测、网络文档分类等跟个领域。在许多实际应用中，包括网络级应用，标签很稀少并且难以获取。因此，在这些场景下，无监督学习是一种很好的模式，但是其性能往往落后于you监督学习。然而，最近对比学习让CV中的无监督模型达到了可以媲美有监督模型的性能。在一些研究visual CL框架的理论和实验性工作中发现，利用大规模数据集，并且使用任务相关的增强手段，对于CL框架能否取得成功，起着非常关键的作用。有趣的是，尽管使用相对较小的数据集和domain-agnostic 图增强手段，graph CL框架依旧能取得很高的性能。 基于这个发现，我们尝试研究为什么现有的graph CL框架依然能表现优异，以及现有图数据增强和流行图CL评估协议在实际应用中的缺陷。我们发现DAGA会破坏任务相关信息，并损害模型学习高质量表示的能力。我们还发现，在小型标准数据集上，GNNs的归纳偏置可以显著弥补这些限制，但是在更大规模数据集的图分类任务中，常用的DAGAs表现不佳。基于以上发现，我们为未来的研究和实践提出了更好的practices and sanity checks，包括遵循visual CL中的增强原则，即设计context-aware图增强。例如，在基于图的文档分类中，我们发现使用task-relevant增强，准确率可以提高超过20%。 1.2 本文工作 背景： 在很多图分类任务场景下，标签稀少并且难以获得，因此这些场景中无监督学习方法称为一种更好选择。但是无监督方法往往性能低于有监督模型。不过，近年来出现的CL方法，可以让无监督模型取得和有监督模型相媲美的性能。 动机： visual CL框架中，一些理论和实验工作表明，VCL有两个关键性principles： training on large, diverse datasets leveraging strong, task-relevant augmentaions 现有的GCL框架并没有遵循这两个原则，它们不仅使用相对小的、binary classification数据集，还通常依赖于domain-agnostic graph augmentations(DAGAs)。但是这些GCL框架依旧取得了很好的性能。这是为什么呢？ 本文工作： 作者提出了一些策略，可以帮助实验人员观察到除了精确度之外的一些现象，从而更好的评价他们的模型性能。并且通过实验发现，对于GCL，VCL中的那两条principles不仅重要，而且是必要的，可以显著提高模型性能。作者的核心工作主要有下面两点： Analysis of limitations in domain-agnostic augmentations 分析了现有主流GCL使用的DAGAs的缺陷 Identification of methodological flaws &amp; better practices 提出了一些评价GCL模型的其他指标，并总结了一些GCL在实际应用中需要注意的点 Case studies with strong augmentations 通过两个case study，说明如何设计context-aware augmentations，以及它的重要性 2. 具体内容 2.1 现有GCL中augmentation和evaluation的缺陷 发现1：现有的DAGAs增强策略会破坏任务相关信息 发现2：现有的GCL评价策略有缺陷，会导致模型学习到弱判别力表示 发现3：为什么GCL框架有缺陷，但是依旧性能比较好？因为randomly-initialized GNNs具有很强的归纳偏置，可以缓解这一缺陷带来的问题。 destroying task-relevant information 对于增强策略的优劣，可以用affinity和diversity两个指标来评价。 affinity：密切性，增强后的图应当和原始图有着类似的分布，并共享任务相关的语义信息。简单来说就是要保留原始语义。 diversity：差异性，增强图要和原始图之间存在差异，避免平凡解。 也就是我们常说的：存在差异的同时保留语义。 一个好的增强策略，这两个指标都应该是最优的。 现有的增强策略，比如子图、丢节点、边扰动等等，差异性是够的，核心问题是affinity是不是足够优秀？ 作者进行了这样一个实验：先用原始数据训练好一个PNA网络，然后使用20%图大小的random node/subgraph dropping生成增强图，最后对比PNA网络在原始图和增强图上的性能表现。实验结果如下表所示： 可以看到，模型在增强图上的分类精确度大幅降低，说明DAGAs破坏了原始图的语义信息。 weakly discriminative representations Limitation1指出，DAGAs会破坏任务相关的语义信息，这个缺陷会衍生出另外一个缺陷：导致错误的positive pairs，因为语义信息被破坏，正样本对中的两个样本可能不再共享task-relevant信息。 也就是说，两个语义上不相似的样本的表示之间的相似度会被扩大（因为它们被误认为是正样本对了），这可能导致最终学习到的intra-class样本间的相似度要低于inter-class样本间的相似度。 为了验证这一猜想，作者进行了如下实验：分别使用GraphCL、InfoGraph和MVGRL学习整个数据集的样本表示，然后计算样本对之间的余弦相似度。实验结果如下图所示： 作者这里用的应该是二分类数据集，对角线上表示相同类别样本间的相似度。可以看到使用difusion-based和subgraph采样的MVGRL和InfoGraph，产生false positive pairs的概率要小于使用DAGAs的GraphCL。反映在图上就是，对角线上两个block的颜色要浅于非对角线上的两个block。 strong inductive bias 在前文L2的实验中，作者发现没有训练的GNNs（L2中图片最左边）已经具有比较好的分类性能了，这是因为GNNs具有很强的归纳偏置能力。作者做了一个简单实验，将GCL模型和随机模型的性能进行比较。 总结 作者通过以上所有实验，总结了GCL在实际应用中需要注意的几点： 使用DAGA会破坏task-relevant信息，应该设计context-aware graph augmentation 在小规模图数据集上，随机模型具有很强的归纳偏置，做实验时应当将其作为baseline 使用negative-sample GCL框架时，不该用small, binary graph datasets 除了accuracy number之外，应当有更多的评价手段，比如affinity、diversity和cosine similarity。 Context-aware augmentation 作者通过两个case study来说明如何结合领域知识来设计context-aware augmentations。 Case Study 1：Document Classification 第一个任务是文档分类。 图构建方式：co-occurrence graph，节点表示单词，两个单词出现在同一个窗口（大小为2或者4）则在两者之间添加一条边。 DAGA增强： node, edge, and subgraph dropping at {5%, 10%, 20%} Context-Aware增强：使用NLP中现有的增强手段， synonym replacement, random word insertion, random word swapping and random word deletion。 Case Study 2：Super-pixel Classification 第二个任务是super-pixel图像分类。 DANAs增强：随机丢节点20% Context-Aware增强： select random colorizing as the context-aware augmentation","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"ES概述","slug":"2 后端/其他/5 ES概述","date":"2022-05-28T05:43:55.000Z","updated":"2022-06-12T14:19:05.017Z","comments":true,"path":"66cb4eac165c/","link":"","permalink":"http://rookieyin.github.io/66cb4eac165c/","excerpt":"文章转自这里","text":"文章转自这里 基本概念 Cluster：包含多个Node的集群。 Node：集群服务单元。 Index：一个ES索引包含一个或多个物理分片，它只是这些分片的逻辑命名空间。 Type：一个index的不同分类，6.x后只能配置一个type，以后将移除。 Document：最基础的可被索引的数据单元，如一个JSON串。 Shards：一个分片是一个底层的工作单元，它仅保存全部数据中的一部分，它是一个Lucence实例 (一个lucene索引最大包含2,147,483,519 (= Integer.MAX_VALUE-128)个文档数量)。 Replicas：分片备份，用于保障数据安全与分担检索压力。 ES依赖一个重要的组件Lucene，关于数据结构的优化通常来说是对Lucene的优化，它是集群的一个存储于检索工作单元，结构如下图： 在Lucene中，分为索引(录入)与检索(查询)两部分，索引部分包含 分词器、过滤器、字符映射器等，检索部分包含 查询解析器 等。 一个Lucene索引包含多个segments，一个segment包含多个文档，每个文档包含多个字段，每个字段经过分词后形成一个或多个term。 通过Luke工具查看ES的lucene文件如下，主要增加了_id和_source字段: Lucene索引实现 Lucene 索引文件结构主要的分为：词典、倒排表、正向文件、DocValues等，如下图: Lucene 随机三次磁盘读取比较耗时。其中.fdt文件保存数据值损耗空间大，.tim和.doc则需要SSD存储提高随机读写性能。 另外一个比较消耗性能的是打分流程，不需要则可屏蔽。 ES索引与检索分片 ES中一个索引由一个或多个lucene索引构成，一个lucene索引由一个或多个segment构成，其中segment是最小的检索域。 数据具体被存储到哪个分片上： 1shard = hash(routing) % number_of_primary_shards 默认情况下 routing参数是文档ID (murmurhash3),可通过 URL中的 _routing 参数指定数据分布在同一个分片中，index和search的时候都需要一致才能找到数据。 如果能明确根据_routing进行数据分区，则可减少分片的检索工作，以提高性能。 ES工作原理 ES写数据工作原理 客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。 coordinating node 对 document 进行路由，将请求转发给对应的 node（所有的primary shard）。 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。 coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。 ES读数据工作原理 可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。 客户端发送请求到任意一个 node，成为 coordinate node。 coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。 接收请求的 node 返回 document 给 coordinate node。 coordinate node 返回 document 给客户端。 ES搜索数据工作原理 客户端发送请求到一个 coordinate node。 协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。 query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。 fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。 写请求是写入 primary shard，然后同步给所有的 replica shard； 读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。 ES底层原理 ES写数据底层原理 先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。 如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中 但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。 每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file 这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。 但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作 如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。 操作系统里面，磁盘文件其实都有一个东西，叫做 os cache，即操作系统缓存 就是说数据写入磁盘文件之前，会先进入 os cache，先进入操作系统级别的一个内存缓存中去。只要 buffer中的数据被 refresh 操作刷入 os cache中，这个数据就可以被搜索到了。 为什么叫 es 是准实时的？ NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的。 可以通过 es 的 restful api 或者 java api，手动执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 os cache中，让数据立马就可以被搜索到。 只要数据被输入 os cache 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。 重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 buffer 数据写入一个又一个新的 segment file 中去，每次 refresh 完 buffer 清空，translog 保留。 随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 commit 操作。 commit 操作发生第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。 然后，将一个 commit point写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到磁盘文件中去。 最后清空 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。 这个 commit 操作叫做 flush。默认 30 分钟自动执行一次 flush，但如果 translog 过大，也会触发 flush。 flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。 translog 日志文件的作用是什么？ 执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中 无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 translog 中 一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。 translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去 所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会丢失 5 秒钟的数据。 但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。 其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的数据丢失。 总结一下，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。 每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。 ES删除/更新数据底层原理 如果是删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。 如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。 buffer 每 refresh 一次，就会产生一个 segment file，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多 此时会定期执行 merge。每次 merge 的时候，会将多个 segment file 合并成一个 同时这里会将标识为 deleted 的 doc 给物理删除掉，然后将新的 segment file 写入磁盘 这里会写一个 commit point，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。 ES性能优化 优化索引性能 批量写入，看每条数据量的大小，一般都是几百到几千。 多线程写入，写入线程数一般和机器数相当，可以配多种情况，在测试环境通过Kibana观察性能曲线。 增加segments的刷新时间，通过上面的原理知道，segment作为一个最小的检索单元，比如segment有50个，目的需要查10条数据，但需要从50个segment分别查询10条，共500条记录，再进行排序或者分数比较后，截取最前面的10条，丢弃490条。 内存分配方面，很多文章已经提到，给系统50%的内存给Lucene做文件缓存，它任务很繁重，所以ES节点的内存需要比较多(比如每个节点能配置64G以上最好）。 磁盘方面配置SSD，机械盘做阵列RAID5 RAID10虽然看上去很快，但是随机IO还是SSD好。 使用自动生成的ID，在我们的案例中使用自定义的KEY，也就是与HBase的ROW KEY，是为了能根据rowkey删除和更新数据，性能下降不是很明显。 关于段合并，合并在后台定期执行，比较大的segment需要很长时间才能完成，为了减少对其他操作的影响(如检索)，elasticsearch进行阈值限制，默认是20MB/s， 可配置的参数：&quot;indices.store.throttle.max_bytes_per_sec&quot; : &quot;200mb&quot; （根据磁盘性能调整） 合并线程数默认是：Math.max(1, Math.min(4, Runtime.getRuntime().availableProcessors() / 2))， 如果是机械磁盘，可以考虑设置为1：index.merge.scheduler.max_thread_count: 1。 优化检索性能 关闭不需要字段的doc values。 尽量使用keyword替代一些long或者int之类，term查询总比range查询好 (参考 lucene说明 )。 关闭不需要查询字段的_source功能，不将此存储仅ES中，以节省磁盘空间。 评分消耗资源，如果不需要可使用filter过滤来达到关闭评分功能，score则为0，如果使用constantScoreQuery则score为1。 关于分页： from + size: 每分片检索结果数最大为 from + size。 假设from = 20, size = 20，则每个分片需要获取20 * 20 = 400条数据，多个分片的结果在协调节点合并(假设请求的分配数为5，则结果数最大为 400*5 = 2000条) 再在内存中排序后然后20条给用户。 这种机制导致越往后分页获取的代价越高，达到50000条将面临沉重的代价，默认from + size默认如下： index.max_result_window ： 10000 search_after: 使用前一个分页记录的最后一条来检索下一个分页记录。 比如首先使用from+size，检索出结果后再使用search_after，在页面上限制用户只能跳5页，不能跳到最后一页。 scroll: 用于大结果集查询，缺陷是需要维护scroll_id。 关于排序：可以增加一个long字段，它用于存储时间和ID的组合(通过移位即可)，正排与倒排性能相差不明显。 关于CPU消耗，检索时如果需要做排序则需要字段对比，消耗CPU比较大，如果有可能尽量分配16cores以上的CPU，具体看业务压力。 关于合并被标记删除的记录，设置为0表示在合并的时候一定删除被标记的记录，默认应该是大于10%才删除：&quot;merge.policy.expunge_deletes_allowed&quot;: &quot;0&quot;。 1234567891011121314151617181920&#123; &quot;mappings&quot;: &#123; &quot;data&quot;: &#123; &quot;dynamic&quot;: &quot;false&quot;, &quot;_source&quot;: &#123; &quot;includes&quot;: [&quot;XXX&quot;] -- 仅将查询结果所需的数据存储仅_source中 &#125;, &quot;properties&quot;: &#123; &quot;state&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, -- 虽然state为int值，但如果不需要做范围查询，尽量使用keyword，因为int需要比keyword增加额外的消耗。 &quot;doc_values&quot;: false -- 关闭不需要字段的doc values功能，仅对需要排序，汇聚功能的字段开启。 &#125;, &quot;b&quot;: &#123; &quot;type&quot;: &quot;long&quot; -- 使用了范围查询字段，则需要用long或者int之类 （构建类似KD-trees结构） &#125; &#125; &#125; &#125;, &quot;settings&quot;: &#123;......&#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"其他","slug":"后端/其他","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://rookieyin.github.io/tags/ElasticSearch/"}]},{"title":"内存屏障是个啥","slug":"2 后端/其他/2 内存屏障是个啥","date":"2022-05-27T05:43:55.000Z","updated":"2022-06-12T14:20:05.740Z","comments":true,"path":"e11f4fa067fe/","link":"","permalink":"http://rookieyin.github.io/e11f4fa067fe/","excerpt":"文章转自：https://www.jianshu.com/p/2ab5e3d7e510 关于内存屏障，还可以参考：https://www.cxyzjd.com/article/qfanmingyiq/107449052和https://gorden5566.com/post/1020.html","text":"文章转自：https://www.jianshu.com/p/2ab5e3d7e510 关于内存屏障，还可以参考：https://www.cxyzjd.com/article/qfanmingyiq/107449052和https://gorden5566.com/post/1020.html 内存屏障（Memory barrier） 为什么会有内存屏障 每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分布在不同CPU执行的不同线程对同一个变量的缓存值不同。 用volatile关键字修饰变量可以解决上述问题，那么volatile是如何做到这一点的呢？那就是内存屏障，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。 内存屏障是什么 硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。 内存屏障有两个作用： 阻止屏障两侧的指令重排序； 强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据； 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。 java内存屏障 java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。 LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 volatile语义中的内存屏障 volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态： 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障； 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障； 由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。 final语义中的内存屏障 对于final域，编译器和CPU会遵循两个排序规则： 新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；（废话嘛） 初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用final值） 总之上面规则的意思可以这样理解，必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用： 写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。 读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。 X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"其他","slug":"后端/其他","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"内存屏障","slug":"内存屏障","permalink":"http://rookieyin.github.io/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"}]},{"title":"聊聊定时任务的实现方式","slug":"2 后端/其他/1 聊聊定时任务的实现方式","date":"2022-05-26T05:43:55.000Z","updated":"2022-06-12T14:04:19.711Z","comments":true,"path":"89003babc13d/","link":"","permalink":"http://rookieyin.github.io/89003babc13d/","excerpt":"利用JDK实现 Thread Sleep 创建一个线程，把任务放到while循环中，每次执行完任务后sleep指定时间。方法简单，但是能够实现的功能十分有限。","text":"利用JDK实现 Thread Sleep 创建一个线程，把任务放到while循环中，每次执行完任务后sleep指定时间。方法简单，但是能够实现的功能十分有限。 1234567891011121314151617181920public class SleepTest &#123; public static void main(String[] args)&#123; final long timeInterval = 1000; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; while (true) &#123; System.out.println(&quot;你好，同学！&quot;); try &#123; Thread.sleep(timeInterval); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start(); &#125;&#125; Timer 和Timer相关的类主要有两个： Timer：是jdk中提供的一个定时器工具，使用的时候会在主线程之外起一个单独的线程执行指定的计划任务，可以指定执行一次或者反复执行多次。 TimerTask：是一个实现了Runnable接口的抽象类，代表一个可以被Timer执行的任务。 使用方式 Timer的使用也非常简单，需要用到时候new Timer()创建一个定时器工具，然后调用schedule()或者 scheduleAtFixedRate ()方法启动任务。下面是一个简单使用示例： 1234567891011121314151617181920212223public class TimerTest &#123; public static void main(String[] args)&#123; Timer timer = new Timer(); timer.schedule(new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;延迟1秒执行&quot;); &#125; &#125;, 1000);//只传一个参数delay timer.schedule(new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;每隔1秒执行1次&quot;); &#125; &#125;, 5000, 1000); timer.schedule((new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;每隔5秒执行1次&quot;); &#125; &#125;), 5000, 5000); &#125;&#125; 除了上面例子中以固定时间间隔执行任务外，还可以通过调用 scheduleAtFixedRate ()实现以固定频率执行任务。 123456timer.scheduleAtFixedRate(new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;以2秒固定速率执行&quot;); &#125;&#125;,1000, 2000);//延迟1秒执行，每2秒执行一次 固定速率和固定间隔有啥区别呢？也就是schedule()和 scheduleAtFixedRate ()有啥区别？ 相同点 任务执行未超时，下次执行时间 = 上次执行开始时间 + period； 任务执行超时，下次执行时间 = 上次执行结束时间； 不同点 schedule的策略是错过了就错过了，后续按照新的节奏来走；scheduleAtFixedRate的策略是如果错过了，就努力追上原来的节奏（制定好的节奏）。 schedule侧重保持间隔时间的稳定 schedule方法会因为前一个任务的延迟而导致其后面的定时任务延时。 scheduleAtFixedRate保持执行频率的稳定 如果第n次执行task时，由于某种原因这次执行时间过长，执行完后的systemCurrentTime&gt;= scheduledExecutionTime(第n+1次)，则此时不做period间隔等待，立即执行第n+1次task。 底层原理 Timer的原理模型如下图所示： 其中 TaskQueue 是一个平衡二叉树堆实现的优先级队列，每个 Timer 对象内部有唯一一个 TaskQueue 队列。用户线程调用 timer 的 schedule 方法就是把 TimerTask 任务添加到 TaskQueue 队列，在调用 schedule 的方法时候 long delay 参数用来说明该任务延迟多少时间执行。 TimerThread 是具体执行任务的线程，它从 TaskQueue 队列里面获取优先级最小的任务进行执行，需要注意的是只有执行完了当前的任务才会从队列里面获取下一个任务而不管队列里面是否有已经到了设置的 delay 时间，一个 Timer 只有一个 TimerThread 线程，所以可知 Timer 的内部实现是一个多生产者单消费者模型。 1234567891011121314151617181920212223242526public void run() &#123; try &#123; mainLoop(); &#125; finally &#123; // 有人杀死了这个线程，表现得好像Timer已取消 synchronized(queue) &#123; newTasksMayBeScheduled = false; queue.clear(); // 消除过时的引用 &#125; &#125;&#125; private void mainLoop() &#123; while (true) &#123; try &#123; TimerTask task; boolean taskFired; //从队列里面获取任务时候要加锁 synchronized(queue) &#123; ...... &#125; if (taskFired) task.run();//执行任务 &#125; catch(InterruptedException e) &#123; &#125; &#125; &#125; 从上述源码可知，当任务执行过程中抛出了除 InterruptedException 之外的异常后，唯一的消费线程就会因为抛出异常而终止，那么队列里面的其他待执行的任务就会被清除。所以 TimerTask 的 run 方法内最好使用 try-catch 结构 catch 主可能的异常，不要把异常抛出到 run 方法外。 总结 Timer使用起来也非常简单，和Thread.sleep()相比，代码实现上更简单，实现的功能也更多，适合单点，执行比较频繁、有规律的场景。 Timer也有很多缺点： 时间敏感：首先Timer对调度的支持是基于绝对时间的，而不是相对时间，所以它对系统时间的改变非常敏感。 捕获异常：其次Timer线程是不会捕获异常的，如果TimerTask抛出的了未检查异常则会导致Timer线程终止，同时Timer也不会重新恢复线程的执行，他会错误的认为整个Timer线程都会取消。同时，已经被安排单尚未执行的TimerTask也不会再执行了，新的任务也不能被调度。故如果TimerTask抛出未检查的异常，Timer将会产生无法预料的行为。 任务冲突：Timer在执行定时任务时只会创建一个线程任务，如果存在多个线程，若其中某个线程因为某种原因而导致线程任务执行时间过长，超过了两个任务的间隔时间，会导致下一个任务执行时间滞后。 这些缺点，在 ScheduledExecutorService 中得到了很好的解决。 ScheduledExecutorService ScheduledExecutorService是JAVA 1.5后新增的定时任务接口，它是基于线程池设计的定时任务类，每个调度任务都会分配到线程池中的一个线程去执行。 使用方式 在使用方法上，ScheduledExecutorService和Timer几乎没啥区别，主要通过下面4个方法开启任务： ScheduledFuture&lt;?&gt; schedule(Runnable command,long delay, TimeUnit unit)：传入Runnable实例，延迟delay执行一次，单位为unit； &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable,long delay, TimeUnit unit)：传入Callable实例，延迟delay，执行一次，单位为unit； ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,long initialDelay,long period,TimeUnit unit)：延迟initialDelay，执行周期为period，单位unit； ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command,long initialDelay,long delay,TimeUnit unit)：延迟initialDelay，间隔delay，单位unit。 ScheduledExecutorService接口的默认实现类是ScheduledThreadPoolExecutor，下面举个简单例子： 123456789101112131415public class ScheduledExecutorServiceTest &#123; public static void main(String[] args)&#123; ScheduledThreadPoolExecutor scheduledThreadPoolExecutor = new ScheduledThreadPoolExecutor(2); scheduledThreadPoolExecutor.scheduleAtFixedRate(()-&gt;&#123; System.out.println(&quot;This is run by &quot; + Thread.currentThread().getName()); &#125;,1,2, TimeUnit.SECONDS); &#125;&#125;//运行结果如下，可以看到任务可能由不同线程执行This is run by pool-1-thread-1This is run by pool-1-thread-1This is run by pool-1-thread-1This is run by pool-1-thread-2This is run by pool-1-thread-2 底层原理 和Timer类似，不过Timer中使用的是单个消费线程，ScheduledThreadPoolExecutor中使用了线程池技术。另外ScheduledExecutorService中使用了DelayQueue技术。 总结 ScheduledExecutorService可以理解成Timer的升级版，基于线程池实现，解决了Timer存在的一些问题。在实际应用中，我们应该优先使用ScheduledExecutorService。 Spring中@Schedule注解的使用 从Spring 3开始，Spring自带了一套定时任务工具Spring-Task，可以把它看成是一个轻量级的Quartz，使用起来十分简单，除Spring相关的包外不需要额外的包，支持注解和配置文件两种形式。通常情况下在Spring体系内，针对简单的定时任务，可直接使用Spring提供的功能。 使用方法 在SpringBoot中使用@Schedule非常容易，只需要在启动类上添加@EnableScheduling来开启定时任务即可。 在Spring中使用@Schedule则稍微复杂一点： 首先需要在配置文件中添加如下配置： 1234567xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:task=&quot;http://www.springframework.org/schema/task&quot;&lt;!-- xsi中添加下面两项--&gt;http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.1.xsd&lt;!-- 在开启注解方式--&gt;&lt;task:annotation-driven/&gt; 给方法加上@Schedule注解即可，它有3中定义方式 @Scheduled(fixedDelay = 1000L)：固定间隔时间执行任务 @Scheduled(fixedRate = 5000)：固定频率执行任务，和Timer类似 @Scheduled(cron = &quot;0 0 3 * * ?&quot;)：cron表达式 123456789101112131415161718//必须要添加@Component，要不然Spring扫描不到@Componentpublic class ScheduledTasks &#123; private static final SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;HH:mm:ss&quot;); //函数必须没有参数，没有返回值 @Scheduled(fixedRate = 5000) public void reportCurrentTime() &#123; System.out.println(dateFormat.format(new Date()) + &quot;---通过fixedRate定义的定时任务&quot;); &#125; @Scheduled(cron = &quot;0 0 3 * * ?&quot;) public void job1() &#123; System.out.println(dateFormat.format(new Date()) + &quot;---通过cron定义的定时任务&quot;); &#125; @Scheduled(fixedDelay = 1000L) public void job2() &#123; System.out.println(dateFormat.format(new Date()) + &quot;---通过fixedDelay定义的定时任务&quot;); &#125;&#125; 下表总结了常用的Cron表达式： 表达式 说明 0 0 12 * * ? 每天12点运行 0 15 10 ? * * 每天10:15运行 0 15 10 * * ? 每天10:15运行 0 15 10 * * ? * 每天10:15运行 0 15 10 * * ? 2008 在2008年每天10:15运行 0 * 14 * * ? 每天14点到15点之间每分钟运行一次，开始于14:00，结束于14:59 0 0/5 14 * * ? 每天14点到15点之间每5分钟运行一次，开始于14:00，结束于14:55 0 0/5 14,18 * * ? 每天14点到15点之间每5分钟运行一次，每天18点到19点也每5分钟运行一次 0 0-5 14 * * ? 每天14:10到14:44，每分钟运行一次 0 10,44 14 ? 3 WED 3月每周三的14:10分到14:44，每分钟运行一次 0 15 10 ? * MON-FRI 每周一、二、三、四、五的10:15分运行 0 15 10 15 * ? 每月15日10:15分运行 0 15 10 L * ? 每月最后一天10:15运行 0 15 10 ? * 6L 每月最后一个星期五10:15运行 0 15 10 ? * 6L 2007-2009 在2007/2008/2009年每个月最后一个星期五10:15分运行 0 15 10 ? * 6#3 每月第三个星期五的10:15分运行 实现原理 底层用的也是ScheduledExecutorService，感兴趣的可以自己去了解。 Quartz的使用 Quartz 是一个完全由 Java 编写的开源作业调度框架，为在 Java 应用程序中进行作业调度提供了简单却强大的机制。另外还提供了集群和持久化的支持。 quartz调度核心元素如下： Scheduler:任务调度器，是实际执行任务调度的控制器。在spring中通过SchedulerFactoryBean封装起来。 Trigger：触发器，用于定义任务调度的时间规则，有SimpleTrigger,CronTrigger,DateIntervalTrigger和NthIncludedDayTrigger，其中CronTrigger用的比较多，本文主要介绍这种方式。CronTrigger在spring中封装在CronTriggerFactoryBean中。 JobDetail:用来描述Job实现类及其它相关的静态信息，如Job名字、关联监听器等信息。在spring中有JobDetailFactoryBean和 MethodInvokingJobDetailFactoryBean两种实现，如果任务调度只需要执行某个类的某个方法，就可以通过MethodInvokingJobDetailFactoryBean来调用。 Job：是一个接口，只有一个方法void execute(JobExecutionContext context),开发者实现该接口定义运行任务，JobExecutionContext类提供了调度上下文的各种信息。Job运行时的信息保存在JobDataMap实例中。实现Job接口的任务，默认是无状态的，若要将Job设置成有状态的，在quartz中是给实现的Job添加@DisallowConcurrentExecution注解（以前是实现StatefulJob接口，现在已被Deprecated）,在与spring结合中可以在spring配置文件的job detail中配置concurrent参数。 JobStore： 存储作业和调度期间的状态。 这些元素的关系如下图所示： Scheduler由SchedulerFactory产生，负责任务的调度。JobDetail可以理解成对Job的一种包装，实际被执行的任务示例是JobDetail，即每次要执行某个job时，会实例化一个新的Job实例放到JobDetail，JobDetail是真正被执行的任务。这样搞的目的主要是提供并发支持。然后，每个Job可以对应一个或多个触发器。 任务的定义 定义一个任务很简单，只需要定义一个实现了Job接口的类QuartzDemo，类中实现执行任务的方法execute（）。然后如下所示，创建一个指定名字和组的JobDetail和Trigger，然后把job和trigger放到scheduler中即可： 123456789101112131415public class QuartzDemo implements Job&#123; @Override public void execute(JobExecutionContext arg0) throws JobExecutionException &#123; System.out.println(&quot;Quartz执行.......&quot;); &#125; &#125; //引进作业程序 JobDetail jobDetail = new JobDetail(&quot;jobDetail-s1&quot;, &quot;jobDetailGroup-s1&quot;, QuartzDemo.class);//定义一个触发器 SimpleTrigger simpleTrigger = new SimpleTrigger(&quot;simpleTrigger&quot;, &quot;triggerGroup-s1&quot;);//这里省略触发器的一些配置信息//作业和触发器设置到调度器中 scheduler.scheduleJob(jobDetail, simpleTrigger); //启动调度器 scheduler.start(); 这样一个任务就定义完成了！ 任务的调度 Quartz是基于线程池实现的。 在 Quartz 中，有两类线程，Scheduler 调度线程和任务执行线程，其中任务执行线程通常使用一个线程池维护一组线程。 常规调度线程：调度器实例化后并启动后，调度线程会一直运行， 轮询存储的所有 trigger（调用acquireNextTriggers 默认获取30s内将要触发的所有triggers），如果有需要触发的 trigger，即到达了下一次触发的时间，则从任务执行线程池获取一个空闲线程，执行与该 trigger 关联的任务。 misfired调度线程： Misfire 线程是扫描所有的 trigger，查看是否有 misfired trigger，如果有的话根据 misfire 的策略分别处理。 任务调度流程图如下： 使用示例 在SpringBoot使用quartz非常简单，在pom中引入spring-boot-starter-quartz依赖可以省去很多准备工作，可以参考这个。 下面是Spring中整合Quzrtz的例子： 面用spring整合Quartz,分四步： 导入依赖 编写Job 编写spring配置文件 启动spring容器（启动调度器） 1. 导入maven依赖 12345678910111213141516171819202122232425262728&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.ouhei.quartz&lt;/groupId&gt; &lt;artifactId&gt;ouhei-quartz&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.0.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.0.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写Job 1234567891011121314151617181920package org.ouhei.quartz;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.context.ApplicationContext;import org.springframework.scheduling.quartz.QuartzJobBean;/** * QuartzJobBean实现了Job接口 * */public class MyJob extends QuartzJobBean &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; System.out.println(&quot;myJob 执行了.............&quot; + context.getTrigger().getKey().getName()); ApplicationContext applicationContext = (ApplicationContext) context.getJobDetail().getJobDataMap() .get(&quot;applicationContext&quot;); System.out.println(&quot;获取到的Spring容器是： &quot; + applicationContext); &#125;&#125; 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd&quot;&gt; &lt;!-- 定义任务bean --&gt; &lt;bean name=&quot;myJobDetail&quot; class=&quot;org.springframework.scheduling.quartz.JobDetailFactoryBean&quot;&gt; &lt;!-- 指定具体的job类 --&gt; &lt;property name=&quot;jobClass&quot; value=&quot;org.ouhei.quartz.MyJob&quot; /&gt; &lt;!-- 指定job的名称 --&gt; &lt;property name=&quot;name&quot; value=&quot;myJob&quot; /&gt; &lt;!-- 指定job的分组 --&gt; &lt;property name=&quot;group&quot; value=&quot;jobs&quot; /&gt; &lt;!-- 必须设置为true，如果为false，当没有活动的触发器与之关联时会在调度器中删除该任务 --&gt; &lt;property name=&quot;durability&quot; value=&quot;true&quot;/&gt; &lt;!-- 指定spring容器的key，如果不设定在job中的jobmap中是获取不到spring容器的 --&gt; &lt;property name=&quot;applicationContextJobDataKey&quot; value=&quot;applicationContext&quot;/&gt; &lt;/bean&gt; &lt;!-- 定义触发器 --&gt; &lt;bean id=&quot;cronTrigger&quot; class=&quot;org.springframework.scheduling.quartz.CronTriggerFactoryBean&quot;&gt; &lt;property name=&quot;jobDetail&quot; ref=&quot;myJobDetail&quot; /&gt; &lt;!-- 每5秒执行一次 --&gt; &lt;property name=&quot;cronExpression&quot; value=&quot;0/5 * * * * ?&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义触发器 --&gt; &lt;!-- 演示：一个job可以有多个trigger；一个trigger只能有一个job --&gt; &lt;bean id=&quot;cronTrigger2&quot; class=&quot;org.springframework.scheduling.quartz.CronTriggerFactoryBean&quot;&gt; &lt;property name=&quot;jobDetail&quot; ref=&quot;myJobDetail&quot; /&gt; &lt;!-- 每一分钟执行一次 --&gt; &lt;property name=&quot;cronExpression&quot; value=&quot;0 */1 * * * ?&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义调度器 --&gt; &lt;bean class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name=&quot;triggers&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;cronTrigger&quot; /&gt; &lt;ref bean=&quot;cronTrigger2&quot; /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 启动Spring容器 123456789package org.ouhei.quartz;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Main &#123; public static void main(String[] args) &#123; new ClassPathXmlApplicationContext(&quot;classpath:applicationContext-scheduler.xml&quot;); &#125;&#125; 参考资料 https://juejin.cn/post/6992719702032121864 https://blog.csdn.net/fuyuwei2015/article/details/83825851 https://segmentfault.com/a/1190000014772752","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"其他","slug":"后端/其他","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"定时任务","slug":"定时任务","permalink":"http://rookieyin.github.io/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"}]},{"title":"Redisson概述","slug":"5 分布式/4 Redisson概述","date":"2022-05-25T12:38:14.000Z","updated":"2022-06-12T13:57:37.181Z","comments":true,"path":"524795742ef5/","link":"","permalink":"http://rookieyin.github.io/524795742ef5/","excerpt":"文章转自这里。","text":"文章转自这里。 一、Redisson 是什么？ 如果你之前是在用 Redis 的话，那使用 Redisson 的话将会事半功倍，Redisson 提供了使用 Redis 的最简单和最便捷的方法。 Redisson 的宗旨是促进使用者对 Redis 的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。 Redisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格（In-Memory Data Grid）。 Netty 框架：Redisson 采用了基于 NIO 的Netty框架，不仅能作为 Redis 底层驱动客户端，具备提供对 Redis 各种组态形式的连接功能，对 Redis 命令能以同步发送、异步形式发送、异步流形式发送或管道形式发送的功能，LUA脚本执行处理，以及处理返回结果的功能 基础数据结构：将原生的 Redis Hash，List，Set，String，Geo，HyperLogLog等数据结构封装为 Java 里大家最熟悉的映射（Map），列表（List），集（Set），通用对象桶（Object Bucket），地理空间对象桶（Geospatial Bucket），基数估计算法（HyperLogLog）等结构， 分布式数据结构：这基础上还提供了分布式的多值映射（Multimap），本地缓存映射（LocalCachedMap），有序集（SortedSet），计分排序集（ScoredSortedSet），字典排序集（LexSortedSet），列队（Queue），阻塞队列（Blocking Queue），有界阻塞列队（Bounded Blocking Queue），双端队列（Deque），阻塞双端列队（Blocking Deque），阻塞公平列队（Blocking Fair Queue），延迟列队（Delayed Queue），布隆过滤器（Bloom Filter），原子整长形（AtomicLong），原子双精度浮点数（AtomicDouble），BitSet等 Redis 原本没有的分布式数据结构。 分布式锁：Redisson 还实现了 Redis文档中提到像分布式锁Lock这样的更高阶应用场景。事实上 Redisson 并没有不止步于此，在分布式锁的基础上还提供了联锁（MultiLock），读写锁（ReadWriteLock），公平锁（Fair Lock），红锁（RedLock），信号量（Semaphore），可过期性信号量（PermitExpirableSemaphore）和闭锁（CountDownLatch）这些实际当中对多线程高并发应用至关重要的基本部件。正是通过实现基于 Redis 的高阶应用方案，使 Redisson 成为构建分布式系统的重要工具。 节点：Redisson 作为独立节点可以用于独立执行其他节点发布到分布式执行服务和分布式调度服务里的远程任务。 二、整合 Redisson Spring Boot 整合 Redisson 有两种方案： 程序化配置。 文件方式配置。 本篇介绍如何用程序化的方式整合 Redisson。 2.1 引入 Maven 依赖 在 passjava-question 微服务的 pom.xml 引入 redisson 的 maven 依赖。 123456&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.15.5&lt;/version&gt;&lt;/dependency&gt;xxxxxxxxxx &lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.15.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.15.5&lt;/version&gt;&lt;/dependency&gt;yaml 2.2 自定义配置类 下面的代码是单节点 Redis 的配置。 123456789101112131415161718@Configurationpublic class MyRedissonConfig &#123; /** * 对 Redisson 的使用都是通过 RedissonClient 对象 * @return * @throws IOException */ @Bean(destroyMethod=&quot;shutdown&quot;) // 服务停止后调用 shutdown 方法。 public RedissonClient redisson() throws IOException &#123; // 1.创建配置 Config config = new Config(); // 集群模式 // config.useClusterServers().addNodeAddress(&quot;127.0.0.1:7004&quot;, &quot;127.0.0.1:7001&quot;); // 2.根据 Config 创建出 RedissonClient 示例。 config.useSingleServer().setAddress(&quot;redis://127.0.0.1:6379&quot;); return Redisson.create(config); &#125;&#125; 2.3 测试配置类 新建一个单元测试方法。 1234567@AutowiredRedissonClient redissonClient;@Testpublic void TestRedisson() &#123; System.out.println(redissonClient);&#125; 我们运行这个测试方法，打印出 redissonClient 1org.redisson.Redisson@77f66138 三、分布式可重入锁 3.1 可重入锁测试 基于 Redis 的 Redisson 分布式可重入锁RLockJava 对象实现了java.util.concurrent.locks.Lock接口。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。 123RLock lock = redisson.getLock(&quot;anyLock&quot;);// 最常见的使用方法lock.lock(); 我们用 passjava 这个开源项目测试下可重入锁的两个点： （1）多个线程抢占锁，后面锁需要等待吗？ （2）如果抢占到锁的线程所在的服务停了，锁会不会被释放？ 3.1.1 验证一：可重入锁是阻塞的吗？ 为了验证以上两点，我写了个 demo 程序：代码的流程就是设置WuKong-lock锁，然后加锁，打印线程 ID，等待 10 秒后释放锁，最后返回响应：“test lock ok”。 123456789101112131415161718192021@ResponseBody@GetMapping(&quot;test-lock&quot;)public String TestLock() &#123; // 1.获取锁，只要锁的名字一样，获取到的锁就是同一把锁。 RLock lock = redisson.getLock(&quot;WuKong-lock&quot;); // 2.加锁 lock.lock(); try &#123; System.out.println(&quot;加锁成功，执行后续代码。线程 ID：&quot; + Thread.currentThread().getId()); Thread.sleep(10000); &#125; catch (Exception e) &#123; //TODO &#125; finally &#123; lock.unlock(); // 3.解锁 System.out.println(&quot;Finally，释放锁成功。线程 ID：&quot; + Thread.currentThread().getId()); &#125; return &quot;test lock ok&quot;;&#125; 先验证第一个点，用两个 http 请求来测试抢占锁。 请求的 URL： 1http:&#x2F;&#x2F;localhost:11000&#x2F;question&#x2F;v1&#x2F;redisson&#x2F;test&#x2F;test-lock 第一个线程对应的线程 ID 为 86，10 秒后，释放锁。在这期间，第二个线程需要等待锁释放。 第一个线程释放锁之后，第二个线程获取到了锁，10 秒后，释放锁。 画了一个流程图，帮助大家理解。如下图所示： 第一步：线程 A 在 0 秒时，抢占到锁，0.1 秒后，开始执行等待 10 s。 第二步：线程 B 在 0.1 秒尝试抢占锁，未能抢到锁（被 A 抢占了）。 第三步：线程 A 在 10.1 秒后，释放锁。 第四步：线程 B 在 10.1 秒后抢占到锁，然后等待 10 秒后释放锁。 由此可以得出结论，Redisson 的可重入锁（lock）是阻塞其他线程的，需要等待其他线程释放的。 3.1.2 验证二：服务停了，锁会释放吗？ 如果线程 A 在等待的过程中，服务突然停了，那么锁会释放吗？如果不释放的话，就会成为死锁，阻塞了其他线程获取锁。 我们先来看下线程 A 的获取锁后的，Redis 客户端查询到的结果，如下图所示： WuKong-lock 有值，而且大家可以看到 TTL 在不断变小，说明 WuKong-lock 是自带过期时间的。 通过观察，经过 30 秒后，WuKong-lock 过期消失了。说明 Redisson 在停机后，占用的锁会自动释放。 那这又是什么原理呢？这里就要提一个概念了，看门狗。 3.2 看门狗原理 如果负责储存这个分布式锁的 Redisson 节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson 内部提供了一个监控锁的看门狗，它的作用是在 Redisson 实例被关闭前，不断的延长锁的有效期。 默认情况下，看门狗的检查锁的超时时间是 30 秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 如果我们未制定 lock 的超时时间，就使用 30 秒作为看门狗的默认时间。只要占锁成功，就会启动一个定时任务：每隔 10 秒重新给锁设置过期的时间，过期时间为 30 秒。 如下图所示： 当服务器宕机后，因为锁的有效期是 30 秒，所以会在 30 秒内自动解锁。（30 秒等于宕机之前的锁占用时间+后续锁占用的时间）。 如下图所示： 3.3 设置锁过期时间 我们也可以通过给锁设置过期时间，让其自动解锁。 如下所示，设置锁 8 秒后自动过期。 1lock.lock(8, TimeUnit.SECONDS); 如果业务执行时间超过 8 秒，手动释放锁将会报错，如下图所示： 所以我们如果设置了锁的自动过期时间，则执行业务的时间一定要小于锁的自动过期时间，否则就会报错。 四、王者方案 上一篇我讲解了分布式锁的五种方案：《从青铜到钻石的演进方案》，这一篇主要是讲解如何用 Redisson 在 Spring Boot 项目中实现分布式锁的方案。 因为 Redisson 非常强大，实现分布式锁的方案非常简洁，所以称作王者方案。 原理图如下： 代码如下所示： 12345678// 1.设置分布式锁RLock lock = redisson.getLock(&quot;lock&quot;);// 2.占用锁lock.lock();// 3.执行业务...// 4.释放锁lock.unlock(); 和之前 Redis 的方案相比，简洁很多。 五、分布式读写锁 基于 Redis 的 Redisson 分布式可重入读写锁RReadWriteLock Java 对象实现了java.util.concurrent.locks.ReadWriteLock接口。其中读锁和写锁都继承了 RLock接口。 写锁是一个拍他锁（互斥锁），读锁是一个共享锁。 读锁 + 读锁：相当于没加锁，可以并发读。 读锁 + 写锁：写锁需要等待读锁释放锁。 写锁 + 写锁：互斥，需要等待对方的锁释放。 写锁 + 读锁：读锁需要等待写锁释放。 示例代码如下： 12345RReadWriteLock rwlock = redisson.getReadWriteLock(&quot;anyRWLock&quot;);// 最常见的使用方法rwlock.readLock().lock();// 或rwlock.writeLock().lock(); 另外 Redisson 还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 123456789101112// 10秒钟以后自动解锁// 无需调用unlock方法手动解锁rwlock.readLock().lock(10, TimeUnit.SECONDS);// 或rwlock.writeLock().lock(10, TimeUnit.SECONDS);// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁boolean res = rwlock.readLock().tryLock(100, 10, TimeUnit.SECONDS);// 或boolean res = rwlock.writeLock().tryLock(100, 10, TimeUnit.SECONDS);...lock.unlock(); 六、分布式信号量 基于 Redis 的 Redisson 的分布式信号量（Semaphore）Java 对象RSemaphore采用了与java.util.concurrent.Semaphore相似的接口和用法。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。 关于信号量的使用大家可以想象一下这个场景，有三个停车位，当三个停车位满了后，其他车就不停了。可以把车位比作信号，现在有三个信号，停一次车，用掉一个信号，车离开就是释放一个信号。 我们用 Redisson 来演示上述停车位的场景。 先定义一个占用停车位的方法： 1234567891011121314/*** 停车，占用停车位* 总共 3 个车位*/@ResponseBody@RequestMapping(&quot;park&quot;)public String park() throws InterruptedException &#123; // 获取信号量（停车场） RSemaphore park = redisson.getSemaphore(&quot;park&quot;); // 获取一个信号（停车位） park.acquire(); return &quot;OK&quot;;&#125; 再定义一个离开车位的方法： 1234567891011121314/** * 释放车位 * 总共 3 个车位 */@ResponseBody@RequestMapping(&quot;leave&quot;)public String leave() throws InterruptedException &#123; // 获取信号量（停车场） RSemaphore park = redisson.getSemaphore(&quot;park&quot;); // 释放一个信号（停车位） park.release(); return &quot;OK&quot;;&#125; 为了简便，我用 Redis 客户端添加了一个 key：“park”，值等于 3，代表信号量为 park，总共有三个值。 然后用 postman 发送 park 请求占用一个停车位。 然后在 redis 客户端查看 park 的值，发现已经改为 2 了。继续调用两次，发现 park 的等于 0，当调用第四次的时候，会发现请求一直处于等待中，说明车位不够了。如果想要不阻塞，可以用 tryAcquire 或 tryAcquireAsync。 我们再调用离开车位的方法，park 的值变为了 1，代表车位剩余 1 个。 注意：多次执行释放信号量操作，剩余信号量会一直增加，而不是到 3 后就封顶了。 其他分布式锁： 公平锁（Fair Lock） 联锁（MultiLock） 红锁（RedLock） 读写锁（ReadWriteLock） 可过期性信号量（PermitExpirableSemaphore） 闭锁（CountDownLatch） 还有其他分布式锁就不在本篇展开了，感兴趣的同学可以查看官方文档。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Redis","slug":"Redis","permalink":"http://rookieyin.github.io/tags/Redis/"}]},{"title":"分布式锁概述","slug":"5 分布式/1 分布式锁概述","date":"2022-05-24T12:38:14.000Z","updated":"2022-06-12T13:58:00.740Z","comments":true,"path":"c727a3d2828a/","link":"","permalink":"http://rookieyin.github.io/c727a3d2828a/","excerpt":"文章转自这里。","text":"文章转自这里。 1.背景 对于锁大家肯定不会陌生，在Java中synchronized关键字和ReentrantLock可重入锁在我们的代码中是经常见的，一般我们用其在多线程环境中控制对资源的并发访问，但是随着分布式的快速发展，本地的加锁往往不能满足我们的需要，在我们的分布式环境中上面加锁的方法就会失去作用。于是人们为了在分布式环境中也能实现本地锁的效果，也是纷纷各出其招，今天让我们来聊一聊一般分布式锁实现的套路。 2.分布式锁 2.1为何需要分布式锁 Martin Kleppmann是英国剑桥大学的分布式系统的研究员，之前和Redis之父Antirez进行过关于RedLock(红锁，后续有讲到)是否安全的激烈讨论。Martin认为一般我们使用分布式锁有两个场景: 效率:使用分布式锁可以避免不同节点重复相同的工作，这些工作会浪费资源。比如用户付了钱之后有可能不同节点会发出多封短信。 正确性:加分布式锁同样可以避免破坏正确性的发生，如果两个节点在同一条数据上面操作，比如多个节点机器对同一个订单操作不同的流程有可能会导致该笔订单最后状态出现错误，造成损失。 2.2分布式锁的一些特点 当我们确定了在不同节点上需要分布式锁，那么我们需要了解分布式锁到底应该有哪些特点: 互斥性:和我们本地锁一样互斥性是最基本，但是分布式锁需要保证在不同节点的不同线程的互斥。 可重入性:同一个节点上的同一个线程如果获取了锁之后那么也可以再次获取这个锁。 锁超时:和本地锁一样支持锁超时，防止死锁。 高效，高可用:加锁和解锁需要高效，同时也需要保证高可用防止分布式锁失效，可以增加降级。 支持阻塞和非阻塞:和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)。 支持公平锁和非公平锁(可选):公平锁的意思是按照请求加锁的顺序获得锁，非公平锁就相反是无序的。这个一般来说实现的比较少。 2.3常见的分布式锁 我们了解了一些特点之后，我们一般实现分布式锁有以下几个方式: MySql Zk Redis 自研分布式锁:如谷歌的Chubby。 下面分开介绍一下这些分布式锁的实现原理。 3Mysql分布式锁 首先来说一下Mysql分布式锁的实现原理，相对来说这个比较容易理解，毕竟数据库和我们开发人员在平时的开发中息息相关。对于分布式锁我们可以创建一个锁表: 前面我们所说的lock(),trylock(long timeout)，trylock()这几个方法可以用下面的伪代码实现。 3.1 lock() lock一般是阻塞式的获取锁，意思就是不获取到锁誓不罢休，那么我们可以写一个死循环来执行其操作: mysqlLock.lcok内部是一个sql,为了达到可重入锁的效果那么我们应该先进行查询，如果有值，那么需要比较node_info是否一致，这里的node_info可以用机器IP和线程名字来表示，如果一致那么就加可重入锁count的值，如果不一致那么就返回false。如果没有值那么直接插入一条数据。伪代码如下: 需要注意的是这一段代码需要加事务，必须要保证这一系列操作的原子性。 3.2tryLock()和tryLock(long timeout) tryLock()是非阻塞获取锁，如果获取不到那么就会马上返回，代码可以如下: tryLock(long timeout)实现如下: mysqlLock.lock和上面一样，但是要注意的是select … for update这个是阻塞的获取行锁，如果同一个资源并发量较大还是有可能会退化成阻塞的获取锁。 3.3 unlock() unlock的话如果这里的count为1那么可以删除，如果大于1那么需要减去1。 3.4 锁超时 我们有可能会遇到我们的机器节点挂了，那么这个锁就不会得到释放，我们可以启动一个定时任务，通过计算一般我们处理任务的一般的时间，比如是5ms，那么我们可以稍微扩大一点，当这个锁超过20ms没有被释放我们就可以认定是节点挂了然后将其直接释放。 3.5 Mysql小结 适用场景: Mysql分布式锁一般适用于资源不存在数据库，如果数据库存在比如订单，那么可以直接对这条数据加行锁，不需要我们上面多的繁琐的步骤，比如一个订单，那么我们可以用select * from order_table where id = ‘xxx’ for update进行加行锁，那么其他的事务就不能对其进行修改。 优点:理解起来简单，不需要维护额外的第三方中间件(比如Redis,Zk)。 缺点:虽然容易理解但是实现起来较为繁琐，需要自己考虑锁超时，加事务等等。性能局限于数据库，一般对比缓存来说性能较低。对于高并发的场景并不是很适合。 3.6 乐观锁 前面我们介绍的都是悲观锁，这里想额外提一下乐观锁，在我们实际项目中也是经常实现乐观锁，因为我们加行锁的性能消耗比较大，通常我们会对于一些竞争不是那么激烈，但是其又需要保证我们并发的顺序执行使用乐观锁进行处理，我们可以对我们的表加一个版本号字段，那么我们查询出来一个版本号之后，update或者delete的时候需要依赖我们查询出来的版本号，判断当前数据库和查询出来的版本号是否相等，如果相等那么就可以执行，如果不等那么就不能执行。这样的一个策略很像我们的CAS(Compare And Swap),比较并交换是一个原子操作。这样我们就能避免加select * for update行锁的开销。 4. ZooKeeper ZooKeeper也是我们常见的实现分布式锁方法，相比于数据库如果没了解过ZooKeeper可能上手比较难一些。ZooKeeper是以Paxos算法为基础分布式应用程序协调服务。Zk的数据节点和文件目录类似，所以我们可以用此特性实现分布式锁。我们以某个资源为目录，然后这个目录下面的节点就是我们需要获取锁的客户端，未获取到锁的客户端注册需要注册Watcher到上一个客户端，可以用下图表示。 /lock是我们用于加锁的目录,/resource_name是我们锁定的资源，其下面的节点按照我们加锁的顺序排列。 4.1Curator Curator封装了Zookeeper底层的Api，使我们更加容易方便的对Zookeeper进行操作，并且它封装了分布式锁的功能，这样我们就不需要再自己实现了。 Curator实现了可重入锁(InterProcessMutex),也实现了不可重入锁(InterProcessSemaphoreMutex)。在可重入锁中还实现了读写锁。 4.2InterProcessMutex InterProcessMutex是Curator实现的可重入锁，我们可以通过下面的一段代码实现我们的可重入锁: 我们利用acuire进行加锁，release进行解锁。 加锁的流程具体如下: 首先进行可重入的判定:这里的可重入锁记录在ConcurrentMap&lt;Thread, LockData&gt; threadData这个Map里面，如果threadData.get(currentThread)是有值的那么就证明是可重入锁，然后记录就会加1。我们之前的Mysql其实也可以通过这种方法去优化，可以不需要count字段的值，将这个维护在本地可以提高性能。 然后在我们的资源目录下创建一个节点:比如这里创建一个/0000000002这个节点，这个节点需要设置为EPHEMERAL_SEQUENTIAL也就是临时节点并且有序。 获取当前目录下所有子节点，判断自己的节点是否位于子节点第一个。 如果是第一个，则获取到锁，那么可以返回。 如果不是第一个，则证明前面已经有人获取到锁了，那么需要获取自己节点的前一个节点。/0000000002的前一个节点是/0000000001，我们获取到这个节点之后，再上面注册Watcher(这里的watcher其实调用的是object.notifyAll(),用来解除阻塞)。 object.wait(timeout)或object.wait():进行阻塞等待这里和我们第5步的watcher相对应。 解锁的具体流程: 首先进行可重入锁的判定:如果有可重入锁只需要次数减1即可，减1之后加锁次数为0的话继续下面步骤，不为0直接返回。 删除当前节点。 删除threadDataMap里面的可重入锁的数据。 4.3读写锁 Curator提供了读写锁，其实现类是InterProcessReadWriteLock，这里的每个节点都会加上前缀： 12private static final String READ_LOCK_NAME = &quot;__READ__&quot;;private static final String WRITE_LOCK_NAME = &quot;__WRIT__&quot;; 根据不同的前缀区分是读锁还是写锁，对于读锁，如果发现前面有写锁，那么需要将watcher注册到和自己最近的写锁。写锁的逻辑和我们之前4.2分析的依然保持不变。 4.4锁超时 Zookeeper不需要配置锁超时，由于我们设置节点是临时节点，我们的每个机器维护着一个ZK的session，通过这个session，ZK可以判断机器是否宕机。如果我们的机器挂掉的话，那么这个临时节点对应的就会被删除，所以我们不需要关心锁超时。 4.5 ZK小结 优点:ZK可以不需要关心锁超时时间，实现起来有现成的第三方包，比较方便，并且支持读写锁，ZK获取锁会按照加锁的顺序，所以其是公平锁。对于高可用利用ZK集群进行保证。 缺点:ZK需要额外维护，增加维护成本，性能和Mysql相差不大，依然比较差。并且需要开发人员了解ZK是什么。 5.Redis 大家在网上搜索分布式锁，恐怕最多的实现就是Redis了，Redis因为其性能好，实现起来简单所以让很多人都对其十分青睐。 5.1Redis分布式锁简单实现 熟悉Redis的同学那么肯定对setNx(set if not exist)方法不陌生，如果不存在则更新，其可以很好的用来实现我们的分布式锁。对于某个资源加锁我们只需要 1setNx resourceName value 这里有个问题，加锁了之后如果机器宕机那么这个锁就不会得到释放所以会加入过期时间，加入过期时间需要和setNx同一个原子操作，在Redis2.8之前我们需要使用Lua脚本达到我们的目的，但是redis2.8之后redis支持nx和ex操作是同一原子操作。 1set resourceName value ex 5 nx 5.2Redission Javaer都知道Jedis，Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持。Redission也是Redis的客户端，相比于Jedis功能简单。Jedis简单使用阻塞的I/O和redis交互，Redission通过Netty支持非阻塞I/O。Jedis最新版本2.9.0是2016年的快3年了没有更新，而Redission最新版本是2018.10月更新。 Redission封装了锁的实现，其继承了java.util.concurrent.locks.Lock的接口，让我们像操作我们的本地Lock一样去操作Redission的Lock，下面介绍一下其如何实现分布式锁。 Redission不仅提供了Java自带的一些方法(lock,tryLock)，还提供了异步加锁，对于异步编程更加方便。 由于内部源码较多，就不贴源码了，这里用文字叙述来分析他是如何加锁的，这里分析一下tryLock方法: 尝试加锁:首先会尝试进行加锁，由于保证操作是原子性，那么就只能使用lua脚本，相关的lua脚本如下： 可以看见他并没有使用我们的sexNx来进行操作，而是使用的hash结构，我们的每一个需要锁定的资源都可以看做是一个HashMap，锁定资源的节点信息是Key,锁定次数是value。通过这种方式可以很好的实现可重入的效果，只需要对value进行加1操作，就能进行可重入锁。当然这里也可以用之前我们说的本地计数进行优化。 如果尝试加锁失败，判断是否超时，如果超时则返回false。 如果加锁失败之后，没有超时，那么需要在名字为redisson_lock__channel+lockName的channel上进行订阅，用于订阅解锁消息，然后一直阻塞直到超时，或者有解锁消息。 重试步骤1，2，3，直到最后获取到锁，或者某一步获取锁超时。 对于我们的unlock方法比较简单也是通过lua脚本进行解锁，如果是可重入锁，只是减1。如果是非加锁线程解锁，那么解锁失败。 Redission还有公平锁的实现，对于公平锁其利用了list结构和hashset结构分别用来保存我们排队的节点，和我们节点的过期时间，用这两个数据结构帮助我们实现公平锁，这里就不展开介绍了，有兴趣可以参考源码。 5.3RedLock 我们想象一个这样的场景当机器A申请到一把锁之后，如果Redis主宕机了，这个时候从机并没有同步到这一把锁，那么机器B再次申请的时候就会再次申请到这把锁，为了解决这个问题Redis作者提出了RedLock红锁的算法,在Redission中也对RedLock进行了实现。 通过上面的代码，我们需要实现多个Redis集群，然后进行红锁的加锁，解锁。具体的步骤如下: 首先生成多个Redis集群的Rlock，并将其构造成RedLock。 依次循环对三个集群进行加锁，加锁的过程和5.2里面一致。 如果循环加锁的过程中加锁失败，那么需要判断加锁失败的次数是否超出了最大值，这里的最大值是根据集群的个数，比如三个那么只允许失败一个，五个的话只允许失败两个，要保证多数成功。 加锁的过程中需要判断是否加锁超时，有可能我们设置加锁只能用3ms，第一个集群加锁已经消耗了3ms了。那么也算加锁失败。 3，4步里面加锁失败的话，那么就会进行解锁操作，解锁会对所有的集群在请求一次解锁。 可以看见RedLock基本原理是利用多个Redis集群，用多数的集群加锁成功，减少Redis某个集群出故障，造成分布式锁出现问题的概率。 5.4 Redis小结 优点:对于Redis实现简单，性能对比ZK和Mysql较好。如果不需要特别复杂的要求，那么自己就可以利用setNx进行实现，如果自己需要复杂的需求的话那么可以利用或者借鉴Redission。对于一些要求比较严格的场景来说的话可以使用RedLock。 缺点:需要维护Redis集群，如果要实现RedLock那么需要维护更多的集群。 6.分布式锁的安全问题 上面我们介绍过红锁，但是Martin Kleppmann认为其依然不安全。有关于Martin反驳的几点，我认为其实不仅仅局限于RedLock,前面说的算法基本都有这个问题，下面我们来讨论一下这些问题: 长时间的GC pause:熟悉Java的同学肯定对GC不陌生，在GC的时候会发生STW(stop-the-world),例如CMS垃圾回收器，他会有两个阶段进行STW防止引用继续进行变化。那么有可能会出现下面图(引用至Martin反驳Redlock的文章)中这个情况： client1获取了锁并且设置了锁的超时时间，但是client1之后出现了STW，这个STW时间比较长，导致分布式锁进行了释放，client2获取到了锁，这个时候client1恢复了锁，那么就会出现client1，2同时获取到锁，这个时候分布式锁不安全问题就出现了。这个其实不仅仅局限于RedLock,对于我们的ZK,Mysql一样的有同样的问题。 时钟发生跳跃:对于Redis服务器如果其时间发生了向跳跃，那么肯定会影响我们锁的过期时间，那么我们的锁过期时间就不是我们预期的了，也会出现client1和client2获取到同一把锁，那么也会出现不安全，这个对于Mysql也会出现。但是ZK由于没有设置过期时间，那么发生跳跃也不会受影响。 长时间的网络I/O:这个问题和我们的GC的STW很像，也就是我们这个获取了锁之后我们进行网络调用，其调用时间由可能比我们锁的过期时间都还长，那么也会出现不安全的问题，这个Mysql也会有，ZK也不会出现这个问题。 对于这三个问题，在网上包括Redis作者在内发起了很多讨论。 6.1 GC的STW 对于这个问题可以看见基本所有的都会出现问题，Martin给出了一个解法，对于ZK这种他会生成一个自增的序列，那么我们真正进行对资源操作的时候，需要判断当前序列是否是最新，有点类似于我们乐观锁。当然这个解法Redis作者进行了反驳，你既然都能生成一个自增的序列了那么你完全不需要加锁了，也就是可以按照类似于Mysql乐观锁的解法去做。 我自己认为这种解法增加了复杂性，当我们对资源操作的时候需要增加判断序列号是否是最新，无论用什么判断方法都会增加复杂度，后面会介绍谷歌的Chubby提出了一个更好的方案。 6.2 时钟发生跳跃 Martin觉得RedLock不安全很大的原因也是因为时钟的跳跃，因为锁过期强依赖于时间，但是ZK不需要依赖时间，依赖每个节点的Session。Redis作者也给出了解答:对于时间跳跃分为人为调整和NTP自动调整。 人为调整:人为调整影响的那么完全可以人为不调整，这个是处于可控的。 NTP自动调整:这个可以通过一定的优化，把跳跃时间控制的可控范围内，虽然会跳跃，但是是完全可以接受的。 6.3长时间的网络I/O 这一块不是他们讨论的重点，我自己觉得，对于这个问题的优化可以控制网络调用的超时时间，把所有网络调用的超时时间相加，那么我们锁过期时间其实应该大于这个时间，当然也可以通过优化网络调用比如串行改成并行，异步化等。可以参考我的两个文章: 并行化-你的高并发大杀器，异步化-你的高并发大杀器 7.Chubby的一些优化 大家搜索ZK的时候，会发现他们都写了ZK是Chubby的开源实现，Chubby内部工作原理和ZK类似。但是Chubby的定位是分布式锁和ZK有点不同。Chubby也是使用上面自增序列的方案用来解决分布式不安全的问题，但是他提供了多种校验方法: CheckSequencer()：调用Chubby的API检查此时这个序列号是否有效。 访问资源服务器检查，判断当前资源服务器最新的序列号和我们的序列号的大小。 lock-delay:为了防止我们校验的逻辑入侵我们的资源服务器，其提供了一种方法当客户端失联的时候，并不会立即释放锁，而是在一定的时间内(默认1min)阻止其他客户端拿去这个锁，那么也就是给予了一定的buffer等待STW恢复，而我们的GC的STW时间如果比1min还长那么你应该检查你的程序，而不是怀疑你的分布式锁了。 8.小结 本文主要讲了多种分布式锁的实现方法，以及他们的一些优缺点。最后也说了一下有关于分布式锁的安全的问题，对于不同的业务需要的安全程度完全不同，我们需要根据自己的业务场景，通过不同的维度分析，选取最适合自己的方案。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"锁","slug":"锁","permalink":"http://rookieyin.github.io/tags/%E9%94%81/"}]},{"title":"内存管理","slug":"8 计算机基础/操作系统/6.内存管理","date":"2022-05-23T14:34:49.000Z","updated":"2022-06-12T13:50:13.709Z","comments":true,"path":"7adcc9586fb9/","link":"","permalink":"http://rookieyin.github.io/7adcc9586fb9/","excerpt":"内存管理概述 CPU能直接访问的通用存储只有内存和处理器内置的寄存器，进程要想被执行，首先要把执行过程中所需要的数据加载到内存中。 我们先从简单的入手，一步步深入，看看如何设计一个安全高效的内存管理系统。 先考虑单道程序系统，如何实现内存管理？ 这个简单，我们可以直接把程序全部加载到内存中，CPU要用到什么数据，直接拿地址去访问内存就好了。 这个方案非常简单，在某些场景下是可行的。但是如果内存空间有限，放不下整个进程怎么办呢？ 略加思考，我们就能想到动态加载技术！程序运行过程中并不需要访问程序的所有代码和数据，我们只需要把一部分代码和数据加载到内存，然后程序用到什么就加载什么，如果内存不够了，把暂时用不到的数据先踢出内存，腾出一些空间给新加载进来的数据。 前面的场景中，考虑的都是单道程序，如果操作系统中同时运行多个进程呢？ 唉呀，有多个程序同时运行就不太好办了！此时，我们不仅要把内存划分成多个区域，每个进程分配一个独立的区域，还要保证每个进程不能越界访问其他进程的内存空间。再考虑动态加载过程中可能存在的问题，那就更麻烦了！此时就需要用到虚拟内存技术了。 下面我们详细介绍下在操作系统的发展历程中，用到的4种内存管理机制。","text":"内存管理概述 CPU能直接访问的通用存储只有内存和处理器内置的寄存器，进程要想被执行，首先要把执行过程中所需要的数据加载到内存中。 我们先从简单的入手，一步步深入，看看如何设计一个安全高效的内存管理系统。 先考虑单道程序系统，如何实现内存管理？ 这个简单，我们可以直接把程序全部加载到内存中，CPU要用到什么数据，直接拿地址去访问内存就好了。 这个方案非常简单，在某些场景下是可行的。但是如果内存空间有限，放不下整个进程怎么办呢？ 略加思考，我们就能想到动态加载技术！程序运行过程中并不需要访问程序的所有代码和数据，我们只需要把一部分代码和数据加载到内存，然后程序用到什么就加载什么，如果内存不够了，把暂时用不到的数据先踢出内存，腾出一些空间给新加载进来的数据。 前面的场景中，考虑的都是单道程序，如果操作系统中同时运行多个进程呢？ 唉呀，有多个程序同时运行就不太好办了！此时，我们不仅要把内存划分成多个区域，每个进程分配一个独立的区域，还要保证每个进程不能越界访问其他进程的内存空间。再考虑动态加载过程中可能存在的问题，那就更麻烦了！此时就需要用到虚拟内存技术了。 下面我们详细介绍下在操作系统的发展历程中，用到的4种内存管理机制。 连续内存分配 “连续内存分配”顾名思义，就是把一段连续空间分配给一个内存。这种策略下，我们关注的问题可能有下面几个： 如何保证每个进程只能访问自己那部分内存，不会出现地址越界？即内存安全问题 每个进程分配多少内存？ 进程结束后，内存怎么回收？回收后的那段空间怎么处理？ 内存保护 这里需要引入逻辑地址的概念。现代操作系统都有2种类型地址： 逻辑地址CPU中使用的叫作逻辑地址； 内存中的真实地址叫作物理地址。 CPU用逻辑地址去访问物理内存中的数据，那么必然需要一种硬件来完成逻辑地址和物理地址之间的映射，这个硬件就是MMU内存管理单元。 现在重新回到“内存保护”这个问题，要想每个进程的内存空间互不干扰，需要依赖重定位寄存器和界地址寄存器。 重定位寄存器（基地址寄存器）：存储每个进程物理地址最小值。 界限寄存器（限长寄存器）：存储每个进程逻辑地址最大值。 当CPU要访问内存时， 分别用这两个地址数值之和与要访问的地址做比较。 具体怎么比较呢？如下图所示： 首先判断CPU传过来的逻辑地址是否大于该进程的逻辑地址上界，如果超出上界，则寻址错误； 如果逻辑地址符合要求，则把逻辑地址和该进程的基地址相加，得到真实的物理地址。 内存分配 通过“内存保护”，我们可以保证每个进程之间互不干扰，那么剩下的一个问题就是如何分配内存了。在介绍具体分配方法前，先了解两个概念： 内部碎片： 给一个进程分配一块空间，这块空间没有用完的部分叫做内部碎片。 外部碎片： 给每个进程分配空间以后，内存中会存在一些区域由于太小而无法利用的空间，叫做外部碎片。 单一连续分配 分配方法 整个内存分成两部分：一部分供系统使用，剩余部分供用户使用。 特点 适用于单道处理系统，方法简单，没有外部碎片问题，因为只有一个进程在系统中运行。 固定分区分配 分配方法 将内存空间划分成若干个大小相等的分区； 每个进程可以申请一块空闲分区使用； 进程终止后，占用的分区被释放，可以供其他进程使用。 特点 没有外部碎片，但是同样有内部碎片问题； 分区大小的设定不够灵活，大的进程可能放不进来，小的进程造成资源浪费。 动态分区分配 这种方案下，操作系统中有一个表，用于记录哪些内存可用和哪些内存已经被使用。新来一个进程，我就在可用内存块中找一块大小合适的空闲块来加载该进程。 动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的外部碎片，内存的利用率随之下降。 克服外部碎片可以通过紧凑（Compaction)技术来解决，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于Windows系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略，考虑以下几种算法： 首次适应(First Fit)算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。 首次适应算法不仅是最简单的，而且通常也是最好和最快的。 首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。 最佳适应(Best Fit)算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。 最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。 最坏适应(Worst Fit)算法：又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。 最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。 邻近适应(Next Fit)算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。 我们可以看到，在连续内存分配策略下，无论怎样都不可避免的产生外部碎片。外部碎片的一个可能解决方案就是：允许进程的逻辑地址空间是不连续的，这样只要物理内存是空闲的，不论多大都可以使用。这就是我们后面要介绍的分段、分页等内存管理机制。 分段管理 段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5个段，每段从0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。这种情况下，CPU逻辑地址到物理地址的映射依赖段表来实现。段表的每个条目都有段基地址和段界限。段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度。 下图展示了操作系统中的分段硬件和分段例子： 在上图分段的例子中，比如段2长度为400，基地址偏移为4300，那么对于段2字节53的逻辑地址会被映射成偏移量为4353的物理地址。 分页管理 到这里，就需要提一下“虚拟内存”的概念了。在虚拟内存场景下，程序中使用的地址（也就是CPU中看到的地址）是虚拟的，并不是真实物理地址。为什么要有虚拟内存呢？主要有下面这几点好处： 所有进程有自己独立的、一致的地址空间，每个进程都认为自己在独占整个单机资源； 方便内存管理，不同进程的空间相互独立，由操作系统协调管理，程序员不需要关心自己使用的具体内存地址； 提高内存利用率，可以对内存进行分页管理，从而让将不连续的物理内存分配给进程使用。 其实在前面提到的连续内存分配、段式分配中，已经有了虚拟内存的影子。前面我们都提到地址类型有2种，逻辑地址和物理地址，这里的逻辑地址其实就是虚拟地址。只不过在连续内存分配和段式内存分配中，虚拟地址和物理地址之间的映射非常简单。 本节，我们重点看下如何利用虚拟内存技术实现内存的分页管理。 在分页管理中，将物理内存划分成固定大小的块，称为页帧；将逻辑内存也划分成同样大小的块，称为页面。当进程需要使用内存时，我们一页一页的给它分配内存。 分页需要下图所示的分页硬件进行支持： CPU中使用的逻辑地址由页码和页偏移两部分组成，页码作为页表的索引，找到对应表项后和页偏移组合到一起，构成物理地址。 分页硬件 页表的硬件实现方法很多，最简单的一种方法是：将页表作为一组专用的寄存器来实现，可以高效地进行分页地址转换。 但是现代计算机基本都允许创建非常大的页表，在这些机器中使用寄存器来实现页表就不可行了，需要将页表放到内存中。在这种设计下，CPU访问内存需要下面这些步骤： 先到页表基地址寄存器中查询页面的内存地址； 然后到存储在内存中的页表查询表项，得到所需数据的物理地址。 因此，一次数据获取，需要访问两次内存，也就是说访问速度减半了，大大降低了系统效率。这个问题的解决方案，用一种我们非常常用的技术就可以解决，那就是缓存！ 操作系统利用TLB（转换缓冲区）来缓存部分页表信息，TLB用的是高速缓存，访问速度非常快。TLB的使用方法如下： TLB中只包含少数页表条目； CPU产生一个逻辑地址后，将页码发给TLB； TLB如果发现自己存储了该条目，将其直接返回给CPU； 如果页码不在TLB中，那么就需要访问页表去查找页信息。 由于程序具有空间局部性原理，实际应用中，TLB的命中率是比较高的。 页表结构 前面讨论的简单分页方式，看似没什么问题，其实存在着空间上的缺陷！ 因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。 那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。 因此我们需要效率更高的页表结构。 多级页表 多级页表用的是一种分层思想：把原来大的页表分成多个小的页表，比如对于一个包含100万表项的大页表，我们对这个大页表进行再分页。下图展示了一个二级页表方案： 对于32位逻辑地址空间和4K大小的页，一个逻辑地址被分成20位页码和12位页偏移。这种设计下，因为对页表进行了再分页，所以20位的页码又被分成了10位页码和10位页偏移。 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？ 当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。 网上很多说法都是粘贴自下面这段话，我感觉很难理解： 其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的局部性原理么？ 每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？ 那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。 我是这样理解的： 在单级页表下，假设进程的逻辑空间为1~10000，那么进程用到的虚拟页号可能是0、1、2，也可能是1034、1035之类的，因此为了能够随机访问，你的表项必须包含1 ~ 10000所有逻辑页，尽管其中可能有很大一部分逻辑页并没有和物理页相对应。 多级页表下，假设每个页表能存1000个表项，这样我一级页表中有10个表项，二级页表有10个页，每个页中分别是1~1000、1001 ~ 2000以此类推。如果进程用到1、1001、 2001 ··· ··· 9001这些逻辑页，那么所有二级页表都要被创建。此时使用多级页表，占用的内存空间反而更大。 但是考虑到程序局部性原理，进程用到的逻辑地址往往都是连续或距离相近的。那么这种情况下进程用到的逻辑页可能是30~130,500 ~ 850。这种情况，如果使用二级页表我们是不是只要建立页号为1~1000的那个二级页表就行了？原来需要10000个表项，现在只要1000个表项就够用了。 总的来说，二级页表能够节约内存的核心有两个：程序的局部性原理；程序用到的实际内存可能远小于可用的逻辑内存。 其他结构 除了多级页表外，还有很多其他页表结构，比如哈希页表、倒置页表，本文不作详细介绍了。 段页式管理 内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。 段页式内存管理实现的方式： 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 这样，地址结构就由段号、段内页号和页内位移三部分组成。 用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示： 段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。 可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。 页面置换 现代操作系统基本都采用动态内存加载和虚拟内存技术，即： 动态加载：每个进程需要用到内存时再分配，需要多少分配多少，而不是一开始就把程序完全加载到内存中； 虚拟内存：将逻辑内存和物理内存分开，程序不受物理内存可用量的限制。 这两种技术会带来一个问题：进程需要申请内存时，内存中没有空闲的页帧，此时就需要从内存中置换出一些暂时用不到的页。本节重点要介绍的就是发生缺页时系统中的页面置换算法。 缺页中断 在了解内存页面置换算法前，我们得先谈一下缺页异常（缺页中断）。 当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于： 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。 我们来看一下缺页中断的处理流程，如下图： 上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？ 找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。 这里提一下，页表项通常有如下图的字段： 那其中： 状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。 修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。 虚拟内存管理流程 下图展示了虚拟内存管理的整个流程： 所以，页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。 那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种： 最佳页面置换算法（OPT） 先进先出置换算法（FIFO） 最近最久未使用的置换算法（LRU） 时钟页面置换算法（Lock） 最不常用置换算法（LFU） 页面置换算法 最佳页面置换算法 思路：置换在未来最长时间不访问的页面，计算 内存中每个逻辑页面“下一次”访问时间，然后选择未来最长时间不访问的页面。 特点：实际应用中无法实现，因为你不知道未来时间会用到哪些页，通常用来衡量其他页置换算法的效率。 先进先出 思路：把在内存中驻留时间最长的页换出去。 特点：简单，但是性能差。 LRU 思路：把最长时间没被访问的页面换出去。 特点：性能不错，但是要维护额外信息，开销比较大。 时钟页面置换算法（第二次机会算法） 思路：类似FIFO，所有页放在一起构成一个环形链表，指针指向下一个可能被置换的页，当需要置换页面时作如下判断： 如果指针所指向的页，访问位为0，就淘汰该页面； 如果指针所指向的页，访问位为1，将访问位设成0，指针向前移动到下一个节点。 最不常用算法 思路：淘汰在一段时间内访问次数最少的页面。 特点：性能可能不错，但是也会有比较大的额外开销。 参考资料 https://zhuanlan.zhihu.com/p/141602175 https://developer.aliyun.com/article/636086 https://xiaolincoding.com/os/3_memory/vmem.html https://xiaolincoding.com/os/5_schedule/schedule.html 《操作系统概念》","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"操作系统","slug":"计算机基础/操作系统","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://rookieyin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内存","slug":"内存","permalink":"http://rookieyin.github.io/tags/%E5%86%85%E5%AD%98/"}]},{"title":"进程与线程","slug":"8 计算机基础/操作系统/2. 进程与线程","date":"2022-05-22T14:34:49.000Z","updated":"2022-06-12T13:48:27.189Z","comments":true,"path":"0451b9009da7/","link":"","permalink":"http://rookieyin.github.io/0451b9009da7/","excerpt":"本文内容基本来自小林coding 什么是进程 进程，简单来说就是“一个运行中的程序”。为什么会出现“进程”这个概念呢？ 早期的计算机系统一次只允许执行一个程序，这个程序拥有系统的所有资源。但是现代计算机系统允许将多个程序调入内存并发执行，这就要求对各种程序提供更严格的控制和更好的划分，从而产生了“进程”的概念，即执行中的程序。系统可以看作由一组进程组成：操作系统进程执行系统代码，用户进程执行用户代码。通过CPU多路复用，所有进程可以并发执行。通过进程之间的切换，操作系统能使计算机更为高效。","text":"本文内容基本来自小林coding 什么是进程 进程，简单来说就是“一个运行中的程序”。为什么会出现“进程”这个概念呢？ 早期的计算机系统一次只允许执行一个程序，这个程序拥有系统的所有资源。但是现代计算机系统允许将多个程序调入内存并发执行，这就要求对各种程序提供更严格的控制和更好的划分，从而产生了“进程”的概念，即执行中的程序。系统可以看作由一组进程组成：操作系统进程执行系统代码，用户进程执行用户代码。通过CPU多路复用，所有进程可以并发执行。通过进程之间的切换，操作系统能使计算机更为高效。 进程的状态 前面提到，进程就是一个执行中的程序。进程在执行过程中会发生状态的改变，下图展示了一个完整的进程状态变迁： NULL——&gt;创建状态：一个进程被创建过程中处于创建状态； 创建状态——&gt;就绪状态：进程创建完成，一切准备就绪后，变为就绪状态； 就绪状态——&gt;运行状态：处于就绪状态的进程，被进程调度器选中后，获取到CPU资源，进行运行状态； 运行状态——&gt;结束状态：程序执行完毕或出错，结束执行； 运行状态——&gt;就绪状态：分配给进程的时间片用完了，进程需要让出CPU，暂停运行，转为就绪状态； 运行状态——阻塞状态：程序运行过程中，需要请求并等待某个事件，这时需要让出CPU，进入阻塞状态； 阻塞状态——&gt;就绪状态：进程要等待的事件完成了，从阻塞状态变为就绪状态，继续等待调度器的调用。 进程控制 前面提到，操作系统中同时存在多个进程，并且进程运行过程中会在多种状态之间来回切换，那么我们怎样区分不同的进程呢？这就要提到“进程控制块（PCB）”了！ 在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。 PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。 PCB包含以下信息： 进程描述信息 包括进程标识符、用户标识符等等。 进程控制和管理信息 进程状态、优先级等等。 资源分配清单 内存地址空间、虚拟地址空间信息、打开的文件信息、使用的IO设备等等。 CPU相关信息 CPU中各个寄存器的值，当进程被切换时，用它来恢复上下文信息。 在系统中通常以链表的形式把所有PCB块组织到一起，构成就绪队列和阻塞队列，如下图所示： 进程调度 前面提到系统中会同时存在多个进程，但是CPU资源是有限的，一个CPU一个时刻只能执行一个程序，因此往往会出现多个进程或线程同时竞争CPU的情景，这时就需要一个合理的进程调度算法，来将CPU资源合理分配给各个进程。 调度原则 我们先来看看一个合理的调度算法应该遵循哪些原则： CPU利用率：调度程序应当尽可能让CPU处于忙碌状态，提高CPU利用率； 系统吞吐量：吞吐量指单位时间内完成的进程数量， 长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量 ； 周转时间：周转时间=运行时间+阻塞时间，一个进程的周转时间越小越好，不希望进程被阻塞太长时间； 等待时间：这个等待不是指处于阻塞状态的时间，而是处于就绪状态的时间，也就是说进程准备好了的话，不要让它等太久才被调用； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间越小越好。 调度算法 不同的调度算法有不同的应用场景，下面说说在单核CPU中常见的调度算法： FCFS：先来先服务算法（非抢占式） 每次从队列头选一个进程执行，然后一直执行，知道进程运行结束或者被阻塞，才会继续从队列中选在下一个进程继续运行。 优点：算法很简单，而且非常公平，先到先运行。 缺点：它的缺点也很明显，如果一个长作业先运行了，那么就绪队列中的短作业需要等待很长时间，不符合我们前面提到的“系统吞吐量”、“等待时间”、“周转时间”、“响应时间”的设计原则。 适用场景：对长作业有利，适用于CPU密集型业务。 SJF：最短作业优先 优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。但是缺点很明显，对长作业不利，长作业可能一直得不到运行。 HRRN：高响应比优先 权衡了长作业和短作业，按照如下公式计算进程优先级： 优先权=等待时间+要求服务时间要求服务时间优先权=\\frac{等待时间+要求服务时间}{要求服务时间} 优先权=要求服务时间等待时间+要求服务时间​ 如果两个进程等待时间相同，优先执行短作业； 如果两个作业运行时间相同，等待时间越长，优先级越高。 RR：时间片轮转 一个进程运行相等大小的时间片： 如果时间片内，进程没运行完，会中断该进程，并把CPU分配给另外一个进程； 如果时间片内，进程运行结束或提前阻塞，立刻把CPU分配给其他进程。 这种算法的一个核心问题就是：如何设置时间片大小？ 时间片太小：CPU上下文切换过于频繁，降低效率； 时间片太大：可能引起短作业等待时间过长。 一般设置成20ms~50ms。 HPF：最高优先级优先 在RR算法中，相当于默认所有进程拥有相同的优先级，大家运行时间一样。但是，在很多场景下，我们希望调度算法是有优先级的，能够优先执行一些紧急任务，希望调度程序能够从就绪队列中选择优先级最高的进程，先执行。 进程的优先级可以分成静态优先级和动态优先级。 前者指在进程创建时就已经指定好优先级，进程运行过程中不会改变； 后者指，进程运行过程中，其优先级会改变，比如等待时间变长，优先级变高。 该方法也有两种处理优先级高的方法，抢占式和非抢占式。它也存在缺点，低优先级的进程可能一直得不到运行。 多级反馈队列 是“时间片轮转”和“最高优先级优先”的综合扩展。 多级：指有多条优先级不同的就绪队列； 反馈： 如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列。 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行。 该算法很好的兼顾了长短作业，同时有较好的响应时间。 进程间通信 一个进程经常需要和其他进程通信，但是每个进程的用户地址空间都是独立的，不能相互访问。因此进程间的通信必须通过内核。 这里简单总结下常用的7种进程通信方式。 管道 管道分为两种，有名管道和匿名管道。 匿名管道 linux命令中常见的“ | ”就是管道，它的功能是将前一个命令的输出作为后一个命令的输入。因此，管道传输数据是单向的。 管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。 匿名管道的局限性在于：（1）单向传数据；（2）只能用于具有亲缘关系的进程；（3）没有名字；（4）管道缓冲区有限等等。 有名管道（FIFO） 数据以先进先出的方式进行传输，并且由于有名字，因此不局限于父子进程之间的通信；； 和匿名管道最大的区别在于，数据以文件形式存在文件系统中； 不过有名管道还是没有解决单项传输数据的问题，如果要双向传输数据，需要建立两个管道。 总之，无论是有名还是匿名，管道这种通信方式的效率比较低下，因为只有当管道中的数据被读取后，消息发送方才能退出，不适合进程间频繁地交换数据。 消息队列 消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。 另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。 共享内存 消息队列的一个弊端是会有数据拷贝的开销，共享内存就很好的解决了这个问题。 现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。 不过由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。 信号量 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 信号量表示资源的数量，控制信号量的方式有两种原子操作： 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程； P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。 信号量与互斥量之间的区别： （1）互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。 **互斥：**是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 **同步：**是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。 在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源 （2）互斥量值只能为0/1，信号量值可以为非负整数。 也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。 （3）互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。 信号 上面说的进程间通信，都是常规状态下的工作模式。**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样。 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号。例如： Ctrl+C 产生 SIGINT 信号，表示终止该进程； Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如： kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程； 所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。 1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。 2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。 套接字 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。 实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。 实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。 线程是个啥 线程是什么 每个进程都有自己的地址空间，即进程空间。一个服务器通常需要接收大量并发请求，为每一个请求都创建一个进程系统开销大、请求响应效率低，因此操作系统引进线程。 线程可以理解成一个进程的子任务， 一个进程中可以有多个线程，多个线程共享进程的所有资源。 线程是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发； 线程是操作系统可识别的最小执行和调度单位。 每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。 每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。 线程和进程的区别 这里简单总结一下线程和进程的区别于联系： 概念：进程是运行中的程序，线程时进程的子任务，一个线程只属于一个进程，一个进程可以有多个线程； 功能：进程是 系统进行资源调度和分配的的基本单位，实现了操作系统的并发； 线程是 是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。 内存空间： 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。 性能： 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。 应用场景： 进程适应于多核、多机分布；线程适用于多核 系统开销：进程创建与销毁开销大，线程创建于销毁开销小。 通信方式： 进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。 死锁是个啥 互斥与临界区 在了解死锁之前，我们先看看多线程或进程对共享资源进行访问时产生的冲突问题。 临界区：访问共同资源的那段代码称之为临界区，不同进程或线程不能同时进入临界区，否则可能会导致程序错误运行。 互斥：要保证只有一个线程或进程在临界区执行。换句话说，当一个线（进）程准备进入临界区时，如果已经有线（进）程进入临界区了，该线（进）程要阻塞，等到临界区空闲时才能进入。 同步 互斥解决了并发进程/线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程/线程进入了临界区，其他试图想进入临界区的进程/线程都会被阻塞着，直到第一个进程/线程离开了临界区。 我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。 例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。 所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。 注意，同步与互斥是两种不同的概念： 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等； 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」。 线程同步方式 为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种： 锁：加锁、解锁操作； 信号量：P、V 操作。 这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。 锁 锁的实现方式有很多种，可以分为“忙等待锁”和“无忙等待锁”： 忙等待锁：比如说CAS自旋锁，等待锁期间，一直空转； 无忙等待锁：就是等待锁时阻塞线程，把CPU让给其他线程执行。 信号量 信号量是操作系统提供的一种协调共享资源访问的方法。 通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。 另外，还有两个原子操作的系统调用函数来控制信号量的，分别是： P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞； P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。 使用信号量可以轻松实现线程的互斥与同步功能。 死锁的产生 了解了线程间的资源竞争，我们就可以来看死锁这个概念了。 所谓死锁，就是：不同线程之间出现资源相互等待，导致所有线程都无法被执行的一种状态。 比如，有A、B两个线程，都需要使用共享资源x和y。现在A获取了x资源的锁，继续申请y资源的锁，但是y资源的锁已经被B获取了，B在申请x资源的锁。此时，A、B两个线程会一直被阻塞下去。 那什么时候系统会出现死锁呢？这里总结下出现死锁的4个必要条件： 互斥：资源处于非共享模式，一次只能被一个线程使用； 占有并等待：某个线程占有了某个非共享资源，并等待使用其他非共享资源。 非抢占：某个线程占用了共享资源后，该资源不能被其他线程抢占； 循环等待：资源等待的状态形成环路，比如前面提到的例子，A等待B释放，B等待A释放。 应对死锁 死锁是我们不希望看到的，如何解决死锁问题呢？可以从预防、避免、检测和解除4个角度去应对死锁问题。 预防死锁 预防死锁的思路可以从前面提到的死锁四大必要条件着手，只要破坏其中一个条件，就可以预防死锁。 第一“互斥”条件显然不太可行，因为有些资源就是互斥的，不能被同时时候。 第三个“非抢占”条件也不太可行， 抢占式可以采用 剥夺式调度算法，但剥夺式调度方法目前一般仅适用于 主存资源 和 处理器资源 的分配，并不适用于所以的资源，会导致 资源利用率下降。 因此只能考虑破坏第2和第4个条件。 静态资源分配 静态分配策略可以破坏死锁产生的第二个条件（占有并等待）。所谓静态分配策略，就是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。 这种方法很简单，但是严重地降低了资源利用率。 层次分配策略 层次分配策略破坏了产生死锁的第四个条件(循环等待)。在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略，证明略。 避免死锁 上面提到的 破坏 死锁产生的四个必要条件之一就可以成功 预防系统发生死锁 ，但是会导致 低效的进程运行 和 资源使用率 。而死锁的避免相反，它的角度是允许系统中同时存在四个必要条件 ，只要掌握并发进程中与每个进程有关的资源动态申请情况，做出 明智和合理的选择 ，仍然可以避免死锁，因为四大条件仅仅是产生死锁的必要条件。 我们将系统的状态分为 安全状态 和 不安全状态 ，每当在未申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。 如果操作系统能够保证所有的进程在有限的时间内得到需要的全部资源，则称系统处于安全状态，否则说系统是不安全的。很显然，系统处于安全状态则不会发生死锁，系统若处于不安全状态则可能发生死锁。 那么如何保证系统保持在安全状态呢？通过算法，其中最具有代表性的 避免死锁算法 就是 Dijkstra 的银行家算法，银行家算法用一句话表达就是：当一个进程申请使用资源的时候，银行家算法 通过先 试探 分配给该进程资源，然后通过 安全性算法 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 真的分配资源给该进程。 检测死锁 对资源的分配加以限制可以 预防和避免 死锁的发生，但是都不利于各进程对系统资源的充分共享。解决死锁问题的另一条途径是 死锁检测和解除 (这里突然联想到了乐观锁和悲观锁，感觉死锁的检测和解除就像是 乐观锁 ，分配资源时不去提前管会不会发生死锁了，等到真的死锁出现了再来解决嘛，而 死锁的预防和避免 更像是悲观锁，总是觉得死锁会出现，所以在分配资源的时候就很谨慎)。 这种方法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 定时地运行一个 “死锁检测” 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。 死锁检测方法 操作系统中的每一刻时刻的系统状态都可以用进程-资源分配图来表示，进程-资源分配图是描述进程和资源申请及分配关系的一种有向图，可用于检测系统是否处于死锁状态。 用一个方框表示每一个资源类，方框中的黑点表示该资源类中的各个资源，每个键进程用一个圆圈表示，用 有向边 来表示进程申请资源和资源被分配的情况。 死锁检测的步骤 知道了死锁检测的原理，我们可以利用下列步骤编写一个 死锁检测 程序，检测系统是否产生了死锁。 如果进程-资源分配图中无环路，则此时系统没有发生死锁 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁。 如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个 既不阻塞又非独立的进程 ，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内 消除所有的边 ，则不会发生死锁，否则会发生死锁。(消除边的过程类似于 拓扑排序) 解除死锁 当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来，常用的解除死锁的方法有以下四种： 立即结束所有进程的执行，重新启动操作系统 ：这种方法简单，但以前所在的工作全部作废，损失很大。 撤销涉及死锁的所有进程，解除死锁后继续运行 ：这种方法能彻底打破死锁的循环等待条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。 逐个撤销涉及死锁的进程，回收其资源直至死锁解除。 抢占资源 ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。 参考资料 https://xiaolincoding.com/os/4_process/process_base.html https://www.jianshu.com/p/c1015f5ffa74 https://xiaolincoding.com/os/4_process/process_commu.html https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html https://cloud.tencent.com/developer/article/1688297","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"操作系统","slug":"计算机基础/操作系统","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://rookieyin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程","slug":"进程","permalink":"http://rookieyin.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"http://rookieyin.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"Cookie、Session和Token","slug":"8 计算机基础/计算机网络/5 Cookie、Session和Token","date":"2022-05-21T14:34:49.000Z","updated":"2022-06-12T13:34:34.412Z","comments":true,"path":"e89afa94e460/","link":"","permalink":"http://rookieyin.github.io/e89afa94e460/","excerpt":"本文重在对比cookie、session和token，并介绍它们的由来，不具体介绍这三个技术更深层次的细节。","text":"本文重在对比cookie、session和token，并介绍它们的由来，不具体介绍这三个技术更深层次的细节。 写在前面 先进行一个宏观总结，再掰开看看细节： Cookie 存储在浏览器的一个小文件，每次发http请求都会带上cookie，让服务器了解客户的状态。 大小、数量有限制，有跨域问题，根据是否有过期时间分为会话cookie和持久cookie。 Session 存储在服务器的一个结构，客户首次和服务器建立连接时，由服务器创建； 每个session有自己唯一的sessionid，服务器可以将sessionid放到cookie中发给客户，这样客户每次请求时，服务器都能从cookie中拿到该客户对应的sessionid。 Token 令牌，更多的用来做登陆验证，不存在使用cookie、session作登陆验证时存在的csrf等问题； token是无状态的，如果要存状态信息，可以联合session一起使用。 Cookie和Session 为什么有Cookie和Session HTTP协议是无状态协议，即每次请求完就完事儿了，服务器不保存客户端的状态，不知道不同请求之间有没有什么关联。因此如果想让服务器知道自己的状态，客户端每次必须带上自己的状态去请求服务器。 早期的Web主要用于文档浏览，所有服务器不需要知道客户端的状态，客户端也不需要把自己的状态告知服务器。这种场景下，无状态http协议能够很好的工作。 但是现阶段随着互联网不断发展，各类交互式Web开始需要保持用户状态，入电商、社交网站等等，都需要保存用户的登陆状态、用户身份信息等等。因此需要一种技术能够保存用户状态，解决http无状态的问题。 Cookie Cookie是浏览器存储在本地的数据文件， 对于用户而言是具体存在的。一般是从服务端接收到，然后保存在本地，当再次请求对应的网站，会带上该域名下的cookie，这样就可以让服务器知道自己的状态。 Cookie的作用通俗的说就是当一个用户通过HTTP协议访问一个服务器的时候，这个服务器会将一些Key/Value键值对返回给客户端浏览器，并给这些数据加上一些限制条件，在条件符合时这个用户下次访问这个服务器的时候，数据又被完整地带回给服务器。 由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用。cookie限制大小一般是4K，保证不会占据太多磁盘空间。另外出于对隐私安全的考虑，Cookie设计为不可跨域名。即www.google.com颁发的Cookie不会被提交到域名www.baidu.com，即使提交过去也不可用。 Session 通过把数据放在cookie中，可以让服务端知道自己的作用，但是由于每个请求都会带上cookie，增加了数据传输量，而且随着交互的不断进行，cookie的体量可能越来越大。另外Cookie存储在客户端，有被篡改、盗取的风险，而Session的出现就是为了解决这个问题。 当用户首次打开某个Web应用时，服务器会为当前会话创建一个session，可以在session中存储用户状态信息。那当客户再次发起请求时，如何知道这个客户对应哪个session呢？每个session都已独一无二的sessionid，服务器创建完session后通过set-cookie，将sessionid放到cookie中返回给客户。当客户再次发起请求时，服务器就可以从cookie中获取到该客户对应的sessionid。 但是cookie可以被认为禁止，如果禁止使用cookie的话，session就无法工作了吗？ 当然不是，我们还有其他机制让客户把sessionid传给服务器： URL重写，cookie被禁用的话，服务器仍会将sessionId以cookie的方式发送给浏览器，但是浏览器不会保存cookie。这时可以直接把sessionid附加在URL路径的后面。 表单隐藏字段， 服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。 Token Token，即令牌，在很多大型网站中都有所应用，比如 Facebook，Twitter，Google，Github 等等，比起传统的身份验证方法，Token 的扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。 一个简单的应用场景：用户输入密码登陆，服务器为该用户生成一个token，把token返回给用户。用户再次发起请求时，只需要带上这个token，服务端对该token进行验证，如果是合法的，说明这个用户已经登陆过，否则重定向到登陆页面。 一个简单的token可能会：uid、time、ip等信息组合到一起，然后使用加密算法加密生成一个字符串。这样服务器拿到用户传来的token，不仅可以验证用户的合法性，还能获得用户的uid。 参考资料 https://www.jianshu.com/p/54c69103f245 https://wuch886.gitbooks.io/front-end-handbook/content/session-cookiehe-token-san-zhe-de-guan-xi-he-qu-bie.html https://www.cnblogs.com/cxuanBlog/p/12635842.html","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"输入一条URL后的那些事","slug":"8 计算机基础/计算机网络/4 输入一条URL后的那些事","date":"2022-05-20T14:34:49.000Z","updated":"2022-06-12T13:34:39.334Z","comments":true,"path":"62b22a6b76c8/","link":"","permalink":"http://rookieyin.github.io/62b22a6b76c8/","excerpt":"本文简单介绍一下：浏览器中输入URL地址，到显示网页期间发生了什么。","text":"本文简单介绍一下：浏览器中输入URL地址，到显示网页期间发生了什么。 上图总结了 输入URL到显示网页的5个过程，主要包括：域名解析、建立TCP连接、发送http请求、服务器处理请求并返回报文、浏览器收到后解析渲染。下面介绍下这几个过程的详细信息。 文章基本搬运自：小林coding 解析 URL解析 浏览器要做的第一件事情就是解析URL。下图展示了一条URL中包括的可能信息： 通过解析URL，浏览器可以知道要用什么协议发送请求、服务器的域名、服务器上文件名，然后可以根据这些信息生成HTTP请求消息。 域名解析 我们通常都是通过域名来访问网页，比如“baidu.com”，但是客户机与服务器之间的通信依赖于IP地址，因此需要先将域名解析成IP地址才能进行接下来的操作。 所谓“域名解析”，也叫DNS解析，通过向DNS服务器发送请求，获取域名对应的IP地址。在介绍这个之前，我们需要先了解一下DNS服务器。 DNS服务器是用来存储域名和IP地址之间映射关系的服务器，当你想查询某个域名对应的服务器IP地址时，只需要向DNS服务器发送请求即可。DNS服务器的分布是一个树状结构： 如上图所示，DNS服务器分为根服务器、顶级域名服务器和权威域名服务器。所有的域名服务器中都保存了根域名服务器，因此只需要和任意一台DNS服务器通信就能获取到根域名服务器的地址。域名解析的过程大致如下图所示： 当然，这里还涉及到另外一个知识点：DNS负载均衡。对于每个域名，如果每次DNS返回的IP地址都一样，那么说明所有请求的资源都位于同一台机器上面，显然对于一个大型网站是不可能的。某些网站，同一个域名可能对应着成千上万的服务器，也就对应着成千上万的IP地址。 DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。 协议栈 拿到服务器IP地址后，接下来就可以把HTTP的传输工作交给操作系统的协议栈了。 协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。 应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，它们两会接受应用层的委托执行收发数据的操作。 协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。 此外 IP 中还包括 ICMP 协议和 ARP 协议。 ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。 ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。 IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。 数据传输 传输层——TCP HTTP使用TCP作为其传输层协议，因此拿到IP后先要和服务器三次握手建立TCP连接。成功建立连接后，就可以把HTTP报文封装到TCP报文中，发给服务器。 当然，如果HTTP请求消息过长（超过MSS），需要将HTTP拆解一个个小块，分别发送。 注：MSS指 除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。 而MTU指 一个网络包的最大长度，以太网中一般为 1500 字节。 网络层——IP TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。 IP报文头部如下图所示： 当存在多个网卡时，需要判断使用的是那块网卡，才能填写源IP地址。那么如何判断呢？需要根据路由表规则来判断哪一个网卡作为源地址IP。具体来说，将目标IP地址和子网掩码进行&amp;操作后，和路由表每一行进行匹配。 链路层——MAC 生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。 MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。 在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。 一般在 TCP/IP 通信里，MAC 包头的协议类型只使用： 0800 ： IP 协议 0806 ： ARP 协议 发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。 接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。 所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。 不知道对方 MAC 地址？不知道就喊呗。 此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。 ARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。 然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。 如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。 不过每次都要广播获取MAC地址的话会很麻烦，操作系统会有一个叫ARP缓存的东西，它把每次广播到的结果存一份到这里。每次广播前，先查一下ARP缓存中有没有，有的话直接返回，无需广播。 网卡 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。 负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。 网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。 起始帧分界符是一个用来表示包起始位置的标记 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏 最后网卡会将包转为电信号，通过网线发送出去。 交换机 下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。 首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。 然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。 计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。 将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。 交换机的 MAC 地址表主要包含两个信息： 一个是设备的 MAC 地址， 另一个是该设备连接在交换机的哪个端口上。 举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。 所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。如果地址表中找不到这个包，就向除了源端口外的所有端口转发该包。 此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。 以下两个属于广播地址： MAC 地址中的 FF:FF:FF:FF:FF:FF IP 地址中的 255.255.255.255 路由器 网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。 这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。 不过在具体的操作过程上，路由器和交换机是有区别的。 因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。 路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。 当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。 路由器接收包 首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。 如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。 总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。 查询输出端口 完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。 接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。 转发操作分为几个阶段，首先是查询路由表判断转发目标。这里和交换机做的工作类似。 发送包 这里和交换机也是类似的，先查路由表，确定对方IP地址，然后通过ARP协议获取对方Mac地址，重新封装好数据包，发送给对方。 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。 至此，可以稍微总结下整个HTTP的数据交互流程，如下图所示：","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"TCP协议","slug":"8 计算机基础/计算机网络/3 TCP协议","date":"2022-05-19T14:34:49.000Z","updated":"2022-06-12T13:31:54.618Z","comments":true,"path":"6b13a81e4596/","link":"","permalink":"http://rookieyin.github.io/6b13a81e4596/","excerpt":"TCP协议是运输层面向连接的、可靠的端到端信息传输协议。在介绍TCP协议之前，我们先看下如何一步步设计出一个可靠数据传输协议。","text":"TCP协议是运输层面向连接的、可靠的端到端信息传输协议。在介绍TCP协议之前，我们先看下如何一步步设计出一个可靠数据传输协议。 可靠数据传输协议 rdt1.0：经完全可靠信道传输 这里我们假设数据传输的底层信道是完全可靠的。此时发送端和接收端的有限状态机如下图所示： 虚线：表示来自上层的调用。 带箭头实线：发送/接收端从一个状态变为另一个状态。 横线上方：表示引起状态发生变化的事件。 横线下方：事件发生时所采取的动作。 可以看到，当底层数据传输信道是可靠的时候，即发送端发送的数据保证能够按序到达接收端，此时我们的可靠数据传输协议非常简单，接收端和发送端只需要接收和发送数据即可。 rdt 2.0：经具有比特差错信道传输 假定底层信道可以保证数据有序传输，但是数据在传输过程中某些比特可能出现差错。 在研究一种经过这种信道进行可靠通信的协议之前，首先考虑一下人们会怎样处理这样的情形。考虑一下你自己是怎样通过电话口述一条长报文的。在通常情况下，报文接收者在听到、理解并记下每句话后可能会说&quot;OK’勹如果报文接收者听到一句含糊不清的话时，他可能要求你重复那句容易误解的话。这种口述报文协议使用了肯定确认( positive a•·knowledgment)(&quot; OK&quot; ) 与否定确认(negative acknowledgment) ( h 请重复一遍＂） 。这些控制报文使得接收方可以让发送方知道哪些内容被正确接收，哪些内容接收有误并因此需要重复。在计算机网络环境中，基于这样重传机制的可靠数据传输协议称为自动重传请求( Automatic Repeat reQuest, ARQ ) 协议。 在ARQ协议中需要三种功能来处理比特差错情况： 差错检测（检验和）：接收端收到一个数据包后，要能够判断该数据包在传输过程中是否出现差错。 接收方反馈：接收端发现数据包传出过程中出错了，要通知发送端。 重传：发送端收到出错通知后，要将出错的数据包重新发送。 上图展示了rdt2.0中，发送端和接收的有限状态机。数据传输过程大致如下： 发送端发送数据后，等待来自接收端的反馈信号。 接收端收到数据后，检测数据是否出现比特差错，出错，返回一个NAK包，未出错，返回ACK包。 发送端收到来自接收端的反馈数据，如果是ACK表示数据正确收到，否则表示收到的数据出错。 上述协议存在的一个致命缺陷就是：没有考虑NAK和ACK包受损的情况。一种比较好的方法就是，发送端收到受损ACN或NAK包，直接重传上一个数据分组。不过当发送端收到受损ACK包时，会带来“冗余分组”的问题。 因此，需要在此基础上再引入一种机制：让发送方对其数据分组编号，在数据分组中添加一个新字段，用于存储该分组的编号。这样接收端收到分组后可以根据编号，判断该分组是否已经被正确接收，如果已经被接收了，就丢弃该分组。 rdt 3.0：经具有比特差错的丢包信道传输 在前面的两个版本rdt协议中，我们通过引入检验和、序号、ACK和重传等机制，设计了可以在具有比特差错信道上可靠传输的协议。但是在现实生活中，数据在传出过程中还可能出现丢包现象，该如何处理呢？ 一种直接的方法就是：定时重传，发送方发送完数据后，启动一个定时器，如果超过一定时间没有收到接收方的反馈数据，就重传该数据分组。下图展示了在丢包情况下，协议的运作情况： 至此，我们通过：检验和、序号、定时器、肯定和否定确认这些技术，得到了一个可靠数据传输协议。 流水线可靠数据传输协议 rdt3.0是一个正确、可靠的协议，但是它的性能并非让人满意。它是一个停等协议，即发送一个数据分组后，发送端要等待收到反馈数据分组，才继续发送下一个数据分组。 对于这种性能问题，一种简单的解决方法就是：不以停等方式运行，允许发送方发送多个分组而无需等待确认。 如上图所示，如果发送方可以在等待确认之前发送3个报文，其利用率基本上提高了3倍。但是在流水线技术下，我们需要对传输协议作如下改进： 增大序号范围，rdt3.0只需要0和1两个序号即可，在流水线技术中需要更大的序号范围 缓存分组，发送方最低限度应当能缓冲那些已发送但没有确认的分组。如下面讨论的那样，接收方或许也需要缓存那 些巳正确接收的分组。 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。解决流水线的差错恢复有两种基本方法是：回退N 步(Go-Back- N,GBN) 和选择重传(Selective Repeat, SR ) 。 回退N步 在回退N 步(GBN ) 协议中，允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。 上图展示了GBN协议中，发送方的窗口信息。我们为什么先要限制这些被发送的、未被确认的分组的数目为N 呢？ 为什么不允许这些分组为无限制的数目呢？其中流量控制是对发送方施加限制的原因之一。 协议的名字“回退N 步”来源于出现丢失和时延过长分组时发送方的行为。就像在停等协议中那样，定时器将再次用千恢复数据或确认分组的丢失。如果出现超时，发送方重传所有已发送但还未被确认过的分组。 在GBN 中，接收方的动作也很简单。如果一个序号为n 的分组被正确接收到，并且按序（即上次交付给上层的数据是序号为n -1 的分组），则接收方为分组n 发送一个ACK, 并将该分组中的数据部分交付到上层。在所有其他情况下，接收方丢弃该分组，并 为最近按序接收的分组重新发送ACK。下图展示了GBN协议的运行流程： 在GBN 协议中，接收方丢弃所有失序分组，尽管这可能是一个正确接收（但失序）的分组，这也是GBN协议的主要缺点。 选择重传 前面也提到过，单个分组的差错就能够引起GBN 重传大量分组，许多分组根本没有必要重传，这大大降低了数据传输效率。 选择重传(SR) 协议通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免了不必要的重传。这时需要接收方也要维护一个窗口，标记那些数据分组是失序的，但是没有出错。 SR 接收方将确认一个正确接收的分组而不管其是否按序。失序的分组将被缓存直到所有丢失分组（即序号更小的分组）皆被收到为止，这时才可以将一批分组按序交付给上层。下图展示了SR协议运作流程： 这里需要注意的一个问题就是：分组需要范围和窗口大小。下图展示了一个窗口大小和分组范围都为3的SR协议： 当接收方窗口太大或者序号范围太小时，可能导致接收方无法判断数据是一个新分组还是一次重传。因此窗口长度必须小于或等于序号空间大小的一半。 TCP协议 TCP概述 TCP协议是一个面向连接、点对点、全双工的运输层可靠数据传输协议，实现了重传机制、滑动窗口、流量控制和拥塞控制。TCP头部格式如下： 端口号：包括源端口号和目的端口号，用于多路复用和多路分解，将TCP连接和上层应用对应上。 序列号：建立连接时随机生成，用于数据分组的编号，每发送一个，数值加1。 用来解决网络包乱序问题。 确认应答号： 指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。 控制位 ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。 FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。 TCP建立连接 TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图： 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。 第一次：客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。 第二次：服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 第三次：客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。 TCP连接销毁 TCP 断开连接是通过四次挥手方式。双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图： 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。 你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。 TCP流量控制 为什么要流量控制？ TCP连接中，接收双方都会维护一个接收缓存。当该TCP连接收到正确、按序的字节后，它就将数据放人接收缓存。相关联的应用进程会从该缓存中读取数据，但不必是数据刚一到达就立即读取。事实上，接收方应用也许正忙千其他任务，甚至要过很长时间后才去读取该数据。如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。 为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。 TCP 通过让发送方维护一个称为接收窗口(receive window) 的变量来提供流量控制。通俗地说，接收窗口用于给发送方一个指示——该接收方还有多少可用的缓存空间。 TCP拥塞控制 为什么要有拥塞控制？和前面流量控制有什么不同？ 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。 一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。 在网络拥堵的时候，丢包现象频繁，但是由于TCP协议的重传机制，可能会陷入丢包，重传，重传又丢包，丢包又重传的恶性循环，加剧网络拥堵。 下面详细介绍下TCP拥塞控制算法。该算法主要包括3个主要部分：慢启动，拥塞避免和快速回复。 慢启动状态 当一条TCP连接开始时，cwnd 的值通常初始置为一个MSS（最大报文段长度） 的较小值。 每当传输的报文段首次被确认，cwnd就增加1倍 。 因此，TCP发送速率起始慢，但在慢启动阶段以指数增长。但是，**何时结束这种指数增长呢？**慢启动对这个问题提供了几种答案。 如果存在一个由超时指示的丢包事件（ 即拥塞）， TCP 发送方将cwnd 设置为1 并重新开始慢启动过程。并且将慢启动阈值ssthresh设置为cwnd/2。 慢启动结束的第二种方式是直接与ssthresh 的值相关联。因为当检测到拥塞时ssthresh 设为cwnd 的值一半，当到达或超过ssthresh 的值时，继续使cwnd 翻番可能有些鲁莽。因此，当cwnd的值等于sstbresh 时，结束慢启动并且TCP 转移到拥塞避免模式。 拥塞避免状态 一旦进入拥塞避免状态， cwnd 的值大约是上次遇到拥塞时的值的一半，即距离拥塞可能并不遥远！因此， TCP 无法每过一个Rtt再将cwnd 的值翻番，而是采用了一种较为保守的方法，每个Rtt只将cwnd 的值增加一个MSS。 但是何时应当结束拥塞避免的线性增长（每RTT 1MSS ) 呢？当出现超时时， 与慢启动的情况一样， cwnd 的值被设置为1个MSS, 当丢包事件出现时， ssthresh 的值被更新为cwnd 值的一半。 然而，前面讲过丢包事件也能由一个三个冗余ACK 事件触发。在这种情况下，网络继续从发送方向接收方交付报文段（就像由收到冗余ACK 所指示的那样） 。因此TCP 对这种丢包事件的行为，相比于超时指示的丢包，应当不那么剧烈： TCP 将cwnd 的值减半（为使测量结果更好，计及已收到的3 个冗余的ACK 要加上3 个MSS), 并且当收到3 个冗余的ACK, 将ssthresh 的值记录为cwnd 的值的一半。接下来进入快速恢复状态。 快速修复状态 进入快速恢复算法如下： 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态 常见问题 TCP vs UDP TCP面向连接，有重传、拥塞控制、流量控制等机制，UDP无连接； TCP传输可靠，UDP不可靠； TCP传字节流，UDP传数据报文段； TCP传输慢，需要资源多，UDP传输快，需要资源少； TCP头部20-60字节，UDP8字节； UDP主要用于即时通信，比如 QQ 语音、 QQ 视频 、直播等等。 TCP 三次握手 为什么是三次握手？不是两次、四次？ 我们知道 TCP 连接：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。 总之：TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。 不使用「两次握手」和「四次握手」的原因： 「两次握手」：无法防止历史连接的建立（比如之前该client发送的一个SYN报文在网络中滞留很久，然后被服务器收到了，服务器误以为是客户端新发过来的连接请求），会造成双方资源的浪费，也无法可靠的同步双方序列号（这个是主要原因）； 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 其他问题 为什么需要 TCP 协议？ TCP 工作在哪一层？ IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。 什么是 TCP ？ TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。 什么是TCP连接 简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。 如何唯一确定一个 TCP 连接呢？ 源地址，源端口，目的地址，目的端口 有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？ 最大连接数 = IP数 × 端口数","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"http://rookieyin.github.io/tags/TCP/"}]},{"title":"HTTP协议","slug":"8 计算机基础/计算机网络/2 HTTP协议","date":"2022-05-18T14:34:49.000Z","updated":"2022-06-12T13:29:41.542Z","comments":true,"path":"87be9444017b/","link":"","permalink":"http://rookieyin.github.io/87be9444017b/","excerpt":"HTTP协议概述 HTTP 协议，全称超文本传输协议（Hypertext Transfer Protocol）， 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 HTTP 是一个无状态（stateless）协议，也就是说服务器不维护任何有关客户端过去所发请求的消息。这其实是一种懒政，有状态协议会更加复杂，需要维护状态（历史信息），而且如果客户或服务器失效，会产生状态的不一致，解决这种不一致的代价更高。","text":"HTTP协议概述 HTTP 协议，全称超文本传输协议（Hypertext Transfer Protocol）， 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 HTTP 是一个无状态（stateless）协议，也就是说服务器不维护任何有关客户端过去所发请求的消息。这其实是一种懒政，有状态协议会更加复杂，需要维护状态（历史信息），而且如果客户或服务器失效，会产生状态的不一致，解决这种不一致的代价更高。 优缺点 HTTP协议最突出的优点就是：简单、灵活和易于扩展、应用广泛和跨平台。 简单 HTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。 灵活，易于扩展 HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。 同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化。 HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCP 层换成了基于 UDP 的 QUIC。 应用广泛，跨平台 互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。 HTTP的缺点就是：无状态、明文传输、不安全。 无状态 所谓“无状态”是指： 每个请求都是完全独立的，每个请求包含了处理这个请求所需的完整的数据，发送请求不涉及到状态变更 。无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。 无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。 对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。 Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了。 明文传输 明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。 但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那你号没了。 不安全 通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。 HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。 HTTP常见状态码 2xx 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。 4xx 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户 5xx 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。 HTTP中常见字段 Host：一个服务器可以有多个域名，用来表明请求是发现哪个域名的。 Content-length： 表明本次回应的数据长度。 Connection： 最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。 Content-Type： 用于服务器回应时，告诉客户端，本次数据是什么格式。 Content-Encoding：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。 HTTP通信流程 HTTP 是应用层协议，它以 TCP（传输层）作为底层协议，默认端口为 80. 通信过程主要如下： 服务器在 80 端口等待客户的请求。 浏览器发起到服务器的 TCP 连接（创建套接字 Socket）。 服务器接收来自浏览器的 TCP 连接。 浏览器（HTTP 客户端）与 Web 服务器（HTTP 服务器）交换 HTTP 消息。 关闭 TCP 连接。 HTTPS协议 前面提到过，HTTP由于是明文传输，所以安全上存在风险：窃听、篡改、冒充风险。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险： 信息加密、校验控制、身份验证。HTTPS协议具有以下特性： HTTPS 协议（Hyper Text Transfer Protocol Secure），是 HTTP 的加强安全版本，默认端口号是 443. HTTPS 协议中，SSL 通道通常使用基于密钥的加密算法，密钥长度通常是 40 比特或 128 比特。 它最大的优点就是保密性好、信任度高。 那么HTTPS协议是如何解决HTTP中存在的三个风险的呢？下面一一介绍。 混合加密 通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。 HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式： 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因： 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 摘要算法 摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。 数字证书 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 这就存在些问题，如何保证公钥不被篡改和信任度？ 所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。 通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。 不同版本HTTP协议 HTTP1.0 vs HTTP1.1 响应状态码 HTTP/1.1中新加入了大量的状态码，比如 100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址 。 缓存处理 加了很多更细致的特性，比如Cache-Control。 连接方式 HTTP/1.0 默认使用短连接 ，也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接 。 为了解决 HTTP/1.0 存在的资源浪费的问题， HTTP/1.1 优化为默认长连接模式 。 Host头处理 域名系统（DNS）允许多个主机名绑定到同一个IP地址上，但是HTTP/1.0并没有考虑这个问题。 HTTP/1.1在请求头中加入了Host字段。 带宽优化 HTTP/1.1引入了范围请求（range request）机制，以避免带宽的浪费。 HTTP/1.1中新加入了状态码100。 HTTP/1.0对数据压缩的选项提供的不多，不支持压缩细节的选择，也无法区分端到端（end-to-end）压缩或者是逐跳（hop-by-hop）压缩。 HTTP/1.1则对内容编码（content-codings）和传输编码（transfer-codings）做了区分。内容编码总是端到端的，传输编码总是逐跳的。 HTTP2新特性 HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。 那 HTTP/2 相比 HTTP/1.1 性能上的改进： 头部压缩 HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。 二进制格式 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。 数据流 每个请求或回应的所有数据包，称为一个数据流（Stream）。每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数 客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。 多路复用 HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。 移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。 服务器推送 HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。 HTTP/2 主要的问题在于，多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。 这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！ HTTP3新特性 大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。 HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。 所以， QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。 QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"HTTP","slug":"HTTP","permalink":"http://rookieyin.github.io/tags/HTTP/"}]},{"title":"网络分层模型","slug":"8 计算机基础/计算机网络/1 网络分层模型","date":"2022-05-17T14:34:49.000Z","updated":"2022-06-12T13:36:02.733Z","comments":true,"path":"2cb48d963c94/","link":"","permalink":"http://rookieyin.github.io/2cb48d963c94/","excerpt":"OSI 7层模型 OSI 七层模型 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示：","text":"OSI 7层模型 OSI 七层模型 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示： 每一层都专注于自己的事情，并且每一层都需要使用下一层提供的功能。 OSI 的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，而且有些功能在多个层中重复出现。 TCP/IP 四层模型 TCP/IP 四层模型 是目前被广泛采用的一种模型,我们可以将 TCP / IP 模型看作是 OSI 七层模型的精简版本，由以下 4 层组成： 应用层、传输层、网络层、网络接口层。 需要注意的是，我们并不能将 TCP/IP 四层模型 和 OSI 七层模型完全精确地匹配起来，不过可以简单将两者对应起来，如下图所示： 应用层 应用层位于传输层智商，主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输。应用层之间交互的数据单元称之为报文。 应用层协议定义了网络通信规则，对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如支持 Web 应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。 常见的协议包括：HTTP、DHCP、FTP、SSH、DNS、IMAP、SMTP等等。 传输层 传输层的主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务。 应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。 传输层有两个传输协议，分别是TCP和UDP。 TCP：全名叫传输控制协议，是一种面向连接的，可靠的数据传输服务。 大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。 UDP：数据报文协议，提供无连接的， 尽最大努力的数据传输服务（不保证数据传输的可靠性）。 网络层 功能：IP协议对数据进行封装、分组；寻址；路由。 网络层负责为分组交换网上的不同主机提供通信服务。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报，简称数据报。 世界上那么多设备，又该如何找到对方呢？因此，网络层需要有区分设备的编号。 我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。只有一个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然不科学。 因此，需要将 IP 地址分成两种意义： 一个是网络号，负责标识该 IP 地址是属于哪个「子网」的； 一个是主机号，负责标识同一「子网」下的不同主机； 怎么分的呢？这需要配合子网掩码才能算出 IP 地址 的网络号和主机号。 举个例子，比如 10.100.122.0/24，后面的/24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用/24代替255.255.255.0。 知道了子网掩码，该怎么计算出网络地址和主机地址呢？ 将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号和主机号。 那么在寻址的过程中，先匹配到相同的网络号（表示要找到同一个子网），才会去找对应的主机。 除了寻址能力， IP 协议还有另一个重要的能力就是路由。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。 路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。 所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘。 网络接口层 生成了 IP 头部之后，接下来要交给**网络接口层（Link Layer）**在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。 IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。 什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。 以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。 MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。 所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。 总结 数据封装格式 为什么要网络分层 说到分层，我们先从我们平时使用框架开发一个后台程序来说，我们往往会按照每一层做不同的事情的原则将系统分为三层（复杂的系统分层会更多）: Repository（数据库操作） Service（业务操作） Controller（前后端数据交互） 复杂的系统需要分层，因为每一层都需要专注于一类事情。网络分层的原因也是一样，每一层只专注于做一类事情。 好了，再来说回：“为什么网络要分层？”。我觉得主要有 3 方面的原因： 各层之间相互独立：各层之间相互独立，各层之间不需要关心其他层是如何实现的，只需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接口调用）。 这个和我们对开发时系统进行分层是一个道理。 提高了整体灵活性 ：每一层都可以使用最适合的技术来实现，你只需要保证你提供的功能以及暴露的接口的规则没有改变就行了。这个和我们平时开发系统的时候要求的高内聚、低耦合的原则也是可以对应上的。 大问题化小 ： 分层可以将复杂的网络间题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实现和标准化。 这个和我们平时开发的时候，一般会将系统功能分解，然后将复杂的问题分解为容易理解的更小的问题是相对应的，这些较小的问题具有更好的边界（目标和接口）定义。 参考资料 https://xiaolincoding.com/network/1_base/tcp_ip_model.html https://javaguide.cn/cs-basics/network/osi&amp;tcp-ip-model.html","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"Redis集群","slug":"2 后端/Redis/Redis集群","date":"2022-05-16T12:38:14.000Z","updated":"2022-06-11T13:41:48.395Z","comments":true,"path":"621962d42a8e/","link":"","permalink":"http://rookieyin.github.io/621962d42a8e/","excerpt":"本文内容基本全部来自：https://www.cnblogs.com/kismetv/p/9853040.html 集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。 集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。集群的作用主要有两点： 数据分区：将数据分散到多个节点，一方面突破Redis单机内存大小限制，另一方面可以做读写负载均衡，大大提高集群响应能力。 高可用：Redis集群支持主从复制和自动故障转移，当任意节点发生故障时，集群仍能够对外提供服务。","text":"本文内容基本全部来自：https://www.cnblogs.com/kismetv/p/9853040.html 集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。 集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。集群的作用主要有两点： 数据分区：将数据分散到多个节点，一方面突破Redis单机内存大小限制，另一方面可以做读写负载均衡，大大提高集群响应能力。 高可用：Redis集群支持主从复制和自动故障转移，当任意节点发生故障时，集群仍能够对外提供服务。 基本原理 集群最核心的功能是数据分区，因此首先介绍数据的分区规则；然后介绍集群实现的细节：通信机制和数据结构；最后以cluster meet(节点握手)、cluster addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。 数据分区方案 最常用的数据分区就是哈希分区，其基本思路是： 对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。 哈希取余分区：计算key的hash值，然后对节点总数取余，从而决定将该数据放到哪个节点。 优点：计算简单 缺点：新增或删除节点时，系统中所有数据都要进行rehash，引发大规模数据迁移 一致性哈希分区 如下图所示，一致性哈希算法将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。 与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。以上图为例，如果在node1和node2之间增加node5，则只有node2中的一部分数据会迁移到node5；如果去掉node2，则原node2中的数据只会迁移到node4中，只有node4会受影响。 一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。还是以上图为例，如果去掉node2，node4中的数据由总数据的1/4左右变为1/2左右，与其他节点相比负载过高。 带虚拟节点的一致性哈希 针对一致性哈希存在问题，我们可以通过引入虚拟节点来解决负载不均衡的问题。即将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器放置到哈希环上，如果要确定对象的服务器，需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器。 这样就可以保证环上的服务器数量足够多，不会导致负载不均衡问题。 在Redis中这个虚拟服务器称之为“槽”。引入槽以后，数据的映射关系由数据hash-&gt;实际节点，变成了数据hash-&gt;槽-&gt;实际节点。 在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。 仍以上图为例，系统中有4个实际节点，假设为其分配16个槽(0-15)； 槽0-3位于node1，4-7位于node2，以此类推。如果此时删除node2，只需要将槽4-7重新分配即可，例如槽4-5分配给node1，槽6分配给node3，槽7分配给node4；可以看出删除node2后，数据在其他节点的分布仍然较为均衡。 槽的数量一般远小于2^32，远大于实际节点的数量；在Redis集群中，槽的数量为16384。 下面这张图很好的总结了Redis集群将数据映射到实际节点的过程： Redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16。 根据哈希值，计算数据属于哪个槽。 根据槽与节点的映射关系，计算数据属于哪个节点。 节点通信机制 端口 在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口： 普通端口：主要用于为客户端提供服务，在节点迁移数据时也会使用。 集群端口：端口号为“普通端口+10000”， 集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。 Gossip协议 Redis使用Gossip协议进行集群节点间通信，其特点为： 在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。 优点：负载低，去中心化，容错性高。 缺点：集群收敛速度慢 为什么不用广播？ 广播虽然可以让集群快速收敛，但是每条消息都要发送给所有节点，CPU、带宽等消耗较大。 消息类型 集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。 节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的。 MEET消息：在节点握手阶段，当节点收到客户端的CLUSTER MEET命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。 PING消息：集群里每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息。PING消息的内容是自身节点和部分其他节点的状态信息；作用是彼此交换信息，以及检测节点是否在线。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。 PONG消息：PONG消息封装了自身状态数据。可以分为两种：第一种是在接到MEET/PING消息后回复的PONG消息；第二种是指节点向集群广播PONG消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。 FAIL消息：当一个主节点判断另一个主节点进入FAIL状态时，会向集群广播这一FAIL消息；接收节点会将这一FAIL消息保存起来，便于后续的判断。 PUBLISH消息：节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该PUBLISH命令。 数据结构 clusterNode 该结构保存了一个节点的当前状态，包括创建时间、节点id、ip和端口号等。每个节点都会用一个clusterNode结构记录自己的状态，并为集群内所有其他节点都创建一个clusterNode结构来记录节点状态。 下面列举了clusterNode的部分字段，并说明了字段的含义和作用： 1234567891011121314151617typedef struct clusterNode &#123; //节点创建时间 mstime_t ctime; //节点id char name[REDIS_CLUSTER_NAMELEN]; //节点的ip和端口号 char ip[REDIS_IP_STR_LEN]; int port; //节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等 int flags; //配置纪元：故障转移时起作用，类似于哨兵的配置纪元 uint64_t configEpoch; //槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中 unsigned char slots[16384/8]; //节点中槽的数量 int numslots;&#125; clusterNode; 除了上述字段，clusterNode还包含节点连接、主从复制、故障发现和转移需要的信息等。 clusterState clusterState结构保存了在当前节点视角下，集群所处的状态。主要字段包括： 1234567891011121314typedef struct clusterState &#123; //自身节点 clusterNode *myself; //配置纪元 uint64_t currentEpoch; //集群状态：在线还是下线 int state; //集群中至少包含一个槽的节点数量 int size; //哈希表，节点名称-&gt;clusterNode节点指针 dict *nodes; //槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL clusterNode *slots[16384]; &#125; clusterState; 除此之外，clusterState还包括故障转移、槽迁移等需要的信息。 集群命令的实现 这一部分将以cluster meet(节点握手)、cluster addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。 cluster meet 假设要向A节点发送cluster meet命令，将B节点加入到A所在的集群，则A节点收到命令后，执行的操作如下： A为B创建一个clusterNode结构，并将其添加到clusterState的nodes字典中 A向B发送MEET消息 B收到MEET消息后，会为A创建一个clusterNode结构，并将其添加到clusterState的nodes字典中 B回复A一个PONG消息 A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息 然后，A向B返回一个PING消息 B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成 之后，A通过Gossip协议将B的信息广播给集群内其他节点，其他节点也会与B握手；一段时间后，集群收敛，B成为集群内的一个普通节点 通过上述过程可以发现，集群中两个节点的握手过程与TCP类似，都是三次握手：A向B发送MEET；B向A发送PONG；A向B发送PING。 cluster addslots 集群中槽的分配信息，存储在clusterNode的slots数组和clusterState的slots数组中，两个数组的结构前面已做介绍；二者的区别在于：前者存储的是该节点中分配了哪些槽，后者存储的是集群中所有槽分别分布在哪个节点。 cluster addslots命令接收一个槽或多个槽作为参数，例如在A节点上执行cluster addslots {0…10}命令，是将编号为0-10的槽分配给A节点，具体执行过程如下： 遍历输入槽，检查它们是否都没有分配，如果有一个槽已分配，命令执行失败；方法是检查输入槽在clusterState.slots[]中对应的值是否为NULL。 遍历输入槽，将其分配给节点A；方法是修改clusterNode.slots[]中对应的比特为1，以及clusterState.slots[]中对应的指针指向A节点 A节点执行完成后，通过节点通信机制通知其他节点，所有节点都会知道0-10的槽分配给了A节点 客户端访问集群 在集群中，数据分布在不同的节点中，客户端通过某节点访问数据时，数据可能不在该节点中；下面介绍集群是如何处理这个问题的。 redis-cli 当节点收到redis-cli发来的命令时，过程如下： 计算key属于哪个槽： CRC16(key) &amp; 16383 判断key所在的槽是否属于当前节点 假设key位于第i个槽，clusterState.slots[i]则指向了槽所在的节点，如果clusterState.slots[i]==clusterState.myself，说明槽在当前节点，可以直接在当前节点执行命令；否则，说明槽不在当前节点，则查询槽所在节点的地址(clusterState.slots[i].ip/port)，并将其包装到MOVED错误中返回给redis-cli。 redis-cli收到MOVED错误后，根据返回的ip和port重新发送请求，如下图所示： 上例中，redis-cli通过-c指定了集群模式，如果没有指定，redis-cli无法处理MOVED错误： Smart客户端 redis-cli这一类客户端称为Dummy客户端，因为它们在执行命令前不知道数据在哪个节点，需要借助MOVED错误重新定向。与Dummy客户端相对应的是Smart客户端。 Smart客户端（以Java的JedisCluster为例）的基本原理： JedisCluster初始化时，在内部维护slot-&gt;node的缓存，方法是连接任一节点，执行cluster slots命令，该命令返回如下所示： 此外，JedisCluster为每个节点创建连接池(即JedisPool)。 当执行命令时，JedisCluster根据key-&gt;slot-&gt;node选择需要连接的节点，发送命令。如果成功，则命令执行完毕。如果执行失败，则会随机选择其他节点进行重试，并在出现MOVED错误时，使用cluster slots重新同步slot-&gt;node的映射关系。 实践需知 集群伸缩 实践中常常需要对集群进行伸缩，如访问量增大时的扩容操作。Redis集群可以在不影响对外服务的情况下实现伸缩；伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动。 例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。 增加节点 假设要增加7003和8003节点，其中8003是7003的从节点；步骤如下： 启动节点：方法参见集群搭建。 节点握手：可以使用cluster meet命令， 但在生产环境中建议使用redis-trib.rb的add-node工具，其原理也是cluster meet，但它会先检查新节点是否已加入其它集群或者存在数据，避免加入到集群后带来混乱。 12redis-trib.rb add-node 192.168.72.128:7003 192.168.72.128 7000redis-trib.rb add-node 192.168.72.128:8003 192.168.72.128 7000 迁移槽： 需要说明的是，Redis集群并没有一个自动实现负载均衡的工具，把多少slots从哪个节点迁移到哪个节点完全是由用户自己来指定的。 推荐使用redis-trib.rb的reshard工具实现。reshard自动化程度很高，只需要输入redis-trib.rb reshard ip:port (ip和port可以是集群中的任一节点)，然后按照提示输入以下信息，槽迁移会自动完成： 待迁移的槽数量：16384个槽均分给4个节点，每个节点4096个槽，因此待迁移槽数量为4096 目标节点id：7003节点的id 源节点的id：7000/7001/7002节点的id 指定主从关系：方法参见集群搭建。 减少节点 假设要下线7000/8000节点，可以分为两步 ： 迁移槽：使用reshard将7000节点中的槽均匀迁移到7001/7002/7003节点 下线节点：使用redis-trib.rb del-node工具；应先下线从节点再下线主节点，因为若主节点先下线，从节点会被指向其他主节点，造成不必要的全量复制。 12redis-trib.rb del-node 192.168.72.128:7001 &#123;节点8000的id&#125;redis-trib.rb del-node 192.168.72.128:7001 &#123;节点7000的id&#125; ASK错误 集群伸缩的核心是槽迁移。在槽迁移过程中，如果客户端向源节点发送命令，源节点执行流程如下： 客户端收到ASK错误后，从中读取目标节点的地址信息，并向目标节点重新发送请求，就像收到MOVED错误时一样。但是二者有很大区别：ASK错误说明数据正在迁移，不知道何时迁移完成，因此重定向是临时的，SMART客户端不会刷新slots缓存；MOVED错误重定向则是(相对)永久的，SMART客户端会刷新slots缓存。 故障迁移 集群的实现与哨兵思路类似：通过定时任务发送PING消息检测其他节点状态；节点下线分为主观下线和客观下线；客观下线后选取从节点进行故障转移。 与哨兵一样，集群只实现了主节点的故障转移；从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。 这里不再详细介绍故障转移的细节，只对重要事项进行说明： 节点数量： 在故障转移阶段，需要由主节点投票选出哪个从节点成为新的主节点；从节点选举胜出需要的票数为N/2+1；其中N为主节点数量(包括故障主节点)，但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点(且部署在不同的物理机上)。 故障转移时间： 从主节点故障发生到完成转移，所需要的时间主要消耗在主观下线识别、主观下线传播、选举延迟等几个环节；具体时间与参数cluster-node-timeout有关，一般来说： 故障转移时间(毫秒) ≤ 1.5 * cluster-node-timeout + 1000 cluster-node-timeout的默认值为15000ms(15s)，因此故障转移时间会在20s量级。 集群的限制及应对方法 由于集群中的数据分布在不同节点中，导致一些功能受限，包括： key批量操作受限：例如mget、mset操作，只有当操作的key都位于一个槽时，才能进行。针对该问题，一种思路是在客户端记录槽与key的信息，每次针对特定槽执行mget/mset；另外一种思路是使用Hash Tag，将在下一小节介绍。 keys/flushall等操作：keys/flushall等操作可以在任一节点执行，但是结果只针对当前节点，例如keys操作只返回当前节点的所有键。针对该问题，可以在客户端使用cluster nodes获取所有节点信息，并对其中的所有主节点执行keys/flushall等操作。 事务/Lua脚本：集群支持事务及Lua脚本，但前提条件是所涉及的key必须在同一个节点。Hash Tag可以解决该问题。 数据库：单机Redis节点可以支持16个数据库，集群模式下只支持一个，即db0。 复制结构：只支持一层复制结构，不支持嵌套。 Hash Tag Hash Tag原理是：当一个key包含 {}的时候，不对整个key做hash，而仅对 {}包括的字符串做hash。 Hash Tag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。不过Hash Tag可能会带来数据分配不均的问题，这时需要：(1)调整不同节点中槽的数量，使数据分布尽量均匀；(2)避免对热点数据使用Hash Tag，导致请求分布不均。 下面是使用Hash Tag的一个例子；通过对product加Hash Tag，可以将所有产品信息放到同一个槽中，便于操作。 参数优化 cluster_node_timeout cluster_node_timeout参数在前面已经初步介绍；它的默认值是15s，影响包括： （1）影响PING消息接收节点的选择：值越大对延迟容忍度越高，选择的接收节点越少，可以降低带宽，但会降低收敛速度；应根据带宽情况和应用要求进行调整。 （2）影响故障转移的判定和时间：值越大，越不容易误判，但完成转移消耗时间越长；应根据网络状况和应用要求进行调整。 cluster-require-full-coverage 前面提到，只有当16384个槽全部分配完毕时，集群才能上线。这样做是为了保证集群的完整性，但同时也带来了新的问题：当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时会集群处于下线状态，无法响应客户端的请求。 cluster-require-full-coverage参数可以改变这一设定：如果设置为no，则当槽没有完全分配时，集群仍可以上线。参数默认值为yes，如果应用对可用性要求较高，可以修改为no，但需要自己保证槽全部分配。 redis-trib.rb redis-trib.rb提供了众多实用工具：创建集群、增减节点、槽迁移、检查完整性、数据重新平衡等；通过help命令可以查看详细信息。在实践中如果能使用redis-trib.rb工具则尽量使用，不但方便快捷，还可以大大降低出错概率。 实战演练 这一部分我们将搭建一个简单的集群：共6个节点，3主3从。方便起见：所有节点在同一台服务器上，以端口号进行区分；配置从简。3个主节点端口号：7000/7001/7002，对应的从节点端口号：8000/8001/8002。 集群的搭建有两种方式：（1）手动执行Redis命令，一步步完成搭建；（2）使用Ruby脚本搭建。二者搭建的原理是一样的，只是Ruby脚本将Redis命令进行了打包封装；在实际应用中推荐使用脚本方式，简单快捷不容易出错。下面分别介绍这两种方式。 使用Redis命令搭建集群 集群的搭建可以分为四步：（1）启动节点：将节点以集群模式启动，此时节点是独立的，并没有建立联系；（2）节点握手：让独立的节点连成一个网络；（3）分配槽：将16384个槽分配给主节点；（4）指定主从关系：为从节点指定主节点。 实际上，前三步完成后集群便可以对外提供服务；但指定从节点后，集群才能够提供真正高可用的服务。 启动节点 集群节点的启动仍然是使用redis-server命令，但需要使用集群模式启动。下面是7000节点的配置文件（只列出了节点正常工作关键配置，其他配置(如开启AOF)可以参照单机节点进行）： 1234567#redis-7000.confport 7000cluster-enabled yescluster-config-file &quot;node-7000.conf&quot;logfile &quot;log-7000.log&quot;dbfilename &quot;dump-7000.rdb&quot;daemonize yes 其中的cluster-enabled和cluster-config-file是与集群相关的配置。 cluster-enabled yes Redis实例可以分为单机模式(standalone)和集群模式(cluster)；cluster-enabled yes可以启动集群模式。在单机模式下启动的Redis实例，如果执行info server命令，可以发现redis_mode一项为standalone。集群模式下的节点，其redis_mode为cluster。 cluster-config-file 该参数指定了集群配置文件的位置。每个节点在运行过程中，会维护一份集群配置文件；每当集群信息发生变化时（如增减节点），集群内所有节点会将最新信息更新到该配置文件；当节点重启后，会重新读取该配置文件，获取集群信息，可以方便的重新加入到集群中。**也就是说，当Redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。**集群配置文件由Redis节点维护，不需要人工修改。 编辑好配置文件后，使用redis-server命令启动该节点： redis-server redis-7000.conf。 节点启动以后，通过cluster nodes命令可以查看节点的情况，如下图所示。 其中返回值第一项表示节点id，由40个16进制字符串组成，节点id与 主从复制 一文中提到的runId不同：Redis每次启动runId都会重新创建，但是节点id只在集群初始化时创建一次，然后保存到集群配置文件中，以后节点重新启动时会直接在集群配置文件中读取。 其他节点使用相同办法启动，不再赘述。需要特别注意，在启动节点阶段，节点是没有主从关系的，因此从节点不需要加slaveof配置。 节点握手 节点启动以后是相互独立的，并不知道其他节点存在；需要进行节点握手，将独立的节点组成一个网络。 节点握手使用cluster meet {ip} {port}命令实现，例如在7000节点中执行cluster meet 192.168.72.128 7001，可以完成7000节点和7001节点的握手；注意ip使用的是局域网ip而不是localhost或127.0.0.1，是为了其他机器上的节点或客户端也可以访问。此时再使用cluster nodes查看： 在7001节点下也可以类似查看： 同理，在7000节点中使用cluster meet命令，可以将所有节点加入到集群，完成节点握手： 1234cluster meet 192.168.72.128 7002cluster meet 192.168.72.128 8000cluster meet 192.168.72.128 8001cluster meet 192.168.72.128 8002 执行完上述命令后，可以看到7000节点已经感知到了所有其他节点： 通过节点之间的通信，每个节点都可以感知到所有其他节点，以8000节点为例： 分配槽 在Redis集群中，借助槽实现数据分区。集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。 cluster info命令可以查看集群状态，分配槽之前状态为fail： 分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕： 123redis-cli -p 7000 cluster addslots &#123;0..5461&#125;redis-cli -p 7001 cluster addslots &#123;5462..10922&#125;redis-cli -p 7002 cluster addslots &#123;10923..16383&#125; 此时查看集群状态，显示所有槽分配完毕，集群进入上线状态： 指定主从关系 集群中指定主从关系不再使用slaveof命令，而是使用cluster replicate命令；参数使用节点id。 通过cluster nodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点： 123redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51aeredis-cli -p 8001 cluster replicate 788b361563acb175ce8232569347812a12f1fdb4redis-cli -p 8002 cluster replicate a26f1624a3da3e5197dde267de683d61bb2dcbf1 此时执行cluster nodes查看各个节点的状态，可以看到主从关系已经建立。 使用Ruby脚本搭建集群 在{REDIS_HOME}/src目录下可以看到redis-trib.rb文件，这是一个Ruby脚本，可以实现自动化的集群搭建。 安装Ruby环境 以Ubuntu为例，如下操作即可安装Ruby环境： 12apt-get install ruby #安装ruby环境gem install redis #gem是ruby的包管理工具，该命令可以安装ruby-redis依赖 启动节点 与第一种方法中的“启动节点”完全相同 搭建集群 redis-trib.rb脚本提供了众多命令，其中create用于搭建集群，使用方法如下： 1.&#x2F;redis-trib.rb create --replicas 1 192.168.72.128:7000 192.168.72.128:7001 192.168.72.128:7002 192.168.72.128:8000 192.168.72.128:8001 192.168.72.128:8002 其中：–replicas=1表示每个主节点有1个从节点；后面的多个{ip:port}表示节点地址，前面的做主节点，后面的做从节点。使用redis-trib.rb搭建集群时，要求节点不能包含任何槽和数据。 执行创建命令后，脚本会给出创建集群的计划，如下图所示；计划包括哪些是主节点，哪些是从节点，以及如何分配槽。 输入yes确认执行计划，脚本便开始按照计划执行，如下图所示。 集群方案设计 设计集群方案时，至少要考虑以下因素： （1）高可用要求：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此高可用集群至少包含6个节点。 （2）数据量和访问量：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的主节点数量。 （3）节点数量限制：Redis官方给出的节点数量限制为1000，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对Redis数据量和访问量的要求，可以考虑：(1)业务分割，大集群分为多个小集群；(2)减少不必要的数据；(3)调整数据过期策略等。 （4）适度冗余：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"Redis哨兵","slug":"2 后端/Redis/Redis哨兵","date":"2022-05-15T12:38:14.000Z","updated":"2022-06-11T13:36:16.158Z","comments":true,"path":"feac293ea536/","link":"","permalink":"http://rookieyin.github.io/feac293ea536/","excerpt":"Redis主从复制的作用有数据热备、负载均衡、故障恢复等；但主从复制存在的一个问题是故障恢复无法自动化。本文将要介绍的哨兵，它基于Redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性。","text":"Redis主从复制的作用有数据热备、负载均衡、故障恢复等；但主从复制存在的一个问题是故障恢复无法自动化。本文将要介绍的哨兵，它基于Redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性。 功能与架构 Redis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。**哨兵的核心功能是主节点的自动故障转移。**下面是Redis官方文档对于哨兵功能的描述： 监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。 下图是一个典型的哨兵集群监控的逻辑图： 工作原理 组建哨兵集群 哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。在主从集群中，主库上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。在下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口（26579）发布到__sentinel__:hello频道上，哨兵 2 和 3 订阅了该频道。那么此时，哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。然后，哨兵 2、3 可以和哨兵 1 建立网络连接。 通过这个方式，哨兵 2 和 3 也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。 哨兵监控Redis库 哨兵监控Redis库是通过向主库发送INFO命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。 主库下线的判定 首先要理解两个概念：主观下线和客观下线 主观下线：任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断； 客观下线：有哨兵集群共同决定Redis节点是否下线； 当某个哨兵（如下图中的哨兵2）判断主库“主观下线”后，就会给其他哨兵发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。 如果赞成票数（这里是2）是大于等于哨兵配置文件中的 quorum 配置项（比如这里如果是quorum=2）, 则可以判定主库客观下线了。 哨兵集群选举 判断完主库下线后，由哪个哨兵节点来执行主从切换呢？这里就需要哨兵集群的选举机制了。 为什么需要选举机制？ 为了避免哨兵单点故障，通常采用哨兵集群模式，既然是集群肯定就涉及到共识问题。另外，执行故障转移和通知都只需要一个主哨兵节点即可。 哨兵选举机制？ 采用Raft算法： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举。 Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。 任何一个想成为Leader的哨兵，都要满足两个条件： 选举票数超过一半 拿到的票数大于等于哨兵配置文件中的quorum值 故障转移 通过选举得到主哨兵节点后，就可以进行故障转移。具体流程可以分三步： 选新主库，其流程如下： 过滤掉不健康的（下线或断线），没有回复过哨兵ping响应的从节点 选择salve-priority从节点优先级最高（redis.conf）的 如果优先级无法区分，选择复制偏移量最大的（复制最完整的节点） 故障转移，假设slave-1被选择为新的主节点，sentinel-3被选为主哨兵，故障转移流程如下： 总结 关于哨兵的原理，关键是了解以下几个概念。 （1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。 （2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。 （3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。 需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。 （4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。 监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。 （5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤： 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。 更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。 将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。 配置与实践建议 配置 下面介绍与哨兵相关的几个配置。 sentinel monitor {masterName} {masterIp} {masterPort} {quorum} sentinel monitor是哨兵最核心的配置，在前文讲述部署哨兵节点时已说明，其中：masterName指定了主节点名称，masterIp和masterPort指定了主节点地址，quorum是判断主节点客观下线的哨兵数量阈值：当判定主节点下线的哨兵数量达到quorum时，对主节点进行客观下线。建议取值为哨兵数量的一半加1。 sentinel down-after-milliseconds {masterName} {time} sentinel down-after-milliseconds与主观下线的判断有关：哨兵使用ping命令对其他节点进行心跳检测，如果其他节点超过down-after-milliseconds配置的时间没有回复，哨兵就会将其进行主观下线。该配置对主节点、从节点和哨兵节点的主观下线判定都有效。 down-after-milliseconds的默认值是30000，即30s；可以根据不同的网络环境和应用要求来调整：值越大，对主观下线的判定会越宽松，好处是误判的可能性小，坏处是故障发现和故障转移的时间变长，客户端等待的时间也会变长。例如，如果应用对可用性要求较高，则可以将值适当调小，当故障发生时尽快完成转移；如果网络环境相对较差，可以适当提高该阈值，避免频繁误判。 sentinel parallel-syncs {masterName} {number} sentinel parallel-syncs与故障转移之后从节点的复制有关：它规定了每次向新的主节点发起复制操作的从节点个数。例如，假设主节点切换完成之后，有3个从节点要向新的主节点发起复制；如果parallel-syncs=1，则从节点会一个一个开始复制；如果parallel-syncs=3，则3个从节点会一起开始复制。 parallel-syncs取值越大，从节点完成复制的时间越快，但是对主节点的网络负载、硬盘负载造成的压力也越大；应根据实际情况设置。例如，如果主节点的负载较低，而从节点对服务可用的要求较高，可以适量增加parallel-syncs取值。parallel-syncs的默认值是1。 sentinel failover-timeout {masterName} {time} sentinel failover-timeout与故障转移超时的判断有关，但是该参数不是用来判断整个故障转移阶段的超时，而是其几个子阶段的超时，例如如果主节点晋升从节点时间超过timeout，或从节点向新的主节点发起复制操作的时间(不包括复制数据的时间)超过timeout，都会导致故障转移超时失败。 failover-timeout的默认值是180000，即180s；如果超时，则下一次该值会变为原来的2倍。 除上述几个参数外，还有一些其他参数，如安全验证相关的参数，这里不做介绍。 实践建议 哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。 哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。 各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。 哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。 当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A 实战演练 常用命令 基础查询：通过这些命令，可以查询哨兵系统的拓扑结构、节点信息、配置信息等。 info sentinel：获取监控的所有主节点的基本信息 sentinel masters：获取监控的所有主节点的详细信息 sentinel master mymaster：获取监控的主节点mymaster的详细信息 sentinel slaves mymaster：获取监控的主节点mymaster的从节点的详细信息 sentinel sentinels mymaster：获取监控的主节点mymaster的哨兵节点的详细信息 sentinel get-master-addr-by-name mymaster：获取监控的主节点mymaster的地址信息，前文已有介绍 sentinel is-master-down-by-addr：哨兵节点之间可以通过该命令询问主节点是否下线，从而对是否客观下线做出判断 增加/移除对主节点的监控 sentinel monitor mymaster2 192.168.92.128 16379 2：后面参数分别指主节点名，主节点ip，主节点端口号和quorum（判断主节点客观下线阈值） sentinel remove mymaster2：取消当前哨兵节点对主节点mymaster2的监控 强制故障转移 sentinel failover mymaster：该命令可以强制对mymaster执行故障转移，即便当前的主节点运行完好；例如，如果当前主节点所在机器即将报废，便可以提前通过failover命令进行故障转移。 部署哨兵系统 这一部分将部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。方便起见：所有这些节点都部署在一台机器上（局域网IP：192.168.92.128），使用端口号区分；节点的配置尽可能简化。 部署主从节点 哨兵系统中的主从节点，与普通的主从节点配置是一样的，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单，不再详述。 12345678910111213141516171819#redis-6379.confport 6379daemonize yeslogfile &quot;6379.log&quot;dbfilename &quot;dump-6379.rdb&quot; #redis-6380.confport 6380daemonize yeslogfile &quot;6380.log&quot;dbfilename &quot;dump-6380.rdb&quot;slaveof 192.168.92.128 6379 #redis-6381.confport 6381daemonize yeslogfile &quot;6381.log&quot;dbfilename &quot;dump-6381.rdb&quot;slaveof 192.168.92.128 6379 配置完成后，依次启动主节点和从节点： 123redis-server redis-6379.confredis-server redis-6380.confredis-server redis-6381.conf 节点启动后，连接柱节点，可以通过info Replication查看主从状态是否正常。 部署哨兵节点 3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式；配置部分尽量简化。 12345#sentinel-26379.confport 26379daemonize yeslogfile &quot;26379.log&quot;sentinel monitor mymaster 192.168.92.128 6379 2 哨兵节点的启动有两种方式，二者作用是完全相同的： 12redis-sentinel sentinel-26379.confredis-server sentinel-26379.conf --sentinel 按照上述方式配置和启动之后，整个哨兵系统就启动完毕了。可以通过redis-cli连接哨兵节点进行验证，如下图所示：可以看出26379哨兵节点已经在监控mymaster主节点(即192.168.92.128:6379)，并发现了其2个从节点和另外2个哨兵节点。 演示故障转移 哨兵的4个作用中，配置提供者和通知需要客户端的配合，本文将在下一章介绍客户端访问哨兵系统的方法时详细介绍。这一小节将演示当主节点发生故障时，哨兵的监控和自动故障转移功能。 kill掉主节点 如果此时立即在哨兵节点中使用info Sentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。 一段时间以后，再次在哨兵节点中执行info Sentinel查看，发现主节点已经切换成6380节点。 但是同时可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线（其含义将在原理部分介绍），因此认为该从节点一直存在。当6379节点重新启动后，会自动变成6380节点的从节点。下面验证一下。 重启6379节点：可以看到6379节点成为了6380节点的从节点。 在故障转移阶段，哨兵和主从节点的配置文件都会被改写。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-sentinel.html https://www.cnblogs.com/kismetv/p/9609938.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"raft算法是个啥","slug":"5 分布式/3 raft算法是个啥","date":"2022-05-13T12:38:14.000Z","updated":"2022-06-01T14:29:19.467Z","comments":true,"path":"c321fe594eaf/","link":"","permalink":"http://rookieyin.github.io/c321fe594eaf/","excerpt":"之前学Redis集群相关知识时候遇到过Raft算法，今天系统的学习一下Raft算法的一些细节。 在继续往下阅读之前可以，先看一个动画，简单了解下Raft算法。或者通过这个实操一下！","text":"之前学Redis集群相关知识时候遇到过Raft算法，今天系统的学习一下Raft算法的一些细节。 在继续往下阅读之前可以，先看一个动画，简单了解下Raft算法。或者通过这个实操一下！ Raft概述 对于分布式算法，最经典的莫过于Paxos，但是它过于难懂，并且工程落地性的门槛很高。因此，后来有人又提出了Raft算法。和Paxos相比，它是一种易于理解、实现简单的leader-based共识算法， 算法设计出发点就是可理解性以及工程的落地性，它在性能、可靠性、可用性方面是不输于Paxos的。 共识算法就是保证一个集群的多台机器协同工作，在遇到请求时，数据能够保持一致。即使遇到机器宕机，整个系统仍然能够对外保持服务的可用性 Raft将共识问题分解三个子问题： Leader election 领导选举：有且仅有一个leader节点，如果leader宕机，通过选举机制选出新的leader； Log replication 日志复制：leader从客户端接收数据更新/删除请求，然后日志复制到follower节点，从而保证集群数据的一致性； Safety 安全性：通过安全性原则来处理一些特殊case，保证Raft算法的完备性。 所以，Raft算法核心流程可以归纳为： 首先选出leader，leader节点负责接收外部的数据更新/删除请求； 然后日志复制到其他follower节点，同时通过安全性的准则来保证整个日志复制的一致性； 如果遇到leader故障，followers会重新发起选举出新的leader。 Raft中的角色 Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）： Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate：Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。Raft算法角色状态转换如下： Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态。 Leader Election Raft算法把时间轴划分为不同任期Term。每个任期Term都有自己的编号TermId，该编号全局唯一且单调递增。如下图，每个任务的开始都 Leader Election 领导选举。如果选举成功，则进入维持任务Term阶段，此时leader负责接收客户端请求并，负责复制日志。Leader和所有follower都保持通信，如果follower发现通信超时，TermId递增并发起新的选举。如果选举成功，则进入新的任期。如果选举失败，TermId递增，然后重新发起选举直到成功。 举个例子，参考下图，Term N选举成功，Term N+1和Term N+2选举失败，Term N+3重新选举成功。 具体的说，Leader在任期内会周期性向其他follower节点发送心跳来维持地位。follower如果发现心跳超时，就认为leader节点宕机或不存在。随机等待一定时间后，follower会发起选举，变成candidate，然后去竞选leader。选举结果有三种情况： 1、获取超过半数投票，赢得选举： 当Candidate获得超过半数的投票时，代表自己赢得了选举，且转化为leader。此时，它会马上向其他节点发送请求，从而确认自己的leader地位，从而阻止新一轮的选举； 投票原则：当多个Candidate竞选Leader时 一个任期内，follower只会投票一次票，且投票先来先得； Candidate存储的日志至少要和follower一样新（安全性准则），否则拒绝投票。 2、投票未超过半数，选举失败： 当Candidate没有获得超过半数的投票时，说明多个Candidate竞争投票导致过于分散，或者出现了丢包现象。此时，认为当期任期选举失败，任期TermId+1，然后发起新一轮选举； 上述机制可能出现多个Candidate竞争投票，导致每个Candidate一直得不到超过半数的票，最终导致无限选举投票循环； 投票分散问题解决：Raft会给每个Candidate在固定时间内随机确认一个超时时间（一般为150-300ms）。这么做可以尽量避免新的一次选举出现多个Candidate竞争投票的现象。 3、收到其他Leader通信请求： 如果Candidate收到其他声称自己是Leader的请求的时候，通过任期TermId来判断是否处理； 如果请求的任期TermId不小于Candidate当前任期TermId，那么Candidate会承认该Leader的合法地位并转化为Follower； 否则，拒绝这次请求，并继续保持Candidate。 简单地说，Leader Election领导选举通过若干的投票原则，保证一次选举有且仅可能最多选出一个leader，从而解决了脑裂问题。 Log Replication 选举Leader成功后，整个集群就可以正常对外提供服务了。Leader接收所有客户端请求，然后转化为log复制命令，发送通知其他节点完成日志复制请求。每个日志复制请求包括状态机命令 &amp; 任期号，同时还有前一个日志的任期号和日志索引。状态机命令表示客户端请求的数据操作指令，任期号表示leader的当前任期。 follower收到日志复制请求的处理流程： 1、follower会使用前一个日志的任期号和日志索引来对比自己的数据： 如果相同，接收复制请求，回复ok； 否则回拒绝复制当前日志，回复error。 2、 leader收到拒绝复制的回复后，继续发送节点日志复制请求，不过这次会带上更前面的一个日志任期号和索引； 3、如此循环往复，直到找到一个共同的任期号&amp;日志索引。此时follower从这个索引值开始复制，最终和leader节点日志保持一致； 4、 日志复制过程中，Leader会无限重试直到成功。如果超过半数的节点复制日志成功，就可以认为当前数据请求达成了共识，即日志可以commit提交了。 综上，Log Replication 日志复制有两个特点： 如果在不同日志中的两个条目有着相同索引和任期号，则所存储的命令是相同的，这点是由leader来保证的； 如果在不同日志中的两个条目有着相同索引和任期号，则它们之前所有条目完全一样，这点是由日志复制的规则来保证的。 举个例子，最上面表示日志索引，这个是保证唯一性。每个方块代表指定任期内的数据操作，目前来看，LogIndex 1-4的日志已经完成同步，LogIndex 5的正在同步，LogIndex6还未开始同步。Raft 日志提交的过程有点类似两阶段原子提交协议2PC，不过和2PC的最大区别是，Raft要求超过一半节点同意即可commited，2PC要求所有节点同意才能commited。 日志不一致问题：在正常情况下，leader和follower的日志复制能够保证整个集群的一致性，但是遇到leader崩溃的时候，leader和follower日志可能出现了不一致的状态，此时follower相比leader缺少部分日志。 为了解决数据不一致性，Raft算法规定follower强制复制leader节日的日志，即follower不一致日志都会被leader的日志覆盖，最终follower和leader保持一致。简单的说，从前向后寻找follower和leader第一个公共LogIndex的位置，然后从这个位置开始，follower强制复制leader的日志。但是这么多还有其他的安全性问题，所以需要引入Safety 安全性规则。 Safety 当前的Leader election 领导选举和Log replication 日志复制并不能保证Raft算法的安全性，在一些特殊情况下，可能导致数据不一致，所以需要引入下面安全性规则。 1、Election Safety 选举安全性：避免脑裂问题 Raft算法规定，所有的数据请求都要交给leader节点处理，要求： leader只能日志追加日志，不能覆盖日志； 只有leader的日志项才能被提交，follower不能接收写请求和提交日志； 只有已经提交的日志项，才能被应用到状态机中； 选举时限制新leader日志包含所有已提交日志项。 3、Log Matching 日志匹配特性 这点主要是为了保证日志的唯一性，要求： 如果在不同日志中的两个条目有着相同索引和任期号，则所存储的命令是相同的； 如果在不同日志中的两个条目有着相同索引和任期号，则它们之间所有条目完全一样。 4、 Leader Completeness 选举完备性：leader必须具备最新提交日志 Raft规定： 只有拥有最新提交日志的follower节点才有资格成为leader节点。 具体做法：candidate竞选投票时会携带最新提交日志，follower会用自己的日志和candidate做比较。 如果follower的更新，那么拒绝这次投票； 否则根据前面的投票规则处理。这样就可以保证只有最新提交节点成为leader。 因为日志提交需要超过半数的节点同意，所以针对日志同步落后的follower（还未同步完全部日志，导致落后于其他节点）在竞选leader的时候，肯定拿不到超过半数的票，也只有那些完成同步的才有可能获取超过半数的票成为leader。 5、State Machine Safety 状态机安全性：确保当前任期日志提交 考虑到当前的日志复制规则： 当前follower节点强制复制leader节点； 假如以前Term日志复制超过半数节点，在面对当前任期日志的节点比较中，很明显当前任期节点更新，有资格成为leader。 所以，Raft对日志提交有额外安全机制：leader只能提交当前任期Term的日志，旧任期Term（以前的数据）只能通过当前任期Term的数据提交来间接完成提交。简单的说，日志提交有两个条件需要满足： 当前任期； 复制结点超过半数。 下面举个例子来解释为什么需要这个原则，如下图： 在阶段a，term为2，S1是Leader，且S1写入日志（term, index）为(2, 2)，并且日志被同步写入了S2； 在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志（term, index）为（3， 2）; S5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志（2， 2）同步到了S3，而此时由于该日志已经被同步到了多数节点（S1, S2, S3），因此，此时日志（2，2）可以被提交了。 在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader（这是因为S5可以满足作为主的一切条件：1. term = 5 &gt; 4，2. 最新的日志为（3，2），比大多数节点（如S2/S3/S4的日志都新），然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志（2，2）被截断了。 增加上述限制后，即使日志（2，2）已经被大多数节点（S1、S2、S3）确认了，但是它不能被提交，因为它是来自之前term（2）的日志，直到S1在当前term（4）产生的日志（4， 4）被大多数Followers确认，S1方可提交日志（4，4）这条日志，当然，根据Raft定义，（4，4）之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志（4，4）。 参考资料 https://zhuanlan.zhihu.com/p/32052223 http://dockone.io/article/2434665","categories":[{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"rand(7)模拟rand(10)的背后","slug":"4 算法/rand(7)模拟rand(10)的背后","date":"2022-05-07T05:39:48.000Z","updated":"2022-06-01T12:47:15.748Z","comments":true,"path":"f85e1f123fb5/","link":"","permalink":"http://rookieyin.github.io/f85e1f123fb5/","excerpt":"刷LeetCode遇到这样一道题：用 Rand7() 实现 Rand10()，本文以这题为引子，深入探讨一下其背后的一些知识。 题目描述如下： 给定方法 rand7 可生成 [1,7] 范围内的均匀随机整数，试写一个方法 rand10 生成 [1,10] 范围内的均匀随机整数。 你只能调用 rand7() 且不能调用其他方法。请不要使用系统的 Math.random() 方法。每个测试用例将有一个内部参数 n，即你实现的函数 rand10() 在测试时将被调用的次数。请注意，这不是传递给 rand10() 的参数。","text":"刷LeetCode遇到这样一道题：用 Rand7() 实现 Rand10()，本文以这题为引子，深入探讨一下其背后的一些知识。 题目描述如下： 给定方法 rand7 可生成 [1,7] 范围内的均匀随机整数，试写一个方法 rand10 生成 [1,10] 范围内的均匀随机整数。 你只能调用 rand7() 且不能调用其他方法。请不要使用系统的 Math.random() 方法。每个测试用例将有一个内部参数 n，即你实现的函数 rand10() 在测试时将被调用的次数。请注意，这不是传递给 rand10() 的参数。 对于这题，有一种更加通用的问法：如何用rand(m)模拟rand(n)？对于这题，m=7，n=10。 这种类型的题还有很多，比如：“ 一个不均匀的硬币，怎么抛硬币可以让我们得到50% 50%的概率事件 ”。 这类问题的核心是**“拒绝采样”**。 所谓“拒绝采样”，我的理解就是，设计一种采样方式，我们取其中若干种可能作为结果集，当遇到其他情况时，本次操作作废，继续下一次采样。 这么说可能比较抽象，用上面抛硬币的例子来理解下，对于这个问题，我们可以这样考虑： 抛两次，先正后反记为1，先反后正记为2。 1和2就是等可能事件。 那么我们是如何避开硬币不均匀的事情的呢，本质就是我们拒绝了一部分事件，比如两次都是正面，或者都是反面，就作废，重新采样。 重新回到“用Rand7模拟Rand10模拟”，这个问题该如何解决呢？ 回想抛硬币问题，我们的解决思路其实是：设计一种采样方式，构造两种等可能采样结果，拒绝其他所有类型采样结果，这样我们就得到两种概率各位50%的采样结果。 同样地，我们要模拟Rand10，需要设计一种采样方式，构造10种等可能结果，拒绝其他采样结果就可以了。 方案1： 一种非常巧妙的方式是，用Rand7进行两次采样， 第一次采样，设计一个Rand2，决定数字是1~5还是6 ~10 具体来说，拒绝7，接受1-6，奇数表示1~5，偶数表示6-10。这样我们得到了2种等概率事件。 第二次采样，设计一个Rand5，拒绝6-7，接受1-5。这样我们得到了5种等概率事件。 两次采样结果合到一起，就得到以10种等概率事件，结果用rand5() + rand2() * 5表示即可。 123456789class Solution extends SolBase &#123; public int rand10() &#123; //思路：使用ran7在【0，6】直接选一个数 使用ran7在【0，5】之间选一个数 int a=rand7();int b=rand7(); while(a==7) a=rand7();//a不能为7 必须为【1，6】这样才能保证奇偶都是1/2概率 while(b&gt;5) b=rand7();//b不能为5以上 因为一会可能要加5 return ((a&amp;1)==0?0:5)+b;//判断a奇偶性1/2 * b取值【1，5】之间1/5=1/10 &#125;&#125; 方案2： 对于其他方案，本质和方案1是一样的，就是想办法利用Rand7进行多次采样，构建10种等概率事件即可。这里举个简单例子。我们可以用Rand7()进行两次采样，将两次采样结果相乘，可以得到如下结果： 一种可能的方案是，计算每个数的生成概率，我们从中挑选10个等概率的事件即可。 另一种更优的方案是，我们可以调用两次Rand7()，那么可以生成 [1, 49]之间的随机整数，我们只用到其中的前 40 个来实现Rand10()，而拒绝剩下的 9 个数，如下图所示（把两次采样结果相乘后，对10取余）。 具体代码实现如下： 1234567891011class Solution extends SolBase &#123; public int rand10() &#123; int row, col, idx; do &#123; row = rand7(); col = rand7(); idx = col + (row - 1) * 7; &#125; while (idx &gt; 40); return 1 + (idx - 1) % 10; &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"随机化","slug":"随机化","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E5%8C%96/"}]},{"title":"B-树","slug":"4 算法/B-树","date":"2022-05-06T05:39:48.000Z","updated":"2022-06-01T12:39:37.612Z","comments":true,"path":"1ffc37519baa/","link":"","permalink":"http://rookieyin.github.io/1ffc37519baa/","excerpt":"B-树 B-树，这里的 B 表示 balance( 平衡的意思),B-树是一种多路自平衡的搜索树（B树是一颗多路平衡查找树） 。它类似普通的平衡二叉树，不同的一点是B-树允许每个节点有更多的子节点。下图是 B-树的简化图：","text":"B-树 B-树，这里的 B 表示 balance( 平衡的意思),B-树是一种多路自平衡的搜索树（B树是一颗多路平衡查找树） 。它类似普通的平衡二叉树，不同的一点是B-树允许每个节点有更多的子节点。下图是 B-树的简化图： B-树有如下特点: 所有键值分布在整颗树中（索引值和具体data都在每个节点里）； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束（最好情况O(1)就能找到数据）； 在关键字全集内做一次查找,性能逼近二分查找； 为什么会出现 B-树这类数据结构？ 传统用来搜索的平衡二叉树有很多，如 AVL 树，红黑树等。这些树在一般情况下查询性能非常好，但当数据非常大的时候它们就无能为力了。原因当数据量非常大时，内存不够用，大部分数据只能存放在磁盘上，只有需要的数据才加载到内存中。一般而言内存访问的时间约为 50 ns，而磁盘在 10 ms 左右。速度相差了近 5 个数量级，磁盘读取时间远远超过了数据在内存中比较的时间。这说明程序大部分时间会阻塞在磁盘 IO 上。那么我们如何提高程序性能？ 减少磁盘 IO 次数，像 AVL 树，红黑树这类平衡二叉树从设计上无法“迎合”磁盘。 B-树，多叉的好处非常明显，有效的降低了B-树的高度，为底数很大的 log n，底数大小与节点的子节点数目有关，一般一棵B-树的高度在 3 层左右。层数低，每个节点区确定的范围更精确，范围缩小的速度越快（比二叉树深层次的搜索肯定快很多）。 B+树 B+树是B-树的变体，也是一种多路搜索树, 它与 B- 树的不同之处在于: 所有关键字存储在叶子节点出现,内部节点(非叶子节点并不存储真正的 data) 为所有叶子结点增加了一个链指针 简化 B+树 如下图： 因为内节点并不存储 data，所以一般B+树的叶节点和内节点大小不同，而B-树的每个节点大小一般是相同的，为一页。 为了增加 区间访问性，一般会对B+树做一些优化，如下图带顺序访问的B+树： B-树 V.S B+树 两者区别 B+树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而B-树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)。 B+树叶节点两两相连可大大增加区间访问性，可使用在范围查询等，而B-树每个节点 key 和 data 在一起，则无法区间查找。 B+树更适合外部存储。由于内节点无 data 域，每个节点能索引的范围更大更精确 由于B树的节点都存了key和data，而B+树只有叶子节点存data，非叶子节点都只是索引值，没有实际的数据，这就时B+树在一次IO里面，能读出的索引值更多。从而减少查询时候需要的IO次数！ InnoDB为什么使用B+树作索引 主要是两个原因： B+树中，非叶子节点不存储数据，只存储键值，和B-树相比，一次IO能拿到更多的节点； B+树叶子节点，按序排列，彼此可以通过指针相连，范围查找、分组排序效率更高。","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"树","slug":"树","permalink":"http://rookieyin.github.io/tags/%E6%A0%91/"}]},{"title":"洗牌算法","slug":"4 算法/洗牌算法","date":"2022-05-05T05:39:48.000Z","updated":"2022-06-01T12:39:00.404Z","comments":true,"path":"8d739821694e/","link":"","permalink":"http://rookieyin.github.io/8d739821694e/","excerpt":"所谓“洗牌算法”，就是把一组序列完全打乱，怎样才算乱呢？需要满足这样一个条件：对于包含n个元素的序列，每个元素出现在每个位置的概率都是1/n1/n1/n。 一种直白的方法就是，统计序列的全排列，然后在全排列集合中随机选取一各排列出来。这种方法虽然简单，但是无论是空间还是时间复杂度都太高了，有没有其他性能更高的算法呢？当然有，本文简单总结下集中常用的洗牌算法。","text":"所谓“洗牌算法”，就是把一组序列完全打乱，怎样才算乱呢？需要满足这样一个条件：对于包含n个元素的序列，每个元素出现在每个位置的概率都是1/n1/n1/n。 一种直白的方法就是，统计序列的全排列，然后在全排列集合中随机选取一各排列出来。这种方法虽然简单，但是无论是空间还是时间复杂度都太高了，有没有其他性能更高的算法呢？当然有，本文简单总结下集中常用的洗牌算法。 Fisher-Yates Shuffle算法 Fisher-Yates Shuffle的思想是：从原始数组中随机取一个之前没有取过的数字放到新数组中，具体步骤如下： 初始化原始数组和新数组，假设数组长度为n； 从原始数组中随机选取之前没选过的数，放到新数组中； 重复第2步，直到所有数字都被选中过； 新数组中的序列就是一个完全随机的序列。 这种方法的正确性也非常容易证明： 证明：对于任意一个元素m被放在位置i的概率=前i−1个位置没有选中m∗第i个位置选中了mP=n−1n×n−2n−1×...×n−i+1n−i+2×1n−i+1=1n\\textbf{证明：}对于任意一个元素m被放在位置i的概率 = 前i-1个位置没有选中m * 第i个位置选中了m \\\\ P = \\frac{n-1}{n}\\times \\frac{n-2}{n-1}\\times ...\\times\\frac{n-i+1}{n-i+2}\\times\\frac{1}{n-i+1} =\\frac{1}{n} 证明：对于任意一个元素m被放在位置i的概率=前i−1个位置没有选中m∗第i个位置选中了mP=nn−1​×n−1n−2​×...×n−i+2n−i+1​×n−i+11​=n1​ 该算法的性能并不高，因为需要维护哪些数字被选中了，哪些没有被选中，时间复杂度为O(n2)O(n^2)O(n2)，空间复杂度为O(n)O(n)O(n)。因此在实际应用中并不常用。 Knuth-Durstenfeld Shuffle算法 该算法是唐纳德在“计算机程序艺术”艺术中提出，是Fisher-Yates Shuffle的改进版本。该算法在原始数组中进行交换操作，不仅省去了额外空间需求，还将时间复杂度降低到了O(n)O(n)O(n)。具体步骤如下： 假设初始数组arr大小为n，下标从0开始； 从0~n-1随机选择一个数k，将arr[k]和arr[n-1]交换； 从0~n-2随机选择一个数k，将arr[k]和arr[n-2]交换； 从0~n-3随机选择一个数k，将arr[k]和arr[n-3]交换； 重复上述步骤直到遍历完整个数组。 下面简单证明一下该算法的正确性： 证明：对于任意arr[i]洗牌后被放置在n−1处概率=第一次就被选中的概率=1/n对于任意arr[i]洗牌后被放置在n−2处概率=第一次没被选中的概率∗第二次被选中的概率=(n−1)/n∗1/(n−1)=1/n...对于任意arr[i]洗牌后被放置在n−k处概率=前k−1次没被选中的概率∗第k次被选总的概率=(n−1)/n∗(n−2)/(n−1)∗...∗(n−k+1)/(n−k+2)∗1/(n−k+1)=1/n\\begin{aligned} 证明： &amp;对于任意arr[i]洗牌后被放置在n-1处概率 = 第一次就被选中的概率 = 1/n\\\\ &amp;对于任意arr[i]洗牌后被放置在n-2处概率 = 第一次没被选中的概率 * 第二次被选中的概率 = (n-1)/n * 1/(n-1) = 1/n\\\\ &amp;...\\\\ &amp;对于任意arr[i]洗牌后被放置在n-k处概率 = 前k-1次没被选中的概率 * 第k次被选总的概率 \\\\ &amp;= (n-1)/n * (n-2)/(n-1) * ... * (n-k+1)/(n-k+2) * 1/(n-k+1) = 1/n \\end{aligned} 证明：​对于任意arr[i]洗牌后被放置在n−1处概率=第一次就被选中的概率=1/n对于任意arr[i]洗牌后被放置在n−2处概率=第一次没被选中的概率∗第二次被选中的概率=(n−1)/n∗1/(n−1)=1/n...对于任意arr[i]洗牌后被放置在n−k处概率=前k−1次没被选中的概率∗第k次被选总的概率=(n−1)/n∗(n−2)/(n−1)∗...∗(n−k+1)/(n−k+2)∗1/(n−k+1)=1/n​ 该算法的优缺点可总结如下： 优点 时间复杂度O(n)，空间复杂度O(1)，效率非常高； 缺点 原始数组被打乱了； 从后往前排序，无法处理不知道长度或者动态增长的数组。 Inside-Out Algorithm算法 Inside-Out算法的基本思想是：将位置i的数据随机插入前i个（包括i）位置中（假设为k），这个操作是在新数组中进行，然后用原始数据中位置k的数字替换新数组位置i的数字。 其实就是从前往后的Knuth-Durstenfeld Shuffle算法，并且操作是在新数组中进行的，不会破坏原始数组。这里用Java简单实现下该算法： 12345678910111213public int[] insideOutShuffle(int[] arr)&#123; int n = arr.length; int[] res = new int[n]; res[0] = arr[0]; Random rand = new Random(); for(int i = 1; i &lt; n; ++i)&#123; int j = rand.nextInt(i+1)-1; //交换res中i和j处的值 res[i] = res[j]; res[j] = arr[i]; &#125; return res;&#125; 下面简单证明下该算法的正确性： 证明：求arr[i]被放在位置k处的概率，(1)当k&lt;=i时，arr[i]被放在k位置的概率=在第i次选中k的概率∗后面n−i次都没选中k=1i∗ii+1∗...∗n−1n=1n(2)当k&gt;i时，arr[i]被放在k位置的概率=arr[i]在第k次被选中的概率∗后面n−k次都没被选中arr[i]的概率=1k∗kk+1∗k+1k+2∗...∗n−1n=1n\\begin{aligned} 证明：&amp;求arr[i]被放在位置k处的概率，\\\\ (1) &amp;当k&lt;=i时，arr[i]被放在k位置的概率 = 在第i次选中k的概率 * 后面n-i次都没选中k \\\\ &amp;= \\frac{1}{i} * \\frac{i}{i+1} * ... * \\frac{n-1}{n} = \\frac{1}{n}\\\\ (2) &amp;当k&gt;i时，arr[i]被放在k位置的概率 = arr[i]在第k次被选中的概率 * 后面n-k次都没被选中arr[i]的概率 \\\\ &amp;= \\frac{1}{k}*\\frac{k}{k+1}*\\frac{k+1}{k+2}* ... *\\frac{n-1}{n} = \\frac{1}{n} \\end{aligned} 证明：(1)(2)​求arr[i]被放在位置k处的概率，当k&lt;=i时，arr[i]被放在k位置的概率=在第i次选中k的概率∗后面n−i次都没选中k=i1​∗i+1i​∗...∗nn−1​=n1​当k&gt;i时，arr[i]被放在k位置的概率=arr[i]在第k次被选中的概率∗后面n−k次都没被选中arr[i]的概率=k1​∗k+1k​∗k+2k+1​∗...∗nn−1​=n1​​ 另外，该算法由于是从前往后，因此适用于数组长度未知或者会动态增强的情况。 蓄水池抽样 问题是这样的： 给定一个数据流，数据流长度N很大，且N直到处理完所有数据之前都不可知，请问如何在只遍历一遍数据（O(N)）的情况下，能够随机选取出m个不重复的数据。 该问题有3个核心点： 数据流长度N很大且不可知，所以不能一次性存入内存； 时间复杂度为O(N)； 随机选取m个数，每个数被选中的概率为m/N。 蓄水池抽样算法的核心代码如下： 1234567891011121314int[] reservoir = new int[m];//蓄水池大小为m// 初始化，将0~m-1处元素放到数组中for (int i = 0; i &lt; reservoir.length; i++)&#123; reservoir[i] = dataStream[i];&#125;for (int i = m; i &lt; dataStream.length; i++)&#123; // 随机获得一个[0, i]内的随机整数 int d = rand.nextInt(i + 1); // 如果随机整数落在[0, m-1]范围内，则替换蓄水池中的元素 if (d &lt; m)&#123; reservoir[d] = dataStream[i]; &#125;&#125; 下面我们简单证明一下该算法的正确性： 证明：第i个元素被保留的概率=第i个数据进入过蓄水池的概率∗之后N−i次操作没有把第i个数据替换出去的概率(1)对于0&lt;i&lt;m，被选中的概率=1∗后面N−m次操作都没有把i替换出去的概率(1.1)第m+1次操作，替换i的概率=1m+1，不替换的概率=1−1m+1=mm+1(1.2)第m+2次操作，替换i的概率=1m+2，不替换的概率=1−1m+2=m+1m+2(1.3)以此类推，第N次操作，替换i的概率=1N，不替换的概率=1−1N=N−1N(1.4)这样，对于0&lt;i&lt;m，被选中概率=mm+1×m+1m+2×...×N−1N=mN(2)对于i≥m，被选中的概率=mi×(1−1i+1)×(1−1i+2)×...×(1−1N)=mi×ii+1×i+1i+2×...×N−1N=mN+1\\begin{aligned} 证明：&amp;第i个元素被保留的概率 = 第i个数据进入过蓄水池的概率 * 之后N-i次操作没有把第i个数据替换出去的概率\\\\ (1)&amp;对于0 &lt; i &lt; m，被选中的概率 = 1 * 后面N-m次操作都没有把i替换出去的概率\\\\ (1.1)&amp;第m+1次操作，替换i的概率 = \\frac{1}{m+1}，不替换的概率 = 1 - \\frac{1}{m+1} = \\frac{m}{m+1}\\\\ (1.2)&amp;第m+2次操作，替换i的概率 = \\frac{1}{m+2}，不替换的概率 = 1 - \\frac{1}{m+2} = \\frac{m+1}{m+2}\\\\ (1.3)&amp;以此类推，第N次操作，替换i的概率 = \\frac{1}{N}，不替换的概率 = 1 - \\frac{1}{N} = \\frac{N-1}{N}\\\\ (1.4)&amp;这样，对于0&lt;i&lt;m，被选中概率 = \\frac{m}{m+1}\\times\\frac{m+1}{m+2}\\times...\\times\\frac{N-1}{N} = \\frac{m}{N}\\\\ (2)&amp;对于i \\geq m，被选中的概率 = \\frac{m}{i} \\times (1-\\frac{1}{i+1}) \\times (1-\\frac{1}{i+2}) \\times...\\times(1-\\frac{1}{N})=\\frac{m}{i}\\times\\frac{i}{i+1}\\times\\frac{i+1}{i+2}\\times ... \\times \\frac{N-1}{N} = \\frac{m}{N+1} \\end{aligned} 证明：(1)(1.1)(1.2)(1.3)(1.4)(2)​第i个元素被保留的概率=第i个数据进入过蓄水池的概率∗之后N−i次操作没有把第i个数据替换出去的概率对于0&lt;i&lt;m，被选中的概率=1∗后面N−m次操作都没有把i替换出去的概率第m+1次操作，替换i的概率=m+11​，不替换的概率=1−m+11​=m+1m​第m+2次操作，替换i的概率=m+21​，不替换的概率=1−m+21​=m+2m+1​以此类推，第N次操作，替换i的概率=N1​，不替换的概率=1−N1​=NN−1​这样，对于0&lt;i&lt;m，被选中概率=m+1m​×m+2m+1​×...×NN−1​=Nm​对于i≥m，被选中的概率=im​×(1−i+11​)×(1−i+21​)×...×(1−N1​)=im​×i+1i​×i+2i+1​×...×NN−1​=N+1m​​ 分布式蓄水池抽样 一块CPU的计算能力再强，也总有内存和磁盘IO拖他的后腿。因此为提高数据吞吐量，分布式的硬件搭配软件是现在的主流。 如果遇到超大的数据量，即使是O(N)的时间复杂度，蓄水池抽样程序完成抽样任务也将耗时很久。因此分布式的蓄水池抽样算法应运而生。运作原理如下： 假设有K台机器，将大数据集分成K个数据流，每台机器使用单机版蓄水池抽样处理一个数据流，抽样m个数据，并最后记录处理的数据量为N1,N2,...,NkN_1, N_2, ..., N_kN1​,N2​,...,Nk​, (假设m&lt;Nkm&lt;N_km&lt;Nk​)。N1+N2+...+NK=NN_1+N_2+...+N_K=NN1​+N2​+...+NK​=N。 取[1, N]一个随机数d，若d&lt;N1d&lt;N_1d&lt;N1​，则在第一台机器的蓄水池中等概率不放回地（1/m）选取一个数据；若N1&lt;=d&lt;(N1+N2)N_1&lt;=d&lt;(N_1+N_2)N1​&lt;=d&lt;(N1​+N2​)，则在第二台机器的蓄水池中等概率不放回地选取一个数据；依次类推，重复m次，则最终从N大数据集中选出m个数据。 m/N的概率验证如下： 第k台机器中的蓄水池数据被选取的概率为m/Nkm/N_km/Nk​。 从第k台机器的蓄水池中选取一个数据放进最终蓄水池的概率为Nk/NN_k/NNk​/N。 第k台机器蓄水池的一个数据被选中的概率为1/m。（不放回选取时等概率的） 重复m次选取，则每个数据被选中的概率为m×(m/Nk×Nk/N×1/m)=m/Nm\\times(m/N_k\\times N_k/N\\times 1/m)=m/Nm×(m/Nk​×Nk​/N×1/m)=m/N。 参考资料 https://blog.csdn.net/qq_26399665/article/details/79831490 https://www.jianshu.com/p/7a9ea6ece2af","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"随机化","slug":"随机化","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E5%8C%96/"}]},{"title":"拓扑排序","slug":"4 算法/拓扑排序","date":"2022-05-04T05:39:48.000Z","updated":"2022-06-01T12:38:02.867Z","comments":true,"path":"3da51d7b8480/","link":"","permalink":"http://rookieyin.github.io/3da51d7b8480/","excerpt":"概述 拓扑排序，我的理解就是：有向图中所有节点的一种排列，这个排列需要满足下面两个条件： 序列包含图中所有节点，且每个节点只出现一次； 若A在序列中排在B的前面，则图中不存在从B到A的路径。","text":"概述 拓扑排序，我的理解就是：有向图中所有节点的一种排列，这个排列需要满足下面两个条件： 序列包含图中所有节点，且每个节点只出现一次； 若A在序列中排在B的前面，则图中不存在从B到A的路径。 从拓扑排序的定义，我们不难推断出下面的结论： 当且仅当图中没有环时，即有向无环图，才有拓扑排序； 任何有向无环图，至少有一个拓扑排序。 对于有向无环图，有两种经典算法，可以求出它的拓扑排序：卡恩算法和深度优先搜索。其中卡恩算法可以理解成广度优先搜索，下面详细介绍下这两种算法的实现。 经典算法 卡恩算法 卡恩在1962年提出了该算法，很好理解，类似于广度优先搜索，大概思路如下： 假设D为存储了所有节点的入度，用集合S存储所有入度为0的节点，L用来存储所有排好序的列表。首先将S中所有节点添加到L的尾部，同时更新和S中节点相关联的其他节点的入度，然后再将更新后入度为0的节点加入S中，重复上述步骤。 下面是来自维基百科的伪代码。 1234567891011L ← 包含已排序的元素的列表，目前为空S ← 入度为零的节点的集合当 S 非空时： 将节点n从S移走 将n加到L尾部 选出任意起点为n的边e = (n,m)，移除e。如m没有其它入边，则将m加入S。 重复上一步。如图中有剩余的边则： return error (图中至少有一个环)否则： return L (L为图的拓扑排序) 光看思路可能不好理解，下图展示了卡恩算法的大致流程： 看到这里，我们已经清楚了卡恩算法的思想和具体实现细节，下面我用java来重述一下如何实现卡恩算法。 1234567891011121314151617181920212223242526//节点入度数组，大小为节点数量int[] degree = new int[n];//类似邻接矩阵，用来记录图中的边，比如节点1指向2和4，可以记录为&#123;1:[2,4]&#125;。也可以用二维数组来记录HashMap&lt;Integer, List&lt;Integer&gt;&gt; edges = new HashMap&lt;&gt;();//记录入度为0的节点，这里用队列Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();for(int i = 0; i &lt; n; ++i)&#123; //所有入度为0的节点放到队列中 if(degree[i] == 0) queue.offer(i);&#125;int count = 0;//记录节点数量，可以用来判断图是否有环int[] topo = new int[n];//记录拓扑排序序列while(!queue.isEmpty())&#123; int node = queue.poll(); topo[count++] = node; if(edges.containsKey(node))&#123; //去掉节点node，更新所有和node相邻的节点的入度 for(Integer item : map.get(node))&#123; degree[item]--; //如果节点入度变为0，将它加入队列中 if(degree[item] == 0) queue.offer(item); &#125; &#125;&#125; 深度优先搜索 另一种拓扑排序的方法是深度优先搜索，卡恩算法是从前往后依次确定拓扑排序中每个节点，深度优先算法则相反，它是从后往前确定序列中每个节点的，也就是先找到那些没有后继节点的节点，把它们放到序列尾部，然后继续搜索。下面是维基百科中给出的伪代码： 123456789101112131415L ← 包含已排序的元素的列表，目前为空当图中存在未永久标记的节点时： 选出任何未永久标记的节点n visit(n)function visit(节点 n) 如n已有永久标记： return 如n已有临时标记： stop (不是定向无环图) 将n临时标记 选出以n为起点的边(n,m)，visit(m) 重复上一步 去掉n的临时标记 将n永久标记 将n加到L的起始 上面的动图展示了DFS的标记过程，下面我们用Java代码进行简单实现： 12345678910111213141516171819202122232425262728//用一个map存储边信息Map&lt;Integer, List&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;();//用flag数组进行深度搜索，0表示未访问，1表示dfs过程的临时标记，2表示节点以加入拓扑序列int[] flag = new int[n];//记录拓扑序列int[] topo = new int[n];for(int i = 0; i &lt; n; ++i)&#123; if(flag[i] == 0) dfs(i, flag, map);&#125;public void dfs(int node, int[] flag, Map&lt;Integer, List&lt;Integer&gt;&gt; map)&#123; //节点已经加入拓扑序列 if(flag[node] == 2) return; flag[node] = 1; if(map.containsKey(node))&#123; for(int item : map.get(node))&#123; //存在环，退出 if(flag[item] == 1) return; dfs(item, flag, map); &#125; &#125; //节点加入拓扑序列中 flag[node] = 2; topo[count++] = node;&#125; 拓扑排序实战 拓扑排序相关的常见问题有一下几种： 给定无向图，让你判断图中是否有环，判断拓扑序列中元素个数是否等于节点个数。 207. 课程表 给定无向图，让你输出任意一种拓扑序列，卡恩算法或者深度优先遍历即可。 210. 课程表 II 给定无向图，问a节点是否是b节点的先序（DFS的话用逆邻接矩阵比较方便，问题转化成a是否在b的先序节点集合中）。 BFS需要额外加一个Map&lt;Integer, Set&lt;Integer&gt;&gt; map记录每个节点的前置节点集合。 1462. 课程表 IV","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"图","slug":"图","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE/"}]},{"title":"平衡二叉树","slug":"4 算法/平衡二叉树","date":"2022-05-03T05:39:48.000Z","updated":"2022-06-01T12:37:18.002Z","comments":true,"path":"325f8721ea9c/","link":"","permalink":"http://rookieyin.github.io/325f8721ea9c/","excerpt":"平衡二叉树（Balanced Binary Tree）具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。 最小二叉平衡树的节点的公式如下 F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。","text":"平衡二叉树（Balanced Binary Tree）具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。 最小二叉平衡树的节点的公式如下 F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 AVL树 AVL树是高度平衡的二叉树。它的特点是: AVL树中任何节点的两个子树的高度最大差别为1。 节点插入 当插入节点导致二叉树失去平衡时，可以概括为4个状态： LL：表示高度失衡节点的左子树的左孩子导致左子树比右子树高度大2，AVL树失去平衡； LR：表示高度失衡节点的左子树的右孩子导致左子树比右子树高度大2，AVL树失去平衡； RR：表示高度失衡节点的右子树的右孩子导致右子树比左子树高度大2，AVL树失去平衡； RL：表示高度失衡节点的右子树的左孩子导致右子树比左子树高度大2，AVL树失去平衡。 当AVL树发生上述4中失衡时，需要对应使用4种类型旋转，调整AVL树，使其重新保持平衡状态： LL单旋：树往右单旋 RR单旋：树往左单旋 LR双旋：先左子树RR单旋，然后整棵树LL单旋 RL双旋：先右子树LL单旋，然后整棵树RR单旋 节点删除 AVL树删除节点的过程是，先找到该节点，然后进行删除。由于删除节点的位置不同，导致删除后节点进行移动的方式不同。删除节点的位置分为以下4类： 叶子节点：直接删除即可，然后依次向上调整为AVL树 只有左孩子的非叶子节点：该节点值替换为左孩子节点，删除左孩子，然后依次向上调整为AVL树 只有右孩子的非叶子节点：该节点值替换为右孩子节点，删除右孩子，然后依次向上调整为AVL树 有左右孩子的非叶子节点：该节点的值替换前驱（左孩子）节点，删除前驱节点（最终状态变成1、2、3中的一个）。 红黑树 红黑树是一棵二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是RED,也可以是BLACK；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。 它必须满足下面性质： 根节点是黑色的； 每个节点非红即黑； 所有叶子节点都是（NIL），为黑色； 如果1个节点红色的，那么它的两个子节点就是黑色的，即没有连续红节点； 任意节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点。 节点插入 红黑树插入节点时需要遵循以下原则： 插入的结点一定是红色的，如果为黑色，会破坏性质5； 如果插入的是根节点，将颜色改为黑色； 如果插入节点的父节点是黑色，则插入完成； 如果插入节点的父节点是红色，则需要修复，且继续向上调整，直到为根或满足规则； 如果根修改之后为红色，一定要改成黑色。 因此，插入节点时最复杂的操作就是出现“红红”时（上述第4条）怎么修复红黑树。 修复方法 前提条件： 插入的结点（cur）是红色，cur的父结点（parent）是红色的，这样的需要修复。 修复要点： 保证修复操作前和修复操作后的黑色结点的数量不变。 可推断出： cur 的祖父结点即父亲的父亲（grandpa）一定是黑色，否则插入当前结点之前已经违反了红黑树的规则 下面对cur节点的uncle节点进行分情况讨论 情况1：uncle存在，并且uncle的颜色是红色 修复方法：grandpa 由黑变红，parent &amp; uncle 由红变黑 。如下图所示： 情况2：uncle不存在，或者uncle存在但是颜色为黑色** 情况2.1：cur是parent的左孩子，且parent是grandpa的左孩子 修复方法： grandpa 右旋之后颜色变为红色，parent 的颜色变为黑色。如下图所示： 情况2.2：cur是parent的右孩子，且parent是grandpa的右孩子** 修复方法：grandpa 左旋后颜色变为红色，parent 颜色变为黑色。如下图所示： 情况2.3：cur是parent的右孩子，且parent是grandpa的左孩子 修复方法：对 parent 左旋之后将 parent 和 cur 的名称交换，再按照2.1的情况处理。如下图所示： 情况2.4：cur是parent的左孩子，且parent是grandpa的右孩子 修复方法：对 parent 右旋之后将 parent 和 cur 的名称交换，再按照2.2的情况处理。如下图所示： 节点删除 和AVL树类似，红黑树删除节点也分三种情况： 删除节点为叶子节点 节点为红色：无需修复，不会破坏红黑树任何性质。 节点为黑色：需要修复，破坏红黑树性质5。 删除节点为非叶子节点 有1个子节点：将删除节点与子节点值交换，删除子节点，此时情况转变成第1种（删除叶子节点） 有2个子节点：将删除节点值与其后继节点值（前驱也可以）交换，删除后继节点，此时有一下两种情况： 后继节点是叶子节点：情况转变成第1种 后继节点有1个子节点：情况变成第2种下的第1种 后继节点有2个子节点：情况变成第2种下的第2种 可以发现删除的所有情况最终都可以转变成第1种。在第1种情况下，节点为红色时无需修复，节点为黑色是需要修复，因此我们只需要关注这一种情况即可。 修复方法 前提条件：删除节点为叶子节点，且颜色为黑色 修复要点：保证修复操作前和修复操作后的黑色结点的数量不变。 可推断出：被删除节点一定有兄弟节点 修复：下面对兄弟节点的颜色分情况讨论（下图中所有黑色方框null表示被删除节点） 情况1：兄弟节点为黑色 情况1.1：兄弟节点为黑色，且有一个与其方向一致的红色子节点 情况1.2：兄弟节点为黑色，且有一个与其方向不一致的红色子节点 情况1.3：兄弟节点为黑色，且没有红色子节点（也不可能有黑色子节点，否则原红黑树不平衡） 情况2：兄弟节点为红色，则其父节点必为黑色（否则红红相连） 图(i)中将brother和father旋转，重新上色后，变成了图(j)，新的brother（原来的son）变成了黑色，这样就变成了情况1。 参考资料 https://blog.csdn.net/qq_21388535/article/details/105601270 https://blog.csdn.net/jinking01/article/details/106020347 https://pdai.tech/md/algorithm/alg-basic-tree-balance.html https://blog.csdn.net/qq_40843865/article/details/102498310","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"二叉树","slug":"二叉树","permalink":"http://rookieyin.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"并查集","slug":"4 算法/并查集","date":"2022-05-03T05:39:48.000Z","updated":"2022-06-01T12:33:14.785Z","comments":true,"path":"14bdfa95fb86/","link":"","permalink":"http://rookieyin.github.io/14bdfa95fb86/","excerpt":"并查集，是一种高级数据结构，常用于数据分组问题。本文简单介绍一下并查集相关概念以及实现方法，并附带一些leetcode练习题。","text":"并查集，是一种高级数据结构，常用于数据分组问题。本文简单介绍一下并查集相关概念以及实现方法，并附带一些leetcode练习题。 并查集基本知识 并查集，和堆十分类似，两者本质上描述的都是一种树状数据结构。不过堆是一棵树，而并查集表示的是一个森林。森林中的每棵树（也叫连通分量）可以看作一个分组，因此常被用于数据分组问题。 底层数据结构：和堆一样，不需要实际定义树结构，依赖数组就可以实现并查集 parent数组：记录每个元素的parent下标。 index数组：记录每个元素在数组中的下标。 比如，下图展示了parent数组和index数组构成的一个森林，由2棵树构成： 操作：并查集主要支持2种操作，合并和查询 查询：find(int x)，查询x节点所在树的根节点，下面给出基本版本的查询操作 123456public int find(int x)&#123; //一直往上，直到根节点 while(x != parent[x]) x = parent[x]; return x;&#125; 合并：union(int x, int y)，把x和y所在的两棵树合并到一起，下面给出基本版本的合并操作 1234567public void union(int x, int y)&#123; int rootX = find(x); int rootY=find(y); if(rootX == rootY) return; //把x所在树的根节点的父亲，设置成y所在树的根节点 parent[rootX] = rootY;&#125; 并查集进阶 从前面的介绍中，我们知道find()的效率和树的高度有关，树越高，查询效率越低。 如果 union 操作直接将两棵树合并，那么多次 union 之后，树的高度可能会很高，那该如何对其进行优化呢？主要有两种优化方式，那就是路径压缩和按秩合并，路径压缩是在 find 方法里进行，而按秩合并则是在 union 方法中进行。 路径压缩 路径压缩又有两种方式：隔代压缩和彻底压缩 「隔代压缩」性能比较高，虽然压缩不完全，不过多次执行「隔代压缩」也能达到比较好的效果，只需要在原 find 方法中加上一句parent[x] = parent[parent[x]];这句代码的意思是把路径上的每个节点的父节点指向其祖父节点。 「彻底压缩」需要借助系统栈，使用递归的写法 。或者使用迭代写法，先找到当前结点的根结点，然后把沿途上所有的节点都指向根节点，需要遍历两次。彻底压缩需要消耗更多的性能，但是压缩的更彻底，可以提高查询效率。 按秩合并 所谓按秩，可以理解成树的高度，合并的时候，把矮树合并到高树上面。那具体要怎么实现呢？ 我们用一个rank数组，表示每个元素作为根节点时，树的高度。我们将rank中所有元素初始化为1，合并时，比较两个根节点的rank值，把rank较小的往较大者上合并。按秩合并的代码实现如下： 123456789101112131415 /**按秩合并*/public void union(int x, int y) &#123; int rootX = find(x), rootY = find(y); if (rootX == rootY) return; //把高度小的合并到高度大的树上 if (ranks[rootX] &gt; ranks[rootY]) &#123; parent[rootY] = rootX; &#125; else if (ranks[rootX] &lt; ranks[rootY]) &#123; parent[rootX] = rootY; &#125; else &#123;//高度一样，随便怎么合并都行，高度+1 parent[rootY] = rootX; ranks[rootX]++; &#125; count--;&#125; 练习题 基础题 547. 省份数量：给定若干个城市，相连的城市属于同一个省份，问一共有多少个省份。其实就是求连通分量的个数。 990. 等式方程的可满足性：给定一个由表示变量之间关系（==或者!=）的字符串方程组成的数组，判断这些方程能否同时满足。其实就是判断不等式左右2个节点是否在同一个连通分量。 684. 冗余连接：环路检测，添加边的时候，如果两个节点已经存在于同一个连通分量，这条边就是冗余的。 1319. 连通网络的操作次数：同上，环路检测，添加边的时候，判断节点是否存在于同一个连通分量。 200. 岛屿数量：这题用DFS比较简单，并查集解法不容易发现。把边界相连的O放到同一个连通分量。 进阶题 这些题并不是“并查集”的实现上有多难，难在于“比较难看出怎么将原始问题转换成直观的并查集问题”。 685. 冗余连接 II ：和冗余连接1类似，不过换成了有向图，变得更加复杂，需要分情况讨论。 778. 水位上升的泳池中游泳：并查集解法比较难想，对路径最大值进行二分衍生出并查集解法，问题转化成“遍历0~max，对于0 &lt; threshold &lt;= max，判断左上角和右下角是否在一个连通图中” 参考资料 https://segmentfault.com/a/1190000022952886","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"并查集","slug":"并查集","permalink":"http://rookieyin.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"}]},{"title":"链表排序","slug":"4 算法/链表排序","date":"2022-05-02T05:39:48.000Z","updated":"2022-06-01T12:25:22.060Z","comments":true,"path":"f106f4426061/","link":"","permalink":"http://rookieyin.github.io/f106f4426061/","excerpt":"148. 排序链表的最优方法应该是归并排序，鉴于面试时候经常会问链表快排，本文简单总结下链表排序的归并和快排方法。至于插入排序或者冒泡排序什么的，比较简单，本文不作介绍。","text":"148. 排序链表的最优方法应该是归并排序，鉴于面试时候经常会问链表快排，本文简单总结下链表排序的归并和快排方法。至于插入排序或者冒泡排序什么的，比较简单，本文不作介绍。 归并排序 自顶向下：采用递归方式进行归并，空间复杂度O(lg n) 123456789101112131415161718192021222324252627282930313233public ListNode sortList(ListNode head) &#123; if(head == null || head.next == null) return head; //归并 ListNode vir = new ListNode(); vir.next = head; ListNode fast = vir, slow = vir; //快慢指针找中点，这里借助虚拟节点，边界处理起来容易一点 while(fast != null &amp;&amp; fast.next != null)&#123; fast = fast.next.next; slow = slow.next; &#125; ListNode p1 = sortList(slow.next); slow.next = null; ListNode p2 = sortList(head); return merge2List(p1, p2);&#125;//合并两个有序链表public ListNode merge2List(ListNode head1, ListNode head2)&#123; ListNode vir = new ListNode(), point = vir; while(head1 != null &amp;&amp; head2 != null)&#123; if(head1.val &lt; head2.val)&#123; point.next = head1; head1 = head1.next; &#125;else&#123; point.next = head2; head2 = head2.next; &#125; point = point.next; &#125; point.next = head1 == null ? head2 : head1; return vir.next;&#125; 自底向上：用sublength辅助，采用非递归方式进行归并，空间复杂度O(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ListNode sortList(ListNode head) &#123; if(head == null || head.next == null) return head; //自底向上非递归 归并 int length = 0; ListNode point = head; while(point != null)&#123; length++; point = point.next; &#125; ListNode vir = new ListNode(0, head), prev = vir; //sublength，每次乘以2 for(int sublength = 1; sublength &lt; length; sublength &lt;&lt;= 1)&#123; prev = vir; while(prev.next != null)&#123; //head1,tail1,head2,tail2分别表示要合并的两个链表的头尾节点 ListNode head1 = prev.next, tail1 = prev; for(int i = 0; i &lt; sublength &amp;&amp; tail1.next != null; ++i)&#123; tail1 = tail1.next; &#125; ListNode head2 = tail1.next, tail2 = tail1; for(int i = 0; i &lt; sublength &amp;&amp; tail2.next != null; ++i)&#123; tail2 = tail2.next; &#125; //把两个链表完全切开，然后调用merge2List tail1.next = null; ListNode temp = tail2.next; tail2.next = null; ListNode[] nodes = merge2List(head1, head2); //合并好的链表再放回原链表 prev.next = nodes[0]; nodes[1].next = temp; prev = nodes[1]; &#125; &#125; return vir.next;&#125;//合并两个有序链表，这里额外返回一个链表尾部public ListNode[] merge2List(ListNode head1, ListNode head2)&#123; ListNode vir = new ListNode(), point = vir; while(head1 != null &amp;&amp; head2 != null)&#123; if(head1.val &lt; head2.val)&#123; point.next = head1; head1 = head1.next; &#125;else&#123; point.next = head2; head2 = head2.next; &#125; point = point.next; &#125; point.next = head1 == null ? head2 : head1; while(point.next != null) point = point.next; return new ListNode[]&#123;vir.next, point&#125;;&#125; 快速排序 快排需要注意两点： 递归时要同时用到head和tail，每次去除pivot节点，否则容易陷入死循环 可以考虑加上随机化算法，即随机在head~tail之间选择一个节点和head交换。本文将head和中点交换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public ListNode sortList(ListNode head)&#123; if(head==null||head.next==null) return head; // 没有条件，创造条件。自己添加头节点，最后返回时去掉即可。 ListNode newHead=new ListNode(-1); newHead.next=head; return quickSort(newHead,null);&#125;// 带头结点的链表快速排序private ListNode quickSort(ListNode head,ListNode end)&#123; if (head==end||head.next==end||head.next.next==end) return head; randHead(head, end); // 将小于划分点的值存储在临时链表中 ListNode tmpHead=new ListNode(-1); // partition为划分点，p为链表指针，tp为临时链表指针 ListNode partition=head.next,p=partition,tp=tmpHead; // 将小于划分点的结点放到临时链表中 while (p.next!=end)&#123; if (p.next.val&lt;partition.val)&#123; tp.next=p.next; tp=tp.next; p.next=p.next.next; &#125;else &#123; p=p.next; &#125; &#125; // 合并临时链表和原链表，将原链表接到临时链表后面即可 tp.next=head.next; // 将临时链表插回原链表，注意是插回！（不做这一步在对右半部分处理时就断链了） head.next=tmpHead.next; quickSort(head,partition); quickSort(partition,end); // 题目要求不带头节点，返回结果时去除 return head.next;&#125;private void randHead(ListNode head,ListNode end)&#123; int length = 0; ListNode slow=head, fast = head; while(fast != end &amp;&amp; fast.next != end)&#123; slow = slow.next; fast = fast.next.next; &#125; ListNode node1 = head.next, node2 = slow.next; head.next = node2; slow.next = node1; ListNode temp = node2.next; node2.next = node1.next; node1.next = temp;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"链表","slug":"链表","permalink":"http://rookieyin.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"01背包问题总结","slug":"4 算法/01背包问题总结","date":"2022-04-19T05:39:48.000Z","updated":"2022-06-01T12:31:08.799Z","comments":true,"path":"a66897223478/","link":"","permalink":"http://rookieyin.github.io/a66897223478/","excerpt":"最近刷leetcode过程中遇到了很多背包问题，趁此机会总结下如何用动态规划解决背包问题及其各种变体。 写在前面： 本文适合有一定dp基础的读者阅读，用来复习回顾背包相关问题，遇到类似问题可快速秒掉。","text":"最近刷leetcode过程中遇到了很多背包问题，趁此机会总结下如何用动态规划解决背包问题及其各种变体。 写在前面： 本文适合有一定dp基础的读者阅读，用来复习回顾背包相关问题，遇到类似问题可快速秒掉。 基础描述： 给定一个容量大小为W的背包，和一系列物品，物品有价值和获取代价。 问题分类： 0/1背包问题 416. 分割等和子集：物品有限，能否装满 494. 目标和：转换后变成，物品有限，能否装满 1049. 最后一块石头的重量 II：其实和416分割等和子集一样，只不过比较难看出来 完全背包问题 322. 零钱兑换：装满的同时，物品数量最少 518. 零钱兑换 II：装满组合数（注意不是排列数，2/2/1等价于2/1/2） 377. 组合总和 Ⅳ：装满排列数 70. 爬楼梯：装满排列数 746. 使用最小花费爬楼梯：装满，代价最小 面试题 08.01. 三步问题：装满排列数 983. 最低票价：和零钱兑换类似 279. 完全平方数：装满，数量最少 多重背包问题 leetcode上暂时没有遇到！ 分组背包问题 1155. 掷骰子的N种方法：每种物品数量若干个，装满方案数 二维费用背包 474. 一和零：两种费用，背包最多装多少 问法分类： 最大价值：不超过背包容量或获取代价，获取物品的最大价值。 最小代价：装满背包，代价最小 最小数量：装满背包，物品数量最少 能否装满：物品没有价值属性，重量即为代价，能否装满背包。 装满方案数：物品有各自重量，把背包装满的方案数。这种问法还有两个细分情景： 排列数：1,2,3和1,3,2属于同一种方案。 组合数：1,2,3和1,3,2属于不同种方案。 算法模板： 不同问法的模板基本一样，这里以“最大价值”问法为例，总结各种类型问题的模板。其他问法模板类似，只不过需要把max改成min或者计数或者boolean的与、或之类的。 0/1背包问题：指物品数量有限，有N件物品，容量为V的背包。 思路： dp[i][v]dp[i][v]dp[i][v] 表示从前i件物品中取出重量为v的物品的最大价值，那么我们dp[N][V]dp[N] [V]dp[N][V]就是我们最终要的答案。 状态转移方程：对于第i件物品，我们可以要，也可以不要： 要第i件物品：那么dp[i][v]=dp[i−1][v−w[i]]+val[i]dp[i][v]= dp[i-1][v-w[i]]+val[i]dp[i][v]=dp[i−1][v−w[i]]+val[i] 不要第i件物品：那么dp[i][v]=dp[i−1][v]dp[i][v]= dp[i-1][v]dp[i][v]=dp[i−1][v] 我们两者取其大，则得到dp[i][v]=max{dp[i−1][v],dp[i−1][v−w[i]]+val[i]}dp[i] [v] = max\\{dp[i-1] [v], dp[i-1] [v-w[i]]+val[i]\\}dp[i][v]=max{dp[i−1][v],dp[i−1][v−w[i]]+val[i]}。 代码模板 从前面状态转移方程来看需要建立一个二维数组，但是利用滚动数组（因为更新dp[i][∗]dp[i] [*]dp[i][∗]的时候，只用到了dp[i−1][∗]dp[i-1] [*]dp[i−1][∗]的值），一维数组即可解决该问题： 12345678int[] dp = new int[V+1];for(int i = 0; i &lt; N; ++i)&#123; //为什么从后往前？因为dp[i][v]计算过程中用到了dp[i-1][v-w[i]] //v-w[i]一定小于v，从后往前保证用到的dp[v-w[i]]属于上一层的 for(int v = V; v-w[i] &gt;= 0; --v)&#123; dp[v] = Math.max(dp[v], dp[v-w[i]]+val[i]); &#125;&#125; 完全背包问题：指物品数量无限，有N种物品，可任意取用，容量为V的背包。 思路：在0/1背包中，因为物品数量有限，我们是从物品角度分析的，即：对于某一件物品要或者不要，它对某一容量背包的影响。但是在完全背包中物品数量无限，我们就需要从背包容量角度分析。其实就是dp的第一个维度由物品转变成背包容量。 状态转移方程：这里我的思路和很多博客上给的不太一样，我们用一维dp来搞定完全背包问题。 现在这样思考：假设背包容量为v时，在某个方案下，获得物品的价值最高。这个方案的最后一步拿到的物品k，那么是不是应当有dp[v]=max{dp[v−w[k]],0&lt;k&lt;N且v−w[k]&gt;=0}dp[v]=max\\{dp[v-w[k]], 0&lt;k&lt;N且v-w[k]&gt;=0\\}dp[v]=max{dp[v−w[k]],0&lt;k&lt;N且v−w[k]&gt;=0}。 代码模板 123456789int[] dp = new int[V+1];for(int v = 1; v &lt;= V; ++v)&#123; //遍历所有物品种类 for(int i = 0； i &lt; N; ++i)&#123; if(v - w[i] &gt;= 0)&#123; dp[v] = Math.max(dp[v], dp[v-w[i]]+val[i]); &#125; &#125;&#125; 多重背包问题：所谓多重背包就是：一共有N种物品，每个物品有n[i]件。 这各问题和0/1背包的解法也是基本一样。有两种方案： 方案1：把物品展开，这样一共有n[0]件物品0，n[1]件物品1，以此类推，这样就完全转换成0/1背包问题了 方案2：在0/1背包的两重循环之间加一重循环，这样第一重循环表示物品种类，第二重循环表示每种物品的数量，第三种循环表示背包容量。 对于这两种方案的状态转移方程和代码模板，本文不作过多叙述了。 分组背包问题：有N件物品，和一个容量为V的背包。这些物品被分成若干组，每组中物品只能选一个，求最大价值。可参考1155. 掷骰子的N种方法。 思路：这种类型问题，可以顺着0/1背包的思路来，把每一组当做0/1背包中的一件物品。在0/1背包中，我们直接拿物品来更新状态，现在由于“物品”是一组物品，因此需要在循环最内部加一重循环，遍历这个组中所有物品。 状态转移方程：dp[i][v]=max{dp[i−1][v],dp[i−1][v−w[k]]+val[i] ∣ 物品k属于第i组}dp[i] [v] = max\\{dp[i-1] [v], dp[i-1] [v-w[k]]+val[i]\\ |\\ 物品k属于第i组\\}dp[i][v]=max{dp[i−1][v],dp[i−1][v−w[k]]+val[i] ∣ 物品k属于第i组} 代码模板：和0/1背包一样，只不过最内层加一重遍历分组的循环。 1234567891011int[] dp = new int[V+1];//N表示分组数量for(int i = 0; i &lt; N; ++i)&#123; //为什么从后往前？因为dp[i][v]计算过程中用到了dp[i-1][v-w[i]] //v-w[i]一定小于v，从后往前保证用到的dp[v-w[i]]属于上一层的 for(int v = V; v-w[i] &gt;= 0; --v)&#123; //遍历分组i for(int k = 0; k &lt; K; ++k) dp[v] = Math.max(dp[v], dp[v-w[k]]+val[k]); &#125;&#125; 二维费用背包：每个物品的有两种代价，两种代价都不能超过背包允许的总代价，求可获取物品的最大价值。可参考这一题474. 一和零。这里以0/1背包为例，完全背包解法类似。 思路：这个解法也很简单，原来一种代价用一维dp，现在两种代价，改成二维dp即可dp[v][u]dp[v][u]dp[v][u]表示代价为v和u时获取物品的最大价值。 状态转移方程：dp[v][u]=max{dp[v][u],dp[v−wvi][u−wui]+val[i]}dp[v][u]=max\\{dp[v][u], dp[v-w_v{i}][u-w_u{i}]+val[i]\\}dp[v][u]=max{dp[v][u],dp[v−wv​i][u−wu​i]+val[i]}。 代码模板：加一重U的for循环即可。","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"动态规划","slug":"动态规划","permalink":"http://rookieyin.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"01背包","slug":"01背包","permalink":"http://rookieyin.github.io/tags/01%E8%83%8C%E5%8C%85/"}]},{"title":"谈谈一致性哈希算法","slug":"5 分布式/2 谈谈一致性哈希算法","date":"2022-04-08T12:38:14.000Z","updated":"2022-06-01T14:28:00.157Z","comments":true,"path":"78f2dc72cab6/","link":"","permalink":"http://rookieyin.github.io/78f2dc72cab6/","excerpt":"这篇文章主要搬运自这里 之前学习Redis集群的数据分区方案时，了解到“一致性hash算法”，今天来详细探究一下一致性hash背后的事儿！ 一致性hash算法主要用于解决分布式环境下的数据分区和负载均衡问题： 分布式环境下，如何确定那个key存储在那个节点上呢？ 如何保证数据或者请求分布均衡呢？也就是我们常说的负载均衡？ 利用一致性hash就能很好的解决上面两个问题。","text":"这篇文章主要搬运自这里 之前学习Redis集群的数据分区方案时，了解到“一致性hash算法”，今天来详细探究一下一致性hash背后的事儿！ 一致性hash算法主要用于解决分布式环境下的数据分区和负载均衡问题： 分布式环境下，如何确定那个key存储在那个节点上呢？ 如何保证数据或者请求分布均衡呢？也就是我们常说的负载均衡？ 利用一致性hash就能很好的解决上面两个问题。 本文内容主要为： 传统Hash算法存在的局限性问题 一致性hash原理 带虚拟节点的一致性hash 传统hash的局限性 使用hash进行数据分区的一种简单实现如下图所示： 图中N表示节点数量，使用hash函数进行分区，可以很好的实现负载均衡，但是存在一个致命问题：节点增减。 如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，如果是持久化存储则要做数据迁移，如果是分布式缓存，则其他缓存就失效了。 一致性hash 一致性哈希算法在 1997 年由麻省理工学院提出，是一种特殊的哈希算法，在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式哈希表（Distributed Hash Table，DHT）中存在的动态伸缩等问题 。 原理 一致性哈希算法通过一个叫作一致性哈希环的数据结构实现。这个环的起点是 0，终点是 2^32 - 1，并且起点与终点连接，故这个环的整数分布范围是 [0, 2^32-1]，如下图所示： 数据映射 假设我们有 “semlinker”、“kakuqo”、“lolo”、“fer” 四个对象，分别简写为 o1、o2、o3 和 o4，然后使用哈希函数计算这个对象的 hash 值，值的范围是 [0, 2^32-1]： 服务器映射 接着使用同样的哈希函数，我们将服务器也放置到哈希环上，可以选择服务器的 IP 或主机名作为键进行哈希，这样每台服务器就能确定其在哈希环上的位置。这里假设我们有 3 台缓存服务器，分别为 cs1、cs2 和 cs3： 对象添加到服务器 将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。 以 o2 对象为例，顺序针找到最近的机器是 cs2，故服务器 cs2 会缓存 o2 对象。而服务器 cs1 则缓存 o1，o3 对象，服务器 cs3 则缓存 o4 对象。 添加服务器 假设由于业务需要，我们需要增加一台服务器 cs4，经过同样的 hash 运算，该服务器最终落于 t1 和 t2 服务器之间，具体如下图所示： 对于上述的情况，只有 t1 和 t2 服务器之间的对象需要重新分配。在以上示例中只有 o3 对象需要重新分配，即它被重新到 cs4 服务器。在前面我们已经分析过，如果使用简单的取模方法，当新添加服务器时可能会导致大部分缓存失效，而使用一致性哈希算法后，这种情况得到了较大的改善，因为只有少部分对象需要重新分配。 删除服务器 假设 cs3 服务器出现故障导致服务下线，这时原本存储于 cs3 服务器的对象 o4，需要被重新分配至 cs2 服务器，其它对象仍存储在原有的机器上。 优点 一致性的核心优点就是可扩展性和系统可控性更好： 可扩展性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，相比传统哈希算法大大节省了数据移动的开销 。 更好地适应数据的快速增长。采用一致性哈希算法分布数据，当数据不断增长时，部分虚拟节点中可能包含很多数据、造成数据在虚拟节点上分布不均衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二、不需要对全部的数据进行重新哈希和划分。 虚拟节点分裂后，如果物理服务器的负载仍然不均衡，只需在服务器之间调整部分虚拟节点的存储分布。这样可以随数据的增长而动态的扩展物理服务器的数量，且代价远比传统哈希算法重新分布所有数据要小很多。 带虚拟节点的一致性hash 前文提到的一致性hash已经比较好用了，但是还存在一些问题：新增服务器时， 新增的服务器 cs4 只分担了 cs1 服务器的负载，服务器 cs2 和 cs3 并没有因为 cs4 服务器的加入而减少负载压力。 针对这个问题，我们可以通过引入虚拟节点来解决负载不均衡的问题。即将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器放置到哈希环上，如果要确定对象的服务器，需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Spring事务管理","slug":"2 后端/Spring/Spring事务管理","date":"2022-03-26T14:34:49.000Z","updated":"2022-06-12T14:15:25.033Z","comments":true,"path":"16c8d0988ee3/","link":"","permalink":"http://rookieyin.github.io/16c8d0988ee3/","excerpt":"推荐看这篇文章，写的很好！","text":"推荐看这篇文章，写的很好！ 基本概念 Spring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。对于纯JDBC操作数据库，想要用到事务，可以按照以下步骤进行： 获取连接 Connection con = DriverManager.getConnection() 开启事务con.setAutoCommit(true/false); 执行CRUD 提交事务/回滚事务 con.commit() / con.rollback(); 关闭连接 conn.close(); 使用Spring的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由Spirng 自动完成。那么Spring是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的呢？解决这个问题，也就可以从整体上理解Spring的事务管理实现原理了。 事务管理器模型 统一一致的事务抽象是Spring框架的一大优势，无论是全局事务还是本地事务，JTA、JDBC、Hibernate还是JPA，Spring都使用统一的编程模型，使得应用程序可以很容易地在全局事务与本地事务，或者不同的事务框架之间进行切换。下图是Spring事务抽象的核心类图： PlatformTransactionManager：事务管理器，只有三个功能接口： 获取事务资源，getTransaction，资源可以是任意的，比如jdbc connection/hibernate mybatis session之类，然后绑定并存储 提交事务 ，commit提交指定的事务资源 回滚事务，rollback回滚指定的事务资源 TransactionDefinition：事务的定义信息，包括隔离级别、传播机制、是否只读等等 TransactionStatus：存储事务的状态，比如回滚状态、是否是新事务、事务是否已经完成等等 获取事务 事务管理器的第一步，就是根据事务定义来获取/创建资源了，这一步最麻烦的是要区分传播行为，不同传播行为下的逻辑不太一样。 “默认的传播行为下，使用当前事务”，怎么算有当前事务呢？ 把事务资源存起来嘛，只要已经存在那就是有当前事务，直接获取已存储的事务资源就行。文中开头的例子也演示了，如果想让多个方法无感的使用同一个事务，可以用 ThreadLocal 存储起来，简单粗暴。 Spring 也是这么做的，不过它实现的更复杂一些，抽象了一层事务资源同步管理器 - TransactionSynchronizationManager（本文后面会简称 TxSyncMgr），在这个同步管理器里使用 ThreadLocal 存储了事务资源（本文为了方便理解，尽可能的不贴非关键源码）。 剩下的就是根据不同传播行为，执行不同的策略了，分类之后只有 3 个条件分支： 当前有事务 - 根据不同传播行为处理不同 当前没事务，但需要开启新事务 彻底不用事务 - 这个很少用 12345678910111213141516171819public final TransactionStatus getTransaction(TransactionDefinition definition) &#123; //创建事务资源 - 比如 Connection Object transaction = doGetTransaction(); if (isExistingTransaction(transaction)) &#123; // 处理当前已有事务的场景 return handleExistingTransaction(def, transaction, debugEnabled); &#125;else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED)&#123; // 开启新事务 return startTransaction(def, transaction, debugEnabled, suspendedResources); &#125;else &#123; // 彻底不用事务 &#125; // ...&#125; 先介绍一下分支 2 - 当前没事务，但需要开启新事务，这个逻辑相对简单一些。只需要新建事务资源，然后绑定到 ThreadLocal 即可： 12345678910private TransactionStatus startTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled, SuspendedResourcesHolder suspendedResources) &#123; // 创建事务 DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); // 开启事务（beginTx或者setAutoCommit之类的操作） // 然后将事务资源绑定到事务资源管理器 TransactionSynchronizationManager doBegin(transaction, definition); 现在回到分支 1 - 当前有事务 - 根据不同传播行为处理不同，这个就稍微有点麻烦了。因为有子方法独立事务的需求，可是 TransactionSynchronizationManager 却只能存一个事务资源。 挂起和恢复 Spring 采用了一种**挂起（Suspend） - 恢复（Resume）**的设计来解决这个嵌套资源处理的问题。当子方法需要独立事务时，就将当前事务挂起，从 TxSyncMgr 中移除当前事务资源，创建新事务的状态时，将挂起的事务资源保存至新的事务状态 TransactionStatus 中；在子方法结束时，只需要再从子方法的事务状态中，再次拿出挂起的事务资源，重新绑定至 TxSyncMgr 即可完成恢复的操作。 整个挂起 - 恢复的流程，如下图所示： 注意：挂起操作是在获取事务资源这一步做的，而恢复的操作是在子方法结束时（提交或者回滚）中进行的。 这样一来，每个 TransactionStatus 都会保存挂起的前置事务资源，如果方法调用链很长，每次都是新事务的话，那这个 TransactionStatus 看起来就会像一个链表： 提交事务 获取资源、操作完毕后来到了提交事务这一步，这个提交操作比较简单，只有两步： 当前是新事务才提交 处理挂起资源 怎么知道是新事务？ 每经过一次事务嵌套，都会创建一个新的 TransactionStatus，这个事务状态里会记录当前是否是新事务。如果多个子方法都使用一个事务资源，那么除了第一个创建事务资源的 TransactionStatus 之外，其他都不是新事务。 如下图所示，A -&gt; B -&gt; C 时，由于 BC 都使用当前事务，那么虽然 ABC 所使用的事务资源是一样的，但是只有 A 的 TransactionStatus 是新事务，BC 并不是；那么在 BC 提交事务时，就不会真正的调用提交，只有回到 A 执行 commit 操作时，才会真正的调用提交操作。 回滚事务 除了提交，还有回滚呢，回滚事务的逻辑和提交事务类似： 如果是新事务才回滚，原因上面已经介绍过了 如果不是新事务则只设置回滚标记 处理挂起资源 注意：事务管理器是不包含回滚策略这个东西的，回滚策略是 AOP 版的事务管理增强的功能，但这个功能并不属于核心的事务管理器 事务隔离级别 ① ISOLATION_DEFAULT：这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。 ② ISOLATION_READ_UNCOMMITTED：读未提交，允许事务在执行过程中，读取其他事务未提交的数据。 ③ ISOLATION_READ_COMMITTED：读已提交，允许事务在执行过程中，读取其他事务已经提交的数据。 ④ ISOLATION_REPEATABLE_READ：可重复读，在同一个事务内，任意时刻的查询结果都是一致的。 ⑤ ISOLATION_SERIALIZABLE：所有事务逐个依次执行。 事务的传播机制 spring事务的传播机制说的是，当多个事务同时存在的时候，spring如何处理这些事务的行为。事务传播机制实际上是使用简单的ThreadLocal实现的，所以，如果调用的方法是在新线程调用的，事务传播实际上是会失效的。 ① PROPAGATION_REQUIRED：（默认传播行为）如果当前没有事务，就创建一个新事务；如果当前存在事务，就加入该事务。 ② PROPAGATION_REQUIRES_NEW：无论当前存不存在事务，都创建新事务进行执行。 ③ PROPAGATION_SUPPORTS：如果当前存在事务，就加入该事务；如果当前不存在事务，就以非事务执行。‘ ④ PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 ⑤ PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则按REQUIRED属性执行。 ⑥ PROPAGATION_MANDATORY：如果当前存在事务，就加入该事务；如果当前不存在事务，就抛出异常。 ⑦ PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 总结来说，就3种： 如果存在事务，用存在的事务或创建新事务 如果不存在事务，就创建事务 不适用任何事务 事务实现方式 spring支持编程式事务管理和声明式事务管理两种方式： 编程式事务管理使用TransactionTemplate。 编程式事务操作更加复杂，但是更加灵活，可控性更好。 声明式事务管理建立在AOP之上的。其本质是通过AOP功能，对方法前后进行拦截，将事务处理的功能编织到拦截的方法中，也就是在目标方法开始之前启动一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。 声明式事务最大的优点就是不需要在业务逻辑代码中掺杂事务管理的代码，只需在配置文件中做相关的事务规则声明或通过@Transactional注解的方式，便可以将事务规则应用到业务逻辑中，减少业务代码的污染。 声明式事务 Spring对方法的增强有五种方式： 前置增强（org.springframework.aop.BeforeAdvice）：在目标方法执行之前进行增强； 后置增强（org.springframework.aop.AfterReturningAdvice）：在目标方法执行之后进行增强； 环绕增强（org.aopalliance.intercept.MethodInterceptor）：在目标方法执行前后都执行增强； 异常抛出增强（org.springframework.aop.ThrowsAdvice）：在目标方法抛出异常后执行增强； 引介增强（org.springframework.aop.IntroductionInterceptor）：为目标类添加新的方法和属性。 声明式事务的实现就是通过环绕增强的方式。spring 中的事务实现从原理上说比较简单，通过 aop 在方法执行前后增加数据库事务的操作。 1、在方法开始时判断是否开启新事务，需要开启事务则设置事务手动提交 set autocommit=0; 2、在方法执行完成后手动提交事务 commit; 3、在方法抛出指定异常后调用 rollback 回滚事务 声明式事务实现起来非常简单，只需要使用@Transactional注解就可以，比如： 1234@Transactional(propagation=propagation.PROPAGATION_REQUIRED)public void someMethod &#123; //do something&#125; 我们通常可以用@Transactional来修饰类和方法： 方法 ：推荐将注解使用于方法上，不过需要注意的是：该注解只能应用到 public 方法上，否则不生效。 类 ：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。 编程式事务 编程式事务需要依赖TransactionTemplate来实现，下面是一个简单例子： 123456789101112131415161718192021222324Integer rows = new TransactionTemplate((PlatformTransactionManager) transactionManager, new DefaultTransactionDefinition(TransactionDefinition.ISOLATION_READ_UNCOMMITTED)) .execute(new TransactionCallback&lt;Integer&gt;() &#123; @Override public Integer doInTransaction(TransactionStatus status) &#123; // update 0 int rows0 = jdbcTemplate.update(...); // update 1 int rows1 = jdbcTemplate.update(...); return rows0 + rows1; &#125; &#125;);Integer rows2 = new TransactionTemplate((PlatformTransactionManager) transactionManager, new DefaultTransactionDefinition(TransactionDefinition.ISOLATION_READ_UNCOMMITTED)) .execute(new TransactionCallback&lt;Integer&gt;() &#123; @Override public Integer doInTransaction(TransactionStatus status) &#123; // update 2 int rows2 = jdbcTemplate.update(...); return rows2; &#125; &#125;); 事务失效场景总结 数据库是否支持事务(Mysql的MyIsam不支持事务) ，行锁才支持事务 是否发生多线程调用？因为事务底层依赖于ThreadLocal，不同线程获取到的数据库连接不一样 注解所在类是否被加载成Bean 入口函数是否是public的 private方法不会生效，JDK中必须是接口，接口中不可能有private方法，protect方法的话，也不生效。原因是spring内部判断方法修饰符如果不是public不生成事务拦截代理类。 方法是否是final？ spring事务底层使用了aop，也就是通过jdk动态代理或者cglib，帮我们生成了代理类，在代理类中实现的事务功能。 但如果某个方法用final修饰了，那么在它的代理类中，就无法重写该方法，而添加事务功能。 如果某个方法是static的，同样无法通过动态代理，变成事务方法。 是否发生了自调用 发生自调用时，不会经过代理类，事务自然也就失效了 1234567891011@Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void update(Order order) &#123; updateOrder(order); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateOrder(Order order) &#123; // update order &#125;&#125; 所有数据源是否加载了事务管理器 @Transactional的传播策略是否配置正确 异常有没有被正常抛出，是不是被子方法吃掉了","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Spring","slug":"后端/Spring","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Spring/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://rookieyin.github.io/tags/Spring/"}]},{"title":"Spring MVC","slug":"2 后端/Spring/Spring MVC","date":"2022-03-25T14:34:49.000Z","updated":"2022-06-12T14:15:20.875Z","comments":true,"path":"c374e129c8f0/","link":"","permalink":"http://rookieyin.github.io/c374e129c8f0/","excerpt":"Spring MVC是一款基于Java的Web MVC框架，是目前主流的Web MVC框架之一，本文结合源码，详细介绍下Spring MVC的相关知识。","text":"Spring MVC是一款基于Java的Web MVC框架，是目前主流的Web MVC框架之一，本文结合源码，详细介绍下Spring MVC的相关知识。 Spring MVC概述 这一章节和下一章节内容主要搬运自这里。 Spring MVC的由来 早期 Java Web 的开发中，把显示层、控制层、数据层的操作全部交给 JSP 或者 JavaBean 来进行处理，我们称之为 Model1： 然而出现了很多的弊端，比如： JSP 和 Java Bean 之间严重耦合，Java 代码和 HTML 代码也耦合在了一起 要求开发者不仅要掌握 Java ，还要有高超的前端水平 前端和后端相互依赖，前端需要等待后端完成，后端也依赖前端完成，才能进行有效的测试 随后出现servlet，就有了早期的MVC模式 首先用户请求到servlet，然后根据请求调用响应的JavaBean，并把所有的显示交给Jsp去处理，这样就称之为mvc模式： M代表模型（Model）：数据、bean V代表视图（View）：网页，jsp…展示模型中的数据 C代表控制器（Controller）：把不同的数据(Model)，显示在不同的视图(View)上，Servlet 扮演的就是这样的角色 为解决持久层中一直未处理好的数据库事务的编程，又为了迎合 NoSQL 的强势崛起，Spring MVC 给出了方案 Spring MVC启动流程 当一个web应用部署tomcat时，在接收用户请求之前，会进行以下初始化过程 部署在web.xml文件里由&lt;listener&gt;元素标记事件的监听器会被创建和初始化 对于所有事件监听器，如果实现了ServletContextListener接口，将会执行其实现的contextInitialized()方法 部署描述文件由元素标记的过滤器会被创建和初始化，并调用其init()方法 部署在描述文件由元素标记的servlet会根据的权值按顺序创建并初始化，并调用其init()方法 Listener初始化 123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 在web.xml里面我们定义了一个&lt;listener&gt;，用于配置监听器，这里我们定义了一个ContextLoaderListener的listener，监听器的初始化就是从这里开始的。 ContextLoaderListener类核心就2个方法：初始化和销毁。 12345678910111213public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; // 初始化方法 @Override public void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext()); &#125; // 销毁方法 @Override public void contextDestroyed(ServletContextEvent event) &#123; closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125; ContextLoaderListener类实现了ServletContextListener，本质上是一个servlet监听器，tomcat将会优先加载servlet监听器组件，并调用contextInitialized方法,在contextInitialized方法中调用initWebApplicationContext方法初始化Spring web上下文。 initWebApplicationContext 这个方法核心功能是下面这段： 1234567891011121314151617181920//判断context是否为空，为空，则创建，默认创建XmlWebApplicationContextif (this.context == null) &#123; this.context = createWebApplicationContext(servletContext);&#125;if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; // 如果该容器还没有刷新过 if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; // 配置并刷新容器 configureAndRefreshWebApplicationContext(cwac, servletContext); &#125;&#125; 该方法的主要目的就是创建root WebApplicationContext对象即IOC容器，其中比较重要的就是，整个Web应用如果存在IOC容器则有且只能有一个，根IOC容器作为全局变量存储在ServletContext即application对象中。将根IOC容器放入到application对象之前进行了IOC容器的配置和刷新操作，调用了configureAndRefreshWebApplicationContext()方法 。 createWebApplicationContext 这个方法比较简单，就是利用反射创建一个根IOC容器。 12345678protected WebApplicationContext createWebApplicationContext(ServletContext sc) &#123; Class&lt;?&gt; contextClass = determineContextClass(sc); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException(&quot;Custom context class [&quot; + contextClass.getName() + &quot;] is not of type [&quot; + ConfigurableWebApplicationContext.class.getName() + &quot;]&quot;); &#125; return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; configureAndRefreshWebApplicationContext 创建好根IOC容器后，调用该方法配置和刷新容器，其源码如下： 1234567891011121314151617181920212223242526272829303132protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; // The application context id is still set to its original default value // -&gt; assign a more useful id based on available information String idParam = sc.getInitParameter(CONTEXT_ID_PARAM); if (idParam != null) &#123; wac.setId(idParam); &#125; else &#123; // Generate default id... wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; // The wac environment&#x27;s #initPropertySources will be called in any case when the context // is refreshed; do it eagerly here to ensure servlet property sources are in place for // use in any post-processing or initialization that occurs below prior to #refresh ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment) env).initPropertySources(sc, null); &#125; customizeContext(sc, wac); wac.refresh();&#125; 比较重要的就是获取到了web.xml中的标签配置的全局变量contextConfigLocation，并最后一行调用了refresh()方法 。 refresh()方法 ConfigurableWebApplicationContext是一个接口，通过对常用实现类ClassPathXmlApplicationContext逐层查找后可以找到一个抽象类AbstractApplicationContext实现了refresh()方法，其源码如下 ： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(&quot;spring.context.refresh&quot;); // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(&quot;spring.context.beans.post-process&quot;); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); contextRefresh.end(); &#125; &#125;&#125; 该方法主要用于创建并初始化contextConfigLocation类配置的xml文件中的Bean，因此，如果我们在配置Bean时出错，在Web应用启动时就会抛出异常，而不是等到运行时才抛出异常 整个ContextLoaderListener类的启动过程到此就结束了，可以发现，创建ContextLoaderListener是比较核心的一个步骤，主要工作就是为了创建根IoC容器并使用特定的key将其放入到application对象中，供整个Web应用使用，由于在ContextLoaderListener类中构造的IOC容器配置的Bean是全局共享的，因此，在标识的contextConfigLocation的xml配置文件一般包括: 数据库DataSource、DAO层、Service层、事务等相关Bean。 Filter初始化 在监听器listener初始化完成后，接下来会进行filter的初始化操作，GenericFilterBean是任何类型的过滤器的一个比较方便的超类，这个类主要实现的就是从web.xml文件中取得init-param中设定的值，然后对Filter进行初始化（当然，其子类可以覆盖init()方法）。 Filter的生命周期如下： void init(FilterConfig config): 用于完成Filter 的初始化 void destroy(): 用于Filter 销毁前，完成某些资源的回收 void doFilter(ServletRequest request, ServletResponse response,FilterChain chain): 实现过滤功能，该方法就是对每个请求及响应增加的额外处理。 过滤器Filter也具有生命周期：init()-&gt;doFilter()-&gt;destroy()，由部署文件中的filter元素驱动 Servlet初始化 Web应用启动的最后一个步骤就是创建和初始化相关Servlet，在开发中常用的Servlet就是DispatcherServlet类前端控制器，前端控制器作为中央控制器是整个Web应用的核心，用于获取分发用户请求并返回响应。 DispatcherServlet类的间接父类实现了Servlet接口，因此其本质上依旧是一个Servlet。DispatcherServlet设计很巧妙，上层父类不同程度的实现了相关接口的部分方法，并留出了相关方法用于子类覆盖，将不变的部分统一实现，将变化的部分预留方法用于子类实现 。 因为一个servlet的生命周期是init()-&gt;service()-&gt;destory()，DispatcherServlet 也是一样的。 init() 该方法解析初始化参数，并创建BeanWrapper，然后调用子类实现的initServletBean()进行后续操作。 1234567891011121314151617181920212223public final void init() throws ServletException &#123; // Set bean properties from init parameters. PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment())); initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException ex) &#123; if (logger.isErrorEnabled()) &#123; logger.error(&quot;Failed to set bean properties on servlet &#x27;&quot; + getServletName() + &quot;&#x27;&quot;, ex); &#125; throw ex; &#125; &#125; // Let subclasses do whatever initialization they like. initServletBean();&#125; initServletBean() 该方法是重写了父类HttpServletBean抽象类的initServletBean()方法，HttpServletBean抽象类在执行init()方法时会调用initServletBean()方法，由于多态的特性，最终会调用其子类FrameworkServlet抽象类的initServletBean()方法。该方法由final标识，子类就不可再次重写了。该方法中比较重要的就是initWebApplicationContext()方法的调用，该方法仍由FrameworkServlet抽象类实现 。 12345678910111213141516171819202122232425262728protected final void initServletBean() throws ServletException &#123; getServletContext().log(&quot;Initializing Spring &quot; + getClass().getSimpleName() + &quot; &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Initializing Servlet &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; long startTime = System.currentTimeMillis(); try &#123; this.webApplicationContext = initWebApplicationContext(); initFrameworkServlet(); &#125; catch (ServletException | RuntimeException ex) &#123; logger.error(&quot;Context initialization failed&quot;, ex); throw ex; &#125; if (logger.isDebugEnabled()) &#123; String value = this.enableLoggingRequestDetails ? &quot;shown which may lead to unsafe logging of potentially sensitive data&quot; : &quot;masked to prevent unsafe logging of potentially sensitive data&quot;; logger.debug(&quot;enableLoggingRequestDetails=&#x27;&quot; + this.enableLoggingRequestDetails + &quot;&#x27;: request parameters and headers will be &quot; + value); &#125; if (logger.isInfoEnabled()) &#123; logger.info(&quot;Completed initialization in &quot; + (System.currentTimeMillis() - startTime) + &quot; ms&quot;); &#125;&#125; initWebApplicationContext() 该方法的主要作用同样是创建一个WebApplicationContext对象，即IOC容器，不过前文讲过每个Web应用最多只能存在一个IOC容器，这里创建的则是特定Servlet拥有的子IOC容器。 父子容器类似于类的继承关系，子类可以访问父类中的成员变量，而父类不可访问子类的成员变量，同样的，子容器可以访问父容器中定义的Bean，但父容器无法访问子容器定义的Bean，根IOC容器做为全局共享的IOC容器放入Web应用需要共享的Bean，而子IOC容器根据需求的不同，放入不同的Bean，这样能够做到隔离，保证系统的安全性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected WebApplicationContext initWebApplicationContext() &#123; //先获取root容器 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext cwac &amp;&amp; !cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; if (wac == null) &#123; // No context instance was injected at construction time -&gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id wac = findWebApplicationContext(); &#125; //创建一个继承自root容器的IOC容器 if (wac == null) &#123; // No context instance is defined for this servlet -&gt; create a local one wac = createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; // Either the context is not a ConfigurableApplicationContext with refresh // support or the context injected at construction time had already been // refreshed -&gt; trigger initial onRefresh manually here. synchronized (this.onRefreshMonitor) &#123; onRefresh(wac); &#125; &#125; if (this.publishContext) &#123; // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); &#125; return wac;&#125; DispatcherServlet类的子IOC容器创建过程，如果当前Servlet存在一个IOC容器则为其设置根IOC容器作为其父类，并配置刷新该容器，用于构造其定义的Bean，这里的方法与前文讲述的根IOC容器类似，同样会读取用户在web.xml中配置的中的值，用于查找相关的xml配置文件用于构造定义的Bean。如果当前Servlet不存在一个子IoC容器就去查找一个，如果仍然没有查找到则调用createWebApplicationContext()方法去创建。 createWebApplicationContext() 123456789101112131415161718192021protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) &#123; Class&lt;?&gt; contextClass = getContextClass(); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException( &quot;Fatal initialization error in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;: custom WebApplicationContext class [&quot; + contextClass.getName() + &quot;] is not of type ConfigurableWebApplicationContext&quot;); &#125; ConfigurableWebApplicationContext wac = (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); wac.setEnvironment(getEnvironment()); wac.setParent(parent); String configLocation = getContextConfigLocation(); if (configLocation != null) &#123; wac.setConfigLocation(configLocation); &#125; configureAndRefreshWebApplicationContext(wac); return wac;&#125; 该方法用于创建一个子IOC容器并将根IOC容器做为其父容器，接着进行配置和刷新操作用于构造相关的Bean。至此，根IOC容器以及相关Servlet的子IOC容器已经配置完成，子容器中管理的Bean一般只被该Servlet使用，因此，其中管理的Bean一般是局部的，如SpringMVC中需要的各种重要组件，包括Controller、Interceptor、Converter、ExceptionResolver等 onrefresh() 当IOC子容器构造完成后调用了onRefresh()方法，该方法的调用与initServletBean()方法的调用相同，由父类调用但具体实现由子类覆盖，调用onRefresh()方法时将前文创建的IOC子容器作为参数传入。 123456789101112131415161718protected void onRefresh(ApplicationContext context) &#123; initStrategies(context);&#125;/*** Initialize the strategy objects that this servlet uses.* &lt;p&gt;May be overridden in subclasses in order to initialize further strategy objects.*/protected void initStrategies(ApplicationContext context) &#123; initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); initHandlerMappings(context); initHandlerAdapters(context); initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context);&#125; onRefresh()方法直接调用了initStrategies()方法，源码如上，通过函数名可以判断，该方法用于初始化创建multipartResovle来支持图片等文件的上传、本地化解析器、主题解析器、HandlerMapping处理器映射器、HandlerAdapter处理器适配器、异常解析器、视图解析器、flashMap管理器等，这些组件都是SpringMVC开发中的重要组件，相关组件的初始化创建过程均在此完成 。 到此，初始化就全部结束了！ 总结 在Spring的web容器启动时会去读取web.xml文件，相关启动顺序为：&lt;context-param&gt; --&gt; &lt;listener&gt; --&gt; &lt;filter&gt; --&gt;&lt;servlet&gt; ，具体为： 1、解析&lt;context-param&gt;键值对 2、创建一个application对象即ServletContext，servlet上下文，用于全局共享 3、将&lt;context-param&gt;键值对放入ServletContext中，web应用全局共享 4、读取&lt;listener&gt;标签，创建监听器，一般使用ContextLoaderListener，如果使用了ContextLoaderListener，Spring就会创建一个WebApplicationContext对象，这个就是IOC容器, ContextLoaderListener创建的IOC容器是全局共享的，并将其放在ServletContext中, 键名为WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, 读取web.xml文件里的contextConfigLocation配置中的xml文件来创建bean 5、listener创建完毕后如果有Filter会去创建Filter 6、初始化Servlet，一般使用DispatchServlet类 7、DispatchServlet的父类FrameworkServlet会重写其父类的initServletBean方法，并调用initWebApplicationContext()以及onRefresh()方法 8、initWebApplicationContext()方法会创建一个当前servlet的一个IOC子容器，如果存在上述的全局WebApplicationContext则将其设置为父容器，如果不存在上述全局的则父容器为null。 9、读取标签的配置的xml文件并加载相关Bean 10、onRefresh()方法创建Web应用相关组件 DispatcherServlet请求处理 这里内容主要搬运自这篇文章。 处理流程 Spring MVC的请求处理流程大致如下图所示： 核心架构的具体流程步骤如下： 首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行 处理，作为统一访问点，进行全局的流程控制； DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一 个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新 的映射策略； DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器， 即适配器设计模式的应用，从而很容易支持很多类型的处理器； HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处 理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）； ModelAndView 的逻辑视图名——&gt; ViewResolver，ViewResolver 将把逻辑视图名解析为具体的View，通过这种策 略模式，很容易更换其他视图技术； View——&gt;渲染，View 会根据传进来的Model 模型数据进行渲染，此处的Model 实际是一个Map 数据结构，因此 很容易支持其他视图技术； 返回控制权给DispatcherServlet，由DispatcherServlet 返回响应给用户，到此一个流程结束。 doGet入口 我们以get请求为例，看下DispatcherServlet是如何处理请求的。servlet处理get请求是doGet方法，这个方法由FrameworkServlet类实现： 1234protected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125; 这个方法很简单，调用processRequest()来处理请求。 processRequest() 这个方法还是由FrameworkServlet类实现： 123456789101112131415161718192021222324252627282930313233343536373839protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = buildLocaleContext(request); RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor()); //初始化context initContextHolders(request, localeContext, requestAttributes); try &#123; //调用doService方法，由子类实现，它是处理请求的核心 doService(request, response); &#125; catch (ServletException | IOException ex) &#123; failureCause = ex; throw ex; &#125; catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException(&quot;Request processing failed&quot;, ex); &#125; finally &#123; resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) &#123; requestAttributes.requestCompleted(); &#125; logResult(request, response, failureCause, asyncManager); publishRequestHandledEvent(request, response, startTime, failureCause); &#125;&#125; doService() 该方法由DispatchServlet实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; logRequest(request); // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. //保存请求相关参数，供后续使用 Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); if (this.flashMapManager != null) &#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &#125; RequestPath previousRequestPath = null; if (this.parseRequestPath) &#123; previousRequestPath = (RequestPath) request.getAttribute(ServletRequestPathUtils.PATH_ATTRIBUTE); ServletRequestPathUtils.parseAndCache(request); &#125; try &#123; //调用doDispatch，分发请求 doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; if (this.parseRequestPath) &#123; ServletRequestPathUtils.setParsedRequestPath(previousRequestPath, request); &#125; &#125;&#125; 分发请求 在doService()方法中调用doDispatch()来分发请求，其源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = HttpMethod.GET.matches(method); if (isGet || HttpMethod.HEAD.matches(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we&#x27;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(&quot;Handler processing failed&quot;, err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 方法的核心点有3个： 调用getHandler(processedRequest)获取处理器 这个方法很简单，就是从一个Map数据结构里面找到和请求对应的处理器 调用getHandlerAdapter(mappedHandler.getHandler())获取处理器适配器 这个方法和getHandler类似，不过是从一个List中获取对应处理器适配器 调用handle()处理请求 这个方法是核心，下面我们重点看看它的细节。 处理请求 handle()是HandlerAdapter接口定义的方法，有5个子类都实现了它。 这里我们以AbstractHandlerMethodAdapter为例，看下处理请求的具体细节。 12345public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //调用handleInternal方法来处理请求 return handleInternal(request, response, (HandlerMethod) handler);&#125; handleInternal() handleInternal方法由其子类RequestMappingHandlerAdapter实现： 1234567891011121314151617181920212223242526272829303132333435363738@Overrideprotected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; checkRequest(request); // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &#125; if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; prepareResponse(response); &#125; &#125; return mav;&#125; 这里再次调用invokeHandlerMethod(request, response, handlerMethod)来处理请求。 invokeHandlerMethod() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * Invoke the &#123;@link RequestMapping&#125; handler method preparing a &#123;@link ModelAndView&#125; * if view resolution is required. * @since 4.2 * @see #createInvocableHandlerMethod(HandlerMethod) */@Nullableprotected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); // 重要：设置handler(controller#list)方法上的参数，返回值处理，绑定databinder等 ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); LogFormatUtils.traceDebug(logger, traceOn -&gt; &#123; String formatted = LogFormatUtils.formatValue(result, !traceOn); return &quot;Resume with async result [&quot; + formatted + &quot;]&quot;; &#125;); invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; // 执行controller中方法 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125; 在invokeHandlerMethod()在通过调用invocableMethod.invokeAndHandle(webRequest, mavContainer);，通过反射，让具体Controller来处理该请求。 返回视图 Controller处理完请求，得到ModelAndView后，重新回到doDispatch方法，进行后续的视图解析和渲染工作。 视图渲染 视图渲染之前首先调用processDispatchResult处理返回的视图： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Handle the result of handler selection and handler invocation, which is * either a ModelAndView or an Exception to be resolved to a ModelAndView. */private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123; boolean errorView = false; // 如果处理过程有异常，则异常处理 if (exception != null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123; logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, exception); mv = ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); &#125; &#125; // 是否需要渲染视图 if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, request, response); // 渲染视图 if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;No view rendering, null ModelAndView returned.&quot;); &#125; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Concurrent handling started during a forward return; &#125; if (mappedHandler != null) &#123; // Exception (if any) is already handled.. mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125; 接下来显然就是渲染视图了, spring在initStrategies方法中初始化的组件（LocaleResovler等）就派上用场了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Render the given ModelAndView. * &lt;p&gt;This is the last stage in handling a request. It may involve resolving the view by name. * @param mv the ModelAndView to render * @param request current HTTP servlet request * @param response current HTTP servlet response * @throws ServletException if view is missing or cannot be resolved * @throws Exception if there&#x27;s a problem rendering the view */protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // Determine locale for request and apply it to the response. Locale locale = (this.localeResolver != null ? this.localeResolver.resolveLocale(request) : request.getLocale()); response.setLocale(locale); View view; String viewName = mv.getViewName(); if (viewName != null) &#123; // We need to resolve the view name. view = resolveViewName(viewName, mv.getModelInternal(), locale, request); if (view == null) &#123; throw new ServletException(&quot;Could not resolve view with name &#x27;&quot; + mv.getViewName() + &quot;&#x27; in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; &#125; else &#123; // No need to lookup: the ModelAndView object contains the actual View object. view = mv.getView(); if (view == null) &#123; throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; + &quot;View object in servlet with name &#x27;&quot; + getServletName() + &quot;&#x27;&quot;); &#125; &#125; // Delegate to the View object for rendering. if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Rendering view [&quot; + view + &quot;] &quot;); &#125; try &#123; if (mv.getStatus() != null) &#123; response.setStatus(mv.getStatus().value()); &#125; view.render(mv.getModelInternal(), request, response); &#125; catch (Exception ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Error rendering view [&quot; + view + &quot;]&quot;, ex); &#125; throw ex; &#125;&#125; 后续就是通过viewResolver进行解析了，这里就不再继续看代码了，上述流程基本上够帮助你构建相关的认知了。最后无非是返回控制权给DispatcherServlet，由DispatcherServlet 返回响应给用户。 参考资料 https://developer.aliyun.com/article/707995#slide-4 https://juejin.cn/post/6844903645100638215#comment https://pdai.tech/md/spring/spring-x-framework-springmvc-source-1.html https://pdai.tech/md/spring/spring-x-framework-springmvc-source-2.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Spring","slug":"后端/Spring","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Spring/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://rookieyin.github.io/tags/Spring/"}]},{"title":"三色标记","slug":"2 后端/Java/JVM/6 三色标记","date":"2022-03-17T14:34:49.000Z","updated":"2022-06-11T13:24:55.026Z","comments":true,"path":"2bc0970c0089/","link":"","permalink":"http://rookieyin.github.io/2bc0970c0089/","excerpt":"本文转自：你对JVM三色标记的理解嘛？ 三色标记法是一种垃圾回收法，它可以让JVM不发生或仅短时间发生STW(Stop The World)，从而达到清除JVM内存垃圾的目的。JVM中的CMS、G1垃圾回收器所使用垃圾回收算法即为三色标记法。","text":"本文转自：你对JVM三色标记的理解嘛？ 三色标记法是一种垃圾回收法，它可以让JVM不发生或仅短时间发生STW(Stop The World)，从而达到清除JVM内存垃圾的目的。JVM中的CMS、G1垃圾回收器所使用垃圾回收算法即为三色标记法。 三色标记算法思想 三色标记法将对象的颜色分为了黑、灰、白，三种颜色。 白色：该对象没有被标记过。（对象垃圾） 灰色：该对象已经被标记过了，但该对象下的属性没有全被标记完。（GC需要从此对象中去寻找垃圾） 黑色：该对象已经被标记过了，且该对象下的属性也全部都被标记过了。（程序所需要的对象） 算法流程 从我们main方法的根对象（JVM中称为GC Root）开始沿着他们的对象向下查找，用黑灰白的规则，标记出所有跟GC Root 相连接的对象，扫描一遍结束后，一般需要进行一次短暂的STW(Stop The World)，再次进行扫描，此时因为黑色对象的属性都也已经被标记过了，所以只需找出灰色对象并顺着继续往下标记（且因为大部分的标记工作已经在第一次并发的时候发生了，所以灰色对象数量会很少，标记时间也会短很多）, 此时程序继续执行，GC线程扫描所有的内存，找出扫描之后依旧被标记为白色的对象（垃圾），清除。 具体流程: 首先创建三个集合：白、灰、黑。 将所有对象放入白色集合中。 然后从根节点开始遍历所有对象（注意这里并不递归遍历），把遍历到的对象从白色集合放入灰色集合。 之后遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合 重复 4 直到灰色中无任何对象 通过write-barrier检测对象有变化，重复以上操作 收集所有白色对象（垃圾） 三色标记存在问题 浮动垃圾：并发标记的过程中，若一个已经被标记成黑色或者灰色的对象，突然变成了垃圾，由于不会再对黑色标记过的对象重新扫描,所以不会被发现，那么这个对象不是白色的但是不会被清除，重新标记也不能从GC Root中去找到，所以成为了浮动垃圾，浮动垃圾对系统的影响不大，留给下一次GC进行处理即可。 对象漏标问题（需要的对象被回收）：并发标记的过程中，一个业务线程将一个未被扫描过的白色对象断开引用成为垃圾（删除引用），同时黑色对象引用了该对象（增加引用）（这两部可以不分先后顺序）；因为黑色对象的含义为其属性都已经被标记过了，重新标记也不会从黑色对象中去找，导致该对象被程序所需要，却又要被GC回收，此问题会导致系统出现问题，而CMS与G1，两种回收器在使用三色标记法时，都采取了一些措施来应对这些问题，CMS对增加引用环节进行处理（Increment Update），G1则对删除引用环节进行处理(SATB)。 解决办法 在JVM虚拟机中有两种常见垃圾回收器使用了该算法：CMS(Concurrent Mark Sweep)、G1(Garbage First) ，为了解决三色标记法对对象漏标问题各自有各自的法: 什么时候，会产生对象消失“的问题”，即原本应该是黑色的对象被误标为白色？ 当且仅当以下两个条件同时满足： 赋值器插入了一条或多条从黑色对象到白色对象的新引用； 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。 那如何解决并发扫描时对象消失问题？ 只需要破坏这两个条件任意一个即可，两种解决方案：增量更新（Increamental Update）和原始快照（Snap shot At The Begining, SATB） CMS 基于 增量更新（Increamental Update）来做并发标记，G1 基于 原始快照（Snap shot At The Begining, SATB）来实现的。 增量更新（Increamental Update）：当一个白色对象被黑色对象引用，将黑色对象重新标记为灰色，让垃圾回收器重新扫描。 原始快照（Snap shot At The Begining, SATB）：原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过得引用关系中的灰色对象为根，重新扫描一次。总而言之就是：无论引用关系删除与否，都会按照刚刚开始扫描的那一刻的对象图快照来进行搜索。 对比增量更新和原始快照： 原始快照关注的是引用删除，增量更新关注的是引用增加。 为啥G1不使用增量更新算法呢？ 因为使用增量更新算法，那变成灰色的对象还要重新扫描一遍，效率太低了，所以G1在处理并发标记的过程比CMS效率要高，这个主要是解决漏标的算法决定的。 CMS回顾 CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网网站或者基于浏览器的B/S系统的服务端上，这类应用通常都会较为关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验。CMS收集器就非常符合这类应用的需求(但是实际由于某些问题,很少有使用CMS作为主要垃圾回收器的)。 从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于标记-清除算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为四个步骤，包括：1）初始标记（CMS initial mark） 2）并发标记（CMS concurrent mark） 3）重新标记（CMS remark） 4）并发清除（CMS concurrent sweep） 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GCRoots能直接关联到的对象，速度很快； 并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行； 重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短； 最后是并发清除阶段，清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 CMS解决办法:增量更新 在应对漏标问题时，CMS使用了增量更新(Increment Update)方法来做： 在一个未被标记的对象（白色对象）被重新引用后，引用它的对象若为黑色则要变成灰色，在下次二次标记时让GC线程继续标记它的属性对象。 但是就算是这样，其仍然是存在漏标的问题： 在一个灰色对象正在被一个GC线程回收时，当它已经被标记过的属性指向了一个白色对象（垃圾） 而这个对象的属性对象本身还未全部标记结束，则为灰色不变 而这个GC线程在标记完最后一个属性后，认为已经将所有的属性标记结束了，将这个灰色对象标记为黑色，被重新引用的白色对象，无法被标记 CMS另两个致命缺陷 CMS采用了Mark-Sweep 算法，最后会产生许多内存碎片，当到一定数量时，CMS无法清理这些碎片了，CMS会让Serial Old垃圾处理器来清理这些垃圾碎片，而Serial Old垃圾处理器是单线程操作进行清理垃圾的，效率很低。所以使用CMS就会出现一种情况，硬件升级了，却越来越卡顿，其原因就是因为进行Serial Old GC时，效率过低。 解决方案：使用Mark-Sweep-Compact 算法，减少垃圾碎片 调优参数（配套使用）： 1-XX:+UseCMSCompactAtFullCollection 开启CMS的压缩-XX:CMSFullGCsBeforeCompaction 默认为0，指经过多少次CMS FullGC才进行压缩 当JVM认为内存不够，再使用CMS进行并发清理内存可能会发生OOM的问题，而不得不进行Serial Old GC，Serial Old 是单线程垃圾回收，效率低 解决方案：降低触发CMS GC 的阈值，让浮动垃圾不那么容易占满老年代 调优参数： 1-XX:CMSInitiatingOccupancyFraction 92% 可以降低这个值，让老年代占用率达到该值就进行CMS GC G1回顾 G1(Garbage First)物理内存不再分代，而是由一块一块的Region组成,但是逻辑分代仍然存在。G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。 Region中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可以通过参数-XX：G1HeapRegionSize设定，取值范围为1MB～32MB，且应为2的N次幂。而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待，如图所示 G1前置知识 Card Table（多种垃圾回收器均具备） 由于在进行YoungGC时，我们在进行对一个对象是否被引用的过程，需要扫描整个Old区，所以JVM设计了CardTable ，将Old区分为一个一个Card，一个Card有多个对象；如果一个Card中的对象有引用指向Young区，则将其标记为Dirty Card，下次需要进行YoungGC时，只需要去扫描Dirty Card即可。 Card Table 在底层数据结构以 Bit Map实现。 RSet(Remembered Set) 是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。 后面说到的CSet(Collection Set)也是辅助GC的，它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。 在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。 而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。每个Region 中都有一个RSet，记录其他Region到本Region的引用信息；使得垃圾回收器不需要扫描整个堆找到谁引用当前分区中的对象，只需要扫描RSet即可。 CSet(Collection Set) 一组可被回收的分区Region的集合, 是多个对象的集合内存区域。 新生代与老年代的比例 5% - 60% ，一般不使用手工指定，因为这是G1预测停顿时间的基准,这地方简要说明一下,G1可以指定一个预期的停顿时间,然后G1会根据你设定的时间来动态调整年轻代的比例,例如时间长,就将年轻代比例调小,让YGC尽早行。 G1解决办法:SATB SATB(Snapshot At The Beginning), 在应对漏标问题时，G1使用了SATB 方法来做,具体流程： 在开始标记的时候生成一个快照图标记存活对象 在一个引用断开后，要将此引用推到GC的堆栈里，保证白色对象（垃圾）还能被GC线程扫描到(在**write barrier(写屏障)**里把所有旧的引用所指向的对象都变成非白的)。 配合Rset，去扫描哪些Region引用到当前的白色对象，若没有引用到当前对象，则回收 SATB详细流程 SATB是维持并发GC的一种手段。G1并发的基础就是SATB。SATB可以理解成在GC开始之前对堆内存里的对象做一次快照，此时活的对像就认为是活的，从而开成一个对象图。 在GC收集的时候，新生代的对象也认为是活的对象，除此之外其他不可达的对象都认为是垃圾对象。 如何找到在GC过程中分配的对象呢？每个region记录着两个top-at-mark-start(TAMS)指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象就是新分配的，因而被视为隐式marked。 通过这种方式我们就找到了在GC过程中新分配的对象，并把这些对象认为是活的对象。 解决了对象在GC过程中分配的问题，那么在GC过程中引用发生变化的问题怎么解决呢？ G1给出的解决办法是通过Write Barrier。Write Barrier就是对引用字段进行赋值做了额外处理。通过Write Barrier就可以了解到哪些引用对象发生了什么样的变化。 mark的过程就是遍历heap标记live object的过程，采用的是三色标记算法，这三种颜色为white（表示还未访问到）、gray（访问到但是它用到的引用还没有完全扫描）、back（访问到而且其用到的引用已经完全扫描完）。 整个三色标记算法就是从GC roots出发遍历heap，针对可达对象先标记white为gray，然后再标记gray为black；遍历完成之后所有可达对象都是balck的，所有white都是可以回收的。 SATB仅仅对于在marking开始阶段进行“snapshot”(marked all reachable at mark start)，但是concurrent的时候并发修改可能造成对象漏标记。 对black新引用了一个white对象，然后又从gray对象中删除了对该white对象的引用，这样会造成了该white对象漏标记。 对black新引用了一个white对象，然后从gray对象删了一个引用该white对象的white对象，这样也会造成了该white对象漏标记。 对black新引用了一个刚new出来的white对象，没有其他gray对象引用该white对象，这样也会造成了该white对象漏标记。 SATB效率高于增量更新的原因？ 因为SATB在重新标记环节只需要去重新扫描那些被推到堆栈中的引用，并配合Rset来判断当前对象是否被引用来进行回收；并且在最后G1并不会选择回收所有垃圾对象，而是根据Region的垃圾多少来判断与预估回收价值（指回收的垃圾与回收的STW时间的一个预估值），将一个或者多个Region放到CSet中，最后将这些Region中的存活对象压缩并复制到新的Region 中，清空原来的Region。 G1会不会进行Full GC? 会，当内存满了的时候就会进行Full GC；且JDK10之前的Full GC，为单线程的，所以使用G1需要避免Full GC的产生。 解决方案： 加大内存； 提高CPU性能，加快GC回收速度，而对象增加速度赶不上回收速度，则Full GC可以避免； 降低进行Mixed GC触发的阈值，让Mixed GC提早发生（默认45%）。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"Java垃圾回收","slug":"2 后端/Java/JVM/5 Java垃圾回收","date":"2022-03-16T14:34:49.000Z","updated":"2022-06-11T13:25:54.997Z","comments":true,"path":"55b22090e61c/","link":"","permalink":"http://rookieyin.github.io/55b22090e61c/","excerpt":"1 回收哪些内存 垃圾收集主要是针对堆和方法区进行；程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。","text":"1 回收哪些内存 垃圾收集主要是针对堆和方法区进行；程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。 1.1 判断对象存活 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡，有可达性分析和引用计数两种方法。 引用计数法 给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 其缺点在于：存在循环引用问题，即两个相互引用的对象永远不会被回收。 Java中引用分为4中：强引用、软引用、弱引用和虚引用，4者区分如下： 强引用：我们平时使用new方法创建的就是强引用， 被强引用关联的对象不会被回收 。 软引用：使用SoftReference类来创建软引用， 被软引用关联的对象只有在内存不够的情况下才会被回收。 弱引用： 使用 WeakReference 类来实现弱引用 ，被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。 虚引用： 使用 PhantomReference 来实现虚引用，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。 其唯一目的就是能在这个对象被回收时收到一个系统通知。 可达性分析法 通过GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。 Java中的GC Roots一般包含： 虚拟机栈中引用的对象； 本地方法栈中引用的对象； 方法区中类静态属性引用的对象； 方法区中的常量引用的对象。 需要注意的是：即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 1.2 方法区回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，因此在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载: 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 2 什么时候回收 通常是不可预测的。 1、在程序空闲的时候； 2、执行代码：system.gc()时候； 3、Java堆内存空间不足的时候。 （1）minor GC: 当新对象生成，并且在Eden申请空间失败时，就会触发minor GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区 （2）Full GC: 对整个堆进行整理，包括Young、old 和Perm。 3 怎么回收 3.1 垃圾回收算法 一、标记-清除算法 算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题： 效率问题，标记和清除的效率都不高 空间问题，GC后产生大量不连续碎片 二、标记-复制算法 将内存分成两个大小相等的块，每次只使用其中一个块。当一个块内存用完后，将存活的对象复制到另外一个块中，然后把已使用的内存空间全部清理掉。 实现简单、运行高效，且不容易产生碎片，但内存利用率低。而且算法的效率和存活对象的数目有关，如果存活对象很多，那么copying算法效率会大大降低。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。 三、标记-整理算法 标记完所有对象后，不直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存。 四、分代收集算法 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代： 新生代：复制算法 老年代：标记-清除或标记-整理算法 3.2 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程: 单线程指的是垃圾收集器只使用一个线程进行收集，而多线程使用多个线程； 串行与并行: 串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并形指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 一、Serial收集器 Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 它是 Client 模式下的默认新生代收集器， 新生代采用标记-复制算法，老年代采用标记-整理算法。 因为在用户的桌面应用场景下，分配给虚拟机管理的内存一般来说不会很大。Serial 收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。 二、ParNew收集器 它是 Serial 收集器的多线程版本。 新生代采用标记-复制算法，老年代采用标记-整理算法。 是 Server 模式下的虚拟机首选新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合工作。 默认开启的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。 三、Parallel Scavenge收集器 Parallel Scavenge 收集器也是使用标记-复制算法的多线程收集器，它看上去几乎和 ParNew 都一样。 那么它有什么特别之处呢？ Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用标记-复制算法，老年代采用标记-整理算法。 四、CMS收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 CMS(Concurrent Mark Sweep)，Mark Sweep 指的是标记 - 清除算法。分为以下四个流程: 初始标记： 仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记： 进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记： 为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 这里有个问题，为什么要重新标记？ 被回收类可能重写了finalize方法，在该方法中，把该对象和安全对象建立上关联。这种情况下，这个对象就不再需要被回收。 并发清除： 不需要停顿。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感，默认启动（核心数+3）/4个线程，当核心数少于4个时，用户程序可能变得比较慢； 无法处理浮动垃圾（并发清理期间产生的垃圾）； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 五、G1收集器 G1(Garbage-First)，它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 G1 把堆划分成多个大小相等的独立区域(Region)，新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间(这两个值是通过过去回收的经验获得)，并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤: 初始标记 并发标记 最终标记: 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收: 首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 G1收集器具有以下特征： 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的 ，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型， 能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 六、ZGC收集器 ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括： 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB级别的堆（未来支持16TB）。 ZGC原理 与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。 ZGC垃圾回收周期如下图所示： ZGC只有三个STW阶段：初始标记，再标记，初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC关键技术 ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。 关于着色指针和读屏障技术，可参考https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html。 参考资料 https://javaguide.cn/java/jvm/jvm-garbage-collection https://pdai.tech/md/java/jvm/java-jvm-gc.html https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"new一个对象的过程","slug":"2 后端/Java/JVM/4 new一个对象的过程","date":"2022-03-15T14:34:49.000Z","updated":"2022-06-11T13:21:38.533Z","comments":true,"path":"b0774fbf50e0/","link":"","permalink":"http://rookieyin.github.io/b0774fbf50e0/","excerpt":"java new一个对象的过程中发生了什么？ 对于第一次使用该类，需要经历两个过程：（1）类加载以及初始化；（2）创建对象。 如果不是第一次使用该类，直接创建对象即可。","text":"java new一个对象的过程中发生了什么？ 对于第一次使用该类，需要经历两个过程：（1）类加载以及初始化；（2）创建对象。 如果不是第一次使用该类，直接创建对象即可。 类加载 对于类加载，可以看我的另一篇文章“Java类加载机制”，这里简单总结一下类加载过程。 java使用双亲委派机制来进行类的加载，所谓双亲委派，就是类加载器是分层级的：根类加载器、扩展类加载器、应用加载器和用户类加载器。当一个类加载器收到类加载请求时，首先将请求委托给负类加载器去完成，层层向上传递。只有当父类加载器反馈自己无法完成该加载请求时，子类加载器才会尝试亲自去加载。 类加载过程包括以下5个步骤： 加载 类加载器根据类全限定名寻找对应class文件， 并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例 连接 验证：包含格式验证、语义验证、操作验证等 格式验证：验证是否符合class文件规范 语义验证：检查一个被标记为final的类型是否包含子类；检查一个类中的final方法是否被子类进行重写；确保父类和子类之间没有不兼容的一些方法声明（比如方法签名相同，但方法的返回值不同） 操作验证：在操作数栈中的数据必须进行正确的操作，对常量池中的各种符号引用执行验证（通常在解析阶段执行，检查是否可以通过符号引用中描述的全限定名定位到指定类型上，以及类成员信息的访问修饰符是否允许访问等） 准备 为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内） 被final修饰的static变量（常量），会直接赋值； 解析 将常量池中的符号引用转为直接引用（得到类或者字段、方法在内存中的指针或者偏移量，以便直接调用该方法），这个可以在初始化之后再执行。 解析需要静态绑定的内容（所有不会被重写的方法和域都会被静态绑定 ）。 初始化 先初始化父类，再初始化子类。初始化主要包括以下内容： 为静态变量赋值 执行static代码块 最终，方法区会存储当前类类信息，包括类的静态变量、类初始化代码（定义静态变量时的赋值语句 和 静态初始化代码块）、实例变量定义、实例初始化代码（定义实例变量时的赋值语句实例代码块和构造方法）和实例方法，还有父类的类信息引用。 类创建 1、在堆区分配对象需要的内存 分配的内存包括本类和父类的所有实例变量，但不包括任何静态变量 2、对所有实例变量赋默认值 将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值 3、执行实例初始化代码 初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法 4、如果有类似于Child c = new Child()形式的c引用的话，在栈区定义Child类型引用变量c，然后将堆区对象的地址赋值给它 需要注意的是，每个子类对象持有父类对象的引用，可在内部通过super关键字来调用父类对象，但在外部不可访问 参考资料 https://www.cnblogs.com/JackPn/p/9386182.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"Java字节码文件","slug":"2 后端/Java/JVM/3 Java字节码文件","date":"2022-03-14T14:34:49.000Z","updated":"2022-06-11T13:21:09.549Z","comments":true,"path":"9bdf8ffee62d/","link":"","permalink":"http://rookieyin.github.io/9bdf8ffee62d/","excerpt":"1 概述 计算机是不能直接运行java代码的，必须要先运行java虚拟机，再由java虚拟机运行编译后的java代码。这个编译后的java代码，就是本文要介绍的java字节码。 在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。","text":"1 概述 计算机是不能直接运行java代码的，必须要先运行java虚拟机，再由java虚拟机运行编译后的java代码。这个编译后的java代码，就是本文要介绍的java字节码。 在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。 Class文件本质上是一个以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在class文件中。jvm根据其特定的规则解析该二进制数据，从而得到相关信息。 Clojure（Lisp 语言的一种方言）、Groovy、Scala 等语言都是运行在 Java 虚拟机之上。下图展示了不同的语言被不同的编译器编译成.class文件最终运行在 Java 虚拟机之上。 2 Class文件结构 根据 Java 虚拟机规范，Class 文件通过 ClassFile 定义，有点类似 C 语言的结构体。ClassFile 的结构如下： 123456789101112131415161718ClassFile &#123; u4 magic; //Class 文件的标志 u2 minor_version;//Class 的小版本号 u2 major_version;//Class 的大版本号 u2 constant_pool_count;//常量池的数量 cp_info constant_pool[constant_pool_count-1];//常量池 u2 access_flags;//Class 的访问标记 u2 this_class;//当前类 u2 super_class;//父类 u2 interfaces_count;//接口 u2 interfaces[interfaces_count];//一个类可以实现多个接口 u2 fields_count;//Class 文件的字段属性 field_info fields[fields_count];//一个类会可以有多个字段 u2 methods_count;//Class 文件的方法数量 method_info methods[methods_count];//一个类可以有个多个方法 u2 attributes_count;//此类的属性表中的属性数 attribute_info attributes[attributes_count];//属性表集合&#125; 这种伪结构中只有两种类型数据： 无符号数：用u1，u2，u4，u8分别代表1/2/4/8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者 表：由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性的以“_info”结尾。 通过分析 ClassFile 的内容，我们便可以知道 class 文件的组成。 通过 jclasslib 可以直观地查看某个类对应的字节码文件，并查看类的基本信息、常量池、接口、属性、函数等信息。 下面 详细介绍一下 Class 文件结构涉及到的一些组件。 一、魔数 每个 Class 文件的头 4 个字节称为魔数（Magic Number）,它的唯一作用是确定这个文件是否为一个能被虚拟机接收的 Class 文件。 1u4 magic; //Class 文件的标志 二、Class文件版本号 紧接着魔数的四个字节存储的是 Class 文件的版本号：第 5 和第 6 位是次版本号，第 7 和第 8 位是主版本号。 12u2 minor_version;//Class 的小版本号u2 major_version;//Class 的大版本号 高版本的 Java 虚拟机可以执行低版本编译器生成的 Class 文件，但是低版本的 Java 虚拟机不能执行高版本编译器生成的 Class 文件。所以，我们在实际开发的时候要确保开发的的 JDK 版本和生产环境的 JDK 版本保持一致。 三、常量池 紧接着主次版本号之后的是常量池，常量池的数量是 constant_pool_count-1（常量池计数器是从 1 开始计数的，将第 0 项常量空出来是有特殊考虑的，索引值为 0 代表“不引用任何一个常量池项”）。 12u2 constant_pool_count;//常量池的数量cp_info constant_pool[constant_pool_count-1];//常量池 常量池主要存放两大常量：字面量和符号引用。字面量比较接近于 Java 语言层面的的常量概念，如文本字符串、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念。包括下面三类常量： 类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。 常量池中每一项常量都是一个表，这 14 种表有一个共同的特点：开始的第一位是一个 u1 类型的标志位 -tag 来标识常量的类型，代表当前这个常量属于哪种常量类型． 三、访问标志 在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口，是否为 public 或者 abstract 类型，如果是类的话是否声明为 final 等等。 四、当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合 1234u2 this_class;//当前类u2 super_class;//父类u2 interfaces_count;//接口u2 interfaces[interfaces_count];//一个类可以实现多个接口 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，由于 Java 语言的单继承，所以父类索引只有一个，除了 java.lang.Object 之外，所有的 java 类都有父类，因此除了 java.lang.Object 外，所有 Java 类的父类索引都不为 0。 接口索引集合用来描述这个类实现了那些接口，这些被实现的接口将按 implements (如果这个类本身是接口的话则是extends) 后的接口顺序从左到右排列在接口索引集合中。 五、字段集合 字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。 12u2 fields_count;//Class 文件的字段的个数field_info fields[fields_count];//一个类会可以有个字段 字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。 1234567field_info&#123; u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];&#125; access_flags: 字段的作用域（public ,private,protected修饰符），是实例变量还是类变量（static修饰符）,可否被序列化（transient 修饰符）,可变性（final）,可见性（volatile 修饰符，是否强制从主内存读写）。 name_index: 对常量池的引用，表示的字段的名称； descriptor_index: 对常量池的引用，表示字段和方法的描述符； attributes_count: 一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数； attributes[attributes_count]: 存放具体属性具体内容 六、方法表集合 12u2 methods_count;//Class 文件的方法的数量method_info methods[methods_count];//一个类可以有个多个方法 Class 文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式。方法表的结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项。 七、属性表 在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。 12u2 attributes_count;//此类的属性表中的属性数attribute_info attributes[attributes_count];//属性表集合 参考资料 https://pdai.tech/md/java/jvm/java-jvm-class.html https://javaguide.cn/java/jvm/class-file-structure","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"Java类加载机制","slug":"2 后端/Java/JVM/2 Java类加载机制","date":"2022-03-13T14:34:49.000Z","updated":"2022-06-11T13:27:15.256Z","comments":true,"path":"00accef91bd0/","link":"","permalink":"http://rookieyin.github.io/00accef91bd0/","excerpt":"1 类生命周期 一个类的完整生命周期如下图所示：","text":"1 类生命周期 一个类的完整生命周期如下图所示： 其中类加载过程包括5个阶段：加载、验证、准备、解析、初始化，其中除了解析外，其余4个阶段的顺序是固定的。 它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定(也成为动态绑定或晚期绑定)。 另外需要注意的一点是，这里说的“顺序固定”是指开始顺序，而不是按顺序进行或完成， 因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 1.1 加载 在加载阶段需要完成3件事情： 通过类全限定名获取此类的二进制字节流； 对于从哪里获取class文件，没有明确规定，主要有下列几种方式： 本地系统直接加载 通过网络下载 从zip、jar等归档文件中加载 从数据库中读取 将Java元文件动态编译为class文件 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在Java堆中生成一个该类的对象，作为对方法区中这些数据的访问入口。 一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 1.2 验证 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作: 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 1.3 准备 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意: 这时候进行内存分配的仅包括类变量（ Class Variables ，即静态变量，被 static 关键字修饰的变量，只与类相关，因此被称为类变量），而不包括实例变量。实例变量会在对象实例化时随着对象一块分配在 Java 堆中。 这里所设置的初始值通常都是数据类型的默认零值，而不是在java代码中被显示赋予的值。 1.4 解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行。 注： 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可，使用符号引用时，被引用的目标不一定已经加载到内存中。 1.5 初始化 目的 初始化阶段是执行初始化方法的过程，是类加载的最后一步，主要对类变量进行初始化。这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。 步骤 如果该类没有被加载和连接，则先加载和连接该类； 如果该类的直接父类还没有被初始化，则先初始化其直接父类 ； 如果类中有初始化语句，则系统依次执行这些初始化语句。 时机 只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种: 当遇到 new 、 getstatic、putstatic 或 invokestatic 这 4 条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forname(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。 当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 1.6 卸载 Java虚拟机将结束生命周期的几种情况 ： 执行了System.exit()方法； 程序正常执行结束； 程序在执行过程中遇到了异常或错误而异常终止； 由于操作系统出现错误而导致Java虚拟机进程终止。 2 类加载器 2.1 类加载器层次 类加载器可以大致划分为以下三类： 启动类加载器 Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。 扩展类加载器 Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。 应用程序类加载器 Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责**加载用户类路径(ClassPath)**所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 2.2 类加载方式 类加载有三种方式： 命令行启动应用时候由JVM初始化加载； 通过Class.forName()方法动态加载 ； 通过ClassLoader.loadClass()方法动态加载。 2.3 双亲委派机制 系统中的 ClassLoader 在协同工作的时候会默认使用 双亲委派模型 。即在类加载的时候： 系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。 加载的时候，首先会把该请求委派给父类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 BootstrapClassLoader 中。 当父类加载器无法处理时，才由自己来处理。 使用双亲委派机制的优势在于： Java 的核心 API 不被篡改，保证了 Java 程序的稳定运行； 比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。 可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类）， 防止内存中出现多份同样的字节码 。 2.4 自定义类加载器 除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。如果我们要自定义自己的类加载器，很明显需要继承 ClassLoader。 需要注意的是： 最好不要重写loadClass方法，因为这样容易破坏双亲委托模式； 调用loadClass函数时，需要使用全限定名称，如com.aaa.bbb.Test。 参考资料 https://pdai.tech/md/java/jvm/java-jvm-classload.html https://javaguide.cn/java/jvm/classloader","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"一句话总结各种设计模式","slug":"6 设计模式/一句话总结各种设计模式","date":"2022-03-13T07:08:10.000Z","updated":"2022-06-01T05:08:39.471Z","comments":true,"path":"ff79fb7493a9/","link":"","permalink":"http://rookieyin.github.io/ff79fb7493a9/","excerpt":"单例模式：系统中只实例化一个对象，通过类的getInstance()方法该实例，常用于线程池、连接池、日志对象等等。 工厂模式：创建与使用分离，把对象实例化的工作交给工厂来作，用户不需要关心对象如何生成的，需要某个对象时，向工厂申请一个即可。 简单工厂：定义一个工厂类，里面有一个createProduct()用于创建对象。实现简单，但是扩展困难，工厂类单一，职责过重。 工厂方法：不再由工厂类创建对象，而是将该任务转嫁给工厂类的各个子类来完成，由子类来决定该实例化哪一个类。 抽象工厂：将多个抽象工厂方法封装到一起，用于生产一系列相关对象（核心功能），这些对象组合在一起是一个更大的产品。比如讲生产CPU的工厂方法和生产内存的工厂方法封装到一起，组成生产电脑的工厂。","text":"单例模式：系统中只实例化一个对象，通过类的getInstance()方法该实例，常用于线程池、连接池、日志对象等等。 工厂模式：创建与使用分离，把对象实例化的工作交给工厂来作，用户不需要关心对象如何生成的，需要某个对象时，向工厂申请一个即可。 简单工厂：定义一个工厂类，里面有一个createProduct()用于创建对象。实现简单，但是扩展困难，工厂类单一，职责过重。 工厂方法：不再由工厂类创建对象，而是将该任务转嫁给工厂类的各个子类来完成，由子类来决定该实例化哪一个类。 抽象工厂：将多个抽象工厂方法封装到一起，用于生产一系列相关对象（核心功能），这些对象组合在一起是一个更大的产品。比如讲生产CPU的工厂方法和生产内存的工厂方法封装到一起，组成生产电脑的工厂。 桥接模式：简单来说就是用组合代替继承，避免直接继承带来的子类爆炸。比如图形类，可以按照形状分，也可以按照颜色分，如果用继承方式，m 种形状和 n 种颜色的图形就有 m×n 种，不但对应的子类很多，而且扩展困难。 适配器模式：系统中某个功能由A接口实现，客户需要用B接口来调用该功能，我们就可以新建一个实现了B接口的适配器类，然后通过组合方式，在适配器类中调用A接口实现的功能。 外观模式：核心目的在于简化接口，把若干个子系统封装到一起，定义一个更高层的接口，用户不需要关心各个子系统是如何实现的，只需要和高层接口打交道即可。缺点是，增加或删除子系统时需要修改外观类，违背开闭原则。 装饰器模式：不改变对象的情况下，动态添加功能。抽象装饰器类和具体对象类，实现相同的接口，以组合的方式给对象动态添加功能。 享元模式：“享元”即共享元素，通过复用一些共享对象，避免创建大量重复对象，减小内存开销。比如围棋中，棋子可以作为抽象享元元素（包含落子方法），黑棋和白棋就是具体享元元素（实现具体享元方法），棋子工厂（创建黑子和白子，存储到一个容器中，并提供获取棋子的方法），非享元元素就是落子的位置，以参数形式传递给享元元素的落子方法。 策略模式：系统中某种功能可能有多种实现方案（比如排序方案、折扣方案等），策略模式可以帮助我们在不改变代码的情况下，动态选择具体实现方式。具体实现上，就是把所有策略封装起来，实现一个共同接口，在客户代码中实际用抽象接口，而不是具体策略类。 观察者模式：一种订阅发布模式，对于目标类，当其发生某种事件时，需要通知所有订阅者。在具体实现上，目标类可能用一个列表存储所有订阅者，当事件发生时，通知订阅者。JDK中提供了Observable接口，不过JDK9中已经被弃用，提供了功能更强大的Flow相关类。 命令模式：把命令封装成对象，我的理解就是把一段实现某种特定功能的代码封装起来，达到快速替换命令的效果，同时解耦客户和命令的具体实现。客户只需要关心执行这个命令，能达到某种效果就行，不需要关心命令的具体实现方式。 模板方法模式：定义算法骨架，其中某些步骤可能在顶层接口中实现了，但是某些步骤只给出定义，具体实现交给子类来完成。相当于创建了一个模板，子类以这个模板为基础，添砖加瓦，实现更加丰富的功能。在Spring的IOC充分使用了该模式。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"行为型——模板方法模式","slug":"6 设计模式/行为型——模板方法模式","date":"2022-03-12T07:08:10.000Z","updated":"2022-06-01T05:08:36.925Z","comments":true,"path":"7ce6880842bc/","link":"","permalink":"http://rookieyin.github.io/7ce6880842bc/","excerpt":"什么是模板方法模式 模板方法模式：定义某种操作的一个算法骨架， 而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 所谓模板方法模式，就是创建一个模板，模板指的就是一个方法或者说操作，这个方法包含一组步骤，其中任何步骤都可以是抽象的，交由子类来具体实现。","text":"什么是模板方法模式 模板方法模式：定义某种操作的一个算法骨架， 而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 所谓模板方法模式，就是创建一个模板，模板指的就是一个方法或者说操作，这个方法包含一组步骤，其中任何步骤都可以是抽象的，交由子类来具体实现。 这样的例子在生活中还有很多，例如，一个人每天会起床、吃饭、做事、睡觉等，其中“做事”的内容每天可能不同。我们把这些规定了流程或格式的实例定义成模板，允许使用者根据自己的需求去更新它，例如，简历模板、论文模板、Word 中模板文件等。 该模式优缺点定义如下： 优点 它封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展。 它在父类中提取了公共的部分代码，便于代码复用。 部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则。 缺点 对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象，间接地增加了系统实现的复杂度。 父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度。 由于继承关系自身的缺点，如果父类添加新的抽象方法，则所有子类都要改一遍。 模板方法模式和策略模式非常相像，下面将两者作一个简单的对比： 功能上的不同 策略模式定义一个算法家族，这些算法之间可以互换 模板方法模式定义一个算法大纲，大纲中的每一个步骤都可以是抽象的，交由子类来实现 实现方式上的不同 策略模式通过组合方式来实现，客户类持有抽象策略类 模板方法模式通过继承方式实现 模板方法模式的结构 模板方法模式用到了虚函数的多态性技术以及“不用调用我，让我来调用你”的反向控制技术，包含以下角色： 抽象模板类 抽象模板类负责 给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。这些方法的定义如下。 模板方法： 定义了算法的骨架，按某种顺序调用其包含的基本方法。 基本方法：算法大纲中的具体步骤 抽象方法： 在抽象类中声明，由具体子类实现。 具体方法： 在抽象类中已经实现，在具体子类中可以继承或重写它。 钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。 具体实现类 实现抽象类中所定义的抽象方法和钩子方法 。 模板方法模式结构图如下： 模板方法模式的应用 应用场景 模板方法模式通常适用于以下场景。 算法的整体步骤很固定，但其中个别部分易变时，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现。 当多个子类存在公共的行为时，可以将其提取出来并集中到一个公共父类中以避免代码重复。首先，要识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。 当需要控制子类的扩展时，模板方法只在特定点调用钩子操作，这样就只允许在这些点进行扩展。 具体应用 JDK中的应用 排序接口，即通过实现 comparable 接口，然后调用 Collections.sort() 或者 Arrays.sort() 方法进行排序。这个方法其实也是个模板方法，比较器的实现步骤如下： 构建对象数组 通过 Arrays.sort 方法对数组排序，传参为 Comparable 接口的实例 比较时候会调用我们的实现类的 compareTo() 方法 将排好序的数组设置进原数组中，排序完成 Spring中的应用 Spring中的应用非常多，比如IOC容器初始化时调用refresh方法 JDBC Template，通过模板方法+回调实现 参考资料 http://c.biancheng.net/view/1376.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Redis主从复制","slug":"2 后端/Redis/Redis主从复制","date":"2022-03-11T14:34:58.000Z","updated":"2022-03-11T14:39:06.554Z","comments":true,"path":"0a87fbe80a6b/","link":"","permalink":"http://rookieyin.github.io/0a87fbe80a6b/","excerpt":"主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 主从复制的目的在于： 数据冗余：从节点备份主节点数据，持久化之外的另一种数据冗余方式。 故障恢复：主节点出现问题，从节点顶上，实现快速故障恢复。 负载均衡：主节点写，从节点读，提高系统并发能力。 高可用基石： 主从复制还是哨兵和集群能够实施的基础","text":"主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 主从复制的目的在于： 数据冗余：从节点备份主节点数据，持久化之外的另一种数据冗余方式。 故障恢复：主节点出现问题，从节点顶上，实现快速故障恢复。 负载均衡：主节点写，从节点读，提高系统并发能力。 高可用基石： 主从复制还是哨兵和集群能够实施的基础 建立主从复制 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 需要注意，主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。 从节点开启主从复制，有3种方式： 配置文件 在从服务器的配置文件中加入：slaveof 启动命令 redis-server启动命令后加入 --slaveof 客户端命令 Redis服务器启动后，直接通过客户端执行命令：slaveof ，则该Redis实例成为从节点。 注意：redis5.0之前使用slaveof，之后使用replicaof。 主从复制原理 主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。 连接建立 该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。 Step 1. 保存主节点信息 slaveof命令执行后， 从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。需要注意的是，slaveof是异步命令。 Step2. 建立Socket连接 从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则： 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 Step3. 发送Ping命令 从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 Step 4. 身份验证 如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 Step 5. 发送从节点端口信息 身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步 主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制 ，下面部分再详细介绍。 命令传播 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。 延迟与不一致 需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。 一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 全量 VS增量复制 全量复制 Redis通过**psync命令**进行**全量复制**的过程如下： （1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行部分复制；具体判断过程需要在讲述了部分复制原理后再介绍。 （2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区 replication buffer ）记录从现在开始执行的所有写命令。 （3）主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 （4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态 （5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态 全量复制是非常重型的操作：主节点需要进行rdb持久化，然后通过网络发给从节点，从节点再载入收到的RDB文件，如果从节点开启了AOF，还要进行bgrewriteaof。 增量复制 Redis2.8之后引入增量复制的目的在于： 如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。 增量复制中有三个关键概念： offset：复制偏移量，主、从节点各有一个offset值，代表主节点向从节点传递的字节数。 主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。 offset用于判断主从节点的数据库状态是否一致。 replbacklog：环形复制缓冲区， 是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB。 在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。 runid：服务器id， 每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 实战问题 主服务器不开启持久化的安全问题 在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。 否则，自动重启后，主服务器数据为空，从服务器复制主服务器数据后也会变成空。 为什么主从复制使用RDB而不是AOF RDB文件进行了压缩，文件比较小有利于网络传输； 使用AOF做全量复制，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。 而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。 无磁盘复制模式？ master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。 主-从-从设计模式？ 如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。 传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力 。 通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上 。 读写分离存在的问题 延迟与不一致问题 延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。 在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。 数据过期问题 在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。 Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。 故障切换问题 在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。 总结 在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。 总结 主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-copy.html https://www.cnblogs.com/kismetv/p/9236731.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"Redis数据结构底层原理","slug":"2 后端/Redis/Redis数据结构底层原理","date":"2022-03-11T14:34:55.000Z","updated":"2022-03-11T14:45:16.617Z","comments":true,"path":"67952895de8b/","link":"","permalink":"http://rookieyin.github.io/67952895de8b/","excerpt":"声明：本文大部分内容都来自Java全站知识体系 Redis的每种对象其实都由对象结构(redisObject) 与 对应编码的数据结构组合而成, 本文主要介绍底层数据结构 部分。 Redis底层包括SDS、QuickList、ZipList、HashTable、IntSet、ZSkipList和Redis Tree of listpack。这些结构和上层数据类型之间的映射关系如下图所示：","text":"声明：本文大部分内容都来自Java全站知识体系 Redis的每种对象其实都由对象结构(redisObject) 与 对应编码的数据结构组合而成, 本文主要介绍底层数据结构 部分。 Redis底层包括SDS、QuickList、ZipList、HashTable、IntSet、ZSkipList和Redis Tree of listpack。这些结构和上层数据类型之间的映射关系如下图所示： SDS简单动态字符串 底层设计 Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。 SDS的结构如下图所示： - 头部：sdshdr，SDS有5中类型头部，其中sdshdr5实际并未使用到 数据：buf，用于存储用户数据，并且数据后面跟一个“\\0” 以sdshdr8为例，其底层代码如下： 123456struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; len：保存SDS保存字符串的长度 alloc： 分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\\0, 剩余的字节数 flags： 始终为一字节, 以低三位标示着头部的类型, 高5位未使用 buf[]：存字符串中所有字符 为什么使用SDS？ - **常数复杂度获取字符串长度** 直接通过len属性获取字符串长度 杜绝缓冲区溢出 在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。 而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。 减少修改字符串的内存重新分配次数 C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。 而对于SDS，由于len属性和alloc属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略： 1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。 2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 alloc 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。） 二进制安全 C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。 兼容部分C字符串函数 虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库&lt;string.h&gt;中的一部分函数。 ZipList压缩列表 ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。他能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。 实际上，ziplist充分体现了Redis对于存储效率的追求。**一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。**而ziplist却是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list），可以看做链表和数组的折中方案。 存储格式 整个ziplist在内存中的存储格式如下： - `zlbytes`字段的类型是uint32_t，这个字段中存储的是整个ziplist所占用的内存的字节数 - `zltail`字段的类型是uint32_t，它指的是ziplist中最后一个entry的偏移量。用于快速定位最后一个entry，以快速完成pop等操作 - `zllen`字段的类型是uint16_t，它指的是整个ziplit中entry的数量。这个值只占2bytes（16位）: 如果ziplist中entry的数目小于65535(2的16次方)，那么该字段中存储的就是实际entry的值。若等于或超过65535，那么该字段的值固定为65535，但实际数量需要一个个entry的去遍历所有entry才能得到。 - `zlend`是一个终止字节, 其值为全F，即0xff。 ziplist保证任何情况下，一个entry的首字节都不会是255。 Entry结构 结构1： &lt;prevlen&gt; &lt;encoding&gt; &lt;entry-data&gt; prevlen：前一个entry的大小 当前一个元素长度小于254（255用于zlend）的时候，prevlen长度为1个字节，值即为前一个entry的长度，如果长度大于等于254的时候，prevlen用5个字节表示，第一字节设置为254，后面4个字节存储一个小端的无符号整型，表示前一个entry的长度。 encoding：不同情况值不同，表示当前entity的类型和长度 encoding的长度和值根据保存的是int还是string，还有数据的长度而定。 前两位用来表示类型，当为“11”时，表示entry存储的是int类型，其他表示存储的是string。 entry-data：用于存真正的数据 结构2：&lt;prevlen&gt; &lt;encoding&gt;，entry-data合并到了encoding中 **源码：**源码中为了方便操作，还添加了几个其他属性。 1234567891011121314151617181920212223/* We use this function to receive information about a ziplist entry. * Note that this is not how the data is actually encoded, is just what we * get filled by a function in order to operate more easily. */typedef struct zlentry &#123; unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/ unsigned int prevrawlen; /* Previous entry len. */ unsigned int lensize; /* Bytes used to encode this entry type/len. For example strings have a 1, 2 or 5 bytes header. Integers always use a single byte.*/ unsigned int len; /* Bytes used to represent the actual entry. For strings this is just the string length while for integers it is 1, 2, 3, 4, 8 or 0 (for 4 bit immediate) depending on the number range. */ unsigned int headersize; /* prevrawlensize + lensize. */ unsigned char encoding; /* Set to ZIP_STR_* or ZIP_INT_* depending on the entry encoding. However for 4 bits immediate integers this can assume a range of values and must be range-checked. */ unsigned char *p; /* Pointer to the very start of the entry, that is, this points to prev-entry-len field. */&#125; zlentry; 优缺点 ZipList的优点从名字“压缩列表”就可以看出是节省空间（和普通list相比）。 如果是普通的数组，那么它每个元素占用的内存是一样的且取决于最大的那个元素（很明显它是需要预留空间的） 。 ZipList的缺点就是： ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作。 结点如果扩容，导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应：其后一个结点的entry.prevlen需要从一字节扩容至五字节。最坏情况下, 第一个结点的扩容, 会导致整个ziplist表中的后续所有结点的entry.prevlen字段扩容。 QuickList快表 QuickList 是一种以ziplist为结点的双端链表结构。 宏观上，quicklist是一个链表，微观上，链表中的每个结点都是一个ziplist。 它的内存布局如下图所示： Quicklist有自己的优点, 也有缺点，对于使用者来说，其使用体验类似于线性数据结构, list作为最传统的双链表, 结点通过指针持有数据, 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题。但引入了新的问题：每次写操作整个ziplist的内存都需要重分配。**quicklist在两者之间做了一个平衡**。并且使用者可以通过自定义`quicklist.fill`，根据实际业务情况， 经验主义调参。 Dict哈希表 哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，哈希表和dictEntry 结构定义如下： 12345678910111213141516typedef struct dictht&#123; dictEntry **table;//哈希表数组 unsigned long size;//哈希表大小 unsigned long sizemask;//哈希表大小掩码，用于计算索引值，总是等于 size-1 unsigned long used;//该哈希表已有节点的数量&#125;dicthttypedef struct dictEntry&#123; void *key;//键 union&#123; void *val; uint64_tu64; int64_ts64; &#125;v;//值 struct dictEntry *next;//指向下一个哈希表节点，形成链表&#125;dictEntry 需要注意的是，dictEntry中还有一个指向下一个节点的指针。因为这里采用的时链地址法解决哈希冲突的问题，通过next指针可以将多个哈希值相同的键值对连接到一起。下面介绍hash表中几个重要知识点： 扩容和收缩： 当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。 x新建，扩容则创建2倍大小的新hash表，缩容则创建一半大小的新hash表； rehash，重新利用上面的哈希算法，计算索引值，然后将键值对放到对应位置； 释放，所有键值对迁徙完毕后，释放旧hash表。 触发扩容条件 服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。 负载因子= 哈希表已保存节点数量 / 哈希表大小 。 渐进式rehash 什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。 其目的在于防止键值对数量过多，导致rehash阻塞主线程时间过长。 在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。 IntSet整数集 整数集合（intset）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。 intset的源码结构如下： 12345typedef struct intset &#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset; encoding：4字节，表示编码方式，取值有三个INTSET_ENC_INT16, INTSET_ENC_INT32, INTSET_ENC_INT64。 length：4字节，代表存储的整数个数 contents： 指向实际存储数值的连续内存区域，就是一个数组。 各个项在数组中按值得大小从小到大有序排序，且数组中不包含任何重复项。 需要注意的一点是，如果在一个int16类型的整数集合中插入一个int32类型的值，整个集合的所有元素都会转换成32类型。 分三步： 根据新元素的类型（比如int32），扩展整数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。 最后改变encoding的值，length+1。 但是如果删掉刚刚加入的int32类型数据时，不会作降级操作。 ZSkipList跳表 通用skiplist 在介绍redis中zskiplist之前，先看下通用的skip list是什么？有什么用？怎么实现的？ skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的，其思想类似于二分查找。 我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）： 在这样一个列表里面，无论是查找、删除还是添加元素的时间复杂度都是O(n)。 假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图： 这样增加的指针构成的新链表的节点数只有原来的一半。 现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的： 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图： 在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。 但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。 kiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程： 当然，这个过程中还有一个重要问题就是： 执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。它的计算过程如下： 首先每个节点肯定都有第一层指针。 如果一个节点有第i层(i&gt;=1)指针，那么它有第(i+1)层指针的概率为p。 节点最大的层数不允许超过一个最大值，记为MaxLevel。 因此通过统计学计算可以得到，一个节点的平均层数1/1−p1/{1-p}1/1−p。 Redis中的skiplist实现 和原版skiplist相比，redis中有如下设定： 增加了backward指针，指向结点的前一个紧邻节点； MaxLevel设置为32，即每个节点最多有32层指针； p设置为1/41/41/4，，即每个节点平均有1.33个指针，比平衡树更有优势。 zskiplist在内存中的布局如下图所示： zskiplist的核心设计要点如下： 头节点不持有任何数据, 且其level[]的长度为32 每个结点 ele字段，持有数据，是sds类型 score字段, 其标示着结点的得分, 结点之间凭借得分来判断先后顺序, 跳跃表中的结点按结点的得分升序排列. backward指针, 这是原版跳跃表中所没有的. 该指针指向结点的前一个紧邻结点. level字段, 用以记录所有结点(除过头节点外)；每个结点中最多持有32个zskiplistLevel结构. 实际数量在结点创建时, 按幂次定律随机生成(不超过32). 每个zskiplistLevel中有两个字段 forward字段指向比自己得分高的某个结点(不一定是紧邻的), 并且, 若当前zskiplistLevel实例在level[]中的索引为X, 则其forward字段指向的结点, 其level[]字段的容量至少是X+1. 这也是上图中, 为什么forward指针总是画的水平的原因. span字段代表forward字段指向的结点, 距离当前结点的距离. 紧邻的两个结点之间的距离定义为1 平衡树、跳表和哈希表三者对比 skiplist和各种平衡树中的元素是有序的，而哈希表不是有序的。因此哈希表适合做单个key查找，不适合做范围查找。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。 **内存占用上来说，skiplist比平衡树更灵活一些。**一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 从算法实现难度上来比较，skiplist比平衡树要简单得多。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html http://zhangtielei.com/posts/blog-redis-ziplist.html https://www.jianshu.com/p/8ac45fd01548","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"Java内存空间","slug":"2 后端/Java/JVM/1 Java内存空间","date":"2022-03-11T14:34:49.000Z","updated":"2022-06-11T13:28:12.957Z","comments":true,"path":"57edbfaf4ec4/","link":"","permalink":"http://rookieyin.github.io/57edbfaf4ec4/","excerpt":"1 概述 Java虚拟机在执行Java程序时会将它所管理的内存划分成若干个不同的数据区域。 下图是JVM的整体结构，中间部分就是Java虚拟机定义的各种运行时数据区域。这些内存区域可以分为两类： 线程私有：程序计数器、虚拟机栈、本地方法栈 线程共享：堆、方法区、堆外内存（Java7的永久代，JDK8的元空间、代码缓存）","text":"1 概述 Java虚拟机在执行Java程序时会将它所管理的内存划分成若干个不同的数据区域。 下图是JVM的整体结构，中间部分就是Java虚拟机定义的各种运行时数据区域。这些内存区域可以分为两类： 线程私有：程序计数器、虚拟机栈、本地方法栈 线程共享：堆、方法区、堆外内存（Java7的永久代，JDK8的元空间、代码缓存） 2 程序计数器 程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 因此程序计数器有两个作用： 代码流程控制： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 线程切换： 在多线程的情况下，程序计数器用于记录当前线程执行位置，从而当线程被切换回来的时候知道该线程上次运行到哪儿了。 3 虚拟机栈 每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java 方法调用，是线程私有的，生命周期和线程一致。 其中每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。 结构如下图所示： 作用 主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 特点 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。 JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈/压栈），方法执行结束出栈。 栈不存在垃圾回收问题。 异常 JVM的虚拟机栈可能出现两种异常： StackOverFlowError ：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 4 本地方法栈 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 5 堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 5.1 堆划分 为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）： 新生代：新对象和没达到一定年龄的对象都在新生代 。新生代又分成三部分（默认比例8:1:1）： Eden：大多数新创建的对象都存在于Eden区。 S0/S1：当Eden空间满时，执行Minor GC，并将所有幸存者移动到同一个S区（所以每次总有一个S区是空的），并且幸存者年龄加1，当幸存者年龄达到阈值后，将其移动到老年区。 老年代： 被长时间使用的对象，老年代的内存空间应该要比年轻代更大 。 需要注意的是， 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝。 元空间 （JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存。元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了，而由系统的实际可用空间来控制，这样能加载的类就更多了 。 5.2 堆内对象分配过程 new 的对象先放在伊甸园区，此区有大小限制 当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区 然后将伊甸园中的剩余对象移动到幸存者 0 区 如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区 如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区 什么时候才会去养老区呢？ 默认是 15 次回收标记 在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理 若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常 6 方法区 虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫non-Heap（非堆），目的应该是将其与Java堆区分开。 方法区是Java虚拟机规范中定义的一种概念， 用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。 下图展示了堆、栈、方法区三者之间的交互关系： 6.1 运行时常量池 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）。 为什么需要运行时常量池？ 一个 Java 源文件中的类、接口，编译后产生一个字节码文件。而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。另外，运行时也可能生成一些常量，比如String类的intern()方法。 运行时常量池工作原理 在加载类和结构到虚拟机后，就会创建对应的运行时常量池 常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的 运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或字段引用。此时不再是常量池中的符号地址了，这里换为真实地址 运行时常量池，相对于 Class 文件常量池的另一个重要特征是：动态性，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 intern() 方法就是这样的 当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛出 OutOfMemoryError 异常。 6.2 元空间、永久代、方法区傻傻分不清？ 方法区（method area）只是 JVM 规范中定义的一个概念，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。 在Java8之后，永久代被移除，替换成元空间。永久代中的类原型信息被移到元空间中，静态变量、常量池等并入堆中。永久代参数 -XX:PermSize 和 -xx:MaxPermSize 也被元空间参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 取代。 7 内存分配策略 对象优先在Eden分配 大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。 经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制。 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。 -XX:MaxTenuringThreshold 用来定义年龄的阈值。 动态对象年龄判定 虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。 8 常见Java 内存泄漏场景 内存泄漏是指：一个不再被程序使用的对象或者变量还在内存中占有存储空间。 情景一：静态集合类 如HashMap、LinkedList等等，如果这些容器类被设置成静态的，那么其生命周期与程序一致，尽管这些对象不被使用，其占用的内存也不会被回收。 情景二：各种连接 如数据库连接、网络连接、IO连接等。当不在使用这些连接时，需要调用close()方法，否则垃圾回收器不会回收这些对象。 情景三：变量不合理的作用域 通常，一个变量定义的作用域范围大于其使用范围时很可能会造成内存泄漏。另一方面，如果没有及时地把对象设置成null，也可能造成内存泄漏。 情景四：内部类持有外部类 在Java中，非静态的内部类和匿名内部类都会隐式地持有其外部类的引用。静态的内部类不会持有外部类的引用。当调用外部类方法产生一个内部类实例后，即使外部类实例不在被使用也不会不GC回收，因为内部类实例隐式地持有外部类实例的引用。 情景五：改变哈希值 一个对象被存储进HashSet集合中后，就不能修改这个对象中那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为参数去HashSet中检索对象，也找不到对象，这会导致无法从HashSet集合中单独删除当前对象，造成内存泄漏。 9 常见内存溢出报错 情景一：java.lang.OutOfMemoryError:Javaheapspace ​ java堆内存不够，一种原因是真的不够（可以通过配置JVM解决），另一种是程序中有死循环。 情景二：java.lang.OutOfMemoryError:GCoverheadlimitexceeded ​ GC释放很小空间却花费大量时间，一般是因为堆太小，没有足够的内存。 ​ 解决方案： 查看系统是否有使用大内存的代码或者死循环；配置JVM，限制使用内存 情景三：java.lang.OutOfMemoryError:PermGenspace ​ 这种是P区内存不够，可以通过配置JVM解决。 情景四：java.lang.OutOfMemoryError:unabletocreatenewnativethread ​ Stack空间不足以创建新的线程，一种是创建线程太多，另一种是stack确实太小了。 ​ 解决方案： 减小单个线程的大小；配置JVM减小堆内存，将内存让给Stack 情景五：java.lang.StackOverflowError ​ 线程栈溢出，要么是方法调用层次过多（无限递归），要么是线程栈太小。 ​ 解决方案： 优化程序设计；增大线程栈大小","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"}]},{"title":"行为型——命令模式","slug":"6 设计模式/行为型——命令模式","date":"2022-03-11T07:08:10.000Z","updated":"2022-06-01T05:08:30.277Z","comments":true,"path":"e875640894b9/","link":"","permalink":"http://rookieyin.github.io/e875640894b9/","excerpt":"概述 所谓“命令模式”，简单解释就是：把命令封装成对象，当客户需要执行某条命令时，直接new一个该命令对应的对象，然后调用命令对象中的excute方法即可。这种设计下，命令调用者无需关心命令具体是怎样执行的，达到命令调用者和命令执行者之间解耦的目的。","text":"概述 所谓“命令模式”，简单解释就是：把命令封装成对象，当客户需要执行某条命令时，直接new一个该命令对应的对象，然后调用命令对象中的excute方法即可。这种设计下，命令调用者无需关心命令具体是怎样执行的，达到命令调用者和命令执行者之间解耦的目的。 这里的“命令”指的是什么？ 任何逻辑处理请求都可以看作是命令，换句话说，某段逻辑处理代码在当前系统中多次出现，或者不同的参数下需要执行不同的逻辑处理代码，你就可以将这些逻辑处理代码封装成一个个命令对象。 现实生活中有没有类似例子？ 前面对“命令模式”的解释可能还有点抽象，现实生活中有没有类似的例子可以对比呢？当然有， 比如看电视时，我们只需要轻轻一按遥控器就能完成频道的切换，这就是命令模式，将换台请求和换台处理完全解耦了。电视机遥控器（命令发送者）通过按钮（具体命令）来遥控电视机（命令接收者）。 定义与实现 命令模式比较正式的定义如下： 将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。 优缺点 命令模式的优缺点如下： 优点 降低耦合度，因为把命令抽象成对象，实现了命令调用者和执行这之间的解耦； 开闭原则，可以方便地扩展、修改、增加、删除命令； 实现命令管理，比如结合“备忘录模式”，实现命令的undo和redo操作。 缺点 类更多，系统更加复杂，同时更难以理解（大部分设计模式的通病）。 类图结构 在“命令模式”中主要涉及三个角色：命令调用者，命令对象和命令执行者。下图是一个比较通用类结构： 宏命令 以“遥控器”为例，有的时候，我们可能希望按一个按钮，同时实现多个功能，这是后就需要用到“宏命令”了。 所谓的宏命令就是：具体命令类中不再拥有单个命令执行者，而是拥有一个命令执行者数组，在execute函数中，用for循环调用每个命令执行者的action方法。 1234567891011public class MacroCommand implements Command&#123; Command[] commands; public MacroCommand(Command[] commands)&#123; this.commands = commands; &#125; public void execute()&#123; for(int i = 0; i &lt; commands.length; ++i)&#123; commands[i].execute(); &#125; &#125;&#125; 命令模式下的“遥控器” 这里我们基于设计模式，实现一个简单的“遥控器”类，并实现打开灯的功能。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//抽象命令类public interface Command &#123; void execute();&#125;//具体命令类：打开灯public class LightOnCommand implements Command &#123; Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.on(); &#125;&#125;//具体命令类：关闭灯public class LightOffCommand implements Command &#123; Light light; public LightOffCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.off(); &#125;&#125;//命令执行者public class Light &#123; public void on() &#123; System.out.println(&quot;Light is on!&quot;); &#125; public void off() &#123; System.out.println(&quot;Light is off!&quot;); &#125;&#125;/** * 命令调用者：遥控器 */public class Invoker &#123; private Command[] onCommands; private Command[] offCommands; private final int slotNum = 7; public Invoker() &#123; this.onCommands = new Command[slotNum]; this.offCommands = new Command[slotNum]; &#125; public void setOnCommand(Command command, int slot) &#123; onCommands[slot] = command; &#125; public void setOffCommand(Command command, int slot) &#123; offCommands[slot] = command; &#125; public void onButtonWasPushed(int slot) &#123; onCommands[slot].execute(); &#125; public void offButtonWasPushed(int slot) &#123; offCommands[slot].execute(); &#125;&#125;//客户public class Client &#123; public static void main(String[] args) &#123; Invoker invoker = new Invoker(); Light light = new Light(); //创建命令实例，并指定命令执行者 Command lightOnCommand = new LightOnCommand(light); Command lightOffCommand = new LightOffCommand(light); invoker.setOnCommand(lightOnCommand, 0); invoker.setOffCommand(lightOffCommand, 0); invoker.onButtonWasPushed(0); invoker.offButtonWasPushed(0); &#125;&#125; 应用 应用场景 当系统的某项操作具备命令语义，且命令实现不稳定（变化）时，可以通过命令模式解耦请求与实现。使用抽象命令接口使请求方的代码架构稳定，封装接收方具体命令的实现细节。接收方与抽象命令呈现弱耦合（内部方法无需一致），具备良好的扩展性。 命令模式通常适用于以下场景。 请求调用者需要与请求接收者解耦时，命令模式可以使调用者和接收者不直接交互。 系统随机请求命令或经常增加、删除命令时，命令模式可以方便地实现这些功能。 当系统需要执行一组操作时，命令模式可以定义宏命令来实现该功能。 当系统需要支持命令的撤销（Undo）操作和恢复（Redo）操作时，可以将命令对象存储起来，采用备忘录模式来实现。 在JDK中的应用 JDK中的Runnable接口，相当于命令模式中的抽象命令，其中的“run”方法，相当于这里的“execute”方法。 JUnit中的Test接口，实现该接口，就可以直接进行测试。 在Spring中的应用 在Jdbc Template里面用到了命令模式，感兴趣的可以自行了解。 参考资料 https://pdai.tech/md/dev-spec/pattern/18_command.html http://c.biancheng.net/view/1380.html 《HeadFirst设计模式》","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"行为型——观察者模式","slug":"6 设计模式/行为型——观察者模式","date":"2022-03-10T07:08:10.000Z","updated":"2022-06-01T05:08:19.526Z","comments":true,"path":"8ae23491da19/","link":"","permalink":"http://rookieyin.github.io/8ae23491da19/","excerpt":"什么是观察者模式 观察者模式：定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会受到通知并自动更新。类似一种订阅发布模式，用户订阅某主题，当该主题有更新后会主动通知订阅者。","text":"什么是观察者模式 观察者模式：定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会受到通知并自动更新。类似一种订阅发布模式，用户订阅某主题，当该主题有更新后会主动通知订阅者。 从定义就可以看出，观察者模式是一种行为模式，包含以下角色： 抽象主题：抽象主题接口，定义了添加观察者、删除观察者、通知观察者的方法。 具体主题：具体主题类，实现抽象目标中的通知方法，当具体主题类内部状态发生改变时，主动通知订阅者。 抽象观察者：抽象观察接口，所有具体观察者类都要实现该接口，定义了response方法，供具体主题调用。 具体观察者：实现抽象观察者中的response方法。 观察者模式的类图如下图所示： 为什么要用观察者模式 了解了观察者模式的一些定义后，观察者模式有什么用呢？什么场景下可能用到观察者模式？ 在软件开发过程中，很多对象并不是独立存在的，有时候一个对象的行为发生变化，可能会同时影响多个其他对象。以《HeadFirst 设计模式》中的“气象站”为例： 有一个气象站用于获取温度、湿度、气压等天气信息，有3个布告板：目前状况、气象统计、气象预报。这3个布告板依赖于气象站获取到的气象信息，进行数据展示。当气象站获取到新的气象数据后，需要及时更新3个布告板中的信息。如下图所示： 如果不使用观察者模式，我们的代码可能是这样的： 这时用观察者模式就能更好地完成任务，不仅符合开闭原则，还能解耦气象站和布告板类。 观察者模式的优缺点可以总结如下： 优点 解耦：降低了目标和观察者之间的耦合关系； 符合依赖倒置原则。 缺点 最主要的缺点可能是：当观察者很多时，通知的发布会花费很多时间，影响程序效率。 JDK中的Observable类 在java.util包中内置了Observer接口和Observable类，前者相当于抽象观察者，后者相当于抽象主题类。我们可以通过实现和继承Observer和Observable，快速实现观察者模式。不过，JDK9中被弃用了。 下面我们简单看下它们的源码： 1234package java.util;public interface Observer &#123; void update(Observable o, Object arg);&#125; 和前面我们提到的观察者模式不同，Observable类中有一个changed字段表示主题状态是否发生变化，这给我们的设计可以带来更大的弹性。因为，我们可以更可控的去通知观察者。以上面的气象站为例，原本我们可能只要监测数据发生一丁点变化就要通知观察者，但是现在我们可以在数据变化超过一定范围时再通知观察者。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package java.util;public class Observable &#123; private boolean changed = false; //是否改变状态 private Vector obs; //Vector利用同步方法来线程安全，线程安全在多线程情况下不会造成数据混乱 public Observable() &#123; obs = new Vector(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) //状态值未改变时返回，不通知 return; arrLocal = obs.toArray(); //将Vector转换成数组 clearChanged(); //重置状态 &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; 观察者模式的应用 应用场景 所有涉及到订阅发布的场景，都可能用到观察者模式； 对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。 JDK中的应用 提供了Observer接口和Observable类。需要注意的是： 抽象主题Observable是类，而不是接口，因此不支持继承。 这两个类（接口）在JDK9中已经被弃用，引入了新的Flow相关类。 为什么弃用它？主要有以下几点原因： 支持的事件模型非常有限，只能单一的通知观察者数据发生更改； 不支持序列化； 通知的顺序未指定。 Spring中的应用 Spring中的事件监听器，是很经典的观察者模式。 参考资料 http://c.biancheng.net/view/1390.html 《HeadFirst设计模式》","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"结构型——策略模式","slug":"6 设计模式/行为型——策略模式","date":"2022-03-09T07:08:10.000Z","updated":"2022-06-01T05:08:11.146Z","comments":true,"path":"7a1bbf9ffc6c/","link":"","permalink":"http://rookieyin.github.io/7a1bbf9ffc6c/","excerpt":"什么是策略模式 在软件开发过程中，某些行为可能具有不同的实现方式，比如，对于排序这一行为，其具体实现可能包括堆排序、插入排序、选择排序、希尔排序、快速排序等等，这些实现方式有着各自的应用场景。在软件运行过程中，对于某种行为，我们希望能够动态选择具体实现方式。这时候就需要用到策略模式了。","text":"什么是策略模式 在软件开发过程中，某些行为可能具有不同的实现方式，比如，对于排序这一行为，其具体实现可能包括堆排序、插入排序、选择排序、希尔排序、快速排序等等，这些实现方式有着各自的应用场景。在软件运行过程中，对于某种行为，我们希望能够动态选择具体实现方式。这时候就需要用到策略模式了。 那什么是策略模式呢？ 策略模式通常定义为： 定义了一系列算法（行为的具体实现），并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。 其目的在于，解耦行为与行为的具体实现，把行为的具体实现委派给其他对象。 策略模式具有如下优缺点： 优点 封装，将行为的具体实现进行封装，方便在多处使用； 解耦，解耦了行为与行为的具体实现，降低耦合度； 开闭原则，可以灵活的添加或删除行为。 缺点 类变多了，增加维护难度； 客户端要理解所有策略算法的区别，调用合适的策略算法。 策略模式的实现 了解了什么是策略模式，下面看看如何实现策略模式。 策略模式主要有3个角色： 抽象策略接口：定义一个公共接口behavior(); 具体策略类：实现抽象策略接口，负责策略的具体实现； 环境类：需要使用调用某种算法或行为的对象，通过成员变量形式调用算法。 策略模式的类图如下： 可以看到，整个结构非常简单，这里就不给出具体代码实现了。 策略模式的应用 能用到策略模式的地方有很多，简单来说，当某种功能有多种实现方式时，你就可以考虑使用策略模式！ 比如电商系统中优惠方案和支付方式、差旅系统中出行方案、排序系统中的排序方案等等。 下面举几个策略模式在JDK和Spring中的应用实例。 JDK中的应用 比如Java中的比价器Comparator接口，我们经常把Comparator接口作为传入参数实现排序策略。这里Comparator相当于抽象策略类，我们实现该接口，并实现compare方法，就相当于构建了一个具体策略类。 Spring中的应用 在Spring中的一个经典应用就是“初始化”，不同类型的类采用不同的初始化策略。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Redis事务","slug":"2 后端/Redis/Redis事务","date":"2022-03-08T12:38:32.000Z","updated":"2022-03-08T12:42:17.356Z","comments":true,"path":"47bd1b89eebf/","link":"","permalink":"http://rookieyin.github.io/47bd1b89eebf/","excerpt":"何为事务 Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。","text":"何为事务 Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性： 1. 原子性，2. 隔离性，3. 持久性，4. 一致性。 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； **Redis 是不支持 roll back 的，因而不满足原子性的。**官网对此做出的解释是： Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。 使用事务 Redis事务相关的命令有5个：multi（开启事务），exec（执行事务中所有操作命令），discard（取消事务，放弃执行事务块中所有命令），watch（监视1个或多个key，事务执行前，这个key被其他命令修改，则事务终断，不会执行事务中任何命令）和unwatch（取消对所有key的监视）。事务的标准执行流程如下： 开始事务，运行multi命令； 输入一些列命令，即命令入队； 执行事务，运行exec命令，事务块中所有命令按照先进先出顺序执行。 错误处理 在执行事务块中的命令时，可能会报错，错误类型可以分两类： 语法错误（编译器错误）：导致事务提交失败，所有命令不会被执行。 类型错误（运行时错误）：跳过有错误的命令，继续执行事务块中剩余其他命令。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-trans.html https://javaguide.cn/database/redis/redis-questions-01","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"Redis过期与内存淘汰机制","slug":"2 后端/Redis/Redis过期与内存淘汰机制","date":"2022-03-08T12:38:24.000Z","updated":"2022-03-08T12:43:30.876Z","comments":true,"path":"c4ebbd2dc215/","link":"","permalink":"http://rookieyin.github.io/c4ebbd2dc215/","excerpt":"Redis数据过期 我们知道Redis中的key可以设置过期时间，如果设置1批key只能存活1分钟，那么1分钟后，Redis是怎么对这批key进行删除的呢？ 常用过期策略有三种： 定时过期：每个设置过期时间的key都创建一个定时器，到期后立即清除。 优点：到期后立即清除数据，对内存友好。 缺点：创建大量定时器，占用过多系统资源，对CPU不友好。 惰性过期：取出key的时候对数据过期时间进行检查。 优点：对CPU友好。 缺点：造成太多过期key没有删除，对内存不友好。 定期过期：每隔一段时间抽取一批key执行删除过期key操作，可以看做是定时和惰性的一种折中方案。 在Redis中同时使用了定期删除+惰性删除。","text":"Redis数据过期 我们知道Redis中的key可以设置过期时间，如果设置1批key只能存活1分钟，那么1分钟后，Redis是怎么对这批key进行删除的呢？ 常用过期策略有三种： 定时过期：每个设置过期时间的key都创建一个定时器，到期后立即清除。 优点：到期后立即清除数据，对内存友好。 缺点：创建大量定时器，占用过多系统资源，对CPU不友好。 惰性过期：取出key的时候对数据过期时间进行检查。 优点：对CPU友好。 缺点：造成太多过期key没有删除，对内存不友好。 定期过期：每隔一段时间抽取一批key执行删除过期key操作，可以看做是定时和惰性的一种折中方案。 在Redis中同时使用了定期删除+惰性删除。 Redis内存淘汰机制 Redis中的过期策略可能漏掉很多过期key没被清除，导致内存溢出。当用于缓存的内存不足时，Redis提供了6种内存淘汰机制（后面两种是4.0版本后增加的）： volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。 allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰。 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧。 volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。 注：注意区分LRU和LFU，LRU指淘汰最长时间没被使用的，LFU指淘汰一段时间内使用次数最少的。 参考资料 https://javaguide.cn/database/redis/redis-questions-01 https://www.cnblogs.com/sddai/p/9739900.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"Redis持久化","slug":"2 后端/Redis/Redis持久化","date":"2022-03-08T12:38:14.000Z","updated":"2022-06-01T04:51:26.836Z","comments":true,"path":"b4a3dfa7f75c/","link":"","permalink":"http://rookieyin.github.io/b4a3dfa7f75c/","excerpt":"为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化（和Memcached的主要区别之一），主要分为两种方式，分别是RDB和AOF。当然实际场景下还会使用这两种的混合模式。","text":"为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化（和Memcached的主要区别之一），主要分为两种方式，分别是RDB和AOF。当然实际场景下还会使用这两种的混合模式。 RDB快照持久化 触发方式 rdb触发方式分为手动触发和自动触发两种： 手动触发：redis客户端执行save或bgsave命令 save命令： 阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用 。 bgsave命令： Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短 ，其流程图如下： 自动触发：在一下4中情况下会自动触发 redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件； 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点； 执行debug reload命令重新加载redis时也会触发bgsave操作； 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作。 相关配置 持久化周期配置 12345678# 周期性执行条件的设置格式为 save &lt;seconds&gt; &lt;changes&gt; # 默认的设置为： save 900 1 #如果900秒内有1条Key信息发生变化，则进行快照save 300 10 #如果300秒内有10条Key信息发生变化，则进行快照save 60 10000 # 如果60秒内有10000条Key信息发生变化，则进行快照# 以下设置方式为关闭RDB快照功能 save &quot;&quot; 其他相关配置 12345678910# 文件名称dbfilename dump.rdb# 文件保存路径，默认&quot;./&quot;，即Redis服务的主目录dir /home/work/app/redis/data/# 如果持久化出错，主进程是否停止写入stop-writes-on-bgsave-error yes# 是否压缩rdbcompression yes# 导入时是否检查。一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。所以如果您的Redis服务需要追求极致的性能，就可以将这个选项设置为nordbchecksum yes 优缺点 优点 RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景； Redis加载RDB文件恢复数据要远远快于AOF方式. 缺点 RDB方式实时性不够，无法做到秒级的持久化； 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高； RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全； 版本兼容RDB文件问题. 深入理解 Redis开辟的内存空间通常较大，在将内存数据同步到硬盘可能会持续比较长的时间。在持久化这段时间一般都会收到数据写操作请求，如何保证数据一致性？ RDB的核心思路就是Copy-on-Write， 需要压缩写入磁盘上的数据在内存中不会发生变化 。在持久化这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。 在进行快照操作的这段时间，如果发生服务崩溃怎么办？ 崩溃了就弃用本次持久化。持久化过程会创建一个临时文件，只有持久化完整过程结束后，才会用该临时文件替换上一次的备份。 可以每秒做一次快照吗？ 快照间隔时间越短，服务崩溃时丢失的数据越少，但是频繁的快照会带来两方面问题： 磁盘压力过大： 多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。 阻塞主线程：虽然bgsave会fork子线程执行IO操作，但是fork子线程会阻塞主线程。 如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。 AOF追加文件持久化 和RDB相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启： appendonly yes。 实现方法 开启AOF后，AOF日志记录Redis的每个写命令，分3步：命令追加、文件写入和文件同步。 命令追加： 服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器的 aof_buf 缓冲区 。 文件写入和同步： 关于何时将 aof_buf 缓冲区的内容写入AOF文件中，Redis提供了三种写回策略： 名称 写会时机 优点 缺点 Always 同步写回 可靠性高，数据基本不丢失 开销过大，影响性能 Everysec 每秒写会 性能适中 宕机时丢失1秒数据 No 操作系统控制写回 性能好 宕机时丢失数据较多 配置文件 名称 说明 appendonly yes/no，是否开启AOF，默认是关闭的 appendfilename AOF持久化文件名 dir AOF文件保存路径 appendfsync 同步策略，always/everysec/no no-appendfsync-on-rewrite 设置no表示在aof重写期间不会将这段时间内发生的写命令放入操作系统 auto-aof-rewrite-percentage 生产环境不可能手动进行AOF持久化，因此需要配置何时自动触发AOF。该配置项表示当前AOF文件大小超过上次重写后AOF文件的百分之多少后，就再次开始重写AOF文件 auto-aof-rewrite-min-size 和auto-aof-rewrite-percentage类似，不过这里给的不是百分比，而是具体文件大小。比如设置为64mb，表示当AOF文件大小超过64mb后，重新开始新的AOF文件 AOF重写 Aof重写过程如下图所示，主线程首先fork出子进程用于重写aof日志，子进程在重写日志完成后，通知主进程追加aof日志缓冲，最后用新日志文件替换掉原来的日志文件。 下面总结了AOF重写的常见问题： 为什么要进行AOF重写？ AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。 AOF重写会阻塞吗？ 和RDB一样，AOF重写也会fork一个子进程，重写过程不阻塞，但是fork子进程会阻塞主进程。 AOF何时会重写？ 如前文“配置项”所述，Redis根据 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 两个配置项决定何时重写。 AOF重写时，有新数据写入怎么处理？ 如前文图片所示，Redis会将新数据放到AOF重写缓冲区，子进程重写完毕后，将缓冲区内容写入新日志。 注：在高并发系统中，重写过程可能有大量新入局进入，导致缓冲区积累数据过多。Redis后来通过Linux管道技术，让aof重写期间能同时进行回放，这样aof重写结束后，缓冲区不会积累过多数据。 主线程fork出子进程的是如何复制内存数据的？ fork子进程时，为了避免一次性拷贝过多数据造成阻塞。fork子进程时，子进程会拷贝父进程的页面，而不会拷贝物理内存。这时候两个进程使用相同的内存地址空间。 此时主进程是可以有数据写入的，如下图所示： 在主进程有数据写入时，如果这个数据恰好在页C中，主进程会创建一个页C的副本，将其映射到主进程中，而子进程还是使用原来的页C。 AOF重写过程中哪些时候会阻塞？ fork子进程时，需要拷贝虚拟页表，会对主进程阻塞。 主进程有bigkey写入时， 操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。 子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。 为什么AOF重写不复用原AOF日志？ 父子进程写同一个文件会产生竞争问题，影响父进程的性能。 如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。 RDB和AOF混合方式（4.0版本） 该模式下，内存快照以一定的频率执行，在两次快照之间，使用AOF日志记录这期间的所有命令操作，如下图所示： ## 从持久化中恢复数据 从持久化文件中恢复数据，只需要重新启动Redis即可。其流程如下图所示： 那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-rdb-aof.html https://javaguide.cn/database/redis/redis-questions-01","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"结构型——享元模式","slug":"6 设计模式/结构型——享元模式","date":"2022-03-08T07:08:10.000Z","updated":"2022-06-01T05:08:04.308Z","comments":true,"path":"7cfcf24ee979/","link":"","permalink":"http://rookieyin.github.io/7cfcf24ee979/","excerpt":"什么是享元模式 享元模式的定义 享元模式定义为：通过共享技术来实现细粒度对象的复用。“享”即共享，“元”即对象，通过复用一些共享对象，避免创建大量重复对象，减小内存开销。 享元模式的本质是缓存共享对象，降低内存消耗。 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。 比如对于Circle对象，有5种不同的颜色，如果需要50个Circle实例。如果不使用享元模式，我们需要创建50个对象。但是如果使用享元模式，可以创建一个Map，key为颜色，value为Circle实例，需要什么颜色的circle就去map里面取，这样最多只需要创建5个对象即可。","text":"什么是享元模式 享元模式的定义 享元模式定义为：通过共享技术来实现细粒度对象的复用。“享”即共享，“元”即对象，通过复用一些共享对象，避免创建大量重复对象，减小内存开销。 享元模式的本质是缓存共享对象，降低内存消耗。 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。 比如对于Circle对象，有5种不同的颜色，如果需要50个Circle实例。如果不使用享元模式，我们需要创建50个对象。但是如果使用享元模式，可以创建一个Map，key为颜色，value为Circle实例，需要什么颜色的circle就去map里面取，这样最多只需要创建5个对象即可。 享元模式的结构 享元模式的定义提出了两个要求，细粒度和共享对象。因为要求细粒度，所以不可避免地会使对象数量多且性质相近，此时我们就将这些对象的信息分为两个部分：内部状态和外部状态。 内部状态指对象共享出来的信息，存储在享元信息内部，并且不回随环境的改变而改变； 外部状态指对象得以依赖的一个标记，随环境的改变而改变，不可共享。 比如，连接池中的连接对象，保存在连接对象中的用户名、密码、连接URL等信息，在创建对象的时候就设置好了，不会随环境的改变而改变，这些为内部状态。而当每个连接要被回收利用时，我们需要将它标记为可用状态，这些为外部状态。 享元模式的主要角色有如下。 抽象享元角色（Flyweight）：是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入。 具体享元（Concrete Flyweight）角色：实现抽象享元角色中所规定的接口。 非享元（Unsharable Flyweight)角色：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中。 享元工厂（Flyweight Factory）角色：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。 上图是享元模式的结构图，其中： UnsharedConcreteFlyweight 是非享元角色，里面包含了非共享的外部状态信息 info； Flyweight 是抽象享元角色，里面包含了享元方法 operation(UnsharedConcreteFlyweight state)，非享元的外部状态以参数的形式通过该方法传入； ConcreteFlyweight 是具体享元角色，包含了关键字 key，它实现了抽象享元接口； FlyweightFactory 是享元工厂角色，它是关键字 key 来管理具体享元； 客户角色通过享元工厂获取具体享元，并访问具体享元的相关方法。 享元模式有啥用 优缺点 优点：对象复用，节约内存； 缺点：增加代码复杂性，需要将对象拆成共享和非共享两部分；牺牲一定速度， 读取享元模式的外部状态 时间变长。 应用场景 程序需要生成数量巨大的相似对象，并消耗巨大内存； 这些相似对象可以提炼出一些不变的共享信息； 由于享元模式需要额外维护一个保存享元的数据结构，如HashMap，所以应当在有足够多的享元实例时才值得使用享元模式。 应用示例 Java中的字符串缓存池、Integer的缓存等。 数据库中的连接池。 享元模式的应用 下面实例来自这里。 【例1】享元模式在五子棋游戏中的应用。 分析：五子棋同围棋一样，包含多个“黑”或“白”颜色的棋子，所以用享元模式比较好。 棋子（ChessPieces）类是抽象享元角色，它包含了一个落子的 DownPieces(Graphics g,Point pt) 方法； 白子（WhitePieces）和黑子（BlackPieces）类是具体享元角色，它实现了落子方法； Point 是非享元角色，它指定了落子的位置； WeiqiFactory 是享元工厂角色，它通过 ArrayList 来管理棋子，并且提供了获取白子或者黑子的 getChessPieces(String type) 方法； 客户类（Chessboard）利用 Graphics 组件在框架窗体中绘制一个棋盘，并实现 mouseClicked(MouseEvent e) 事件处理方法，该方法根据用户的选择从享元工厂中获取白子或者黑子并落在棋盘上。 其结构图如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115import javax.swing.*;import java.awt.*;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import java.util.ArrayList;public class WzqGame &#123; public static void main(String[] args) &#123; new Chessboard(); &#125;&#125;//棋盘class Chessboard extends MouseAdapter &#123; WeiqiFactory wf; JFrame f; Graphics g; JRadioButton wz; JRadioButton bz; private final int x = 50; private final int y = 50; private final int w = 40; //小方格宽度和高度 private final int rw = 400; //棋盘宽度和高度 Chessboard() &#123; wf = new WeiqiFactory(); f = new JFrame(&quot;享元模式在五子棋游戏中的应用&quot;); f.setBounds(100, 100, 500, 550); f.setVisible(true); f.setResizable(false); f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); JPanel SouthJP = new JPanel(); f.add(&quot;South&quot;, SouthJP); wz = new JRadioButton(&quot;白子&quot;); bz = new JRadioButton(&quot;黑子&quot;, true); ButtonGroup group = new ButtonGroup(); group.add(wz); group.add(bz); SouthJP.add(wz); SouthJP.add(bz); JPanel CenterJP = new JPanel(); CenterJP.setLayout(null); CenterJP.setSize(500, 500); CenterJP.addMouseListener(this); f.add(&quot;Center&quot;, CenterJP); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; g = CenterJP.getGraphics(); g.setColor(Color.BLUE); g.drawRect(x, y, rw, rw); for (int i = 1; i &lt; 10; i++) &#123; //绘制第i条竖直线 g.drawLine(x + (i * w), y, x + (i * w), y + rw); //绘制第i条水平线 g.drawLine(x, y + (i * w), x + rw, y + (i * w)); &#125; &#125; public void mouseClicked(MouseEvent e) &#123; Point pt = new Point(e.getX() - 15, e.getY() - 15); if (wz.isSelected()) &#123; ChessPieces c1 = wf.getChessPieces(&quot;w&quot;); c1.DownPieces(g, pt); &#125; else if (bz.isSelected()) &#123; ChessPieces c2 = wf.getChessPieces(&quot;b&quot;); c2.DownPieces(g, pt); &#125; &#125;&#125;//抽象享元角色：棋子interface ChessPieces &#123; public void DownPieces(Graphics g, Point pt); //下子&#125;//具体享元角色：白子class WhitePieces implements ChessPieces &#123; public void DownPieces(Graphics g, Point pt) &#123; g.setColor(Color.WHITE); g.fillOval(pt.x, pt.y, 30, 30); &#125;&#125;//具体享元角色：黑子class BlackPieces implements ChessPieces &#123; public void DownPieces(Graphics g, Point pt) &#123; g.setColor(Color.BLACK); g.fillOval(pt.x, pt.y, 30, 30); &#125;&#125;//享元工厂角色class WeiqiFactory &#123; private ArrayList&lt;ChessPieces&gt; qz; public WeiqiFactory() &#123; qz = new ArrayList&lt;ChessPieces&gt;(); ChessPieces w = new WhitePieces(); qz.add(w); ChessPieces b = new BlackPieces(); qz.add(b); &#125; public ChessPieces getChessPieces(String type) &#123; if (type.equalsIgnoreCase(&quot;w&quot;)) &#123; return (ChessPieces) qz.get(0); &#125; else if (type.equalsIgnoreCase(&quot;b&quot;)) &#123; return (ChessPieces) qz.get(1); &#125; else &#123; return null; &#125; &#125;&#125; 参考资料 http://c.biancheng.net/view/1371.html https://www.runoob.com/design-pattern/flyweight-pattern.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"结构型——适配器、装饰、外观","slug":"6 设计模式/结构型——适配器、装饰、外观","date":"2022-03-07T07:08:10.000Z","updated":"2022-06-01T05:07:55.558Z","comments":true,"path":"2eaef0cfc8be/","link":"","permalink":"http://rookieyin.github.io/2eaef0cfc8be/","excerpt":"适配器、装饰、外观这三种设计模式本质都是在原有类的基础上进行“外观”上的改动，让原来的类看起来不一样。不过它们的意图是不同的： 装饰器模式：不改变原有接口，添加新的功能； 适配器模式：将一个接口转变成另一个接口，解决客户和功能组件之间接口不兼容的问题； 外观模式：让接口更简单，将复杂系统的各种方法进行封装，让系统看起来更简单，方便客户使用。 下面，我们一起看看这三种模式是如何实现各自的意图的。","text":"适配器、装饰、外观这三种设计模式本质都是在原有类的基础上进行“外观”上的改动，让原来的类看起来不一样。不过它们的意图是不同的： 装饰器模式：不改变原有接口，添加新的功能； 适配器模式：将一个接口转变成另一个接口，解决客户和功能组件之间接口不兼容的问题； 外观模式：让接口更简单，将复杂系统的各种方法进行封装，让系统看起来更简单，方便客户使用。 下面，我们一起看看这三种模式是如何实现各自的意图的。 适配器模式 什么是适配器模式 适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。 适配器的类图定义如下： 如上图所示，适配器模式具有很好的OO设计原则，创建一个实现了目标接口的适配器类，通过组合方式，将目标接口的任务委托给被适配者执行。上面这种适配器模式称之为对象适配器模式，其实还有一种类适配器模式： 类适配器通过多重继承实现，由于Java不支持多重继承，因此只能使用对象适配器模式。 类结构型模式和对象结构型模式相比，前者类之间的耦合度比后者高，且要求程序员了解现有组件库中的相关组件的内部结构，所以应用相对较少些。 适配器模式有什么用 在现实生活中，经常出现两个对象因接口不兼容而不能在一起工作的实例，这时需要第三者进行适配。例如，讲中文的人同讲英文的人对话时需要一个翻译，用直流电的笔记本电脑接交流电源时需要一个电源适配器，用计算机访问照相机的 SD 内存卡时需要一个读卡器等。 在软件设计中也可能出现：需要开发的具有某种业务功能的组件在现有的组件库中已经存在，但它们与当前系统的接口规范不兼容，如果重新开发这些组件成本又很高，这时用适配器模式能很好地解决这些问题。 适配器模式的优缺点如下： 优点 客户端通过适配器可以透明地调用目标接口。 复用了现存的类，程序员不需要修改原有代码而重用现有的适配者类。 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题。 在很多业务场景中符合开闭原则。 缺点 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性。 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱。 适配器模式通常适用于： 以前开发的系统存在满足新系统功能需求的类，但其接口同新系统的接口不一致。 使用第三方提供的组件，但组件接口定义和自己要求的接口定义不同。 适配器模式的应用 适配器模式的实现 这里简单实现了对象适配器模式，至于类适配器实现代码类似，只不过通过继承被适配者来实现。 123456789101112131415161718192021222324//对象适配器类class ObjectAdapter implements Target&#123; private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) &#123; this.adaptee=adaptee; &#125; public void request() &#123; adaptee.specificRequest(); &#125;&#125;//客户端代码public class ObjectAdapterTest&#123; public static void main(String[] args) &#123; System.out.println(&quot;对象适配器模式测试：&quot;); Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request(); &#125;&#125; 实战演练 早期Java集合类型都实现了一个名为elements()的方法，该方法返回一个Enumeration对象。这个Enumeration接口可以逐个遍历集合中每个元素，而无需知道它们在集合内是如何被管理的。 在新版本的Java中，开始使用Iterator迭代器接口，这个接口和枚举接口很像，都可以用来遍历集合中每个元素，但不同的是，迭代器还提供了删除元素的功能。 面对历史遗留代码，这些代码可能暴露出枚举接口，但是希望在新的代码中只使用迭代器，如何利用适配器模式解决这个问题呢？ 12345678910111213141516public class EnumerationIterator implements Iterator&#123;//适配器实现目标接口 Enumeration enum;//组合方式，和被适配者关联 public EnumerationIterator(Enumeration enum)&#123; this.enum = enum; &#125; public boolean hasNext()&#123; return enum.hasMoreElements(); &#125; public Object next()&#123; return enum.nextElement(); &#125; public void remove()&#123; //原有的枚举不支持remove()方法，因此需要抛出异常 throw new UnsupportedOperationException(); &#125;&#125; #### 适配器在JDK中的应用 java.util.Arrays中的asList()方法 java.io.InputStreamReader(InputStream) ，java.io.OutputStreamWriter(OutputStream)实现字符流和字节流的转换 javax.xml.bind.annotation.adapters.XmlAdapter#marshal()，javax.xml.bind.annotation.adapters.XmlAdapter#unmarshal() JUC中FutureTask类也用到了适配器模式，RunnableAdapter将一个Runnable封装成Callable。 适配器在Spring中的应用 这部分转自：http://c.biancheng.net/view/8447.html Spring AOP 在 Spring 的 Aop 中，适配器模式应用的非常广泛。Spring 使用 Advice（通知）来增强被代理类的功能，Advice 的类型主要有 BeforeAdvice、AfterReturningAdvice、ThrowsAdvice。每种 Advice 都有对应的拦截器，即 MethodBeforeAdviceInterceptor、AfterReturningAdviceInterceptor、ThrowsAdviceInterceptor。 各种不同类型的 Interceptor，通过适配器统一对外提供接口，如下类图所示：client —&gt; target —&gt; adapter —&gt; interceptor —&gt; advice。最终调用不同的 advice来实现被代理类的增强。 Spring MVC 具体可以看原文。 外观模式 概述 外观模式，简单来说就是：把原来的若干个子系统重新封装一下，定义一个高层接口，客户端通过它来访问各个子系统的功能。 其目的在于：简化接口，对原来复杂的系统进行封装，暴露简单的接口供用户使用（因为用户往往不关注你的具体实现，实现一个功能越简单越好）。因此外观模式遵从最少知识原则，即减少对象之间的交互，只和密友谈话。下图展示了外观模式的简易类图： 外观模式的优点就是简化接口，方便系统使用，降低了客户端和子系统之间的耦合性，提升了子系统的可维护性。但是它也有缺点： 在外观模式中，当增加或移除子系统时需要修改外观类，这**违背了“开闭原则”**。 如果引入抽象外观类，则在一定程度上解决了该问题。 外观模式的应用 应用示例 观看电影需要操作很多电器，使用外观模式实现一键看电影功能。 123456789101112131415161718192021222324252627282930public class SubSystem &#123; public void turnOnTV() &#123; System.out.println(&quot;turnOnTV()&quot;); &#125; public void setCD(String cd) &#123; System.out.println(&quot;setCD( &quot; + cd + &quot; )&quot;); &#125; public void starWatching()&#123; System.out.println(&quot;starWatching()&quot;); &#125;&#125;public class Facade &#123; private SubSystem subSystem = new SubSystem(); public void watchMovie() &#123; subSystem.turnOnTV(); subSystem.setCD(&quot;a movie&quot;); subSystem.starWatching(); &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); facade.watchMovie(); &#125;&#125; JDK中的应用 在 JDK 中 java.lang.Class、java.util.logging.LogManager 都使用了外观模式。java.util.logging.LogManager 是外观角色，其它都是子系统角色 ： #### Spring中的应用 Spring的jdbc模块中的JdbcUtils类使用了外观模式，该工具类主要对原生的jdbc进行了封装。 装饰器模式 装饰器模式概述 什么是装饰器模式 装饰器模式指：在不改变原有对象的情况下，给对象动态添加功能。听起来有点抽象，后面可以通过实例，加深理解。 给对象添加功能，也就是要扩展一个类，为什么不用继承方式呢？ 继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。 如果使用组合关系来创建一个包装对象（即装饰对象）来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能，这就是装饰器模式的目标。 装饰器模式主要包含以下角色。 抽象构件（Component）角色：定义一个抽象接口以规范准备接收附加责任的对象。 具体构件（ConcreteComponent）角色：实现抽象构件，通过装饰角色为其添加一些职责。 抽象装饰（Decorator）角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。 具体装饰（ConcreteDecorator）角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 装饰器模式的结构图下图所示： #### 装饰器模式优缺点 装饰器模式的优缺点可总结如下： 优点 装饰器是继承的有力补充，比继承灵活，在不改变原有对象的情况下，动态的给一个对象扩展功能，即插即用； 通过使用不用装饰类及这些装饰类的排列组合，可以实现不同效果； 装饰器模式完全遵守开闭原则。 缺点 装饰器模式会增加许多子类，过度使用会增加程序得复杂性。 装饰器模式的应用 应用场景 装饰器模式目的在于给类动态添加功能，主要用于以下场景： 无法继承：当需要给一个现有类添加附加职责，而又不能采用生成子类的方法进行扩充时。例如，该类被隐藏或者该类是终极类或者采用继承方式会产生大量的子类。 组合过多：当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现，而采用装饰器模式却很好实现。 动态添加：当对象的功能要求可以动态地添加，也可以再动态地撤销时。 装饰器模式实现“饮料价格计算” 下面看一个“饮料”示例： 设计不同种类的饮料，饮料可以添加各种不同配料，并且支持动态添加新配料。每增加一种配料，该饮料的加个就要重新计算，要求计算每种饮料的价格。 下图表示在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Whip 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Whip 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//饮料接口public interface Beverage &#123; double cost();&#125;//具体饮料类，实现饮料接口public class DarkRoast implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125;//具体饮料类，实现饮料接口public class HouseBlend implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125;//抽象装饰器类，也实现了饮料接口public abstract class CondimentDecorator implements Beverage &#123; //组合方式，拥有饮料对象 protected Beverage beverage;&#125;//具体装饰类，继承了抽象装饰类public class Milk extends CondimentDecorator &#123; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125;//具体装饰类，继承了抽象装饰类public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125;//客户调用方式public class Client &#123; public static void main(String[] args) &#123; Beverage beverage = new HouseBlend();//新建一个基本饮料 beverage = new Mocha(beverage);//添加摩卡 beverage = new Milk(beverage);//添加牛奶 System.out.println(beverage.cost());//计算价格 &#125;&#125; 装饰器模式实现“游戏人物变身” 在《恶魔战士》中，游戏角色“莫莉卡·安斯兰”的原身是一个可爱少女，但当她变身时，会变成头顶及背部延伸出蝙蝠状飞翼的女妖，当然她还可以变为穿着漂亮外衣的少女。这些都可用装饰器模式来实现，在本实例中的“莫莉卡”原身有 setImage(String t) 方法决定其显示方式，而其 变身“蝙蝠状女妖”和“着装少女”可以用 setChanger() 方法来改变其外观，原身与变身后的效果用 display() 方法来显示（点此下载其原身和变身后的图片），下图是其结构图。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package decorator;import java.awt.*;import javax.swing.*;public class MorriganAensland &#123; public static void main(String[] args) &#123; Morrigan m0 = new original(); m0.display(); Morrigan m1 = new Succubus(m0); m1.display(); Morrigan m2 = new Girl(m0); m2.display(); &#125;&#125;//抽象构件角色：莫莉卡interface Morrigan &#123; public void display();&#125;//具体构件角色：原身class original extends JFrame implements Morrigan &#123; private static final long serialVersionUID = 1L; private String t = &quot;Morrigan0.jpg&quot;; public original() &#123; super(&quot;《恶魔战士》中的莫莉卡·安斯兰&quot;); &#125; public void setImage(String t) &#123; this.t = t; &#125; public void display() &#123; this.setLayout(new FlowLayout()); JLabel l1 = new JLabel(new ImageIcon(&quot;src/decorator/&quot; + t)); this.add(l1); this.pack(); this.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); this.setVisible(true); &#125;&#125;//抽象装饰角色：变形class Changer implements Morrigan &#123; Morrigan m; public Changer(Morrigan m) &#123; this.m = m; &#125; public void display() &#123; m.display(); &#125;&#125;//具体装饰角色：女妖class Succubus extends Changer &#123; public Succubus(Morrigan m) &#123; super(m); &#125; public void display() &#123; setChanger(); super.display(); &#125; public void setChanger() &#123; ((original) super.m).setImage(&quot;Morrigan1.jpg&quot;); &#125;&#125;//具体装饰角色：少女class Girl extends Changer &#123; public Girl(Morrigan m) &#123; super(m); &#125; public void display() &#123; setChanger(); super.display(); &#125; public void setChanger() &#123; ((original) super.m).setImage(&quot;Morrigan2.jpg&quot;); &#125;&#125; 装饰器模式JDK中的应用 Java I/O标准库。 例如，InputStream 的子类 FilterInputStream，OutputStream 的子类 FilterOutputStream，Reader 的子类 BufferedReader 以及 FilterReader，还有 Writer 的子类 BufferedWriter、FilterWriter 以及 PrintWriter 等，它们都是装饰类。 下面代码是为 FileReader 增加缓冲区而采用的装饰类 BufferedReader 的例子： 12BufferedReader in = new BufferedReader(new FileReader(&quot;filename.txt&quot;));String s = in.readLine(); java.util.Collections#synchronizedList(List) 装饰器模式Spring中的应用 TransactionAwareCacheDecorator 类相当于装饰器模式中的抽象装饰角色，主要用来处理事务缓存。 MVC 中的装饰器模式：HttpHeadResponseDecorator 类，相当于装饰器模式中的具体装饰角色。 参考资料 https://pdai.tech/md/dev-spec/pattern/9_adapter.html http://c.biancheng.net/view/1361.html http://c.biancheng.net/view/8447.html http://c.biancheng.net/view/1369.html https://pdai.tech/md/dev-spec/pattern/8_facade.html https://pdai.tech/md/dev-spec/pattern/12_decorator.html http://c.biancheng.net/view/1366.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Redis缓存相关问题","slug":"2 后端/Redis/Redis缓存相关问题","date":"2022-03-07T06:03:48.000Z","updated":"2022-03-08T12:41:18.696Z","comments":true,"path":"654023d35e3a/","link":"","permalink":"http://rookieyin.github.io/654023d35e3a/","excerpt":"Redis最常见的应用场景就是作为缓存，本文主要介绍Redis作为缓存过程中可能遇到的若干问题，包括缓存穿透、击穿、雪崩和一致性等问题。","text":"Redis最常见的应用场景就是作为缓存，本文主要介绍Redis作为缓存过程中可能遇到的若干问题，包括缓存穿透、击穿、雪崩和一致性等问题。 缓存穿透 问题来源 使用Redis作为缓存的目的就是：将经常使用的数据放到Redis中，这样在使用的时候就可以直接从缓存中取，无需访问数据库，大大提高数据读取效率。 缓存穿透是指：大量请求的key没有命中缓存，导致请求直接到了数据库上。比如，某个黑客故意制造缓存中不存在的key发起大量请求，很可能就导致DB挂掉了。 解决方案 接口校验 这是最基本方案，直接在接口层增加校验，比如 用户鉴权校验，id校验（不能小于0） 邮箱格式校验等等，将不合法请求拦截。 缓存无效key 如果缓存和数据库中都查不到某个key，就写一个到Redis中，并设置过期时间。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。 布隆过滤器 布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。 具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。 缓存击穿 问题来源 缓存击穿是指：一些设置过期时间的key在过期后的某个时间点，突然被超高并发访问，这些请求发现缓存过期后，同时向DB发起请求。 解决方案 **永不过期：**设置热点数据永不过期； **mutex互斥锁：**只将一个请求发送到数据库，拿到数据并回设缓存后，解除锁； 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。 （这个不太懂） 缓存雪崩 问题来源 缓存雪崩指： 缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 可能出现在两个场景： 系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。 有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。 和缓存击穿的区别在于， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案 针对 Redis 服务不可用的情况 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 针对热点缓存失效的情况 设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效。 数据库与缓存一致性 将Redis作为缓存使用时，读数据一般不会出现问题，向数据库写数据时就会出现一致性问题。我们是先向写数据库再写缓存？还是写些缓存后写数据库？无论哪种方式，如果第一步执行成功，第二步执行失败都会导致缓存与数据库数据不一致。 Cache Aside Pattern 旁路缓存模式 Cache Aside Pattern是最常用的一种缓存更新模式，其设定如下图所示： 当然，这种模式下也可能会出现更新数据库成功，删除缓存失败的场景，导致后续从缓存中读取的都是旧数据。解决方案有三种： 缩短过期时间：指标不治本，短时间内读取的还是旧数据。 同步重试 异步重试 总结 看到这里你可能会想，这些方案还是不够完美，我就想让缓存和数据库「强一致」，到底能不能做到呢？ 其实很难。 要想做到强一致，最常见的方案是 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。 相反，这时我们换个角度思考一下，我们引入缓存的目的是什么？ 没错，性能。 一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。 如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。 参考资料 https://pdai.tech/md/db/nosql-redis/db-redis-x-cache.html https://javaguide.cn/database/redis/redis-questions-01 https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&amp;mid=2247487312&amp;idx=1&amp;sn=fa19566f5729d6598155b5c676eee62d&amp;chksm=e8beb8e5dfc931f3e35655da9da0b61c79f2843101c130cf38996446975014f958a6481aacf1&amp;scene=178&amp;cur_album_id=1699766580538032128#rd","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"结构型——桥接模式","slug":"6 设计模式/结构型——桥接模式","date":"2022-03-06T07:08:10.000Z","updated":"2022-06-01T05:07:39.111Z","comments":true,"path":"1a7dd1f20983/","link":"","permalink":"http://rookieyin.github.io/1a7dd1f20983/","excerpt":"桥接模式概述 为什么需要桥接模式 在现实生活中，某些类具有两个或多个维度的变化，如图形既可按形状分，又可按颜色分。如何设计类似于 Photoshop 这样的软件，能画不同形状和不同颜色的图形呢？如果用继承方式，m 种形状和 n 种颜色的图形就有 m×n 种，不但对应的子类很多，而且扩展困难。","text":"桥接模式概述 为什么需要桥接模式 在现实生活中，某些类具有两个或多个维度的变化，如图形既可按形状分，又可按颜色分。如何设计类似于 Photoshop 这样的软件，能画不同形状和不同颜色的图形呢？如果用继承方式，m 种形状和 n 种颜色的图形就有 m×n 种，不但对应的子类很多，而且扩展困难。 当然，这样的例子还有很多，如不同颜色和字体的文字、不同品牌和功率的汽车、不同性别和职业的男女、支持不同平台和不同文件格式的媒体播放器等。如果用桥接模式就能很好地解决这些问题。 桥接（Bridge）模式的优点是： 抽象与实现分离，扩展能力强 符合开闭原则 符合合成复用原则 其实现细节对客户透明 缺点是：由于聚合关系建立在抽象层，要求开发者针对抽象化进行设计与编程，能正确地识别出系统中两个独立变化的维度，这增加了系统的理解与设计难度。 桥接模式的定义 桥接（Bridge）模式的定义如下：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 这句话比较难懂，什么是抽象？什么是实现？抽象和实现其实都可以看做是前面提到的不同维度，比如我可以把形状当做抽象，颜色当做实现。 桥接（Bridge）模式包含以下主要角色。 抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。 扩展抽象化（Refined Abstraction）角色：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。 实现化（Implementor）角色：定义实现化角色的接口，供扩展抽象化角色调用。 具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。 其结构图如下图 所示： 桥接模式的实现 这里用一个“汽车例子”，简单实现一下桥接模式。 假设某个汽车厂商生产三种品牌的汽车：Big、Tiny和Boss，每种品牌又可以选择燃油、纯电和混合动力。如果用传统的继承来表示各个最终车型，一共有3个抽象类加9个最终子类： 如果要新增一个品牌，或者加一个新的引擎（比如核动力），那么子类的数量增长更快。所以，桥接模式就是为了避免直接继承带来的子类爆炸。使用桥接模式，可以这样实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//相当于抽象角色public abstract class Car &#123; // 使用组合方式：引用Engine: protected Engine engine; public Car(Engine engine) &#123; this.engine = engine; &#125; public abstract void drive();&#125;//相当于抽象实现化角色public interface Engine &#123; void start();&#125;//相当于修正抽象角色，它可有可无，根据具体需求public abstract class RefinedCar extends Car &#123; public RefinedCar(Engine engine) &#123; super(engine); &#125; public void drive() &#123; this.engine.start(); System.out.println(&quot;Drive &quot; + getBrand() + &quot; car...&quot;); &#125; public abstract String getBrand();&#125;//具体抽象化角色public class BossCar extends RefinedCar &#123; public BossCar(Engine engine) &#123; super(engine); &#125; public String getBrand() &#123; return &quot;Boss&quot;; &#125;&#125;//相当于具体实现角色public class HybridEngine implements Engine &#123; public void start() &#123; System.out.println(&quot;Start Hybrid Engine...&quot;); &#125;&#125;public static void main(String[] args)&#123; //创建一个Boss品牌的混动车 RefinedCar bossCar = new BossCar(new HybridEngine())；&#125; 桥接模式的应用 应用场景 桥接模式实现比较复杂，实际应用也非常少，用于那些有多个维度变化的场景。但它提供的设计思想值得借鉴，即不要过度使用继承，而是优先拆分某些部件，使用组合的方式来扩展功能。 JDK中的应用 java.util.logging是JDK自带的日志包，可以将日志输出到文件、内存或者控制台，作用与我们常用的log4j类似。 包中的Handler类和Formatter类在设计上利用了桥接模式 。 Handle和Formatter类是两个抽象类，它们可以分别独立的变化（有不同的子类）；而Handle类中包含对Formatter类的引用。 JDBC中的Driver接口使用了桥接模式。 基于JDBC的应用程序，使用JDBC的API，相当于是对数据库操作的抽象的扩展，算作桥接模式的抽象部分；而具体的接口实现是由驱动来完成的，驱动这边自然就相当于桥接模式的实现部分了 。 参考资料 https://www.liaoxuefeng.com/wiki/1252599548343744/1281319266943009 https://zhuanlan.zhihu.com/p/58903776 http://c.biancheng.net/view/1364.html https://www.icode9.com/content-4-1178561.html https://segmentfault.com/a/1190000015360433","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"bitmap详解","slug":"2 后端/其他/4 bitmap详解","date":"2022-03-06T05:43:55.000Z","updated":"2022-03-06T05:56:06.047Z","comments":true,"path":"0932f16224a0/","link":"","permalink":"http://rookieyin.github.io/0932f16224a0/","excerpt":"什么是bitmap bitmap即位图，一种用bit存储数据的数据结构，主要用于数据的快速排序、去重和查询等操作，其优势在于可以在一个非常高的空间利用率下保存大量0-1状态。 比如Java中1个int类型数据就需要占用4Byte，但是4Byte（32bit）大小的位图可以存储32个数据。","text":"什么是bitmap bitmap即位图，一种用bit存储数据的数据结构，主要用于数据的快速排序、去重和查询等操作，其优势在于可以在一个非常高的空间利用率下保存大量0-1状态。 比如Java中1个int类型数据就需要占用4Byte，但是4Byte（32bit）大小的位图可以存储32个数据。 bitmap怎么使用 存储原理 每个bit中数字为1则代表该bit对应的index存在，为0则不存在。下图中的bitmap表示1,3,5,7这四个数字存在，0,2,4,6这四个数字不存在。 存查数据 建：创建合适大小的bitmap，比如在JAVA中，需要查找的总数为N=10000N=10000N=10000，那么需要申请的内存空间大小为int a[1+N/32]​（1个int数据大小为4Byte，32bit），其中a[0]对应0-31，a[1]对应32-63，以此类推。 存：比如向bitmap中存数据x=35，计算x//31=1和x%31=4，将a[1]中第4个bit设为1。 查：和存类似，通过计算x//31和x%31的值找到目标bit，然后检查该bit处值为0还是1。 bitmap应用场景 海量数据下验证目标数据是否存在。 快速去重 （1）判断正整形数组是否存在重复。 （2）海量数据中查找不重复的正整数。 ​ 解法1：采用2-bitmap，即每个数分配2个bit，00表示不存在，01表示出现1次，10表示多次，11无意义。 ​ 解法2：使用2个bitmap，对于目标数据，先判断是否存在于第一个bitmap，若存在就设置第二个bitmap对应位置为1。 快速排序，正整形数组的排序。 当然bitmap也存在一些缺点： 数据碰撞，比如将字符串映射到bitmap中（不同字符串hash成同一个整数）。 数据稀疏，比如存入（3,1232324,923122311）这三个数字，需要建立999999999长度的bitmap，造成了很大空间浪费。 扩展 java中的bitmap JDK中BitSet类实现了位图这一数据结构，其内部数据使用long数组来存储。 构造方法 有参构造：传入位图长度参数 无参构造：默认长度为64bit。 set方法 单点set：set(int bitIndex)和set(int bitIndex, boolean value)分别表示设置指定bit为true和指定值value。 范围set：set(int fromIndex, int toIndex)和set(int fromIndex, int toIndex, boolean value)，区别同上 get方法：和set方法类似，分为单点get和范围get两种，范围get返回一个子集BitSet 与，或，异或，与非方法 and(BitSet set) ， or(BitSet set)， xor(BitSet set)， andNot(BitSet set); 压缩BitMap 前面提到bitmap的一个缺点就是在数据稀疏是十分浪费空间，google开发的javaEWAH包中CompressedBitmap很好的解决了这个问题。 在EWAHCompressedBitmap中，也是采用long数组来保存数据，不过数组中的long数据分两类： Literal Word：存储真正的bit位 Running Length Word：存储跨度信息 比如存储数据1和1亿时，EWAHCompressedBitmap中可能是这样的： 其中，中间那个long数据就属于Running Length Word，表示是前后两个long数据之间有1千万个0。同样地，如果有多个连续1出现，也可以将它们压缩到一起用一个long数据表示。 Bloom Filter 布隆过滤器（Bloom Filter）可以看做一个由bitmap和一系列hash函数两部分组成的数据结构。 存取原理 如上图所示，如果将一个字符串存入过滤器中，首先使用一些列hash函数将其映射成整数，然后将bit数组中对应位置值设为1。如果要判断字符串是否存在，只需使用同样的hash函数，然后判断bit数组对应位置是否为1。 优点：占用空间少，效率高。 缺点： 存在误判（因为hash函数不能保证一对一映射），可以通过增加hash函数个数，扩充bitmap大小缓解。 删除困难（不同数据可能被映射成相同整数）。 用途：和bitmap用途类似 判定数据是否存在：防止缓存穿透、垃圾邮件过滤、黑名单等功能； 去重：比如爬给定网址的时候，对爬取过的URL去重 Redis中的bitmap 常用命令：setbit，getbit，bitcount，bittop set/get：setbit key offset value，getbit key offset ，时间复杂度为O(1) bitcount：bitcount key start end，统计某范围内值为1的bit数，时间复杂度O(n) bittop：bittop operation destkey key，对不同bitmap进行位运算（and，or，not，xor），时间复杂度O(n) 应用场景： 适合需要保存状态信息（比如是否签到、是否登录…）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。 参考资料 https://www.cnblogs.com/dragonsuc/p/10993938.html https://www.jianshu.com/p/c4c5a00b40db https://juejin.cn/post/6844903879201718280 https://javaguide.cn/cs-basics/data-structure/bloom-filter.html https://javaguide.cn/database/redis/redis-questions-01/#bitmap","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"其他","slug":"后端/其他","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Redis数据类型","slug":"2 后端/Redis/Redis数据类型","date":"2022-03-06T05:43:43.000Z","updated":"2022-03-06T05:57:40.524Z","comments":true,"path":"cca58972b6b1/","link":"","permalink":"http://rookieyin.github.io/cca58972b6b1/","excerpt":"Redis所有key都是字符串，存储值有5种基本数据结构：string，list，hash，set和zset（有序集合），3种特殊数据结构：HyperLogLogs（基数统计），Bitmaps（位图）和Geospatial（地理位置），Redis 5.0中还增加了Stream类型，借鉴了kafka的设计，是一个强大的支持多播的可持久化消息队列。","text":"Redis所有key都是字符串，存储值有5种基本数据结构：string，list，hash，set和zset（有序集合），3种特殊数据结构：HyperLogLogs（基数统计），Bitmaps（位图）和Geospatial（地理位置），Redis 5.0中还增加了Stream类型，借鉴了kafka的设计，是一个强大的支持多播的可持久化消息队列。 5种基础数据类型 结构类型 结构存储的值 结构的读写能力 String字符串 可以是字符串、整数或浮点数 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； List列表 一个链表，链表上的每个节点都包含一个字符串 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素； Set集合 包含字符串的无序集合 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 Hash散列 包含键值对的无序散列表 包含方法有添加、获取、删除单个元素 Zset有序集合 和散列一样，用于存储键值对 字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 String字符串 Redis的字符串是动态字符串，采用预分配冗余空间的方式来减少内存的频繁分配（即当前字符串实际分配空间一般高于字符串实际长度）。 常用命令：get，set，del，strlen，getrange（获取子串），setrange（覆盖子串），append（追加子串），incr（键值加1），decr（键值减1），incrby（键值增加指定整数），decrby（键值减去指定整数） 注：字符串类型没有提供子串插入方法和子串删除方法。后面四种改变键值方法是将字符串当做计数器使用，其值的上下限分别为Long.Max和Long.Min 底层原理：不是使用C语言的字符串，而是自己构建的SDS抽象类型。 应用场景：缓存（常用信息、图片、视频等）、计数器、session List列表 Redis中的List其实就是一个双向列表，可以用于实现消息队列等功能。 常用命令：rpush，lpush，rpop，lpop，lrange（返回指定范围所有值），lindex（指定索引下的值，-1表示最后一个元素），llen（返回链表长度），lset（指定位置修改元素），linsert（指定位置插入元素，不是通过下标，而是通过具体值指定，并通过参数before和after指定前置或后置插入），lrem（删除元素，也不是通过位置删除，需要指定删除最大个数和元素的值），ltrim（指定起始下标start和结束下标end，删除范围之外的所有元素）。 底层原理：List在数据量较少时使用的时ZipList，即压缩列表，分配一块连续内存，所有元素紧挨着存储。在数据量较大时，List底层采用的QuickList。因为普通链表需要附加空间指针太大，比较浪费时间，所以Redis中的QuickList是将若干个ZipList用指针连起来。这样既满足快速的插入性能，又不会出现太大的空间冗余。 应用场景：消息队列，展示最新列表信息等。 Set集合 Redis中Set是String类型的无序集合，通过哈希表实现，所有value都指向同一内部值，添加、删除、查找的复杂度都是O(1)。 常用命令：sadd，scard，smember（返回集合所有成员），sismember（集合是否存在某元素）。 应用场景：标签（给用户加标签或者用户给消息添加标签）、点赞、收藏等。 Zset有序集合 Zset和set基本类似，区别在于集合中每个元素会关联一个分数，redis正是通过这个分数来为集合中成员进行从小到大的排序。 常用命令：zadd key score value（将一个带有给定分值的成员添加到集合），zrange，zrem key value（从集合中移除value），zcard（获取集合元素个数），zrem（删除1个或多个元素），zincrby（计数器），zscore（分数），zrank（排名），zrange（获取范围内所有元素，携带withscores可一并获取元素权重），zrangebyscore（分数范围获取元素，±inf表示正负无穷），zremrangebyrank（通过rank范围移除元素），zremrangebyscore（通过score范围移除元素） 底层原理：redis有序集合底层通过跳跃列表来实现的，比较复杂，感兴趣的可以自行了解。 应用：排行榜。 Hash散列 Hash是一种string类型key和value的映射表，适合用于存储对象。 常用命令：hset，hmset（增加多个键值对），hget，hmget（获取多个key对应的value），hkeys，hvalues，hdel（删除指定的1个或多个key），hexists，hincrby（计数器）。 底层原理：Redis中hash底层结构类似java中的hashmap或python中的dict，通过一个二维结构来实现。第一维是数组，第二维是链表，hash的key和value分别存放于数组和链表中。通过key查找元素时，先计算key的hashcode，然后用hashcode对链表长度取模定位到链表表头，再对链表进行遍历获取到相应的value值， 链表的作用就是用来将产生了「hash碰撞」的元素串起来 。 扩容：hash碰撞频繁发生时需要进行扩容。扩容时需要申请新的两倍大小数组，然后将所有key-value键值对进行rehash存储，之一过程对于单线程redis来说有点压力过大。Redis采用的是渐进式rehash方案，同时保留两个新旧hash结构，在后续定时任务以及hash结构的读写指令中逐渐将旧hash迁移到新hash中。 缩容：原理和扩容类似，新数组大小是旧数组的一半。 3种特殊类型 HyperLogLogs（基数统计） HyperLogLogs用于基数统计（即一个集合中不重复的元素数量），比如 注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等，它允许容错。 特点：每个键占用12K空间，不管什么值都可以可以存储近2642^{64}264个值。需要注意的是它估算出来的基数并不一定准确， 是一个带有 0.81% 标准错误的近似值 。（其背后的HyperLogLog算法，感兴趣可以自行了解。） 常用命令：pfadd，pfcount，pfmerge 应用场景：计算日活、统计网站日UV、注册IP数、访问IP数等等。 Bitmap（位图） bitmap通过操作bit来进行记录，只有0和1两个状态，可以大幅节省存储空间。 常用命令：setbit，getbit，bitcount（值为1的bit数量） 应用场景：用户行为分析、保存状态信息（是否签到、是否登录等）、活跃用户、用户在线状态等。 Geospatial（地理位置） Redis的Geo用于存储位置信息，可以通过地理位置（经纬度），推算两地之间距离、附近的人等。 常用命令：geoadd（geoadd key longitude latitude member [longitude latitude member …]），geodist（geodist key member1 member2 [unit] unit可以指定长度单位：m,km,ft等 默认为m），geohash（geohash key member [member …]，返回位置元素的hash表示），geopos（geopos key member [member …]），georadius（ georadiuskey longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]，半径内所有元素），georadiusbymember（和georadius类似，不过中心点不是经纬度，而是已添加的某个位置）。 底层：其底层为zset，因此可以使用zset命令来操作geo，比如zrange key 0 -1 withscores。 参考链接 https://pdai.tech/md/db/nosql-redis/db-redis-data-types.html https://juejin.cn/post/6844903644798664712","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"}]},{"title":"创建型——工厂模式","slug":"6 设计模式/创建型——工厂模式","date":"2022-03-05T07:08:10.000Z","updated":"2022-06-01T05:07:23.662Z","comments":true,"path":"b2e275c3967c/","link":"","permalink":"http://rookieyin.github.io/b2e275c3967c/","excerpt":"本文介绍一下设计模式中的工厂模式。工厂，在现实生活中是用来生产产品的，在OO编程中，对象就是产品，也就是用来生产对象的。和工厂相关的设计模式主要有三种：简单工厂模式、工厂方法模式和抽象工厂模式。下面，我们分别叫啥下这三种模式。","text":"本文介绍一下设计模式中的工厂模式。工厂，在现实生活中是用来生产产品的，在OO编程中，对象就是产品，也就是用来生产对象的。和工厂相关的设计模式主要有三种：简单工厂模式、工厂方法模式和抽象工厂模式。下面，我们分别叫啥下这三种模式。 简单工厂模式 什么是简单工厂模式？ 所谓“简单工厂”，就是把实例化操作单独放到一个类中（简单工厂类），让该类来决定应该用哪个具体子类来实例化。 为什么要用简单工厂模式？ 在日常开发中，有些时候需要生成复杂的对象，用简单工厂模式可以达到“创建与使用分离”的目的。客户往往为了系统更具有弹性，可能希望new一个上层抽象类或接口，而不关注具体是什么子（实现）类。举个例子，Pizza是个抽象类，CheesePizza和GreekPizza是具体实现类，客户请求披萨的代码可能是这样的： 1234567891011Pizza orderPizza(String type)&#123; Pizza pizza; if(type.equals(&quot;cheese&quot;))&#123; pizza = new CheesePizza(); &#125;else if(type.equals(&quot;greek&quot;))&#123; pizza = new GreekPizza(); &#125; pizza.prepare(); pizza.bake(); ...&#125; 此时，如果再加入更多类型的pizza，new一个对象的逻辑就变得更复杂了，而且需要更改所有客户的代码。 怎么用简单工厂模式？ 还是上面Pizza那个例子，我们可以创建一个简单工厂类，将实例化Pizza的工作交给工厂来做： 123456789101112131415161718public class SimplePizzaFactory&#123; public Pizza createPizza(String type)&#123; Pizza pizza = null; if(type.equals(&quot;cheese&quot;))&#123; pizza = new CheesePizza(); &#125;else if(type.equals(&quot;greek&quot;))&#123; pizza = new GreekPizza(); &#125; return pizza; &#125;&#125;//客户中orderPizza方法Pizza orderPizza(String type)&#123; //客户持有SimplePizzaFactory实例 Pizza pizza = factory.createPizza(type); pizza.prepare(); ...&#125; 可以看到，原来的系统中，每个客户都要清楚了解Pizza所有子类，并和这些子类耦合在一起。但是引入简单工厂后，客户只需要耦合Pizza工厂类即可，不需要知道有多少类型pizza，系统的耦合性大大降低。 简单工厂模式的类图是啥样？ 优缺点总结 优点：很简单，最终目的就是“使用和创建分离”，降低了系统耦合度，增加了系统可扩展性。 缺点 工厂类单一，职责过重，代码可能过于臃肿； 扩展困难，增加新类型，需要修改工厂类代码，不满足“开闭原则”； 工厂类创建对象的方法一般是static，难以继承扩展。 工厂方法模式 有了简单工厂，为什么要有工厂方法？ 工厂方法模式，是在简单工厂的基础上进行再抽象。 简单工厂具有以下缺点： 当产品类型过多时，逻辑过于复杂，容易出错； 所有类型产品的创建都放在一个工厂类中，过于臃肿、职责过重； 简单工厂，同场使用static方法，不能继承； 不满足“开闭原则”，当新加入一些类型时，需要修改工厂类。 工厂方法模式长啥样？ 为了解决这些问题，在工厂方法模式中，不再由工厂类创建对象，而是将该任务转嫁给工厂类的各个子类来完成，由子类来决定该实例化哪一个类。工厂方法模式的类图如下： 代码示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//创建抽象工厂abstract class Factory&#123; public abstract Product Manufacture();&#125;//创建抽象产品类abstract class Product&#123; public abstract void Show();&#125;//具体产品A类class ProductA extends Product&#123; @Override public void Show() &#123; System.out.println(&quot;生产出了产品A&quot;); &#125;&#125;//具体产品B类class ProductB extends Product&#123; @Override public void Show() &#123; System.out.println(&quot;生产出了产品B&quot;); &#125;&#125;//工厂A类 - 生产A类产品class FactoryA extends Factory&#123; @Override public Product Manufacture() &#123; return new ProductA(); &#125;&#125;//工厂B类 - 生产B类产品class FactoryB extends Factory&#123; @Override public Product Manufacture() &#123; return new ProductB(); &#125;&#125;//生产工作流程public class FactoryPattern &#123; public static void main(String[] args)&#123; //客户要产品A FactoryA mFactoryA = new FactoryA(); mFactoryA.Manufacture().Show(); //客户要产品B FactoryB mFactoryB = new FactoryB(); mFactoryB.Manufacture().Show(); &#125;&#125; 优缺点总结 优点：基本对应我们前文提到的简单工厂存下的缺点。 符合开闭原则、单一职责原则、不适用静态方法，可以继承等等。 缺点 类变多了，系统更加复杂，实现时可能还要用DOM、反射等技术； 一个具体工厂只能创建一种具体产品。 抽象工厂模式 有了工厂方法，为什么还要有抽象工厂？ 前面提到，工厂方法模式的一个缺点是：一个具体工厂只能创建一种具体产品。但是在实际应用中，一个产品可能由多个零部件构成，此时需要将多个子产品组合成一个完整产品。 比如，我们要组装一台电脑，可能用到主板和CPU等各种零部件，为了方便起见这里只考虑CPU和主板。 一种解决方案是，主板和CPU分别按照工厂方法模式设计，这样有两个抽象工厂方法类，用户可以任意组合具体类型CPU和主板。但是如果考虑CPU和主板之间的兼容性，这种设计方案就无法满足需求了，需要用到抽象工厂模式重新设计。 什么是抽象工厂？ 抽象工厂的本质是：将多个抽象工厂方法封装到一起，用于生产一系列相关对象（核心功能），这些对象组合在一起是一个更大的产品。这是它和工厂方法模式最大的不同。抽象工厂模式的类图如下： 总结 三种工厂模式对比 简单工厂，与其说是一种设计模式，不如说是一种编码习惯（因为它太简单了），其核心操作就是：把创建对象的复杂逻辑单独封装成一个类，降低系统耦合性，达到“使用与创建”分离的目的。 工厂方法，是在简单工厂基础上的进一步抽象，将创建对象的操作转嫁给抽象工厂的具体实现类。这样每种具体工厂类负责生产一种类型产品，系统可扩展性进一步提高，符合“开闭原则”。 抽象工厂，工厂方法适合生产单一产品，可以理解成这个产品就是最小单元，不能拆分成更小的产品。但是往往一个产品是由若干个子产品组合而成，此时就需要抽象工厂上场了。抽象工厂的核心就是把若干个抽象工厂方法封装到一起。 JDK中的应用举例 java.util.Calendar类中getInstance方法就使用了简单工厂。 java.util.Collection接口的iterator方法运用了抽象工厂，具体生成什么类型的迭代器由子类决定。 Spring中应用举例 Spring中的BeanFactory运用了抽象工厂，其子接口子接口 ConfigurableBeanFactory 接口运用了工厂方法。 参考资料 https://www.jianshu.com/p/d0c444275827 https://pdai.tech/md/dev-spec/pattern/5_abstract_factory.html https://pdai.tech/md/dev-spec/pattern/4_factory_method.html https://pdai.tech/md/dev-spec/pattern/3_simple_factory.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"创建型——单例模式","slug":"6 设计模式/创建型——单例模式","date":"2022-03-04T07:08:10.000Z","updated":"2022-06-01T05:07:00.246Z","comments":true,"path":"3a62052bd839/","link":"","permalink":"http://rookieyin.github.io/3a62052bd839/","excerpt":"概述 这里我们通过几个问题，来简单了解下单例模式。 什么是单例模式？ 所谓单例模式，顾名思义就是：一个类只有一个实例，且这个实例是有该类自己创建的一种模式。 为什么要有单例模式？ 在实际应用中，很多对象其实我们只需要一个，比如：线程池、缓存、对话框、注册表对象、日志对象等等。往往这些类对象只能有一个实例，否则可能出现很多问题，例如：程序的行为异常、资源浪费或者不一致的结果等。","text":"概述 这里我们通过几个问题，来简单了解下单例模式。 什么是单例模式？ 所谓单例模式，顾名思义就是：一个类只有一个实例，且这个实例是有该类自己创建的一种模式。 为什么要有单例模式？ 在实际应用中，很多对象其实我们只需要一个，比如：线程池、缓存、对话框、注册表对象、日志对象等等。往往这些类对象只能有一个实例，否则可能出现很多问题，例如：程序的行为异常、资源浪费或者不一致的结果等。 单例模式的类图啥样？ 因为单例模式下类只能有一个实例，因此需要通过 一个私有构造函数、一个私有静态变量以及一个公有静态函数来实现。 单例模式的特点可以总结为： 单例类只有一个实例对象； 该单例对象必须由单例类自行创建； 单例类对外提供一个访问该单例的全局访问点。 单例模式有什么优缺点？ 单例模式的目的是：保证系统中只有一个对象实例，使用全局变量也可以达到同样的效果，那么单例模式有什么优势呢？ 单例模式 VS 全局变量 使用全局变量的话，那么必须在程序一开始就创建好对象，万一程序运行过程中没有用到这个对象，那么就白创建了，造成资源浪费。 全局变量管理不方便，容易存在命名冲突。 单例模式的缺点 当然，单例模式也不是没有缺点的： 单例模式一般没有接口，扩展困难； 单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则（大家都这么说，我在实际应用中，还没体会到这点）。 单例模式使用过程中，有没有什么要注意的？ 使用时不能用反射模式创建单例，否则会实例化一个新的对象 ； 使用懒单例模式时注意线程安全问题 ； 饿单例模式和懒单例模式构造方法都是私有的，因而是不能被继承的。 实现方式 饿汉式 饿汉式单例模式，直接在类中定义一个初始化好的实例对象： 12345678public class Singleton &#123; private static Singleton uniqueInstance = new Singleton(); private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; return uniqueInstance; &#125;&#125; 该模式的优点就是：线程安全，但是丢失了延迟实例化带来的节约资源的好处。 懒汉式 懒汉式的思想是，用到的时候我再创建实例对象，不用就不创建。懒汉式分为两种：线程安全和线程不安全。 线程不安全 123456789101112131415public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //多个线程同时进入，会创建多个实例，因此是线程不安全的 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; 线程安全 1234567891011121314public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; //Synchronized修饰get方法，线程安全，但是影响并发性能 public static synchronized Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125;&#125; 双重校验锁 在线程安全的基础上，把synchronized移动到get方法里面： 123456789101112131415161718public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 细心的小伙伴，可能会发现： 为什么get方法中有两次null判断？ 12345if (uniqueInstance == null) &#123; synchronized (Singleton.class) &#123; uniqueInstance = new Singleton(); &#125;&#125; 如上面代码所示，如果只使用了一个 if 语句。在 uniqueInstance == null 的情况下，如果两个线程同时执行 if 语句，那么两个线程就会同时进入 if 语句块内。虽然在 if 语句块内有加锁操作，但是两个线程都会执行 uniqueInstance = new Singleton(); 这条语句，只是先后的问题，那么就会进行两次实例化，从而产生了两个实例。因此必须使用双重校验锁，也就是需要使用两个 if 语句。 单例实例引用为什么使用volatile修饰？ 这就要说到uniqueInstance = new Singleton()的执行过程了，其实分三步：分配内存空间、初始可能对象、将uniqueInstance指向内存地址。因为JVM具有指令重拍的特性，有可能第3步先于第2步执行，多线程环境中可能将一个未初始化的对象分配出去，导致线程出错。 这里volatile的作用就是禁止指令重排序。 静态内部类（登记式） 当 Singleton 类加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 getUniqueInstance() 方法从而触发 SingletonHolder.INSTANCE 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例。 这种方式不仅具有延迟初始化的好处，而且由虚拟机提供了对线程安全的支持。 因此优缺点如下： 优点： 资源利用率高，不执行getInstance()不被实例–&gt;弥补了饿汉式的缺点，同时不需要像双重校验那样麻烦，且不像懒汉式那样效率低下 。 **缺点：**第一次加载时反应不够快；由于是静态内部类的形式去创建单例的，故外部无法传递参数进去 。 12345678910111213public class Singleton &#123; private Singleton() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getUniqueInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举实现 这是单例模式的最佳实践，它实现简单，并且在面对复杂的序列化或者反射攻击的时候，能够防止实例化多次。 但是和饿汉模式一样，在初始化时就需要创建单例对象。 123public enum Singleton &#123; uniqueInstance;&#125; 下面是一个利用枚举实现单例的例子： 123456789101112131415161718192021 // 单例public enum BeanContext &#123; Instance; private BeanContext() &#123; System.out.println(&quot;init&quot;); &#125; public void print() &#123; System.out.println(&quot;hello&quot;); &#125; //测试 public static void main(String[] args) &#123; BeanContext b1 = BeanContext.Instance; b1.print(); BeanContext b2 = BeanContext.Instance; b2.print(); BeanContext b3 = BeanContext.Instance; b3.print(); BeanContext b4 = BeanContext.Instance; b4.print(); &#125;&#125; 总结 上图摘自https://pdai.tech/md/dev-spec/pattern/2_singleton.html。 不同实现方式有着各自的优缺点和应用场景。在实际应用中可以参考以下建议： 不考虑资源浪费的情况下，最佳实践是使用枚举类型，因为不会出现反射攻击（这个后文会说）。 多个类加载器情况下，最好显示指定某个加载器加载单例类，否则可能导致系统中出现多个单例对象。 尽量使用饿汉模式，防止浪费资源。 单例模式的应用 常见应用场景 多线程的线程，以及各种连接池，比如数据库连接池、IO连接池等等； 资源共享的情况下，避免由于资源操作时导致的性能或损耗，避免并发操作冲突等。如应用程序的日志应用，共享的日志文件一直处于打开状态，因为只能有一个实例去操作，否则内容不好追加；应用的配置对象的读取，配置文件是共享的资源；Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例（一个文件系统）来进行。 一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，只能有一个PrinterSpooler，在输出的时候不能两台打印机打印同一个文件。 网站的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来，否则难以同步。 单例模式下的反射机制 通过在get方法中new一个实例方式实现的单例模式，可能会被反射破坏。 下面的内容来自：https://www.cnblogs.com/ideal-20/p/13912766.html。 单例是如何破坏的 下面用双重锁定的懒汉式单例演示一下，这是我们原来的写法，new 两个实例出来，输出一下。 123456789101112131415161718192021222324252627282930313233public class Lazy1 &#123; // 构造器私有，静止外部new private Lazy1()&#123; System.out.println(Thread.currentThread().getName() + &quot; 访问到了&quot;); &#125; // 定义即可，不真正创建 private static volatile Lazy1 lazy1 = null; // 获取本类实例的唯一全局访问点 public static Lazy1 getLazy1()&#123; // 如果实例不存在则new一个新的实例，否则返回现有的实例 if (lazy1 == null) &#123; // 加锁 synchronized(Lazy1.class)&#123; // 第二次判断是否为null if (lazy1 == null)&#123; lazy1 = new Lazy1(); &#125; &#125; &#125; return lazy1; &#125; public static void main(String[] args) &#123; Lazy1 lazy1 = getLazy1(); Lazy1 lazy2 = getLazy1(); System.out.println(lazy1); System.out.println(lazy2); &#125;&#125; 运行后不难发现，结果是单例没有问题。 一个普通实例化，一个反射实例化 但是我们如果通过反射的方式进行实例化类，会有什么问题呢？ 1234567891011public static void main(String[] args) throws Exception &#123; Lazy1 lazy1 = getLazy1(); // 获得其空参构造器 Constructor&lt;Lazy1&gt; declaredConstructor = Lazy1.class.getDeclaredConstructor(null); // 使得可操作性该 declaredConstructor 对象 declaredConstructor.setAccessible(true); // 反射实例化 Lazy1 lazy2 = declaredConstructor.newInstance(); System.out.println(lazy1); System.out.println(lazy2);&#125; 运行结果： main 访问到了 main 访问到了 cn.ideal.single.Lazy1@1b6d3586 cn.ideal.single.Lazy1@4554617c 可以看到，单例被破坏了 解决办法：因为我们反射走的其无参构造，所以在无参构造中再次进行非null判断，加上原来的双重锁定，现在也就有三次判断了 12345678// 构造器私有，静止外部newprivate Lazy1()&#123; synchronized (Lazy1.class)&#123; if(lazy1 != null) &#123; throw new RuntimeException(&quot;反射破坏单例异常&quot;); &#125; &#125;&#125; 不过结果也没让人失望，这种测试下，第二次实例化会直接报异常。 两个都是反射实例化 如果两个都是反射实例化出来的，也就是说，根本就不去调用 getLazy1() 方法，那可怎么办？如下： 12345678910111213public static void main(String[] args) throws Exception &#123; // 获得其空参构造器 Constructor&lt;Lazy1&gt; declaredConstructor = Lazy1.class.getDeclaredConstructor(null); // 使得可操作性该 declaredConstructor 对象 declaredConstructor.setAccessible(true); // 反射实例化 Lazy1 lazy1 = declaredConstructor.newInstance(); Lazy1 lazy2 = declaredConstructor.newInstance(); System.out.println(lazy1); System.out.println(lazy2);&#125; 运行结果： main 访问到了 main 访问到了 cn.ideal.single.Lazy1@1b6d3586 cn.ideal.single.Lazy1@4554617c 单例又被破坏了 解决方案：增加一个标识位，例如下文通过增加一个布尔类型的 ideal 标识，保证只会执行一次，更安全的做法，可以进行加密处理，保证其安全性 1234567891011// 构造器私有，静止外部newprivate Lazy1()&#123; synchronized (Lazy1.class)&#123; if (ideal == false)&#123; ideal = true; &#125; else &#123; throw new RuntimeException(&quot;反射破坏单例异常&quot;); &#125; &#125; System.out.println(Thread.currentThread().getName() + &quot; 访问到了&quot;);&#125; 这样就没问题了吗，并不是，一旦别人通过一些手段得到了这个标识内容，那么他就可以通过修改这个标识继续破坏单例，代码如下（这个把代码贴全一点，前面都是节选关键的，都可以参考这个） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Lazy1 &#123; private static boolean ideal = false; // 构造器私有，静止外部new private Lazy1()&#123; synchronized (Lazy1.class)&#123; if (ideal == false)&#123; ideal = true; &#125; else &#123; throw new RuntimeException(&quot;反射破坏单例异常&quot;); &#125; &#125; System.out.println(Thread.currentThread().getName() + &quot; 访问到了&quot;); &#125; // 定义即可，不真正创建 private static volatile Lazy1 lazy1 = null; // 获取本类实例的唯一全局访问点 public static Lazy1 getLazy1()&#123; // 如果实例不存在则new一个新的实例，否则返回现有的实例 if (lazy1 == null) &#123; // 加锁 synchronized(Lazy1.class)&#123; // 第二次判断是否为null if (lazy1 == null)&#123; lazy1 = new Lazy1(); &#125; &#125; &#125; return lazy1; &#125; public static void main(String[] args) throws Exception &#123; Field ideal = Lazy1.class.getDeclaredField(&quot;ideal&quot;); ideal.setAccessible(true); // 获得其空参构造器 Constructor&lt;Lazy1&gt; declaredConstructor = Lazy1.class.getDeclaredConstructor(null); // 使得可操作性该 declaredConstructor 对象 declaredConstructor.setAccessible(true); // 反射实例化 Lazy1 lazy1 = declaredConstructor.newInstance(); ideal.set(lazy1,false); Lazy1 lazy2 = declaredConstructor.newInstance(); System.out.println(lazy1); System.out.println(lazy2); &#125;&#125; 运行结果： main 访问到了 main 访问到了 cn.ideal.single.Lazy1@4554617c cn.ideal.single.Lazy1@74a14482 实例化 lazy1 后，其执行了修改 ideal 这个布尔值为 false，从而绕过了判断，再次破坏了单例。 单例模式在JDK和Spring中的应用 java.lang.Runtime类 12345678910public class Runtime &#123; private static java.lang.Runtime currentRuntime = new java.lang.Runtime(); public static java.lang.Runtime getRuntime() &#123; return currentRuntime; &#125; private Runtime() &#123;&#125; ...&#125; 在 Spring 中，bean 可以被定义为两种模式：prototype（多例）和 singleton（单例）。 参考资料 《Head First设计模式》 https://pdai.tech/md/dev-spec/pattern/2_singleton.html http://c.biancheng.net/view/1338.html https://jackromer.github.io/2019/08/27/JAVA使用枚举实现单例模式/ https://bbs.huaweicloud.com/blogs/239657 https://www.cnblogs.com/ideal-20/p/13912766.html http://m.biancheng.net/view/8378.html","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java中的Unsafe类","slug":"2 后端/Java/Java并发/12 Java中的Unsafe类","date":"2022-02-13T14:34:49.000Z","updated":"2022-06-11T13:03:35.918Z","comments":true,"path":"e15edccb26c1/","link":"","permalink":"http://rookieyin.github.io/e15edccb26c1/","excerpt":"本文转自：Java魔法类：Unsafe应用解析 Unsafe概述 什么是Unsafe Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。","text":"本文转自：Java魔法类：Unsafe应用解析 Unsafe概述 什么是Unsafe Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 如下Unsafe源码所示，Unsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。 1234567891011121314151617public final class Unsafe &#123; // 单例对象 private static final Unsafe theUnsafe; private Unsafe() &#123; &#125; @CallerSensitive public static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(); // 仅在引导类加载器`BootstrapClassLoader`加载时才合法 if(!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException(&quot;Unsafe&quot;); &#125; else &#123; return theUnsafe; &#125; &#125;&#125; 使用方法 那如若想使用这个类，该如何获取其实例？有如下两个可行方案。 从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。 1java -Xbootclasspath/a: $&#123;path&#125; // 其中path为调用Unsafe相关方法的类所在jar包路径 通过反射获取单例对象theUnsafe。 12345678910private static Unsafe reflectGetUnsafe() &#123; try &#123; Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); return (Unsafe) field.get(null); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); return null; &#125;&#125; Unsafe功能 如下图所示，Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。 内存操作 这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。 123456789101112131415161718//分配内存, 相当于C++的malloc函数public native long allocateMemory(long bytes);//扩充内存public native long reallocateMemory(long address, long bytes);//释放内存public native void freeMemory(long address);//在给定的内存块中设置值public native void setMemory(Object o, long offset, long bytes, byte value);//内存拷贝public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);//获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);//为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);//获取给定地址的byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果为确定的）public native byte getByte(long address);//为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果才是确定的）public native void putByte(long address, byte x); 通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。 为什么使用堆外内存 对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。 提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。 典型应用 DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。 下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。 CAS相关 这部分应该是最常用的了，源代码如下： 12345678910111213/** * CAS * @param o 包含要修改field的对象 * @param offset 对象中某field的偏移量 * @param expected 期望值 * @param update 更新值 * @return true | false */public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object update);public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update); public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update); 关于什么是CAS这里就不细说了， CAS是一条CPU的原子指令（cmpxchg指令），不会造成所谓的数据不一致问题，Unsafe提供的CAS方法（如compareAndSwapXXX）底层实现即为CPU指令cmpxchg。 CAS在java.util.concurrent.atomic相关类、Java AQS、CurrentHashMap等实现上有非常广泛的应用。如下图所示，AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。 线程调度 这部分，包括线程挂起、恢复、锁机制等方法。 12345678910111213//取消阻塞线程public native void unpark(Object thread);//阻塞线程public native void park(boolean isAbsolute, long time);//获得对象锁（可重入锁）@Deprecatedpublic native void monitorEnter(Object o);//释放对象锁@Deprecatedpublic native void monitorExit(Object o);//尝试获取对象锁@Deprecatedpublic native boolean tryMonitorEnter(Object o); 如上源码说明中，方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。 Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。 Class相关 此部分主要提供Class和它的静态字段的操作相关方法，包含静态字段内存定位、定义类、定义匿名类、检验&amp;确保初始化等。 123456789101112//获取给定静态字段的内存地址偏移量，这个值对于给定的字段是唯一且固定不变的public native long staticFieldOffset(Field f);//获取一个静态类中给定字段的对象指针public native Object staticFieldBase(Field f);//判断是否需要初始化一个类，通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。 当且仅当ensureClassInitialized方法不生效时返回false。public native boolean shouldBeInitialized(Class&lt;?&gt; c);//检测给定的类是否已经初始化。通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。public native void ensureClassInitialized(Class&lt;?&gt; c);//定义一个类，此方法会跳过JVM的所有安全检查，默认情况下，ClassLoader（类加载器）和ProtectionDomain（保护域）实例来源于调用者public native Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain);//定义一个匿名类public native Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; hostClass, byte[] data, Object[] cpPatches); 从Java8开始，java支持的Lambda表达式会用到这部分。 对象操作 此部分主要包含对象成员属性相关操作及非常规的对象实例化方式等相关方法。 1234567891011121314//返回对象成员属性在内存地址相对于此对象的内存地址的偏移量public native long objectFieldOffset(Field f);//获得给定对象的指定地址偏移量的值，与此类似操作还有：getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);//给定对象的指定地址偏移量设值，与此类似操作还有：putInt，putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);//从对象的指定偏移量处获取变量的引用，使用volatile的加载语义public native Object getObjectVolatile(Object o, long offset);//存储变量的引用到对象的指定的偏移量处，使用volatile的存储语义public native void putObjectVolatile(Object o, long offset, Object x);//有序、延迟版本的putObjectVolatile方法，不保证值的改变被其他线程立即看到。只有在field被volatile修饰符修饰时有效public native void putOrderedObject(Object o, long offset, Object x);//绕过构造方法、初始化代码来创建对象public native Object allocateInstance(Class&lt;?&gt; cls) throws InstantiationException; 常规对象实例化方式：我们通常所用到的创建对象的方式，从本质上来讲，都是通过new机制来实现对象的创建。但是，new机制有个特点就是当类只提供有参的构造函数且无显示声明无参构造函数时，则必须使用有参构造函数进行对象构造，而使用有参构造函数时，必须传递相应个数的参数才能完成对象实例化。 非常规的实例化方式：而Unsafe中提供allocateInstance方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提类对象即可创建相应的对象。由于这种特性，allocateInstance在java.lang.invoke、Objenesis（提供绕过类构造器的对象生成方式）、Gson（反序列化时用到）中都有相应的应用。 数组相关 这部分主要介绍与数据操作相关的arrayBaseOffset与arrayIndexScale这两个方法，两者配合起来使用，即可定位数组中每个元素在内存中的位置。 1234//返回数组中第一个元素的偏移地址public native int arrayBaseOffset(Class&lt;?&gt; arrayClass);//返回数组中一个元素占用的大小public native int arrayIndexScale(Class&lt;?&gt; arrayClass); 内存屏障 在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。 123456//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence(); 系统相关 这部分包含两个获取系统相关信息的方法。 1234//返回系统指针的大小。返回值为4（32位系统）或 8（64位系统）。public native int addressSize(); //内存页的大小，此值为2的幂次方。public native int pageSize(); 典型应用 如下图所示的代码片段，为java.nio下的工具类Bits中计算待申请内存所需内存页数量的静态方法，其依赖于Unsafe中pageSize方法获取系统内存页大小实现后续计算逻辑。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java中的Atomic类","slug":"2 后端/Java/Java并发/11 Java中的Atomic类","date":"2022-02-12T14:34:49.000Z","updated":"2022-06-11T13:02:44.995Z","comments":true,"path":"dae3554cec93/","link":"","permalink":"http://rookieyin.github.io/dae3554cec93/","excerpt":"概述 Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。","text":"概述 Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 分类 Java中的原子类都在java.util.concurrent.atomic包下面，根据操作的数据类型，可以将它们分成4类： 基本类型 AtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 数组类型 AtomicIntegerArray：整型数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray ：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 对象的属性类型 AtomicIntegerFieldUpdater：原子更新整型字段的更新器 AtomicLongFieldUpdater：原子更新长整型字段的更新器 AtomicReferenceFieldUpdater：原子更新引用类型里的字段 再提CAS java中的原子类基本都是通过CAS+volatile实现的，因此在介绍其他内容前，先讲讲CAS。 CAS的全称为Compare-And-Swap，就是在更新变量值的时候，先看看内存中的值有没有被修改过，没被修改过就直接更新，否则放弃更新。 JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。 因为，通过CAS+自旋可以在无锁的方式下解决并发环境中的数据一致性问题，和Synchronized相比通常性能更优。 但是使用CAS也存在几个问题： ABA问题 即原来值为A，线程1将它的值改为B，然后紧接着线程2将它的值又改回了A，在当前线程看来，该值没有发生变化。举个例子： 年初，现金为零，然后通过正常劳动赚了三百万，之后正常消费了（比如买房子）三百万。年末，虽然现金零收入（可能变成其他形式了），但是赚了钱是事实，还是得交税的！ ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A-&gt;B-&gt;A就会变成1A-&gt;2B-&gt;3A。 循环时间过长 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。 单个变量 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。 基本类型原子类 基本类型原子类有三个：AtomicInteger，AtomicLong和AtomicBoolean。这三个类都支持CAS，另外， AtomicInteger、AtomicLong 还支持算术运算。 由于这三个类提供的方法基本一样，这里只详细介绍AtomicInteger提供的方法和实现原理。 常用方法 1234567public final int get() // 获取当前值public final int getAndSet(int newValue) // 获取当前值，并设置新值public final int getAndIncrement()// 获取当前值，并自增public final int getAndDecrement() // 获取当前值，并自减public final int getAndAdd(int delta) // 获取当前值，并加上预期值boolean compareAndSet(int expect, int update) // 如果输入值（update）等于预期值，将该值设置为输入值public final void lazySet(int newValue) // 最终设置为 newValue，使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 使用示例 123456789101112131415161718public class AtomicIntegerDemo &#123; public static void main(String[] args) throws InterruptedException &#123; //创建1000个线程，对count执行自增操作 ExecutorService executorService = Executors.newFixedThreadPool(5); AtomicInteger count = new AtomicInteger(0); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit((Runnable) () -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; count=&quot; + count.get()); count.incrementAndGet(); &#125;); &#125; executorService.shutdown(); executorService.awaitTermination(30, TimeUnit.SECONDS); System.out.println(&quot;Final Count is : &quot; + count.get()); &#125;&#125; 实现原理 AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 下面我们以getAndSet方法源码为例，进行具体分析。 123456789101112131415161718192021222324// setup to use Unsafe.compareAndSwapInt for updates//获取Unsafe实例private static final Unsafe unsafe = Unsafe.getUnsafe();//value用volatile修饰，保证可见性private volatile int value;public final int getAndSet(int newValue) &#123; //直接调用unsafe类中的getAndSetInt方法，实现变量值的更新 return unsafe.getAndSetInt(this, valueOffset, newValue);&#125;public final int getAndSetInt(Object var1, long var2, int var4) &#123; int var5; //内部使用自旋的方式进行CAS更新（while循环进行CAS更新，如果更新失败，则循环再次重试） do &#123; //获取对象内存地址偏移量上的数值var5 var5 = this.getIntVolatile(var1, var2); //如果现在还是var5,设置为 var4,否则返回false,继续循环再次重试. &#125; while(!this.compareAndSwapInt(var1, var2, var5, var4)); return var5;&#125;//调用本地方法实现cas更新int值public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 数组类型原子类 数组类型原子类也有三个：AtomicIntegerArray，AtomicLongArray和AtomicReferenceArray。 数组类型的原子类为 数组元素 提供了 volatile 类型的访问语义，这是普通数组所不具备的特性——volatile 类型的数组仅在数组引用上具有 volatile 语义。 这三个类提供的方法也基本一致，因此这里只详细介绍AtomicIntegerArray的具体实现。 常用方法 1234567public final int get(int i) //获取 index=i 位置元素的值public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValuepublic final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减public final int getAndAdd(int i, int delta) //获取 index=i 位置元素的值，并加上预期的值boolean compareAndSet(int i, int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update）public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 使用示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class AtomicIntegerArrayDemo &#123; private static AtomicIntegerArray atomicIntegerArray = new AtomicIntegerArray(10); public static void main(final String[] arguments) throws InterruptedException &#123; System.out.println(&quot;Init Values: &quot;); for (int i = 0; i &lt; atomicIntegerArray.length(); i++) &#123; atomicIntegerArray.set(i, i); System.out.print(atomicIntegerArray.get(i) + &quot; &quot;); &#125; System.out.println(); Thread t1 = new Thread(new Increment()); Thread t2 = new Thread(new Compare()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(&quot;Final Values: &quot;); for (int i = 0; i &lt; atomicIntegerArray.length(); i++) &#123; System.out.print(atomicIntegerArray.get(i) + &quot; &quot;); &#125; System.out.println(); &#125; static class Increment implements Runnable &#123; @Override public void run() &#123; for (int i = 0; i &lt; atomicIntegerArray.length(); i++) &#123; int value = atomicIntegerArray.incrementAndGet(i); System.out.println(Thread.currentThread().getName() + &quot;, index = &quot; + i + &quot;, value = &quot; + value); &#125; &#125; &#125; static class Compare implements Runnable &#123; @Override public void run() &#123; for (int i = 0; i &lt; atomicIntegerArray.length(); i++) &#123; boolean swapped = atomicIntegerArray.compareAndSet(i, 2, 3); if (swapped) &#123; System.out.println(Thread.currentThread().getName() + &quot; swapped, index = &quot; + i + &quot;, value = 3&quot;); &#125; &#125; &#125; &#125;&#125; 引用类型原子类 基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用 引用类型原子类。 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicMarkableReference ：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以缓解使用 CAS 进行原子更新时可能出现的 ABA 问题。当发生奇数次修改，不存在ABA问题，但是当发生偶数次修改，无法判断是否发生修改。 因为boolean相当于只有0和1两个版本号，初始版本号为0，偶数次修改后版本号还是0，奇数次修改后版本号变成1。 上面三个类提供的方法几乎相同，所以我们这里以 AtomicReference 为例子来介绍。 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicReference;public class AtomicReferenceTest &#123; public static void main(String[] args) &#123; AtomicReference&lt;Person&gt; ar = new AtomicReference&lt;Person&gt;(); Person person = new Person(&quot;SnailClimb&quot;, 22); ar.set(person); Person updatePerson = new Person(&quot;Daisy&quot;, 20); ar.compareAndSet(person, updatePerson); System.out.println(ar.get().getName()); System.out.println(ar.get().getAge()); &#125;&#125;class Person &#123; private String name; private int age; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 上述代码首先创建了一个 Person 对象，然后把 Person 对象设置进 AtomicReference 对象中，然后调用 compareAndSet 方法，该方法就是通过 CAS 操作设置 ar。如果 ar 的值为 person 的话，则将其设置为 updatePerson。实现原理与 AtomicInteger 类中的 compareAndSet 方法相同。 对象属性更新原子类 如果需要原子更新某个类里的某个字段时，需要用到对象的属性修改类型原子类。 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater ：原子更新引用类型里的字段的更新器 要想原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新的对象属性必须使用 public volatile 修饰符。 上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerFieldUpdater为例子来介绍。 123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;public class AtomicIntegerFieldUpdaterTest &#123; public static void main(String[] args) &#123; AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, &quot;age&quot;); User user = new User(&quot;Java&quot;, 22); System.out.println(a.getAndIncrement(user));// 22 System.out.println(a.get(user));// 23 &#125;&#125;class User &#123; private String name; public volatile int age; public User(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 参考资料 https://javaguide.cn/java/concurrent/atomic-classes.html https://www.cnblogs.com/jingmoxukong/p/12109049.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"JUC锁之ReentrantLock","slug":"2 后端/Java/Java并发/10 JUC锁之ReentrantLock","date":"2022-02-11T14:34:49.000Z","updated":"2022-06-11T13:02:19.970Z","comments":true,"path":"1ec85058707f/","link":"","permalink":"http://rookieyin.github.io/1ec85058707f/","excerpt":"前面，我们介绍了Java中非常重要的同步器框架AQS，本文将介绍Java类库中基于AQS实现的一个同步器ReentrantLock。同样地，我们还是循着：它是什么？它有什么用？它底层怎么实现的？怎么使用它？这些问题，来深入了解ReentrantLock。","text":"前面，我们介绍了Java中非常重要的同步器框架AQS，本文将介绍Java类库中基于AQS实现的一个同步器ReentrantLock。同样地，我们还是循着：它是什么？它有什么用？它底层怎么实现的？怎么使用它？这些问题，来深入了解ReentrantLock。 ReentrantLock概述 ReentrantLock，翻译成中文就是可重入锁，它是Java类库中基于AQS框架实现的一个可重入锁同步器。在介绍ReentrantLock之前，先了解下可重复锁相关的知识。 可重入锁 什么是可重入锁？ 可重入锁，顾名思义就是可以重复申请，指一个线程可以多次获取一把锁。比如：一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，这是该线程可以直接调用该方法，而无需重新获得锁，这样就能避免死锁现象。 Java中的ReentrantLock和synchronized都是可重入锁。 可重入锁有什么用？ 最大的作用就是避免死锁。 怎么实现可重入锁？ 通常情况下为每个锁关联一个获取计数器和一个所有者线程,当计数值为0的时候,这个锁就没有被任何线程持有。 什么场景下需要用它？ 在很多情况下，线程需要多次进入锁内执行任务。 场景一： 递归调用 。 场景二： 此线程调用同一对象其它synchronized或者有同步锁函数。 ReentrantLock类结构 ReentrantLock实现了Lock接口，Lock接口中定义了lock与unlock相关操作，并且还存在newCondition方法，表示生成一个条件。 1public class ReentrantLock implements Lock, java.io.Serializable ReentrantLock总共有三个内部类，并且三个内部类是紧密相关的，下图展示了三个类的关系： 其中Sync类继承自AQS抽象类，NonfairSync和FairSync都继承自Sync类。从名字就可以看出，ReentrantLock同时支持公平锁和非公平锁，两者分别基于NonfairSync和FairSync实现的。 1234567891011121314/** * 默认构造方法，非公平锁 */public ReentrantLock() &#123; sync = new NonfairSync();&#125;/** * true公平锁，false非公平锁 * @param fair */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; ReentrantLock实现原理 Sync类 Sync类的源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 序列号 private static final long serialVersionUID = -5179523762034025860L; // 获取锁 abstract void lock(); // 非公平方式获取 final boolean nonfairTryAcquire(int acquires) &#123; // 当前线程 final Thread current = Thread.currentThread(); // 获取状态 int c = getState(); if (c == 0) &#123; // 表示没有线程正在竞争该锁 if (compareAndSetState(0, acquires)) &#123; // 比较并设置状态成功，状态0表示锁没有被占用 // 设置当前线程独占 setExclusiveOwnerThread(current); return true; // 成功 &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 当前线程拥有该锁 int nextc = c + acquires; // 增加重入次数 if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); // 设置状态 setState(nextc); // 成功 return true; &#125; // 失败 return false; &#125; // 试图在共享模式下获取对象状态，此方法应该查询是否允许它在共享模式下获取对象状态，如果允许，则获取它 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) // 当前线程不为独占线程 throw new IllegalMonitorStateException(); // 抛出异常 // 释放标识 boolean free = false; if (c == 0) &#123; free = true; // 已经释放，清空独占 setExclusiveOwnerThread(null); &#125; // 设置标识 setState(c); return free; &#125; // 判断资源是否被当前线程占有 protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don&#x27;t need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; // 新生一个条件 final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class // 返回资源的占用线程 final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; // 返回状态 final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; // 资源是否被占用 final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ // 自定义反序列化逻辑 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; NonfairSync类 NonfairSync类继承了Sync类，表示采用非公平策略获取锁，其实现了Sync类中抽象的lock方法，源码如下。 12345678910111213141516171819// 非公平锁 static final class NonfairSync extends Sync &#123; // 版本号 private static final long serialVersionUID = 7316153563782823691L; // 获得锁 final void lock() &#123; if (compareAndSetState(0, 1)) // 比较并设置状态成功，状态0表示锁没有被占用 // 把当前线程设置独占了锁 setExclusiveOwnerThread(Thread.currentThread()); else // 锁已经被占用，或者set失败 // 以独占模式获取对象，忽略中断 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; NonfairSync的非公平性体现在哪里？ 从lock方法可以看出， 每一次都尝试获取锁 ， 而并不会按照公平等待的原则进行等待，让等待时间最久的线程获得锁。 FairSyn类 123456789101112131415161718192021222324252627282930313233343536373839// 公平锁static final class FairSync extends Sync &#123; // 版本序列化 private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; // 以独占模式获取对象，忽略中断 acquire(1); &#125; /** * Fair version of tryAcquire. Don&#x27;t grant access unless * recursive call or no waiters or is first. */ // 尝试公平获取锁 protected final boolean tryAcquire(int acquires) &#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取状态 int c = getState(); if (c == 0) &#123; // 状态为0 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; // 不存在已经等待更久的线程并且比较并且设置状态成功 // 设置当前线程独占 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 状态不为0，即资源已经被线程占据 // 下一个状态 int nextc = c + acquires; if (nextc &lt; 0) // 超过了int的表示范围 throw new Error(&quot;Maximum lock count exceeded&quot;); // 设置状态 setState(nextc); return true; &#125; return false; &#125;&#125; 跟踪lock方法的源码可知，当资源空闲时，它总是会先判断sync队列（AbstractQueuedSynchronizer中的数据结构）是否有等待时间更长的线程，如果存在，则将该线程加入到等待队列的尾部，实现了公平获取原则。 总结 通过分析前文的源代码，我们可以发现ReentrantLock可重入的关键在于：FairSync和NonfairSync中tryAcquire和tryRelease方法的实现。 tryAcquire()方法 每次申请锁时，如果锁被占用了，那么不会直接退出，而是判断当前占有所的线程是不是自己，如果是自己就执行int nextc = c + acquires;setState(nextc); 实现锁的可重入。 tryRelease()方法 释放锁的时候不是直接将锁状态置为0，而是执行int c = getState() - releases;setState(c); ，相当于释放部分资源量。 ReentrantLock的应用 ReentrantLock作为公平锁示例 123456789101112131415161718192021222324252627282930313233343536373839package com.hust.grid.leesf.abstractqueuedsynchronizer;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class MyThread extends Thread &#123; private Lock lock; public MyThread(String name, Lock lock) &#123; super(name); this.lock = lock; &#125; public void run () &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread() + &quot; running&quot;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;public class AbstractQueuedSynchonizerDemo &#123; public static void main(String[] args) throws InterruptedException &#123; Lock lock = new ReentrantLock(true); MyThread t1 = new MyThread(&quot;t1&quot;, lock); MyThread t2 = new MyThread(&quot;t2&quot;, lock); MyThread t3 = new MyThread(&quot;t3&quot;, lock); t1.start(); t2.start(); t3.start(); &#125;&#125; ReentrantLock v.s Synchronized 可重入锁 两者支持可重入，Synchronized是本地方法C++实现的，而ReentrantLock是JUC中的类，基于AQS实现。 实现方式 ReentrantLock是轻量级锁，基于AQS，即cas+volatile管理线程，无需线程切换，属于乐观锁。 Synchronized是重量级锁，锁被占用是，阻塞当前线程， 需要将线程从内核态和用户态来回切换，属于悲观锁。 使用方式 ReentrantLock 可以修饰实例方法，静态方法，代码块。自动释放锁。 Synchronized 一般需要try catch finally语句，在try中获取锁，在finally释放锁。需要手动释放锁。 公平性 ReentrantLock 支持公平锁和非公平锁两种，默认是非公平的。 Synchronized 只有非公平锁。 中断 Synchronized是不可中断的。 ReentrantLock提供可中断和不可中断两种方式。其中lockInterruptibly方法表示可中断，lock方法表示不可中断。 条件队列 Synchronized只有一个等待队列。 ReentrantLock中一把锁可以对应多个条件队列。通过newCondition表示。 参考资料 https://www.cnblogs.com/leesf456/p/5383609.html https://pdai.tech/md/java/thread/java-thread-x-lock-ReentrantLock.html https://segmentfault.com/a/1190000039091031","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"JUC锁之AQS","slug":"2 后端/Java/Java并发/9 JUC锁之AQS","date":"2022-02-10T14:34:49.000Z","updated":"2022-06-11T13:01:45.593Z","comments":true,"path":"7ed9e0093845/","link":"","permalink":"http://rookieyin.github.io/7ed9e0093845/","excerpt":"学习一个新技术比较好的一个路线就是去尝试回答四个问题：它是什么？它有什么用？它底层是怎么实现的？怎么用？ 本文也同样沿着这个路线，一探AQS的真面目！ 注：本文对AQS中的condition相关知识没有进行过多介绍，感兴趣的同学可以查阅其他资料。","text":"学习一个新技术比较好的一个路线就是去尝试回答四个问题：它是什么？它有什么用？它底层是怎么实现的？怎么用？ 本文也同样沿着这个路线，一探AQS的真面目！ 注：本文对AQS中的condition相关知识没有进行过多介绍，感兴趣的同学可以查阅其他资料。 AQS概述 AQS，全名 AbstractQueuedSynchronizer ，它是一个抽象类，也是JUC锁中的核心类之一。AQS源码中是这样介绍自己的： Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues. This class is designed to be a useful basis for most kinds of synchronizers that rely on a single atomic {@code int} value to represent state. 翻译成中文就是：“AQS是一个依赖于FIFO等待队列的框架，用于实现阻塞锁和相关同步器。它可以作为基础架构，用来设计各种依赖单个原子变量表示状态的同步器。” 简单来说就是，AQS是一个基本框架，当你想设计一个依赖原子变量表示状态的同步器时，你可以直接基于AQS来实现。 使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。 下图展示了AQS的整体框架： 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 实现原理 AQS的核心职责就是维护这个同步变量state，保证并发环境中state可以安全读写: 1234/** * The synchronization state. */private volatile int state; 为了实现这一功能，AQS的核心思想就是： 如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 等待队列 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 主要原理图如下： AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 队列中每个节点都是AQS内部类Node的一个实例。Node类源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static final class Node &#123; // 模式，分为共享与独占 // 共享模式 static final Node SHARED = new Node(); // 独占模式 static final Node EXCLUSIVE = null; // 结点状态 // CANCELLED，值为1，表示当前的线程被取消 // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中 // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行 // 值为0，表示当前节点在sync队列中，等待着获取锁 static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 结点状态 volatile int waitStatus; // 前驱结点 volatile Node prev; // 后继结点 volatile Node next; // 结点所对应的线程 volatile Thread thread; // 下一个等待者 Node nextWaiter; // 结点是否在共享模式下等待 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取前驱结点，若前驱结点为空，抛出异常 final Node predecessor() throws NullPointerException &#123; // 保存前驱结点 Node p = prev; if (p == null) // 前驱结点为空，抛出异常 throw new NullPointerException(); else // 前驱结点不为空，返回 return p; &#125; // 无参构造方法 Node() &#123; // Used to establish initial head or SHARED marker &#125; // 构造方法 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 构造方法 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; Node类中主要记录节点的资源申请模式以及所处状态，前后节点指针等信息。 临界资源的访问 在AQS中定义了两种资源访问方式： Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 。 因此AQS中一共需要4种临界资源访问方式：获取/释放独占锁以及获取/释放共享锁。 acquire(int)方法 12345public final void acquire(int arg) &#123; //tryAcquire 尝试获取资源 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 我们可以看到在acquire方法中用到了3个函数，我们先分别了解下这3个函数是干嘛的，再分析acquire的流程。 tryAcquire()方法 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 可以看出，这里只是AQS的简单实现， AQS这里只定义了一个接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS）。至于能不能重入，能不能加塞，那就看具体的自定义同步器怎么去设计了。当然，自定义同步器在进行资源访问时要考虑线程安全的影响。 addWaiter()方法 12345678910111213141516171819202122232425262728293031323334private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123;//cas方法插入节点 pred.next = node; return node; &#125; &#125; //尾结点是null，说明队列中没有元素，初始化一个头结点，然后新建节点作为尾结点 enq(node); return node;&#125;private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125;private Node enq(final Node node) &#123; //CAS&quot;自旋&quot;，直到成功加入队尾 for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 该方法 用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。 acquireQueued()方法 下面我们先看一下acquireQueued源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final boolean acquireQueued(final Node node, int arg) &#123; // 标记是否成功拿到资源 boolean failed = true; try &#123; // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) &#123; // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;// 靠前驱节点判断当前线程是否应该被阻塞private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus&gt;0是取消状态 if (ws &gt; 0) &#123; do &#123; // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this);//调用park()使线程进入waiting状态 //有两种途径可以唤醒该线程：1）被unpark()；2）被interrupt()。 return Thread.interrupted();//如果被唤醒，查看自己是不是被中断的，同时清除了中断标志，否则如果被中断唤醒，无法进入park，陷入死循环。&#125; 这里面有两个函数： shouldParkAfterFailedAcquire：判断自己前面有没有节点放弃申请资源了，如果有前驱放弃了，我们可以加塞到这个节点前面。 parkAndCheckInterrupt：找到加塞点后，当前线程就可以休息了，防止一致循环，浪费系统资源。parkAndCheckInterrupt做的事情就是调用park方法，中断当前线程，等待被唤醒。 对于这个方法，大家可能有个问题，为什么要返回Thread.interrupted()，并且在acquireQueued方法中需要有一个中断标记变量interrupted来接收这一返回值，并在acquire方法执行结束后返回这个中断标记呢？ 要回答这两个问题，要先明白这两点： 如果线程处于中断状态，那么park方法无法阻塞该线程 Thread.interrupted()方法有两个功能， 检查当前线程是否已被中断并清除线程的中断状态 有两种方式将线程从park里面被唤醒，中断和unpark 因此当从park状态被唤醒后，执行Thread.interrupted()的目的在于清除中断标志，防止再次执行parkAndCheckInterrupt()方法时park无法阻塞线程，acquireQueued（）陷入死循环。那为什么要返回Thread.interrupted()呢？因为Thread.interrupted()会清除中断标志，当``acquireQueued（）运行结束后，如果不返回中断标记，acquire()`就无法知道在申请锁过程中，线程是否被中断过，就无法响应该中断，这违背了中断的设计原则。 因此，我们可以看出 acquireQueued 方法中作的事情主要有两个：一是判断自己是不是头结点，如果是，尝试去申请资源；申请失败的话就寻找一个安全点（加塞到已经取消申请资源的节点前面），中断当前线程，等待被唤醒。流程如下： acquire总结 分析完acquire中调用的三个方法，我们再回到acquire方法本身： 12345public final void acquire(int arg) &#123; //tryAcquire 尝试获取资源 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 它的流程可以总结如下： 调用tryAcquire()尝试直接去获取资源，如果成功则直接返回； 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 release(int)方法 前面我们已经了解完了如何加锁，现在看看如何解锁。release方法源码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head;//找到头结点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒等待队列里的下一个线程 return true; &#125; return false;&#125; 首先调用tryRelease()尝试释放锁，如果释放成功从等待队列中唤醒下一个线程。 tryRelease()方法 此方法尝试去释放指定量的资源。下面是tryRelease()的源码： 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，**release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！**所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。 unparkSuccessor()方法 此方法用于唤醒等待队列中下一个线程。下面是源码： 12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // 从后向前找。 if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒&#125; 这个函数的功能也很简单，一句话概括就是：唤醒等待队列中第一个未放弃申请资源的线程。这里有一个知识点：为什么要从后往前找第一个非Cancelled的节点呢？ 因为有两种异常情况，会导致next链不一致： 因为在addWaiter()方法中节点入队并不是原子操作： s.waitStatus &gt; 0，中间有节点取消时会出现（如超时） 总之，由于并发问题，addWaiter()入队操作和cancelAcquire()取消排队操作都会造成next链的不一致，而prev链是强一致的，所以这时从后往前找是最安全的。 为什么prev链是强一致的？因为addWaiter()里每次compareAndSetTail(pred, node)之前都有node.prev = pred，即使compareAndSetTail失败，enq()会反复尝试，直到成功。一旦compareAndSetTail成功，该node.prev就成功挂在之前的tail结点上了，而且是唯一的，这时其他新结点的prev只能尝试往新tail结点上挂。这里的组合用法非常巧妙，能保证CAS之前的prev链强一致，但不能保证CAS后的next链强一致 acquireShared(int)方法 此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。下面是acquireShared()的源码： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是： tryAcquireShared()尝试获取资源，成功则直接返回； 失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回。 doAcquireShared()方法 此方法用于将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。下面是doAcquireShared()的源码： 1234567891011121314151617181920212223242526272829private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加入队列尾部 boolean failed = true;//是否成功标志 try &#123; boolean interrupted = false;//等待过程中是否被中断过的标志 for (;;) &#123; final Node p = node.predecessor();//前驱 if (p == head) &#123;//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的 int r = tryAcquireShared(arg);//尝试获取资源 if (r &gt;= 0) &#123;//成功 setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程 p.next = null; // help GC if (interrupted)//如果等待过程中被打断过，此时将中断补上。 selfInterrupt(); failed = false; return; &#125; &#125; //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这里和 acquireQueued()很相似，只不过把补中断操作放到了方法里面，这样方法就不用返回中断标记了。 跟独占模式比，还有一点需要注意的是，这里只有线程是head.next时（“老二”），才会去尝试获取资源，有剩余的话还会唤醒之后的队友。那么问题就来了，假如老大用完后释放了5个资源，而老二需要6个，老三需要1个，老四需要2个。老大先唤醒老二，老二一看资源不够，他是把资源让给老三呢，还是不让？答案是否定的！老二会继续park()等待其他线程释放资源，也更不会去唤醒老三和老四了。独占模式，同一时刻只有一个线程去执行，这样做未尝不可；但共享模式下，多个线程是可以同时执行的，现在因为老二的资源需求量大，而把后面量小的老三和老四也都卡住了。当然，这并不是问题，只是AQS保证严格按照入队顺序唤醒罢了（保证公平，但降低了并发）。 setHeadAndPropagate 12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node);//head指向自己 //如果还有剩余量，继续唤醒下一个邻居线程 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 此方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，毕竟是共享模式！ releaseShared(int)方法 会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//尝试释放资源 doReleaseShared();//唤醒后继结点 return true; &#125; return false;&#125; 此方法的流程也比较简单，一句话：释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。 dodoReleaseShared()方法 主要用于唤醒后继节点。 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head)// head发生变化 break; &#125;&#125; AQS的应用 AQS在JUC中的应用 AQS作为并发编程的框架，为很多其他同步工具提供了良好的解决方案。下面列出了JUC中的几种同步工具，大体介绍一下AQS的应用场景： 工具名 介绍 ReentrantLock 使用AQS保存锁重复持有的次数，实现可重入特性。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 自定义同步工具 自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 下面实现一个同步工具： 123456789101112131415161718192021222324252627282930public class LeeLock &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire (int arg) &#123; return compareAndSetState(0, 1); &#125; @Override protected boolean tryRelease (int arg) &#123; setState(0); return true; &#125; @Override protected boolean isHeldExclusively () &#123; return getState() == 1; &#125; &#125; private Sync sync = new Sync(); public void lock () &#123; sync.acquire(1); &#125; public void unlock () &#123; sync.release(1); &#125;&#125; 通过我们自己定义的Lock完成一定的同步功能。 1234567891011121314151617181920212223242526272829303132public class LeeMain &#123; static int count = 0; static LeeLock leeLock = new LeeLock(); public static void main (String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run () &#123; try &#123; leeLock.lock(); for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; leeLock.unlock(); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(count); &#125;&#125; 上述代码每次运行结果都会是20000。通过简单的几行代码就能实现同步功能，这就是AQS的强大之处。 总结 总之，AQS就是一个基于队列的同步框架，基于AQS我们能快速实现一个自定义同步器！ 参考资料 https://www.cnblogs.com/waterystone/p/4920797.html https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java中常见的锁","slug":"2 后端/Java/Java并发/8 Java中常见的锁","date":"2022-02-09T14:34:49.000Z","updated":"2022-06-11T13:06:03.422Z","comments":true,"path":"1ecc1ddc27d3/","link":"","permalink":"http://rookieyin.github.io/1ecc1ddc27d3/","excerpt":"本文转自：不可不说的Java“锁”事 概述 Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。","text":"本文转自：不可不说的Java“锁”事 概述 Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 乐观锁 VS 悲观锁 概念 乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 悲观锁： 认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 乐观锁： 认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 自旋锁 VS适应性自旋锁 什么是自旋锁？ 自旋，顾名思义就是让线程自己旋转一会。当线程要申请的资源被占用的时候，不是直接阻塞线程，而是线程不断空转（循环来实现），直到申请的资源被释放。 为什么要使用自旋锁？ 阻塞或唤醒一个线程需要在内核态和用户态之间来回切换，需要耗费很多时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户执行的时间还要长。 认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 这就可以用自旋锁。 自旋锁有什么优缺点？ 优点：自旋锁通过不断尝试申请锁（自旋等待），避免了线程切换的开销。 缺点：自旋需要占用CPU时间， 如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。 因此， 自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自适应自旋锁又是什么？ 自适应自旋锁，顾名思义就是在自旋锁的基础上添加了自适应功能。那具体可以自适应什么呢？ 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。 如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁 这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 Synchronized同步原理 为什么Synchronized能实现线程同步？ 在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 Java对象头 synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？ 我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word： 默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point： 对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 Monitor Monitor可以理解为一个同步工具或一种同步机制（有时称之为监视器），通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 同步原理 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 锁状态 存储内容 标志位 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁 轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 公平锁 VS 非公平锁 公平锁：即 多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。 优点：不存在饥饿现象 缺点：整体吞吐率略低 非公平锁： 多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。 优点： 可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。 缺点： 处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 可重入锁 VS 非可重入锁 这两个从名字上就很好区分。 可重入锁： 又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。 优点：可以一定程度上避免死锁。 Synchronized和ReentrantLock就是可重入锁。 非可重入锁：就是不能重入呗。 共享锁 VS 独占锁 独占锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java线程池之ThreadPoolExecutor","slug":"2 后端/Java/Java并发/7 Java 线程池之ThreadPoolExecutor","date":"2022-02-08T14:34:49.000Z","updated":"2022-06-11T12:59:51.887Z","comments":true,"path":"d4fa1f097a58/","link":"","permalink":"http://rookieyin.github.io/d4fa1f097a58/","excerpt":"如下图所示，ThreadPoolExecutor实现的顶层接口是Executor ，本文主要介绍了如何创建线程池、线程池底层原理等内容，其中重点内容是线程的生命周期。 关于ThreadPoolExecutor的具体方法和属性，本文不作详细介绍，可以直接查阅Java官方API文档。ThreadPoolExecutor中比较特殊的一个字段是ctl。它是一个复合属性，保存两部分信息： 线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了Integer类型来保存，高3位保存runState，低29位保存workerCount。COUNT_BITS 就是29，CAPACITY就是1左移29位减1（29个1），这个常量表示workerCount的上限值，大约是5亿。","text":"如下图所示，ThreadPoolExecutor实现的顶层接口是Executor ，本文主要介绍了如何创建线程池、线程池底层原理等内容，其中重点内容是线程的生命周期。 关于ThreadPoolExecutor的具体方法和属性，本文不作详细介绍，可以直接查阅Java官方API文档。ThreadPoolExecutor中比较特殊的一个字段是ctl。它是一个复合属性，保存两部分信息： 线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了Integer类型来保存，高3位保存runState，低29位保存workerCount。COUNT_BITS 就是29，CAPACITY就是1左移29位减1（29个1），这个常量表示workerCount的上限值，大约是5亿。 创建线程池 创建ThreadPoolExecutor线程池有两种方式：new和Executors工厂类。 直接new ThreadPoolExecutor类提供了很4种构造方法，构造方法的参数包括： corePoolSize：线程池中保留的核心线程数量 maximumPoolSize：线程池允许的最大线程数量 keepAliveTime：线程数量超过核心数量后，空闲线程最多存活多长时间 workQueue：任务队列，有很多类型，比如阻塞队列、无边界队列等等 threadFactory：线程池用来创建线程的线程工程，用户可以自定义，也可以用系统默认的 handler：阻塞队列满了，并且没有空闲线程时，线程池需要采取的策略。默认有4钟，用户也可以自定义。 Executors工厂类 Executors提供了很多静态工厂方法，用于创建Executor、ThreadFactory、Callable等实例对象。里面提供了多种用于创建ThreadPoolExecutor的静态方法： newFixedThreadPool 1234567891011public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; newSingleThreadExecutor 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newCachedThreadPool 1234567891011public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; 使用线程池 ThreadPoolExecutor是如何运行，如何同时维护线程和执行任务的呢？其运行机制如下图所示： 主要由两部分组成：线程池和任务缓冲队列。用户提交一个新任务后，判断能否立即分配线程执行，能就执行任务，不能则将任务放入等待队列中。整个线程池在运行过程中具有5个状态： RUNNING ：能接受新提交的任务，并且也能处理阻塞队列中的任务； SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown()方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用shutdown()方法进入该状态）； STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态； TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。 TERMINATED：在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做。 进入TERMINATED的条件如下： 线程池不是RUNNING状态； 线程池状态不是TIDYING状态或TERMINATED状态； 如果线程池状态是SHUTDOWN并且workerQueue为空； workerCount为0； 设置TIDYING状态成功。 下图展示了线程池的状态转换过程： 任务提交：submit方法 提交任务用的是AbstractExecutorService.submit()，可以获取执行完的返回值， 而ThreadPoolExecutor 是AbstractExecutorService.submit()的子类，所以submit方法也是ThreadPoolExecutor的方法。 12345678// submit方法在AbstractExecutorService中的实现public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 通过submit方法提交的Callable任务会被封装成了一个FutureTask对象。 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 通过submit方法提交的Callable任务会被封装成了一个FutureTask对象。通过Executor.execute方法提交FutureTask到线程池中等待被执行，最终执行的是FutureTask的run方法. 任务执行：execute方法 execute()方法源代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * clt记录着runState和workerCount */ int c = ctl.get(); /* * workerCountOf方法取出低29位的值，表示当前活动的线程数； * 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中； * 并把任务添加到该线程中。 */ if (workerCountOf(c) &lt; corePoolSize) &#123; /* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断； * 如果为true，根据corePoolSize来判断； * 如果为false，则根据maximumPoolSize来判断 */ if (addWorker(command, true)) return; /* * 如果添加失败，则重新获取ctl值 */ c = ctl.get(); &#125; /* * 如果当前线程池是运行状态并且任务添加到队列成功 */ if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重新获取ctl值 int recheck = ctl.get(); // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了， // 这时需要移除该command // 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); /* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示： * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动； * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断； * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。 */ else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; /* * 如果执行到这里，有两种情况： * 1. 线程池已经不是RUNNING状态； * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize； * 如果失败则拒绝该任务 */ else if (!addWorker(command, false)) reject(command);&#125; 这里有一个点就是：判断线程池状态的时候进行了double check，任务添加到队列前后都进行了状态检查。因为在多线程环境下，线程池的状态时刻在变化，而ctl.get()是非原子操作，很有可能刚获取了线程池状态后线程池状态就改变了。 倘若没有double check，万一线程池处于非running状态(在多线程环境下很有可能发生)，那么command永远不会执行。 在执行execute()方法时如果状态一直是RUNNING时，执行过程如下： 创建线程：addWorker方法 addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取运行状态 int rs = runStateOf(c); /* * 这个if判断 * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务； * 接着判断以下3个条件，只要有1个不满足，则返回false： * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 * 2. firsTask为空 * 3. 阻塞队列不为空 * * 首先考虑rs == SHUTDOWN的情况 * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false； * 然后，如果firstTask为空，并且workQueue也为空，则返回false， * 因为队列中已经没有任务了，不需要再添加线程了 */ // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; // 获取线程数 int wc = workerCountOf(c); // 如果wc超过CAPACITY，也就是ctl的低29位的最大值（二进制是29个1），返回false； // 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较， // 如果为false则根据maximumPoolSize来比较。 // if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试增加workerCount，如果成功，则跳出第一个for循环 if (compareAndIncrementWorkerCount(c)) break retry; // 如果增加workerCount失败，则重新获取ctl的值 c = ctl.get(); // Re-read ctl // 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个for循环继续执行 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 根据firstTask来创建Worker对象 w = new Worker(firstTask); // 每一个Worker对象都会创建一个线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN表示是RUNNING状态； // 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。 // 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // workers是一个HashSet workers.add(w); int s = workers.size(); // largestPoolSize记录着线程池中出现过的最大线程数量 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 启动线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 从上面代码可以看到，addWork()方法的核心是创建一个Worker实例，然后在t.start()处启动该worker。需要注意的是，这里启动线程会调用Worker类中的run方法，Worker本身也实现了Runnable接口，所以 一个Worker类型的对象也是一个线程。 整个添加线程的流程如下： Worker类 线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象，看一下Worker的定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; Worker继承了AQS， 并实现了Runnable接口，注意其中的firstTask和thread属性： firstTask： 用它来保存传入的任务 thread： 在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程 这里有两个问题，需要关注： 为什么Worker要加锁？ 简单来说就是，防止线程在执行任务过程中被中断。从后文介绍的runWorker源代码中我们可以看到，线程执行任务之前会上锁，任务完成后会释放锁。 线程池执行中断方法时，会先获取该线程的锁，如果可以获取到，说明此时线程处于空闲状态，否则线程正在执行任务，禁止被中断。 为什么通过继承AQS来实现独占锁功能？ 可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的： lock方法一旦获取了独占锁，表示当前线程正在执行任务中； 如果正在执行任务，则不应该中断线程； 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； 之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 所以，Worker继承自AQS，用于判断线程是否空闲以及是否可以被中断。 runWorker方法 从前面我们知道线程池中的所有线程都被封装成了Worker实例， 在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为空，则通过getTask来获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask方法 观察上面runWorker方法的源代码，其中一个非常重要的环节就是调用getTask方法，获取可执行任务。getTask源代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private Runnable getTask() &#123; // timeOut变量的值表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. /* * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断： * 1. rs &gt;= STOP，线程池是否正在stop； * 2. 阻塞队列是否为空。 * 如果以上条件满足，则将workerCount减1并返回null。 * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。 */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? // timed变量用于判断是否需要进行超时控制。 // allowCoreThreadTimeOut默认是false，也就是核心线程不允许进行超时； // wc &gt; corePoolSize，表示当前线程池中的线程数量大于核心线程数量； // 对于超过核心线程数量的这些线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法； * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1； * 如果减1失败，则返回重试。 * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; /* * 根据timed来判断，如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务，则返回null； * 否则通过take方法，如果这时队列为空，则take方法会阻塞直到队列不为空。 * */ Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 如果 r == null，说明已经超时，timedOut设置为true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试 timedOut = false; &#125; &#125;&#125; getTask方法功能非常简单，就是从任务队列里面获取任务。但是如果任务队列为空怎么办？阅读上述源代码后半部分的try…catch…，可以看到这时候keepAliveTime就派上用场了。 在研究线程池的时候，我们心里可能有个疑惑：我们知道线程池中的线程分为核心线程和非核心线程，核心线程是不会被销毁的，而非核心线程在空闲状态下超过一定时间会被销毁。线程池是如何实现这一功能的呢？getTask方法的源码给了我们答案。 变量boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;表示是否对当前线程进行超时控制 若timed==true，获取任务时候执行 workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)，队列为空，超时后返回null，当runWork方法中获取null任务时，运行结束，线程也就被销毁了 若timed==false，获取任务时候执行workQueue.take()，队列为空时，会一直阻塞，因此getTask方法不会运行结束，runWork方法也就不会结束，线程也就不会被销毁。 默认allowCoreThreadTimeOut 参数为false，这样当运行任务数小于核心线程数时，timed变量始终为false，就不会再销毁线程。 销毁线程 什么时候会销毁？当然是runWorker方法执行完之后，也就是Worker中的run方法执行完，由JVM自动回收。 getTask方法返回null时，在runWorker方法中会跳出while循环，然后会执行processWorkerExit方法。processWorkerExit方法源代码如下： 12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1； // 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。 if (completedAbruptly) // If abrupt, then workerCount wasn&#x27;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //统计完成的任务数 completedTaskCount += w.completedTasks; // 从workers中移除，也就表示着从线程池中移除了一个工作线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); /* * 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker； * 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker； * 如果allowCoreThreadTimeOut=false，workerCount不少于corePoolSize。 */ if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125; 线程生命周期 以上就是整个工作线程的生命周期，从execute方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker通过getTask获取任务，然后执行任务，如果getTask返回null，进入processWorkerExit方法，整个线程结束，如图所示： 关闭线程池 前面我们介绍了如何创建线程池，以及线程池底层运行原理，那么如何关闭线程池呢？ tryTerminate方法 在介绍销毁线程的processWorkerExit方法时，其源代码中间部分有一行代码tryTerminate()，即尝试关闭线程池。 tryTerminate方法根据线程池状态进行判断是否结束线程池，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); /* * 当前线程池的状态为以下几种情况时，直接返回： * 1. RUNNING，因为还在运行中，不能停止； * 2. TIDYING或TERMINATED，因为线程池中已经没有正在运行的线程了； * 3. SHUTDOWN并且等待队列非空，这时要执行完workQueue中的task； */ if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 如果线程数量不为0，则中断一个空闲的工作线程，并返回 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 这里尝试设置状态为TIDYING，如果设置成功，则调用terminated方法 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // terminated方法默认什么都不做，留给子类实现 terminated(); &#125; finally &#123; // 设置状态为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; shutdown方法 shutdown方法要将线程池切换到SHUTDOWN状态，并调用interruptIdleWorkers方法请求中断所有空闲的worker，最后调用tryTerminate尝试结束线程池。 1234567891011121314151617public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 安全策略判断 checkShutdownAccess(); // 切换状态为SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试结束线程池 tryTerminate();&#125; 其中核心一句代码就是中断空闲线程：interruptIdleWorkers()，下面分析下这个方法。 interruptIdleWorkers方法 123456789101112131415161718192021222324private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; interruptIdleWorkers遍历workers中所有的工作线程，若线程没有被中断tryLock成功，就中断该线程。 这里有两个知识点： 和前文我们提到的一个问题“为什么getTask方法中执行任务前后要加锁和释放锁”呼应上了 我们可以看到在for循环的第一个if条件中一项就是w.tryLock（）即获取当前worker的锁，如果当前worker正在执行任务，那么getTask方法中就会获取锁，这里的w.tryLock（）就无法获取锁，进而无法中断该线程。 这样就能达到我们的目的：正在执行任务的线程禁止被中断。 为什么需要持有mainLock？ 因为workers是HashSet类型的，不能保证线程安全。 shutdownNow方法 1234567891011121314151617public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); // 中断所有工作线程，无论是否空闲 interruptWorkers(); // 取出队列中没有被执行的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125; shutdownNow方法与shutdown方法类似，不同的地方在于： 设置状态为STOP； 中断所有工作线程，无论是否是空闲的； 取出阻塞队列中没有被执行的任务并返回。 shutdownNow方法执行完之后调用tryTerminate方法，该方法在上文已经分析过了，目的就是使线程池的状态设置为TERMINATED。 总结 本文主要介绍了一下知识点： 如何创建线程池？ 有两种方法：new和Executors工厂类。尽量不要使用Executors去创建线程池，因为其本质也是调用new ThreadPoolExecutor()，但是由于参数固定，存在很多缺陷。 newFixedThreadPool和newSingleThreadExecutor: 主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。 newCachedThreadPool和newScheduledThreadPool: 主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。 线程池中线程的生命周期 threadpool-lifecycle.png 线程池中线程的生命周期如上图所示，这里面有很多知识点。比如核心线程和非核心线程的销毁，getTask方法的细节，runWorker方法的细节，为什么Worker要加锁之类的。 线程池关闭 怎么关闭线程池？shutdown和shutdownNow有什么区别？ 参考资料 http://www.ideabuffer.cn/2017/04/04/ https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html https://pdai.tech/md/java/thread/java-thread-x-juc-executor-ThreadPoolExecutor.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java线程池概述","slug":"2 后端/Java/Java并发/6 Java线程池概述","date":"2022-02-07T14:34:49.000Z","updated":"2022-06-11T12:58:18.977Z","comments":true,"path":"b486854617ea/","link":"","permalink":"http://rookieyin.github.io/b486854617ea/","excerpt":"什么是线程池 线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。 注： 池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。","text":"什么是线程池 线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。 注： 池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。 线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务，实现了线程和任务之间的解耦。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。 下图展示了线程池的原理： 为什么用线程池 线程池要解决什么问题？ 线程池解决的核心问题就是资源管理问题。在并发环境下，系统不能够确定在任意时刻中，有多少任务需要执行，有多少资源需要投入。这种不确定性将带来以下若干问题： 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。 对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。 系统无法合理管理内部的资源分布，会降低系统的稳定性。 线程池的好处 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 什么时候使用线程池 单个任务处理时间比较短 需要处理的任务数量很大 Java中线程池类图 上图展示了Java中和线程池相关的部分类图。其中层次关系如下： Executor接口：线程池顶层接口，提供了一种思想： 将任务提交和任务执行进行解耦。 用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。 ExecutorService接口：增加了一些能力 扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法； 提供了管控线程池的方法，比如停止线程池的运行。 ScheduledExecutorService ： 扩展了ExecutorService。支持Future和定期执行任务 AbstractExecutorService：上层抽象类， 将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。 底层实现类：ThreadPoolExecutor和ScheduledThreadPoolExecutor 一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 参考资料 http://www.ideabuffer.cn/2017/04/04/ https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html https://pdai.tech/md/java/thread/java-thread-x-juc-executor-ThreadPoolExecutor.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"深入ThreadLocal","slug":"2 后端/Java/Java并发/5 深入ThreadLocal","date":"2022-02-06T14:34:49.000Z","updated":"2022-06-11T12:57:52.350Z","comments":true,"path":"c935ab160905/","link":"","permalink":"http://rookieyin.github.io/c935ab160905/","excerpt":"我们知道 线程安全(是指广义上的共享资源访问安全性，因为线程隔离是通过副本保证本线程访问资源安全性，它不保证线程之间还存在共享关系的狭义上的安全性)的解决思路有： 互斥同步： synchronized 和 ReentrantLock 等。 非阻塞同步： CAS, AtomicXXXX 。 无同步方案： 栈封闭，本地存储(Thread Local)，可重入代码 。 其中“无同步方案”中的ThreadLocal就是本文的主角。","text":"我们知道 线程安全(是指广义上的共享资源访问安全性，因为线程隔离是通过副本保证本线程访问资源安全性，它不保证线程之间还存在共享关系的狭义上的安全性)的解决思路有： 互斥同步： synchronized 和 ReentrantLock 等。 非阻塞同步： CAS, AtomicXXXX 。 无同步方案： 栈封闭，本地存储(Thread Local)，可重入代码 。 其中“无同步方案”中的ThreadLocal就是本文的主角。 ThreadLocal简介 ThreadLocal是java.lang.Object包下面的一个类，官方文档是这样讲的： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID). 翻译成中文就是：这个类提供线程本地的变量，这些变量与普通变量的区别在于，线程访问这些本地变量时，访问的是自己的副本。 ThreadLocal实例通常是类中的私有静态字段，它们希望将状态与线程相关联(例如，用户ID或事务ID)。 总结来说就是：ThreadLocal提供了线程隔离的功能，当使用ThreaLocal维护变量时，每个线程都有自己的副本，不同线程之间互不影响。 避免因多线程操作共享变量而导致的数据不一致的情况。 ThreadLocal底层原理 ThreadLocal数据结构 知道了ThreadLocal是什么，有什么用，那么ThreadLocal底层是怎样实现的呢？它是如何为每个线程都维护一个变量副本的？ 在 Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，也就是说每个线程有一个自己的ThreadLocalMap 。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 整个数据存储结构如下图所示： 每个线程在往ThreadLocal里放值的时候，都会往自己的ThreadLocalMap里存，读也是以ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。 ThreadLocalMap类 ThreadLocalMap是ThreadLocal中的静态内部类，只能供ThreadLocal使用。官方文档中是这样介绍它的： ThreadLocalMap is a customized hash map suitable only for maintaining thread local values. 本质上来讲, 它就是一个Map, 但是这个ThreadLocalMap与我们平时见到的Map有点不一样 ： 它没有实现Map接口; 它没有public的方法, 最多有一个default的构造方法, 因为这个ThreadLocalMap的方法仅仅在ThreadLocal类中调用, 属于静态内部类 ThreadLocalMap的Entry实现继承了WeakReference&lt;ThreadLocal&lt;?&gt;&gt; 该方法仅仅用了一个Entry数组来存储Key, Value; Entry并不是链表形式, 而是每个bucket里面仅仅放一个Entry; 下面部分源码展示了ThreadLocalMap中的部分属性和静态内部类Entry。 1234567891011121314151617181920static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; private int threshold; // Default to 0 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125;&#125; 既然ThreadLocalMap类是一个类似Map结构，那么我们最关系的就是它的哈希算法和get、set等方法了。 hash算法 12//ThreadLocal&lt;?&gt; key，i表示数组下标，len表示数组长度int i = key.threadLocalHashCode &amp; (len-1); 其中threadLocalHashCode是ThreadLocal类的成员变量，生成方式如下： 12345678private final int threadLocalHashCode = nextHashCode();//初始值为0private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;//每创建一个ThreadLocal对象，nextHashCode值都增加0x61c88647private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 每当创建一个ThreadLocal对象，这个ThreadLocal.nextHashCode 这个值就会增长 0x61c88647 。 这个值很特殊，它是斐波那契数 也叫 黄金分割数。hash增量为 这个数字，带来的好处就是 hash 分布非常均匀。 hash冲突 虽然ThreadLocalMap中使用了黄金分割数来作为hash计算因子，大大减少了Hash冲突的概率，但是仍然会存在冲突。 ThreadLocalMap 中并没有链表结构，因此采用线性探查法解决hash冲突问题。即 发生冲突时线性向后查找，一直找到 Entry 为 null 的槽位才会停止查找，将当前元素放入此槽位中。 set()方法 先直接上源码： 12345678910111213141516171819202122232425262728293031private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //线性探查法解决hash冲突 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //如果相等，说明是更新 if (k == key) &#123; e.value = value; return; &#125; //如果为null，直接插入，否则产生hash冲突，向后寻找第一个空位 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; //插入或更新完成后，需要进行过期元素的处理，并rehash if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;//hash冲突时，寻找下一个空位private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125; get()方法 get调用的时getEntry方法，其源码如下： 123456789101112131415161718192021222324252627282930private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; //确定下标 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; //如果存在，并且其key等于我们要找的，直接返回 if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;/** * Version of getEntry method for use when key is not found in * its direct hash slot. */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i);//顺带删除一下过时的entry else i = nextIndex(i, len);//向后探查 e = tab[i]; &#125; return null;&#125; 关于ThreadLocalMap扩容，过期key的清理这些内容，本文就不详细介绍了。 ThreadLocal的get和set方法 get()方法 12345678910111213141516171819202122232425/** * Returns the value in the current thread&#x27;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread&#x27;s value of this thread-local */public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程下的map ThreadLocalMap map = getMap(t); if (map != null) &#123; //将ThreadLocal对象作为key，从map中取数据 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; //map为空，使用初始值创建map return setInitialValue();&#125; set()方法 1234567891011121314151617/** * Sets the current thread&#x27;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread&#x27;s copy of * this thread-local. */public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; set方法很简单，map不为空则插入数据，为空则创建map。 总结 看到这里，还有块内容比较蒙：Thread，ThreadLocal和ThreadLocalMap三者什么关系？如何通过ThreadLocal实现每个共享变量隔离？Thread里面这样set、get数据的？如果你也有同样的感觉，看完这个总结，就能解答全部疑惑了。 Thread，ThreadLocal和ThreadLocalMap关系 Thread不用多说，每个线程就是一个Thread实例 ThreadLocalMap，ThreadLocal类中的静态内部类，是线程用来存储共享变量副本的（Thread类中有一个成员变量ThreadLocal.ThreadLocalMap threadLocals = null;） 从前两点看来，Thread用于ThreadLocalMap就已经实现了共享变量的隔离，要ThreadLocal有何用？ 原因有两点： ThreadLocalMap是ThreadLocal，有ThreadLocal才能用（没啥说服力）。 ThreadLocalMap中的key是ThreadLocal实例的引用，当有多个ThreadLocal实例时，需要根据其引用到map中找value 因此ThreadLocal存在的意义就是作为key，当线程中存在多个共享变量时（有多个ThreadLocal实例），我们要将ThreadLocal实例的引用作为key，来确定我们要set或get哪个共享变量。 线程中get/set共享变量 捋清楚了Thread，ThreadLocal和ThreadLocalMap三者之间的关系，这里我们总结下在线程中访问共享变量的流程： 上图展示的时set方法的流程，简单总结就是：将ThreadLocal实例的引用作为key，去map中set。 get方法也是类似的，这里不再详细描述。 内存泄漏问题 为什么会内存泄漏 先看一下ThreadLocal的原理图： 每个Thread都有自己的ThreadLocalMap表，map表的key是ThreadLocal实例本身，value存储的是数据。在前面讨论Thread，ThreadLocal和ThreadLocalMap三者之间的关系时我们就提到，存储数据靠着ThreadLocalMap就够了，ThreadLocal存在的目的就是作为key。当线程中有多个共享变量时，我们需要根据ThreadLocal实例作为key，来寻找我们需要的那个共享变量。 上图值得注意的就是那条虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收（指没有强引用的情况下）。 了解了ThreadLocal原理，我们再来分析为什么可能发生内存泄漏： ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏 。 为什么用弱引用 从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，其实并不是这样。但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys. 下面我们分两种情况讨论： key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 最佳实践 综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 把 ThreadLocal 对象定义成 static 的，即定义成类变量，这样，我们会一直持有 ThreadLocal 对象，从根源上断绝了内存泄露的情况（不知道大家有没有注意到，上面讨论的弱引用也好，内存泄露也好，都是在 ThreadLocal 对象会被业务代码释放引用的前提下进行讨论的）。 在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。 ThreadLocal应用 现在我们已经知道了ThreadLocal的核心功能在于：在多个线程之间隔离共享变量。那么在实际开发中，它有哪些引用场景呢？ 序列号 如果我们希望通过某个类将状态(例如用户ID、事务ID)与线程关联起来，那么通常在这个类中定义private static类型的ThreadLocal 实例。 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.test; public class TestNum &#123; // ①通过匿名内部类覆盖ThreadLocal的initialValue()方法，指定初始值 private static ThreadLocal&lt;Integer&gt; seqNum = new ThreadLocal&lt;Integer&gt;() &#123; public Integer initialValue() &#123; return 0; &#125; &#125;; // ②获取下一个序列值 public int getNextNum() &#123; seqNum.set(seqNum.get() + 1); return seqNum.get(); &#125; public static void main(String[] args) &#123; TestNum sn = new TestNum(); // ③ 3个线程共享sn，各自产生序列号 TestClient t1 = new TestClient(sn); TestClient t2 = new TestClient(sn); TestClient t3 = new TestClient(sn); t1.start(); t2.start(); t3.start(); &#125; private static class TestClient extends Thread &#123; private TestNum sn; public TestClient(TestNum sn) &#123; this.sn = sn; &#125; public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; // ④每个线程打出3个序列值 System.out.println(&quot;thread[&quot; + Thread.currentThread().getName() + &quot;] --&gt; sn[&quot; + sn.getNextNum() + &quot;]&quot;); &#125; &#125; &#125; &#125; 通常我们通过匿名内部类的方式定义ThreadLocal的子类，提供初始的变量值，如例子中①处所示。TestClient线程产生一组序列号，在③处，我们生成3个TestClient，它们共享同一个TestNum实例。运行以上代码，在控制台上输出以下的结果： 123456789thread[Thread-0] --&gt; sn[1]thread[Thread-1] --&gt; sn[1]thread[Thread-2] --&gt; sn[1]thread[Thread-1] --&gt; sn[2]thread[Thread-0] --&gt; sn[2]thread[Thread-1] --&gt; sn[3]thread[Thread-2] --&gt; sn[2]thread[Thread-0] --&gt; sn[3]thread[Thread-2] --&gt; sn[3] 考察输出的结果信息，我们发现每个线程所产生的序号虽然都共享同一个TestNum实例，但它们并没有发生相互干扰的情况，而是各自产生独立的序列号，这是因为我们通过ThreadLocal为每一个线程提供了单独的副本。 Session管理 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s; &#125; 线程内部创建ThreadLocal 还有一种用法是在线程类内部创建ThreadLocal，基本步骤如下： 在多线程的类(如ThreadDemo类)中，创建一个ThreadLocal对象threadXxx，用来保存线程间需要隔离处理的对象xxx。 在ThreadDemo类中，创建一个获取要隔离访问的数据的方法getXxx()，在方法中判断，若ThreadLocal对象为null时候，应该new()一个隔离访问类型的对象，并强制转换为要应用的类型。 在ThreadDemo类的run()方法中，通过调用getXxx()方法获取要操作的数据，这样可以保证每个线程对应一个数据对象，在任何时刻都操作的是这个对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ThreadLocalTest implements Runnable&#123; ThreadLocal&lt;Student&gt; StudentThreadLocal = new ThreadLocal&lt;Student&gt;(); @Override public void run() &#123; String currentThreadName = Thread.currentThread().getName(); System.out.println(currentThreadName + &quot; is running...&quot;); Random random = new Random(); int age = random.nextInt(100); System.out.println(currentThreadName + &quot; is set age: &quot; + age); Student Student = getStudentt(); //通过这个方法，为每个线程都独立的new一个Studentt对象，每个线程的的Studentt对象都可以设置不同的值 Student.setAge(age); System.out.println(currentThreadName + &quot; is first get age: &quot; + Student.getAge()); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println( currentThreadName + &quot; is second get age: &quot; + Student.getAge()); &#125; private Student getStudentt() &#123; Student Student = StudentThreadLocal.get(); if (null == Student) &#123; Student = new Student(); StudentThreadLocal.set(Student); &#125; return Student; &#125; public static void main(String[] args) &#123; ThreadLocalTest t = new ThreadLocalTest(); Thread t1 = new Thread(t,&quot;Thread A&quot;); Thread t2 = new Thread(t,&quot;Thread B&quot;); t1.start(); t2.start(); &#125; &#125;class Student&#123; int age; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; SimpleDateFormat方法 SimpleDateFormat是线程不安全的，因为其内部用个Canlendar对象，多线程环境下，访问这个共享对象存在问题。 阿里巴巴 java 开发手册中推荐的 ThreadLocal 的用法： 12345678910111213141516171819import java.text.DateFormat;import java.text.SimpleDateFormat; public class DateUtils &#123; //把DateFormat放到ThreadLocal中，这样每个线程都有自己的DateFormat实例 public static final ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;()&#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); &#125; &#125;; public static String format(Date date) &#123; return local.get().format(date); &#125; public static Date parse(String dateStr) throws ParseException &#123; return local.get().parse(dateStr); &#125;&#125; 这是不使用ThreadLocal，多线程情况下出错的场景演示： 123456789101112131415161718192021222324252627282930313233343536public class DateUtil &#123; private static SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); public static String format(Date date) &#123; return dateFormat.format(date); &#125; public static Date parse(String dateStr) throws ParseException &#123; return dateFormat.parse(dateStr); &#125; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(1); final String[] strs = new String[] &#123;&quot;2016-01-01 10:24:00&quot;, &quot;2016-01-02 20:48:00&quot;, &quot;2016-01-11 12:24:00&quot;&#125;; for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int i = 0; i &lt; 10; i++)&#123; try &#123; System.out.println(Thread.currentThread().getName()+ &quot;\\t&quot; + parse(strs[i % strs.length])); Thread.sleep(100); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125; latch.countDown(); &#125;&#125; 参考资料 https://pdai.tech/md/java/thread/java-thread-x-threadlocal.html# https://javaguide.cn/java/concurrent/threadlocal.html#threadlocal https://blog.jrwang.me/2016/java-simpledateformat-multithread-threadlocal/ https://www.kancloud.cn/java-jdxia/big-data/573682","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Final关键字","slug":"2 后端/Java/Java并发/4 Final关键字","date":"2022-02-05T14:34:49.000Z","updated":"2022-06-11T12:56:56.622Z","comments":true,"path":"d2695845d35c/","link":"","permalink":"http://rookieyin.github.io/d2695845d35c/","excerpt":"final的功能 final关键字可以用于多个场景，且在不同场景中具有不同的作用。 修饰类 当某个类的整体定义为final时， 这个类禁止被继承。 因此final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。","text":"final的功能 final关键字可以用于多个场景，且在不同场景中具有不同的作用。 修饰类 当某个类的整体定义为final时， 这个类禁止被继承。 因此final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。 修饰方法 所有的private方法都是隐式的final，因为 由于无法取用private方法，所以也就不能覆盖它。可以对private方法增添final关键字，但这样做并没有什么好处。 final方法可以重载 修饰参数 Java允许在参数列表中以声明的方式将参数指明为final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。 修饰变量 final可以修饰非编译器常量，即final int a = varb。 static final： 一个既是static又是final 的字段只占据一段不能改变的存储空间，它必须在定义的时候进行赋值，否则编译器将不予通过。 空白final： 也就是说被声明为final但又没有给出定值的字段,但是必须在该字段被使用之前被赋值（在构造函数中赋值）。 final修饰引用对象时，引用不能变，但是被引用对象的内容可变。 final修饰基本类型时，看做常量，存于常量池中。 final域重排序规则 final域为基本类型 1234567891011121314151617181920public class FinalDemo &#123; private int a; //普通域 private final int b; //final域 private static FinalDemo finalDemo; public FinalDemo() &#123; a = 1; // 1. 写普通域 b = 2; // 2. 写final域 &#125; public static void writer() &#123; finalDemo = new FinalDemo(); &#125; public static void reader() &#123; FinalDemo demo = finalDemo; // 3.读对象引用 int a = demo.a; //4.读普通域 int b = demo.b; //5.读final域 &#125;&#125; 写final域重排序规则 写final域的重排序规则禁止对final域的写重排序到构造函数之外，这个规则的实现主要包含了两个方面： JMM禁止编译器把final域的写重排序到构造函数之外； 编译器会在final域写之后，构造函数return之前，插入一个storestore屏障。这个屏障可以禁止处理器把final域的写重排序到构造函数之外， 同时保证前面的对final写入对其他线程/CPU可见 。 因此，写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域就不具有这个保障。 读final域重排序规则 读final域重排序规则为：在一个线程中，初次读对象引用和初次读该对象包含的final域，JMM会禁止这两个操作的重排序。(注意，这个规则仅仅是针对处理器)，处理器会在读final域操作的前面插入一个LoadLoad屏障。实际上，读对象的引用和读该对象的final域存在间接依赖性，一般处理器不会重排序这两个操作。但是有一些处理器会重排序，因此，这条禁止重排序规则就是针对这些处理器而设定的。 总之， 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。 final域为引用类型 写final域重排序规则 在基本类型的基础上增加了一条： 在构造函数内对一个final修饰的对象的成员域的写入，与随后在构造函数之外把这个被构造的对象的引用赋给一个引用变量，这两个操作是不能被重排序的。 1234567891011121314151617181920212223public class FinalReferenceDemo &#123; final int[] arrays; private FinalReferenceDemo finalReferenceDemo; public FinalReferenceDemo() &#123; arrays = new int[1]; //1 arrays[0] = 1; //2 &#125; public void writerOne() &#123; finalReferenceDemo = new FinalReferenceDemo(); //3 &#125; public void writerTwo() &#123; arrays[0] = 2; //4 &#125; public void reader() &#123; if (finalReferenceDemo != null) &#123; //5 int temp = finalReferenceDemo.arrays[0]; //6 &#125; &#125;&#125; 针对上面的实例程序，线程线程A执行wirterOne方法，执行完后线程B执行writerTwo方法，然后线程C执行reader方法。 由于对final域的写禁止重排序到构造方法外，因此1和3不能被重排序。由于一个final域的引用对象的成员域写入不能与随后将这个被构造出来的对象赋给引用变量重排序，因此2和3不能重排序。 读final域重排序规则 JMM可以确保线程C至少能看到写线程A对final引用的对象的成员域的写入，即能看下arrays[0] = 1，而写线程B对数组元素的写入可能看到可能看不到。JMM不保证线程B的写入对线程C可见，线程B和线程C之间存在数据竞争，此时的结果是不可预知的。如果可见的，可使用锁或者volatile。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Volite关键字","slug":"2 后端/Java/Java并发/3 Volatile关键字","date":"2022-02-04T14:34:49.000Z","updated":"2022-06-11T12:56:11.650Z","comments":true,"path":"97a7e424d2a5/","link":"","permalink":"http://rookieyin.github.io/97a7e424d2a5/","excerpt":"并发3特性 原子性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 Java中，基本数据类型的访问、读写都是具备原子性的，例外就是long和double的非原子性协定，但是一般无需在意这个。另外如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。","text":"并发3特性 原子性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 Java中，基本数据类型的访问、读写都是具备原子性的，例外就是long和double的非原子性协定，但是一般无需在意这个。另外如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。 可见性 可见性是指：当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。 举个简单的例子： 12345//线程1执行的代码int i = 0;i = 10;//线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 在Java中，可以通过Synchronized、lock和Volatile等关键字保证可见性。 有序性 有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码： 1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？ 处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然指令重排序不会影响单个线程内程序的结果，但是多线程情况下可能出现问题。下面看个例子： 12345678//线程1:context = loadContext(); //语句1inited = true; //语句2//线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 对于程序次序规则来说，看起来好像就可以保证程序的有序性，为什么还要Volatile等关键字呢？这里需要注意的一点是，有序性通常是指CPU执行的指令的有序，一般一行程序编译后会得到若干条不同指令（比如i++编译后会有3条指令）。因此这条原则可以保证程序是按照代码顺序执行的，但是虚拟机可能会对程序代码进行指令重排序。这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作 也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 Volatile作用 Volatile的作用主要有两个：保证可见性和防止重排序。 可见性 先看一个多线程下优于可见性问题导致程序可能出错的例子： 1234567//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125;//线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。那么线程1读取到的就是最新的正确的值。 防止指令重排序 我们从一个最经典的例子来分析重排序问题。大家应该都很熟悉单例模式的实现，而在并发环境下的单例实现方式，我们通常可以采用双重检查加锁(DCL，volatile+synchronized)的方式来实现。其源码如下： 1234567891011121314151617public class Singleton &#123; public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() &#123;&#125;; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： 分配内存空间。 初始化对象。 将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： 分配内存空间。 将内存空间的地址赋值给对应的引用。 初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。 原子性 对于原子性，需要强调一点，也是大家容易误解的一点：对volatile变量的单次读/写操作可以保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 Volatile原理 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 应用场景 synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。常见应用场景如下： 状态标志 也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 12345678volatile boolean shutdownRequested;......public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; DCL（双重检查锁） 前文提到过，在经典单例模式中，需要Volatile和Synchronized关键字配合使用，保证多线程安全，即双重检查锁（DCL）。 一次性安全发布 缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原始值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值(由另一个线程写入)和该对象状态的旧值同时存在。(这就是造成著名的双重检查锁定(double-checked-locking)问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象)。 独立观察 安全使用 volatile 的另一种简单模式是定期 发布 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。 volatile bean 模式 在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。(这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义)。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。 开销较低的读-写锁策略 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作(读、添加、存储)的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。 如果读操作远远超过写操作，可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。 安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。 123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the &#x27;this&#x27; lock held @GuardedBy(&quot;this&quot;) private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; 参考资料 https://www.cnblogs.com/dolphin0520/p/3920373.html https://pdai.tech/md/java/thread/java-thread-x-key-volatile.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Synchronized关键字","slug":"2 后端/Java/Java并发/2 Synchronized关键字","date":"2022-02-03T14:34:49.000Z","updated":"2022-06-11T13:08:15.785Z","comments":true,"path":"e920947d370d/","link":"","permalink":"http://rookieyin.github.io/e920947d370d/","excerpt":"在Java中除了提供Lock API外还在语法层面上提供了synchronized关键字来实现互斥同步原语，可以保证同步对象的原子性、可见性和有序性（ 加上synchronized后，依然会发生重排序，只不过，我们有同步代码块，可以保证只有一个线程执行同步代码快中的代码，从而保证有序性）。 不过需要注意的是，这里保证可见性和volatile保证可见性有一定区别。volatile保证绝对的可见性，synchronized是通过获取锁时强制从主存取数据保证的，如果访问变量时没有获取锁，就不保证可见性。","text":"在Java中除了提供Lock API外还在语法层面上提供了synchronized关键字来实现互斥同步原语，可以保证同步对象的原子性、可见性和有序性（ 加上synchronized后，依然会发生重排序，只不过，我们有同步代码块，可以保证只有一个线程执行同步代码快中的代码，从而保证有序性）。 不过需要注意的是，这里保证可见性和volatile保证可见性有一定区别。volatile保证绝对的可见性，synchronized是通过获取锁时强制从主存取数据保证的，如果访问变量时没有获取锁，就不保证可见性。 1 Synchronized的使用 synchronized可修饰的对象有以下几种： 方法 被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象 。 静态方法 其作用的范围是整个静态方法，作用的对象是这个类的所有对象。 代码块 被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象。 类 其作用的范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 1234567class ClassName &#123; public void method() &#123; synchronized(ClassName.class) &#123; // todo &#125; &#125;&#125; 另外需要注意的一点是： synchronized具有锁重入功能，也就是说一个线程获得锁，再次请求是可以再次得到对象的锁的 。关于这部分的具体实验，可参考这篇博客。 2 Synchronized原理 2.1 加/释放锁原理 123456789101112public class SynchronizedDemo2 &#123; Object object = new Object(); public void method1() &#123; synchronized (object) &#123; &#125; method2(); &#125; private static void method2() &#123; &#125;&#125; 将上述代码用javac编译生成.class文件后，使用javap反编译查看.class文件信息如下： 可以看出synchronized的底层原理在于monitorenter和monitorexit两条指令。 Monitorenter和Monitorexit指令可以让被执行对象的锁计数器加1或者减1。 每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一： monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加 这把锁已经被别的线程获取了，等待锁释放 monitorexit指令：释放对于monitor的所有权，释放过程很简单，就是将monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。 2.2 可重入原理 上面的demo中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗? 答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条monitorexit指令，并没有monitorenter获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。 Synchronized先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加1，释放锁后就会将计数器减1。 2.3 可见性原理 synchronized规定，线程在加锁时，先清空工作内存→在主内存中拷贝最新变量的副本到工作内存→执行完代码→将更改后的共享变量的值刷新到主内存中→释放互斥锁。 3 锁升级 3.1 为什么要锁升级 通过前面的介绍，我们知道Synchronized依赖于monitor，而monitor依赖于底层操作系统的mutex lock来实现，因此需要从用户态切换到内核态，而这一操作是重量级的。 在JDK1.5之前，synchronized是重量级锁，1.6以后对其进行了优化，有了一个 无锁–&gt;偏向锁–&gt;自旋锁–&gt;重量级锁 的锁升级的过程，而不是一上来就是重量级锁了，为什么呢？因为重量级锁获取锁和释放锁需要经过操作系统，是一个重量级的操作。对于重量锁来说，一旦线程获取失败，就要陷入阻塞状态，并且是操作系统层面的阻塞，这个过程涉及用户态到核心态的切换，是一个开销非常大的操作。而研究表明，线程持有锁的时间是比较短暂的，也就是说，当前线程即使现在获取锁失败，但可能很快地将来就能够获取到锁，这种情况下将线程挂起是很不划算的行为。所以要对&quot;synchronized总是启用重量级锁&quot;这个机制进行优化。 3.2 锁升级原理 在Java虚拟机中，普通对象在内存中分为三块区域：对象头、实例数据、对齐填充数据（数组对象比普通对象在对象头位置多一个数组长度）。 对象头：包括markword（8字节）和类型指针（开启压缩指针4字节，不开启8字节，如果是32g以上内存，都是8字节） 实例数据：就是对象的成员变量 padding：就是为了保证对象的大小为8字节的倍数，将对象所占字节数补到能被8整除。 和锁相关的信息就存储在对象头中。 64位HotSpot JVM中，如下图所示，不同锁状态下，对象头存储不同的信息： 目前锁状态一种有四种，从级别由低到高依次是：无锁、偏向锁，轻量级锁，重量级锁，锁状态只能升级，不能降级。 下图总结了锁状态变化路线图： 可以看到上图多了一个“匿名偏向锁”： 什么是匿名偏向锁？ 匿名偏向锁，就是不偏向任何线程的偏向锁。JVM中有一个启动参数-XX:BiasedLockingStartupDelay，表示延时启动偏向锁的时间。即如果在延时时间内创建的对象，会进入无锁状态，延时时间外创建的对象处于匿名偏向锁状态。 为什么要有它？ JVM 内部的代码有很多地方用到了synchronized，如果直接开启偏向，产生竞争就要有锁升级，会带来额外的性能损耗，所以就有了延迟策略 ，这样启动后立刻创建的对象处于无锁状态，产生竞争后，直接进入轻量级锁，不使用偏向锁。 3.3 无锁状态 无锁状态，标志位为 0 01，此时对象没有任何同步限制。 3.4 偏向锁 偏向锁状态，标志位为1 01。 3.4.1 为什么要有偏向锁 有研究表明，其实在大部分场景都不会发生锁资源竞争，并且锁资源往往都是由一个线程获得的。如果这种情况下，同一个线程获取这个锁都需要进行一系列操作，比如说CAS自旋，那这个操作很明显是多余的。偏向锁就解决了这个问题。其核心思想就是：一个线程获取到了锁，那么锁就会进入偏向模式，当同一个线程再次请求该锁的时候，无需做任何同步，直接进行同步区域执行。这样就省去了大量有关锁申请的操作。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果。 3.4.2 偏向撤销 在了解偏向锁之前，需要先了解下偏向撤销的概念。可以参考这个 偏向锁撤销和偏向锁释放是两码事 撤销：笼统的说就是多个线程竞争导致不能再使用偏向模式的时候，主要是告知这个锁对象不能再用偏向模式 释放：和你的常规理解一样，对应的就是 synchronized 方法的退出或 synchronized 块的结束 如果只是一个线程获取锁，再加上「偏心」的机制，是没有理由撤销偏向的，所以偏向的撤销只能发生在有竞争的情况下。 想要撤销偏向锁，还不能对持有偏向锁的线程有影响，所以就要等待持有偏向锁的线程到达一个 safepoint 安全点 (这里的安全点是 JVM 为了保证在垃圾回收的过程中引用关系不会发生变化设置的一种安全状态，在这个状态上会暂停所有线程工作)， 在这个安全点会挂起获得偏向锁的线程。 在这个安全点，线程可能还是处在不同状态的，先说结论（因为源码就是这么写的，可能有疑惑的地方会在后面解释） 线程不存活或者活着的线程但退出了同步块，很简单，直接撤销偏向就好了 活着的线程但仍在同步块之内，那就要升级成轻量级锁 这个和 epoch 貌似还是没啥关系，因为这还不是全部场景。偏向锁是特定场景下提升程序效率的方案，可并不代表程序员写的程序都满足这些特定场景，比如这些场景（在开启偏向锁的前提下）： 一个线程创建了大量对象并执行了初始的同步操作，之后在另一个线程中将这些对象作为锁进行之后的操作。这种case下，会导致大量的偏向锁撤销操作 明知有多线程竞争（生产者/消费者队列），还要使用偏向锁，也会导致各种撤销 很显然，这两种场景肯定会导致偏向撤销的，一个偏向撤销的成本无所谓，大量偏向撤销的成本是不能忽视的。那怎么办？既不想禁用偏向锁，还不想忍受大量撤销偏向增加的成本，JVM为我们提供了两重底线：批量重偏向和批量撤销，主要这两个措施是针对类的，而不是对象。 1、批量重偏向和批量撤销是针对类的优化，和对象无关，对象进入轻量级锁后，就不会再使用偏向锁了。 2、偏向锁重偏向一次之后不可再次重偏向。 3、当某个类已经触发批量撤销机制后，JVM会默认当前类产生了严重的问题，剥夺了该类的新实例对象使用偏向锁的权利 一、批量重偏向 重偏向：重新换个线程偏向。 对于某个类，在A线程中创建了100个对象然后，并进入同步代码块，完成任务后退出。在B线程中，如果分别使用那100个对象进入临界区，因为此时这100个对象都是偏向A线程的，那么这100次操作都是直接获取轻量级锁，这会造成很多额外开销。 如果设置重偏向阈值为20，那么对比B线程前19次操作都是获取轻量级锁，第20次发生重偏向，开始使用偏向锁。 这是第一种场景的快速解决方案， 以 class 为单位，为每个 class 维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器 +1，当这个值达到重偏向阈值（默认20）时： 这是第一种场景的快速解决方案，以 class 为单位，为每个 class 维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器 +1，当这个值达到重偏向阈值（默认20）时： 1BiasedLockingBulkRebiasThreshold = 20 JVM 就认为该class的偏向锁有问题，因此会进行批量重偏向, 它的实现方式就用到了我们上面说的 epoch。 每个 class 对象会有一个对应的epoch字段，每个处于偏向锁状态对象的mark word 中也有该字段，其初始值为创建该对象时 class 中的epoch的值（此时二者是相等的）。每次发生批量重偏向时，就将该值加1，同时遍历JVM中所有线程的栈 找到该 class 所有正处于加锁状态的偏向锁对象，将其epoch字段改为新值 class 中不处于加锁状态的偏向锁对象（没被任何线程持有，但之前是被线程持有过的，这种锁对象的 markword 肯定也是有偏向的），保持 epoch 字段值不变 这样下次获得锁时，发现当前对象的epoch值和class的epoch不同，本着今朝不问前朝事 的原则（上一个纪元），那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过 CAS 操作将其mark word的线程 ID 改成当前线程 ID，这也算是一定程度的优化，毕竟没升级锁； 如果 epoch 都一样，说明没有发生过批量重偏向, 如果 markword 有线程ID，还有其他锁来竞争，那锁自然是要升级的(如同前面举的例子 epoch=0)。 批量重偏向是第一阶梯底线，还有第二阶梯底线 二、 批量撤销 当达到重偏向阈值后，假设该 class 计数器继续增长，当其达到批量撤销的阈值后（默认40）时， 1BiasedLockingBulkRevokeThreshold = 40 JVM就认为该 class 的使用场景存在多线程竞争，会标记该 class 为不可偏向。之后对于该 class 的锁，直接走轻量级锁的逻辑 这就是第二阶梯底线，但是在第一阶梯到第二阶梯的过渡过程中，也就是在彻底禁用偏向锁之前，还给一次改过自新的机会，那就是另外一个计时器： 1BiasedLockingDecayTime = 25000 如果在距离上次批量重偏向发生的 25 秒之内，并且累计撤销计数达到40，就会发生批量撤销（偏向锁彻底 game over） 如果在距离上次批量重偏向发生超过 25 秒之外，那么就会重置在 [20, 40) 内的计数, 再给次机会 大家有兴趣可以写代码测试一下临界点，观察锁对象 markword 的变化。 至此，整个偏向锁的工作流程可以用一张图表示： 下面看一个例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public static void main(String[] args) throws Exception &#123; //延时产生可偏向对象 Thread.sleep(5000); //创造100个偏向线程t1的偏向锁 List&lt;MyThread&gt; listA = new ArrayList&lt;&gt;(); Thread t1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt;100 ; i++) &#123; MyThread a = new MyThread(); synchronized (a)&#123; listA.add(a); &#125; &#125; try &#123; //为了防止JVM线程复用，在创建完对象后，保持线程t1状态为存活 Thread.sleep(100000000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); //睡眠3s钟保证线程t1创建对象完成 Thread.sleep(3000); System.out.println(&quot;打印t1线程，list中第20个对象的对象头：&quot;); System.out.println((ClassLayout.parseInstance(listA.get(19)).toPrintable())); //创建线程t2竞争线程t1中已经退出同步块的锁 Thread t2 = new Thread(() -&gt; &#123; //这里面只循环了40次！！！ for (int i = 0; i &lt; 40; i++) &#123; MyThread a =listA.get(i); synchronized (a)&#123; //分别打印第19次和第20次偏向锁重偏向结果 if(i==18||i==19)&#123; System.out.println(&quot;第&quot;+ ( i + 1) + &quot;次偏向结果&quot;); System.out.println((ClassLayout.parseInstance(a).toPrintable())); &#125; &#125; &#125; try &#123; Thread.sleep(10000000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); t2.start(); Thread.sleep(3000); System.out.println(&quot;打印list中第11个对象的对象头：&quot;); System.out.println((ClassLayout.parseInstance(listA.get(10)).toPrintable())); System.out.println(&quot;打印list中第26个对象的对象头：&quot;); System.out.println((ClassLayout.parseInstance(listA.get(25)).toPrintable())); System.out.println(&quot;打印list中第41个对象的对象头：&quot;); System.out.println((ClassLayout.parseInstance(listA.get(40)).toPrintable())); Thread t3 = new Thread(() -&gt; &#123; for (int i = 20; i &lt; 40; i++) &#123; MyThread a =listA.get(i); synchronized (a)&#123; if(i==20||i==22)&#123; System.out.println(&quot;thread3 第&quot;+ i + &quot;次&quot;); System.out.println((ClassLayout.parseInstance(a).toPrintable())); &#125; &#125; &#125; &#125;); t3.start(); Thread.sleep(10000); System.out.println(&quot;重新输出新实例A&quot;); System.out.println((ClassLayout.parseInstance(new MyThread()).toPrintable()));&#125; 总结一下就是： 一开始100个对象偏向线程1，线程2中前19次执行，直接出发轻量级锁，到第20次，达到阈值，触发重偏向，第20~40个对象，发生重偏向，重新偏向线程2。在线程3中，由于达到阈值40，因此发生批量撤销，不会再次重偏向到线程3，而是直接触发轻量级锁。 3.4.3 偏向锁适用场景 使用与不常发生锁竞争的场景。 始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁。在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向锁的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。所以一般JVM并不是一开始就开启偏向锁的，而是有一定的延迟，这也就是为什么会有无锁态的原因。可以使用-XX:BiasedLockingStartupDelay=0来关闭偏向锁的启动延迟, 也可以使用-XX:-UseBiasedLocking=false来关闭偏向锁。 3.5 轻量级锁 当有另外一个线程竞争获取这个锁时，由于该锁已经是偏向锁，当发现对象头 Mark Word 中的线程 ID 不是自己的线程 ID，销偏向锁状态，将锁对象markWord中62位修改成指向自己线程栈中Lock Record的指针（CAS抢）执行在用户态，消耗CPU的资源（自旋锁不适合锁定时间长的场景、等待线程特别多的场景），此时锁标志位为：00。 3.5.1 自适策略 JVM 提供了一种自旋锁，可以通过自旋方式不断尝试获取锁，从而避免线程被挂起阻塞。这是基于大多数情况下，线程持有锁的时间都不会太长，毕竟线程被挂起阻塞可能会得不偿失。 JDK 1.6引入了更加聪明的自旋锁，叫做自适应自旋锁。他的自旋次数是会变的，我用大白话来讲一下，就是线程如果上次自旋成功了，那么这次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么这次自旋也很有可能会再次成功。反之，如果某个锁很少有自旋成功，那么以后的自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 3.5.2 加锁过程 在代码进入同步块的时候： 如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。 拷贝对象头中的Mark Word复制到锁记录中； 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word中的62位更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态。 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。此时为了提高获取锁的效率，线程会不断地循环去获取锁, 这个循环是有次数限制的。 如果在循环结束之前CAS操作成功, 那么线程就获取到锁, 如果循环结束依然获取不到锁, 则获取锁失败, 对象的MarkWord中的记录会被修改为指向互斥量（重量级锁）的指针，锁标志的状态值变为10，线程被挂起，后面来的线程也会直接被挂起。 3.5.3 释放锁 释放锁线程视角： 由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。因为重量级锁被修改了，所有display mark word和原来的markword不一样了。 怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。 尝试获取锁线程视角： 如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。 从 JDK1.7 开始，自旋锁默认启用，自旋次数由 JVM 设置决定，这里我不建议设置的重试次数过多，因为 CAS 重试操作意味着长时间地占用 CPU。自旋锁重试之后如果抢锁依然失败，同步锁就会升级至重量级锁，锁标志位改为 10。在这个状态下，未抢到锁的线程都会进入 Monitor，之后会被阻塞在 _WaitSet 队列中。 3.6 重量级锁 此时锁标志位为：10。前面我们提到的markWord，若是重量锁，对象头中还会存在一个监视器对象，也就是Monitor对象。这个Monitor对象就是实现synchronized的一个关键。 在Java虚拟机(HotSpot)中，Monitor对象其实就是ObjectMonitor对象，这个对象是一个C++对象，定义在虚拟机源码中。 ObjectMonitor有比较多的属性，但是比较重要的属性有四个： _count：计数器。用来记录获取锁的次数。该属性主要用来实现重入锁机制。 owner：记录着当前锁对象的持有者线程。 _WaitSet：队列。当一个线程调用了wait方法后，它会释放锁资源，进入WaitSet队列等待被唤醒。 EntryList：队列。里面存放着所有申请该锁对象的线程。 所以一个线程获取锁对象的流程如下： 判断锁对象的锁标志位是重量级锁，于是想要获取Monitor对象锁。 如果Monitor中的_ count属性是0，说明当前锁可用，于是把 _ owner 属性设置为本线程，然后把 _ count 属性+1。这就成功地完成了锁的获取。 如果Monitor中的_count属性不为0，再检查 _owner 属性，如果该属性指向了本线程，说明可以重入锁，于是把 _count 属性再加上1，实现锁的重入。 如果 _owner 属性指向了其他线程，那么该线程进入 _EntryList 队列中等待锁资源的释放。 如果线程在持有锁的过程中调用了wait()方法，那么线程释放锁对象，然后进入 _WaitSet 队列中等待被唤醒。 3.7 Hashcode哪儿去了 从前文我们知道，只有无锁状态下，对象头才会存储hashcode。在其他状态下，我们要获取hashcode值该怎么办呢？ 首先要知道，hashcode 不是创建对象就帮我们写到对象头中的，而是要经过第一次调用 Object::hashCode() 或者System::identityHashCode(Object) 才会存储在对象头中的。第一次生成的 hashcode后，该值应该是一直保持不变的，但偏向锁又是来回更改锁对象的 markword，必定会对 hashcode 的生成有影响，那怎么办呢？ 即便初始化为可偏向状态的对象，一旦调用 Object::hashCode() 或者System::identityHashCode(Object) ，进入同步块就会直接使用轻量级锁 已经生成hashcode，进入同步代码块，直接使用轻量级锁 如果对象处在已偏向状态，生成 hashcode 后，就会直接升级成重量级锁 wait 方法是互斥量（重量级锁）独有的，一旦调用该方法，就会升级成重量级锁（这个是面试可以说出的亮点内容哦） 轻量级锁： 获取锁后，会在栈帧中创建一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。释放锁后再将其换回去。 重量级锁： ObjectMonitor类里有字段可以记录非加锁状态下的mark word，其中可以存储identity hash code的值 4 锁优化 以上介绍的锁不是我们代码中能够控制的，但是借鉴上面的思想，我们可以优化我们自己线程的加锁操作。 锁消除 锁消除用大白话来讲，就是在一段程序里你用了锁，但是jvm检测到这段程序里不存在共享数据竞争问题，也就是变量没有逃逸出方法外，这个时候jvm就会把这个锁消除掉 我们程序员写代码的时候自然是知道哪里需要上锁，哪里不需要，但是有时候我们虽然没有显示使用锁，但是我们不小心使了一些线程安全的API时，如StringBuffer、Vector、HashTable等，这个时候会隐形的加锁。 减少锁的时间 不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放 减小锁的粒度 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间（如ConcurrentHashMap、LinkedBlockingQueue、LongAdder）； 锁粗化 大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度; 在以下场景下需要粗化锁的粒度： 假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的； 使用读写锁 ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写。 参考资料 https://segmentfault.com/a/1190000039755370 https://blog.csdn.net/weixin_40910372/article/details/107726978 https://segmentfault.com/a/1190000041194920 https://www.cnblogs.com/LemonFive/p/11248248.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"初识Java多线程编程","slug":"2 后端/Java/Java并发/1 初识Java多线程编程","date":"2022-02-02T14:34:49.000Z","updated":"2022-06-11T13:06:14.884Z","comments":true,"path":"b8b0651f57b7/","link":"","permalink":"http://rookieyin.github.io/b8b0651f57b7/","excerpt":"本文主要介绍下线程的相关概念，以及Java中关于多线程的标准类库java.lang.Thread的相关知识。 我们知道进程是程序的运行实例，当我们在操作系统上运行一个程序时，相当于新建了一个进程。那线程是什么呢？线程是操作系统能够进行运算调度的最小单位，一个进程可以包含多个线程。 线程和进程的区别如下： 进程是程序向操作系统申请资源（如内存空间和文件句柄）的基本单位。线程（Thread）是进程中可独立执行的最小单位。 一个进程可以包含多个线程。 同一个进程中的所有线程共享该进程中的资源，如内存空间、文件句柄等。","text":"本文主要介绍下线程的相关概念，以及Java中关于多线程的标准类库java.lang.Thread的相关知识。 我们知道进程是程序的运行实例，当我们在操作系统上运行一个程序时，相当于新建了一个进程。那线程是什么呢？线程是操作系统能够进行运算调度的最小单位，一个进程可以包含多个线程。 线程和进程的区别如下： 进程是程序向操作系统申请资源（如内存空间和文件句柄）的基本单位。线程（Thread）是进程中可独立执行的最小单位。 一个进程可以包含多个线程。 同一个进程中的所有线程共享该进程中的资源，如内存空间、文件句柄等。 Java中的Thread java标准库类java.lang.Thread就是java平台对多线程的实现。Thread类或者其子类的一个实例就是一个线程。 线程的创建、启动与运行 创建：在java中创建一个线程就是要创建一个Thread类（或其子类）的一个实例 Thread类有两个常用构造器：Thread()和Thread(Runnable target)。因此创建线程的方式有两种： 定义Thread类的子类：在子类中Override run方法，并实现线程任务处理逻辑； 创建一个Runnable接口：new Thread(new RunnableImp())方式创建线程。 1234567891011121314// 定义Thread类的子类class WelcomeThread extends Thread &#123; @Override public void run() &#123; &#125;&#125;Thread t0 = new WelcomeThread();//实现Runnable接口class WelcomeTask implements Runnable &#123; @Override public void run() &#123; &#125;&#125;Thread t1 = new Thread(new WelcomTask()); 从OOP角度来看，第一种方式基于继承技术，第二种方式基于组合技术。组合的耦合度低于继承，因此大多数情况下我们使用第二种方式创建线程。不过需要注意的一点是：使用组合方式创建线程，多个线程实例会共享同一个Runnable实例。 启动：要启动线程，需要调用Thread类中的run方法 调用Thread.start()方法即可启动线程，需要注意的是，启动线程后，线程可能不会立即执行，具体什么时候执行由线程调度器决定。 运行：线程具体何时能够运行是由线程调度器决定的 一旦线程的run方法执行完毕，相应的线程的运行也就结束了。虽然线程的run方法总是由Java虚拟机直接调用的，Java语言并不阻止我们直接通过Thread实例调用run方法。但是，多数情况下我们不能这样做，因为这样做有违创建线程（对象）的初衷。 Thread类中的属性 线程的属性包括线程的编号（ID）、名称（Name）、线程类别（Daemon）和优先级（Priority），详情如下表所示： 属性 属性类型及用途 只读属性 重要注意事项 编号（ID） long，用于表示不同线程，不同线程编号不同。 是 线程结束后，该线程的编号可能被其他后建线程使用。 名称（Name） String，面向人，默认值与线程的编号有关，默认格式为：“Thread-线程编号”。 否 Java不禁止不同线程有相同的名称，但是为了便于调试，线程应当合理取名。 线程类别（Daemon） boolean，true表示为守护线程，否则为用户线程，默认值继承自父线程。 否 该属性必须在线程启动之前设置，启动后修改该属性会抛出异常。 优先级（Priority） int，给线程调度器用的。Java定义了 1~10优先级，一般默认为5。对于具体线程而言，其优先级的默认值与父线程相同。 否 一般使用默认优先级即可，设置不当可能出现问题。 守护线程？用户线程？ 所谓守护线程，是指在程序运行的时候在后台提供一种通用服务的线程，比如垃圾回收线程就是一个很称职的守护者，并且这种线程并不属于程序中不可或缺的部分。 两者的区别在于： 如果用户线程已经全部退出运行了，只剩下守护线程存在了，虚拟机也就退出了。因为没有了被守护者，守护线程也就没有工作可做了，也就没有继续运行程序的必要了。 Thread类中的常用方法 下表列出了Thread中的常用方法API： 方法 功能 备注 static Thread currentThread() 返回当前线程，即当前代码的执行线程 同一段代码调用该方法，返回值可能对应不同线程。 void run() 用于实现线程的任务处理逻辑 有Java虚拟机直接调用，用户一般不应该调用。 void start() 启动相应线程 一个Thread实例，只能调用一次start方法，多次调用会抛出异常。 void join() 等待相应线程运行结束 若线程A调用线程B的join方法，那么线程A的运行会被暂停，直到线程B运行结束。 static void yield() 使当前线程主动放弃对处理器的占用 这个方法是不可靠的。该方法被调用时当前线程可能仍然继续运行（视系统当前的运行状况而定） static void sleep(long millis) 使当前线程休眠指定时间 线程进阶 线程的层次关系 Java中的线程并不是孤立的，线程与线程之间总是存在一些联系。假设线程A所执行的代码创建了线程B，那么，习惯上我们称线程B为线程A的子线程， 相应地线程A就被称为线程B的父线程。 当然，子线程所执行的代码中也可以创建其他线程，因此一个子线程也可以是其他线程的父线程。线程的这种父子关系就被称为线程的层次关系。下面我们总结了java中父子线程之间存在的一些关联： 一个线程是否是守护线程，默认和其父线程一样。 一个线程的默认优先级和其父进程一样。 java平台没有提供API用于获取一个线程的父线程，或者获取一个线程的所有子线程。 父子线程之间的运行周期没有必然的联系。比如父线程运行结束，子线程可以继续运行。 线程的生命周期 一个线程从其创建、启动到其运行结束的整个生命周期可能经历若干状态，如下图所示： Java线程的状态可以使用监控工具查看，也可以通过Thread.getState()调用来获取。Thread.getState() 的返回值类型Thread.State 是一个枚举类型（ Enum ） 。Thread.State所定义的线程状态包括以下几种： NEW：一个创建而未启动的线程所处的状态。 RUNNABLE：该状态包含两个子状态：READY和RUNNING。前者表示线程可以被线程调度器进行调度而转变为RUNNING状态。后者表示线程正在运行。 BLOCKED：一个线程发起一个阻塞式IO操作后，或者申请一个由其他线程持有的独占资源（比如锁）时，相应的线程会处于该状态。 WAITING：一个线程执行了某些特定方法之后就会处于这种等待其他线程执行另外一些特定操作的状态。能够使其执行线程变更为WAITING 状态的方法包括：Object.wait() 、Thread.join() 和LockSupport.park(Object) 。能够使相应线程从 WAITING 变更为RUNNABLE 的相应方法包括： Object.notify()/notifyAll() 和LockSupport.unpark(Object))。 TIMED_WAITING：该状态和WAITING类似，差别在于处于该状态的线程并非无限制地等待其他线程执行特定操作，而是处于带有时间限制的等待状态。当其他线程没有在指定时间内执行该线程所期望的特定操作时，该线程的状态自动转换为RUNNABLE。 TERMINATED：已经执行结束的线程处于该状态。 Java线程 VS 操作系统线程 操作系统中进程（线程）的状态有： 初始状态（NEW) 可运行状态（READY） 对应 Java中的 RUNNBALE 状态 运行状态（RUNNING) 对应 Java中的 RUNNBALE 状态 等待状态（WAITING) 该状态在 Java中被划分为了 BLOCKED，WAITING，TIMED_WAITING 三种状态 当线程调用阻塞式 API时，进程(线程)进入等待状态，这里指的是操作系统层面的。从 JVM层面来说，Java线程仍然处于 RUNNABLE 状态。 JVM 并不关心操作系统线程的实际状态，从 JVM 看来，等待CPU使用权（操作系统状态为可运行态）与等待 I/O（操作系统处于等待状态）没有区别，都是在等待某种资源，所以都归入RUNNABLE 状态 终止状态 （TERMINATED） 下面是几个常见问题： Java线程有几种状态： 六种而不是五种容易漏掉TIMEWAITING状态，操作系统线程状态可以说是五种也可以说三种（排除新建和终止） 线程sleep之后处于什么状态：timewaiting A线程被sychnolozy锁阻塞了，B线程被lock锁阻塞了 AB两个线程是否处于相同状态是什么状态： sych锁是blocked状态，blocked状态只能从sych锁进入无其他方式 lock锁的阻塞是waiting或timewaiting状态 当java线程发生IO阻塞时 线程处于什么状态： rannable状态，当io阻塞时一定处于操作系统线程状态的waiting状态，操作系统的waiting状态的定义是：表示线程等待（或者说挂起），让出CPU资源给其他线程使用。java线程中 waiting、timewaiting、blocked都必然处于操作系统线程waiting状态、rannable则有可能处于waiting状态（调用阻塞式API）。IO阻塞在java的定义中就是rannable状态只不过让出了cpu资源。 多线程编程中的挑战 多线程的目的在于将原本的串行计算改为并发乃至并行计算，提高程序运行效率。但是，在多线程编程中也存在很多挑战，下面对这些挑战进行简单介绍。 竞态 什么是竞态？竞态指多个线程共享某一资源，导致计算结果有时正确，有时错误的现象。 导致竞态的常见因素是多个线程在没有采取任何控制措施的情况下并发地更新、读取同一个共享变量。 竞态具有两种模式：read-modify-write(读-写-写)和check-then-act(检测后行动)。 read-modify-write：先读取共享变量的值，然后根据读到的数据作一些计算，接着更新共享变量的值。比如我们常见的“i++”c操作包含三条指令。 check-then-act：读取某个共享变量的值， 根据该变量的值决定下一步的动作是什么。 原子性 原子（Atomic）的字面意思是不可分割的（Indivisible）。在多线程编程中，对于涉及共享变量访问的操作，若该操作从其执行线程以外的任意线程来看是不可分割的，那么该操作就是原子操作，相应地我们称该操作具有原子性 （Atomicity）。 所谓“不可分割”，这里有两层含义： 其中一个含义是指访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未发生，即其他线程不会“看到”该操作执行了部分的中间效果。 访问同一组共享变量的原子操作是不能够被交错的。 Java中有两种方式来实现原子性： 锁：锁具有排他性，可以保证同一时间只能有一个线程访问共享变量。 CAS：其实现方式与锁本质上是相同的，差别在于锁通常在软件这一层实现的，而CAS是直接在硬件这一层次实现的。 CAS是一种乐观锁，通过CPU指令实现，可以以无锁+循环方式实现原子性读写操作。 CAS有三个操作数，旧值A，新值B，以及需要读取的内存值V，在更新一个变量时，当且仅当A=V相同时，CAS才会将内存值V修改为B，否则什么都不做。 其优点是，相比较重量级锁synchronized，它性能更高，是轻量级的乐观锁。但是也有缺点： ABA问题： 线程C、D；线程D将A修改为B后又修改为A，此时C线程以为A没有改变过，java的原子类AtomicStampedReference，通过控制变量值的版本号来保证CAS的正确性。 自旋时间过长： 如果资源竞争激烈，多线程自旋长时间消耗资源。 只能保证一个变量的原子操作。 在Java中除了long和double外的所有其他基本类型的写操作都是原子的，对于任何变量的读操作都是原子的。 可见性 在多线程环境下，一个线程对某个共享变量进行更新之后，后续访问该变量的线程可能无法立刻读取到这个更新的结果，甚至永远也无法读取到这个更新的结果。这就是线程安全问题的另外一个表现形式：可见性（Visibility）。 并发编程下，导致可见性问题的原因来自两方面：第一个是JIT编译器优化；第二个是计算机的存储系统。 编译器优化导致不可见 看下面一个可见性的例子：启动一个线程，如果10秒钟后线程没有执行完，调用cancel（）方法取消线程。 1234567891011121314151617181920212223242526272829303132333435363738public class VisibilityDemo &#123; public static void main(String[] args) throws InterruptedException &#123; TimeConsumingTask timeConsumingTask = new TimeConsumingTask(); Thread thread = new Thread(new TimeConsumingTask()); thread.start(); // 指定的时间内任务没有执行结束的话，就将其取消 Thread.sleep(10000); timeConsumingTask.cancel(); &#125;&#125;class TimeConsumingTask implements Runnable &#123; private boolean toCancel = false; @Override public void run() &#123; while (! toCancel) &#123; if (doExecute()) &#123; break; &#125; &#125; if (toCancel) &#123; System.out.println(&quot;Task was canceled.&quot;); &#125; else &#123; System.out.println(&quot;Task done.&quot;); &#125; &#125; private boolean doExecute() &#123; boolean isDone = false; System.out.println(&quot;executing...&quot;); // 模拟实际操作的时间消耗 Tools.randomPause(50); // 省略其他代码 return isDone; &#125; public void cancel() &#123; toCancel = true; System.out.println(this + &quot; canceled.&quot;); &#125;&#125; 上述代码的运行结果可能是：线程一直在运行，没有打印“Task is canceled”。这种现象只有一种解释，那就是子线程thread所 读取到的toCancel变量值始终是false，尽管某个时刻main线程会将共享变量toCancel的值更新为true。可见，这里产生了可见性问题，即main线程对共享变量toCancel的更新对子线程thread而言不可见。 上述例子中的可见性问题是因为代码没有给JIT编译器足够的提示而使得其认为状态变量toCancel只有一个线程对其进行访问，从而导致JIT编译器为了避免重复读取状态变量toCancel以提高代码的运行效率，而将TimeConsumingTask的run方法中的while循环优化成与如下代码等效的本地代码（机器码）： 1234567if (! toCancel) &#123; while (true) &#123; if (doExecute()) &#123; break; &#125; &#125;&#125; 不幸的是，此时这种优化导致了死循环，也就是我们所看到的程序一直运行而没有退出。 存储系统导致不可见 每个处理器都有其寄存器，而一个处理器无法读取另外一个处理器上的寄存器中的内容。因此，如果两个线程分别运行在不同的处理器上，而这两个线程所共享的变量却被分配到寄存器上进行存储，那么可见性问题就会产生。 另外，即便某个共享变量是被分配到主内存中进行存储的，也不能保证该变量的可见性。这是因为处理器对主内存的访问并不是直接访问，而是通过其高速缓存（Cache）子系统进行的。一个处理器上运行的线程对变量的更新可能只是更新到该处理器的写缓冲器（Store Buffer）中，还没有到达该处理器的高速缓存中，更不用说到主内存中了。而一个处理器的写缓冲器中的内容无法被另外一个处理器读取，因此运行在另外一个处理器上的线程无法看到这个线程对某个共享变量的更新。 有序性 有序性是指程序按照代码的先后顺序执行。但是一方面编译器在编译代码的时候，为了优化性能有时候会改变程序中语句的先后顺序。另一方面，处理器在执行指令的时候也有可能进行指令重排序。 在单线程场景中，这种重排序不会导致程序运行结果的变化，但是在多线程场景中，重排序可能给程序带来意向不到的错误。 我们可以将重排序划分成两类，如下表所示： 指令重排序 主要发生在三个地方：javac编译生成字节码文件，JIT编译字节码生成机器码，以及处理器执行机器码。一般重排序导致程序出错的概率很小，但是一旦出错，可能造成很大影响。 存储子系统重排序（又叫内存重排序） 主存相对于处理器是一个慢速设备，为了提高效率，处理器并不是直接访问主内存，而是通过高速缓存（Cache）访问主内存的，并且引入了写缓冲器以提高写告诉缓存操作的效率。这里将高速缓存和写缓冲器称之为存储子系统。 存储子系统重排序是指：它是一种现象而不是一种动作，它并没有真正对指令执行顺序进行调整，而只是造成了一种指令的执行顺序像是被调整过一样的现象，其重排序的对象是内存操作的结果，因此又叫“内存重排序”。 从处理器的角度来说，读内存操作的实质是从指定的RAM地址加载数据（通过高速缓存加载）到寄存器，因此读内存操作通常被称为Load，写内存操作的实质是将数据（可能作为操作数直接存储在指令中，也可能存储在寄存器中）存储到指定地址表示的RAM存储单元中，因此写内存操作通常被称为Store。所以，内存重排序实际上只有以下4种可能： 重排序类型 含义 LoadLoad重排序（Loads reordered after loads） 该重排序指一个处理器上先后执行两个读内存操作L1和L2，其他处理器对这两个内存操作的感知顺序可能是L2→L1 [10] ，即L1被重排序到L2之后 StoreStore重排序（Stores reordered after stores） 该重排序指一个处理器上先后执行两个写内存操作W1和W2，其他处理器对这两个内存操作的感知顺序可能是W2→W1，即W1被重排序到W2之后 StoreStore重排序（Stores reordered after stores） 该重排序指一个处理器上先后执行读内存操作L1和写内存操作W2，其他处理器对这两个内存操作的感知顺序可能是W2→L1，即L1被重排序到W2之后 StoreLoad重排序（Stores reordered after loads） 该重排序指一个处理器上先后执行写内存操作W1和读内存操作L2，其他处理器对这两个内存操作的感知顺序可能是L2→W1，即W1被重排序到L2之后 上下文切换 概念 上下文切换（Context Switch）在某种程度上可以被看作多个线程共享同一个处理器的产物 [12] ，它是多线程编程中的一个重要概念。 单处理器上的多线程其实就是通过这种时间片分配的方式实现的。时间片决定了一个线程可以连续占用处理器运行的时间长度。当一个进程中的一个线程由于其时间片用完或者其自身的原因（比如，它需要稍后再继续运行）被迫或者主动暂停其运行时，另外一个线程（可能是同一个进程或者其他进程中的一个线程）可以被操作系统（线程调度器）选中占用处理器开始或者继续其运行。这种一个线程被暂停，即被剥夺处理器的使用权，另外一个线程被选中开始或者继续运行的过程就叫作线程上下文切换 。 从Java应用的角度来看，一个线程的生命周期状态在RUNNABLE状态与非RUNNABLE状态（包括BLOCKED、WAITING和TIMED_WAITING中的任意一个子状态）之间切换的过程就是一个上下文切换的过程。当一个线程的生命周期状态由RUNNABLE转换为非RUNNABLE时，我们称这个线程被暂停 。线程的暂停就是相应线程被切出的过程，这里操作系统会保存相应线程的上下 文，以便该线程稍后再次进入RUNNABLE状态时能够在之前执行进度的基础上进展。而一个线程的生命周期状态由非RUNNABLE 状态进入RUNNABLE 状态时， 我们就称这个线程被唤醒（Wakeup）。一个线程被唤醒仅代表该线程获得了一个继续运行的机会，而并不代表其立刻可以占用处理器运行。 分类 按照导致上下文切换的因素进行划分，可以将上下文切换分为自发性上下文切换和非自发性上下文切换。 自发性上下文切换 从Java平台的角度来看，一个线程在其运行过程中执行下列任意一个方法都会引起自发性上下文切换：Thread.sleep，Object.wait()/wait(long timeout)/wait(long timeout, int nanos)，Thread.yield ()，Thread.join()/Thread.join(long timeout)，LockSupport.park ()。 线程发起了I/O操作（如读取文件）或者等待其他线程持有的锁也会导致自发性上下文切换。 非自发性上下文切换 非自发性上下文切换 指线程由于线程调度器的原因被迫切出。导致非自发性上下文切换的常见因素包括被切出线程的时间片用完或者有一个比被切出线程优先级更高的线程需要被运行。 比如JVM中的垃圾会收可能导致非自发性上下文切换。 活性故障 由资源稀缺性或者程序自身的问题和缺陷导致线程一直处于非RUNNABLE状态，或者线程虽然处于RUNNABLE状态但是其要执行的任务却一直无法进展的现象就被称为线程活性故障。常见的活性故障包括以下几种： 死锁：死锁产生的典型场景是一个线程X持有资源A的时候等待另外一个线程释放资源B，而另外一个线程Y在持有资源B的时 候却等待线程X释放资源A。最终导致两个线程都处于非RUNNABLE状态。 锁死：锁死就好比睡美人的故事中睡美人醒来的前提是她要得到王子的亲吻，但是如果王子无法亲吻她（比如王子“挂了”……），那么睡美人将一直沉睡！ 活锁：活锁好比小猫试图咬自己的尾巴，虽然它总是追着自己的尾巴咬，但却始终无法咬到。活锁的外在表现是线程可能处于RUNNABLE状态，但是线程所要执行的任务却丝毫没有进展，即线程可能一直在做无用功。 饥饿：饥饿好比母鸟给雏鸟喂食的情形，健壮的雏鸟总是抢先从母鸟的嘴中抢到食物，从而导致那些弱小的雏鸟总是挨饿。饥饿就是线程因无法获得其所需的资源而使得任务执行无法进展的现象。 资源争用 由于资源的稀缺性或者资源本身的特性，我们往往需要在多个线程之间共享同一个资源。但是有些资源具有排他性，即一次只能被一个线程占用，比如处理器、数据库连接、文件等。 资源争用：指一个线程占用一个排他性资源进行访问而未释放其对资源所有权时，其他线程视图访问该资源的现象。 既然存在资源争用，那么就会带来另外一个问题，即资源调度。当多个线程同时申请某个资源时，应该把资源分配给哪个线程呢？资源调度策略的一个常见特性就是它能否保证公平性。如果按照线程申请顺序，分配资源，那么这种策略被称为公平的，反之则不公平。 公平调度策略：一种常见策略就是排队 优点：线程申请资源所需的时间偏差较小，并且不会导致饥饿现象。 缺点：吞吐率小，因为需要维护线程申请资源的顺序，开销较大。 非公平调度策略：允许插队现象 优点：吞吐率高，是我们多数情况下首选的资源调度策略。 缺点：资源申请者申请资源所需的时间偏差可能较大，并可能导致饥饿现象。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"ConcurrentHashMap源码解读","slug":"2 后端/Java/Java容器/10.ConcurrentHashMap源码解读","date":"2022-02-01T14:34:49.000Z","updated":"2022-06-11T12:40:28.088Z","comments":true,"path":"455d24388919/","link":"","permalink":"http://rookieyin.github.io/455d24388919/","excerpt":"ConcurrentHashMap是线程安全的HashMap，JDK8之后，采用volatile+自旋锁+Synchronized（锁桶）方式实现并发控制，并发性能非常高。下面介绍下ConcurrentHashMap的具体细节。","text":"ConcurrentHashMap是线程安全的HashMap，JDK8之后，采用volatile+自旋锁+Synchronized（锁桶）方式实现并发控制，并发性能非常高。下面介绍下ConcurrentHashMap的具体细节。 ConcurrentHashMap结构 JDK8中，ConcurrentHashMap和HashMap基本一致，由桶数组+链表/红黑树构成。ConcurrentHashMap的类成员变量和HashMap基本一致，包括初始大小、阈值、加载因子、链表转树阈值等等。除此之外，ConcurrentHashMap还多了下面这些成员变量： 1234567891011121314151617181920212223242526272829303132/** * Minimum number of rebinnings per transfer step. Ranges are * subdivided to allow multiple resizer threads. This value * serves as a lower bound to avoid resizers encountering * excessive memory contention. The value should be at least * DEFAULT_CAPACITY. */private static final int MIN_TRANSFER_STRIDE = 16;/** * The number of bits used for generation stamp in sizeCtl. * Must be at least 6 for 32bit arrays. */private static int RESIZE_STAMP_BITS = 16;/** * The maximum number of threads that can help resize. * Must fit in 32 - RESIZE_STAMP_BITS bits. */private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;/** * The bit shift for recording size stamp in sizeCtl. */private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;/* * Encodings for Node hash fields. See above for explanation. */static final int MOVED = -1; // hash for forwarding nodes，表示同正在迁移static final int TREEBIN = -2; // hash for roots of trees，表示正在转成红黑树static final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash/** Number of CPUS, to place bounds on some sizings */static final int NCPU = Runtime.getRuntime().availableProcessors(); put()方法 有几个细节，这里先总结一下： 先判断桶数组是否创建，没创建的话，调用initTable()初始化桶数组； 和HashMap初始化不同，这里采用CAS判断是否有其他线程抢先进行了初始化。 外层加了一个for循环for (Node&lt;K,V&gt;[] tab = table;;)，不断自旋； 没有碰撞，即桶数组(n-1) &amp; hash处是null，casTabAt自旋插入（防止同时有其他线程执行了相同key的插入操作）； 存在hash碰撞 如果正在扩容，线程转去帮助扩容； 不在扩容，那么准备插入，执行synchronized (f)给当前桶加锁，然后再插入； 插入成功后，判断是否要树化或者扩容。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public V put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode());//hash，对hashcode再散列，高16位和低16位异或 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123;//迭代桶数组，自旋，直到成功put Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0)//懒加载。如果为空，则进行初始化 tab = initTable();//初始化桶数组 //(n - 1) &amp; hash)计算下标，取值，为空即无hash碰撞 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //这里同样采用自旋插入，防止插入冲突 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null)))//通过cas插入新值 break; // no lock when adding to empty bin &#125; //判断是否正在扩容。如果正在扩容，当前线程帮助进行扩容。 //每个线程只能同时负责一个桶上的数据迁移，并且不影响其它桶的put和get操作。 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123;//put5,存在hash碰撞 V oldVal = null; //此处，f在上面已经被赋值，f为当前下标桶的首元素。对链表来说是链表头对红黑树来说是红黑树的头元素。 synchronized (f) &#123; //再次检查当前节点是否有变化，有变化进入下一轮自旋 //为什么再次检查？因为不能保证，当前线程到这里，有没有其他线程对该节点进行修改 if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123;//当前桶为链表 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123;//迭代链表节点 K ek; if (e.hash == hash &amp;&amp;//key相同，覆盖（onlyIfAbsent有什么用？） ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //找到链表尾部，插入新节点。（什么这里不用CAS？因为这在同步代码块里面） if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123;//当前桶为红黑树 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123;//想红黑树插入新节点 oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //树化。binCount &gt; 8，进行树化，链表转红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) //如果容量 &lt; 64则直接进行扩容；不转红黑树。 //（你想想，假如容量为16，你就插入了9个元素，巧了，都在同一个桶里面， //如果这时进行树化，时间复杂度会增加，性能下降，不如直接进行扩容，空间换时间） treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount);//扩容。addCount内部会进行判断要不要扩容 return null;&#125; transfer()方法 这里简单总结下扩容的流程，和一些重要细节： 扩容前，先作一些准备工作，包括设置并发数、创建新数组等操作； 判断桶是不是已经迁移完毕了，或者桶中没有数据，如果是的话，直接跳到下一个桶； 如果桶中有数据，并且还没有迁移，那么给桶加锁，开始迁移。 迁移完毕后，把旧桶头结点设置成ForwardingNode，setTabAt(tab, i, fwd);表示改桶已经被迁移了，这样如果其他线程执行get或者put操作时，发现它是fwd节点，就会到新桶中去执行相应操作。（这一点在get和put的源码中有所体现） 旧数组和新数组中的桶都是共享变量，加锁的时候只锁了旧数组中的桶，新数组中的桶并没有加锁，这样会不会有线程安全问题？答案是不会，因为不可能同时向新数组同一个桶迁移数据，详情可以了解HashMap中扩容原理。 链表顺序问题： 对比JDK7 HashMap，JDK8 HashMap，JDK8 ConcurrentHashMap在扩容后对节点相对顺序的保证方面，JDK7 HashMap是完全倒序。JDK8 HashMap不改变相对顺序。JDK8 ConcurrentHashMap 保证部分节点的相对顺序，其余的倒序。 ConcurrentHashMap这里有个优化，首先通过一次链表扫描找到lastRun，lastRun后面的所有节点在新数组中的index都是oldIndex + oldCap ，减少判断次数。下图演示了扩容前后，链表中元素分布： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//tab旧桶数组，nextTab新桶数组private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //控制并发数，控制CPU的资源 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating//新数组为空，则初始化新数组 try &#123; @SuppressWarnings(&quot;unchecked&quot;) //扩容为原来的两倍 n &lt;&lt; 1 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; //在这里面进行new Node将node.hash置为-1。表示该桶正在进行移动。 //（这里很重要的一点是，只锁表头，所以只需要将链表（或者红黑树）头结点.hash置为-1即可） ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); //advance是控制是否继续进行移动的条件，当advance == false，表示正在移动一个桶。 //true表示可以继续进行下一个桶的移动 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123;//自旋 Node&lt;K,V&gt; f; int fh; while (advance) &#123;//start int nextIndex, nextBound; //当前桶是不是已经移动完了 if (--i &gt;= bound || finishing) advance = false; //两个停止移动的条件。移动完了。（这个是真正停止的条件。下面那个条件会进行一次检查） else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123;//结束扩容 nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit 再次检查一遍，防止有桶中还有数据没移动。 &#125; &#125;//end 从start到end可看可不看就是条件控制，包括结束条件的控制，移动进度的控制等。 //该桶没数据 else if ((f = tabAt(tab, i)) == null) //将oldtab中的该桶设置为fwd节点，hash=-1 advance = casTabAt(tab, i, null, fwd); //已经移动过的桶其hash=-1 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; synchronized (f) &#123;//上锁 if (tabAt(tab, i) == f) &#123; //ln新链表，不需要移动的节点重新组组织成的链表。 //hn新链表，需要移动的节点重新组织成的链表 Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123;//链表 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; //start //从start，到end之间。不看也行。实在费脑子。其实这段代码写的有点让人费解 //主要是不认真看不知道作者的意图。本意是这样的。判断是不是可以从某个节点n开始 //后面的节点是不是都是和节点n一样，移动的目标桶一样的。 //如果是一样的，则后面的这些节点就不用移动了，只需要移动n节点即可。 //（注意链表的引用，next指针就把后面的都带过去了） //想一个极端情况，如果在这里迭代后发现，所有节点，扩容后数据移动的目标桶都是一样的。 //则只需要移动头结点即可。不用重新拼接链表了。 ......//和HashMap差不多，不过更新操作换成了线程安全的操作 &#125; else if (f instanceof TreeBin) &#123;//红黑树 ......//和HashMap差不多，不过更新操作换成了线程安全的操作 &#125; &#125; &#125; &#125; &#125;&#125; get()方法 get()方法比较简单，就一个细节需要关注： 需要判断桶的状态，即tabAt(tab, (n - 1) &amp; h).hash，如果小于0，说明桶被迁移了，需要到新数组中去找 123456789101112131415161718192021public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode());//hash if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123;//取桶 if ((eh = e.hash) == h) &#123;//key相同直接返回 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0)//hash &lt; 0 表示正在扩容 //在这里需要非常注意的一点，扩容后的桶会放入fwd节点 //该节点hash = MOVED，fwd.nextTable为扩容后新的数组。 return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123;//迭代链表 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; remove()方法 remove()方法底层调用了replaceNode方法，下面是其源码。这里我们先总结下replaceNode中的一些细节： 先判断是否正在扩容，如果在扩容，先帮助扩容； 不在扩容的话，采用自旋+Synchronized锁桶方式进行替换； 判断是否是数组对应位置是否为null，不为null继续，否则直接返回； 如果是链表，则遍历链表，如果是红黑树则遍历红黑树； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151/** * Implementation for the four public remove/replace methods: * Replaces node value with v, conditional upon match of cv if * non-null. If resulting value is null, delete. */final V replaceNode(Object key, V value, Object cv) &#123; //计算key经过扰动运算后的hash int hash = spread(key.hashCode()); //自旋 for (Node&lt;K,V&gt;[] tab = table;;) &#123; //f表示桶位头结点 //n表示当前table数组长度 //i表示hash命中桶位下标 //fh表示桶位头结点 hash Node&lt;K,V&gt; f; int n, i, fh; //CASE1： //条件一：tab == null true-&gt;表示当前map.table尚未初始化.. false-&gt;已经初始化 //条件二：(n = tab.length) == 0 true-&gt;表示当前map.table尚未初始化.. false-&gt;已经初始化 //条件三：(f = tabAt(tab, i = (n - 1) &amp; hash)) == null true -&gt; 表示命中桶位中为null，直接break， 会返回 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; //CASE2： //前置条件CASE2 ~ CASE3：当前桶位不是null //条件成立：说明当前table正在扩容中，当前是个写操作，所以当前线程需要协助table完成扩容。 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); //CASE3: //前置条件CASE2 ~ CASE3：当前桶位不是null //当前桶位 可能是 &quot;链表&quot; 也可能 是 &quot;红黑树&quot; TreeBin else &#123; //保留替换之前的数据引用 V oldVal = null; //校验标记 boolean validated = false; //加锁当前桶位 头结点，加锁成功之后会进入 代码块。 synchronized (f) &#123; //判断sync加锁是否为当前桶位 头节点，防止其它线程，在当前线程加锁成功之前，修改过 桶位 的头结点。 //条件成立：当前桶位头结点 仍然为f，其它线程没修改过。 if (tabAt(tab, i) == f) &#123; //条件成立：说明桶位 为 链表 或者 单个 node if (fh &gt;= 0) &#123; validated = true; //e 表示当前循环处理元素 //pred 表示当前循环节点的上一个节点 Node&lt;K,V&gt; e = f, pred = null; for (;;) &#123; //当前节点key K ek; //条件一：e.hash == hash true-&gt;说明当前节点的hash与查找节点hash一致 //条件二：((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) //if 条件成立，说明key 与查询的key完全一致。 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; //当前节点的value V ev = e.val; //条件一：cv == null true-&gt;替换的值为null 那么就是一个删除操作 //条件二：cv == ev || (ev != null &amp;&amp; cv.equals(ev)) 那么是一个替换操作 if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; //删除 或者 替换 //将当前节点的值 赋值给 oldVal 后续返回会用到 oldVal = ev; //条件成立：说明当前是一个替换操作 if (value != null) //直接替换 e.val = value; //条件成立：说明当前节点非头结点 else if (pred != null) //当前节点的上一个节点，指向当前节点的下一个节点。 pred.next = e.next; else //说明当前节点即为 头结点，只需要将 桶位设置为头结点的下一个节点。 setTabAt(tab, i, e.next); &#125; break; &#125; pred = e; if ((e = e.next) == null) break; &#125; &#125; //条件成立：TreeBin节点。 else if (f instanceof TreeBin) &#123; validated = true; //转换为实际类型 TreeBin t TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; //r 表示 红黑树 根节点 //p 表示 红黑树中查找到对应key 一致的node TreeNode&lt;K,V&gt; r, p; //条件一：(r = t.root) != null 理论上是成立 //条件二：TreeNode.findTreeNode 以当前节点为入口，向下查找key（包括本身节点） // true-&gt;说明查找到相应key 对应的node节点。会赋值给p if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; //保存p.val 到pv V pv = p.val; //条件一：cv == null 成立：不比对value，就做替换或者删除操作 //条件二：cv == pv ||(pv != null &amp;&amp; cv.equals(pv)) 成立：说明“对比值”与当前p节点的值 一致 if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; //替换或者删除操作 oldVal = pv; //条件成立：替换操作 if (value != null) p.val = value; //删除操作 else if (t.removeTreeNode(p)) //这里没做判断，直接搞了...很疑惑 setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; //当其他线程修改过桶位 头结点时，当前线程 sync 头结点 锁错对象时，validated 为false，会进入下次for 自旋 if (validated) &#123; if (oldVal != null) &#123; //替换的值 为null，说明当前是一次删除操作，oldVal ！=null 成立，说明删除成功，更新当前元素个数计数器。 if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null;&#125; public V remove(Object key) &#123; return replaceNode(key, null, null);&#125; JDK 8之前 VS 之后 首先和HashMap一样，JDK8之前没有引入红黑树 JDK7中ConcurrentHashMap采用分段锁，具体来说给每个Segment加上ReentrantLock，性能要低于JDK8。其底层数据结构如下：","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"HashMap源码解读","slug":"2 后端/Java/Java容器/9.HashMap源码解读","date":"2022-01-31T14:34:49.000Z","updated":"2022-06-11T12:35:40.625Z","comments":true,"path":"40b9b0acf80a/","link":"","permalink":"http://rookieyin.github.io/40b9b0acf80a/","excerpt":"本文简单分析下HashMap的源码，重点解读了HashMap的resize、put和remove方法。","text":"本文简单分析下HashMap的源码，重点解读了HashMap的resize、put和remove方法。 HashMap类概览 先看一下HashMap中的一些重要字段和常用方法，这里先总结一下比较重要的属性： capacity：桶数组大小，默认16 load_factor：加载因子，用来计算扩容的阈值 threshold：扩容阈值，等于capacity*load_factor treeify_threshold：将链表转为红黑树的阈值，默认8 untreeify_threshold：将红黑树转为链表阈值，默认6 min_treeify_capacity：将链表转为红黑树，桶数组最小长度，默认64；也就是说数组长度小于64时，即使链表长度大于8也不会将其转为红黑树。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//继承自AbstractMap，实现了Map、Cloneable和Serializable接口public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; //默认大小为2^4，也就是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量为一个int大小，2^30 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //加载因子，默认为0.75，也就是size &gt; 0.75 * capacity时，进行扩容 static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表长度超过8，转成红黑树 static final int TREEIFY_THRESHOLD = 8; //树中节点数量小于6，转成链表 //这里留个小疑问，为什么是6而不是8 static final int UNTREEIFY_THRESHOLD = 6; //capacity大于64，才会将链表转成红黑树 static final int MIN_TREEIFY_CAPACITY = 64; //hash方法，允许key为null，key的hash值的低16位和高16位异或，应该是减少hash冲突 static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; //node数组 transient Node&lt;K,V&gt;[] table; //entrySet的缓存 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //map中记录了多少个键值对 transient int size; //阈值，前面提到过的，默认8 int threshold; //加载因子，前面也提到过，默认0.75 final float loadFactor; //get方法，通过key找对应value public V get(Object key) &#123; &#125; //判断是否包含key public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; //Map中元素添加到当前map public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; &#125; //删除某个键值对 public V remove(Object key) &#123; &#125; //删除Map中所有元素 public void clear() &#123; &#125; //是否包含value public boolean containsValue(Object value) &#123; &#125; //通过key获取对应value public V getOrDefault(Object key, V defaultValue) &#123; &#125; public V putIfAbsent(K key, V value) &#123; &#125; public boolean remove(Object key, Object value) &#123; &#125; //forEach方法，内部其实就是个for循环 public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; &#125; //下面3个是迭代器方法 final class KeyIterator extends HashIterator &#125; final class ValueIterator extends HashIterator &#125; final class EntryIterator extends HashIterator &#125;&#125; put()方法 在读源码前，这里先总结下put()方法中值得关注的一些细节： 桶下标：确定key的桶下标用的是(n - 1) &amp; hash，而不是hash % n 用位运算效率更高 因为n始终是2的幂，可以保证(n - 1) &amp; hash =hash % n 扩容：如果size &gt; capacity * loadfactor，调用resize()对桶数组进行扩容 链表转红黑树：如果链表长度达到8 如果capacity&lt;64，扩容数组 如果capacity&gt;=64，将链表转为转红黑树 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V put(K key, V value) &#123; //调用putVal方法 return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table是null，或者长度为0，需要调用resize函数初始化一下 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //(n-1) &amp; hash = hash % n，因为n是2的次幂 //这里也是HashMap扩容每次乘以2的原因之一，可以通过位运算快速确定元素下标 if ((p = tab[i = (n - 1) &amp; hash]) == null) //这个位置没有，直接放在链表头部 tab[i] = newNode(hash, key, value, null); else &#123; //这个位置已经有元素了，发生哈希冲突？或者两者key相同 Node&lt;K,V&gt; e; K k; //p表示的是原来位置i处的节点 //如果原来该位置的节点的hash等于参数hash，并且两者key相同，说明当前的put操作等价于更新 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //两个key不同，发生hash冲突，创建一个新的节点放到链表或红黑树中 //节点是红黑树节点，走这条分支 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //是链表节点，走这条分支 else &#123; //遍历链表一直到链表尾部 //如果中间发现相同的key，说明Map中存在该key，更新下key值对应的value即可 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //已经到了链表尾部，没有发现具有相同key值的键值对 //那就要创建一个新的节点，添加到链表尾部 p.next = newNode(hash, key, value, null); //如果链表长度超过阈值（默认8），链表转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //找到具有相同key值的键值对，直接break if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //e不为空，说明Map中存在相同key的键值对，直接更新 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //容量超过阈值，调用resize函数扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize()方法 现在来看看resize()函数里面的扩容细节，这里面有三个细节需要注意： 桶数组大小是有限制的，默认为2^30，如果oldCap∗2&gt;230oldCap*2 &gt;2^{30}oldCap∗2&gt;230不进行扩容，并将阈值设置成Integer.MAX_VALUE； e=oldTab[j]之后，立即将oldTab[j]=null，帮助gc？？； 迁移元素时，对于链表，将其分成两部分，其中一部分如果在j位置，迁移后依旧在j位置，剩下那部分迁移后在j+oldCap位置: 链表中哪些节点index不变？hash &amp; oldCap == 0的节点index不变，其余的变为j+oldCap； 这一特性再次体现了数组容量是2的n次幂的好处。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //oldCap表示原始长度，oldThr表示原始的扩容阈值 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; //新的容量和扩容阈值 int newCap, newThr = 0; //原始容量大于0，说明不是第一次 if (oldCap &gt; 0) &#123; //如果旧的容量已经大于最大限制，也就是2^30，无法再扩容了，直接返回 //并将扩容阈值设置成int型的最大值，即后续不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //数组大小乘2，也就是左移1位，同样地，新的扩容阈值也要乘2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //oldCap == 0，并且oldThr &gt; 0 的情况下进入该分支 //带初始容量构造器时，将容量设置成threshold else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //oldCap == 0，并且oldThr == 0 的情况下进入该分支 else &#123; // zero initial threshold signifies using defaults //这种情况说明桶数组还是null，没有初始化，直接新建一个默认大小，也就是8的数组 newCap = DEFAULT_INITIAL_CAPACITY; //扩容阈值 = 加载因子 * 容量 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果新的阈值还是0，用加载因子乘以新的容量，得到新的阈值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) //创建一个newCap大小的数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历原来的桶数组，把所有元素迁移到新的桶数组中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; //唉？很细节，先把旧数组j位置设成null，防止内存泄漏？快速gc？ oldTab[j] = null; //这个位置就链表头一个元素，直接放到新数组对应位置即可 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果是个树节点，调用split方法把树中所有节点迁移到新数组中 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //进入这个分支，说明是个链表节点，并且链表中不止一个元素 else &#123; // preserve order //链表分为两部分，一部分需要移动，一部分不需要移动 //那么怎么知道链表中哪些需要移动，哪些不需要移动呢？ Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //一个do-while循环遍历链表 do &#123; next = e.next; //如果hash &amp; oldCap == 0，这些元素不需要移动 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //否则需要移动位置 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; //loHead不需要移动，直接放到新数组j位置 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; //hiHead需要移动，放到新数组j+oldCap位置 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; remove()方法 这里面需要注意的细节不多，比较有趣的一点是：删除节点后，如果红黑树节点数量小于等于6，将树转为链表，而不是8，防止在链表和红黑树之间来回转换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public V remove(Object key) &#123; Node&lt;K,V&gt; e; //直接调用removeNode方法 return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; //上面条件中，定位到hash(key)在桶数组中的index，并用p表示链表头节点 Node&lt;K,V&gt; node = null, e; K k; V v; //如果表头就是我们要找的key，直接令node=p if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) //如果是树节点，去树里面找 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; //一直往后找，直到找到或者到达链表尾部 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //找到了key对应的value，进入下面代码，否则直接返回 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"使用PriorityQueue实现堆","slug":"2 后端/Java/Java容器/8. 使用PriorityQueue实现堆","date":"2022-01-30T14:34:49.000Z","updated":"2022-06-11T12:35:02.845Z","comments":true,"path":"3e4a83fe1b86/","link":"","permalink":"http://rookieyin.github.io/3e4a83fe1b86/","excerpt":"本文转自：[PriorityQueue]:Java中PriorityQueue的用法 不指定Comparator时默认为最小堆,通过传入自定义的Comparator函数可以实现大顶堆。 123456789PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;Integer&gt;(); //小顶堆，默认容量为11PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(11,new Comparator&lt;Integer&gt;()&#123; //大顶堆，容量11 @Override public int compare(Integer i1,Integer i2)&#123; return i2-i1; &#125;&#125;);//Comparator也可以使用lambda实现PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(11, (Integer o1, Integer o2)-&gt;o2-o1);","text":"本文转自：[PriorityQueue]:Java中PriorityQueue的用法 不指定Comparator时默认为最小堆,通过传入自定义的Comparator函数可以实现大顶堆。 123456789PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;Integer&gt;(); //小顶堆，默认容量为11PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(11,new Comparator&lt;Integer&gt;()&#123; //大顶堆，容量11 @Override public int compare(Integer i1,Integer i2)&#123; return i2-i1; &#125;&#125;);//Comparator也可以使用lambda实现PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(11, (Integer o1, Integer o2)-&gt;o2-o1); PriorityQueue的API文档说明 构造方法 说明 PriorityQueue() 使用默认的初始容量（11）创建一个 PriorityQueue，并根据其自然顺序对元素进行排序。 PriorityQueue(Collection&lt;? extends E&gt; c) 创建包含指定 collection 中元素的 PriorityQueue。 PriorityQueue(int initialCapacity) 使用指定的初始容量创建一个 PriorityQueue，并根据其自然顺序对元素进行排序。 PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) 使用指定的初始容量创建一个 PriorityQueue，并根据指定的比较器对元素进行排序。 PriorityQueue(PriorityQueue&lt;? extends E&gt; c) 创建包含指定优先级队列元素的 PriorityQueue。 PriorityQueue(SortedSet&lt;? extends E&gt; c) 创建包含指定有序 set 元素的 PriorityQueue。 其他方法 说明 add(E e) 将指定的元素插入此优先级队列。 clear() 从此优先级队列中移除所有元素。 Comparator&lt;? super E&gt; comparator() 返回用来对此队列中的元素进行排序的比较器；如果此队列根据其元素的自然顺序进行排序，则返回 null。 contains(Object o) 如果此队列包含指定的元素，则返回 true。 Iterator iterator() 返回在此队列中的元素上进行迭代的迭代器。 offer(E e) 将指定的元素插入此优先级队列。 peek() 获取但不移除此队列的头；如果此队列为空，则返回 null。 poll() 获取并移除此队列的头，如果此队列为空，则返回 null。 remove(Object o) 从此队列中移除指定元素的单个实例（如果存在）。 size() 返回此 collection 中的元素数。 toArray() 返回一个包含此队列所有元素的数组。 toArray(T[] a) 返回一个包含此队列所有元素的数组；返回数组的运行时类型是指定数组的类型。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"常见并发容器总结","slug":"2 后端/Java/Java容器/7. 常见并发容器总结","date":"2022-01-29T14:34:49.000Z","updated":"2022-06-11T12:34:38.118Z","comments":true,"path":"2c9c354cbe3d/","link":"","permalink":"http://rookieyin.github.io/2c9c354cbe3d/","excerpt":"Java中并发集合类有很多，其结构关系如下图所示： 本文主要介绍两个最常用的并发集合类：ConcurrentHashMap和CopyOnWriteArrayList。","text":"Java中并发集合类有很多，其结构关系如下图所示： 本文主要介绍两个最常用的并发集合类：ConcurrentHashMap和CopyOnWriteArrayList。 ConcurrentHashMap ConcurrentHashMap是Java中线程安全的hashmap。自从被提出后，另外一个线程安全的哈希类Hashtable就被弃用了，因为其效率过低。为什么HashTable慢？ 因为其实现使用了synchronized关键字对put等操作进行加锁，而synchronized关键字加锁是对整个对象进行加锁，也就是说在进行put等修改Hash表的操作时，锁住了整个Hash表，从而使得其表现的效率低下。 在JDK1.5~1.7和JDK1.8中，ConcurrentHashMap有着不同的实现，下面分别进行介绍。 ConcurrentHashMap-JDK1.7 在JDK1.5~1.7版本，Java使用了分段锁机制实现ConcurrentHashMap. 简而言之，ConcurrentHashMap在对象中保存了一个Segment数组，即将整个Hash表划分为多个分段；而每个Segment元素，即每个分段则类似于一个Hashtable；这样，在执行put操作时首先根据hash算法定位到元素属于哪个Segment，然后对该Segment加锁即可。因此，ConcurrentHashMap在多线程并发编程中可是实现多线程put操作。接下来分析JDK1.7版本中ConcurrentHashMap的实现原理。 一、数据结构 ConcurrentHashMap的数据结构如下图所示： ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。 再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。 二、初始化 和HashMap类似，主要有两个重要参数： initialCapacity： 初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。 loadFactor： 负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。 初始化完成，我们得到了一个 Segment 数组。我们就当是用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后: Segment 数组长度为 16，不可以扩容 Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容 这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍 当前 segmentShift 的值为 32 - 4 = 28，segmentMask 为 16 - 1 = 15，姑且把它们简单翻译为移位数和掩码，这两个值马上就会用到 关于put、remove等操作的源码分析可以参考Java全站知识体系。 ConcurrentHashMap-JDK1.8 在JDK1.7之前，ConcurrentHashMap是通过分段锁机制来实现的，所以其最大并发度受Segment的个数限制。因此，在JDK1.8中，ConcurrentHashMap的实现原理摒弃了这种设计，而是选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。 其数据结构和HashMap基本一样，不过为了保证线程安全，其源码要更复杂一点，感兴趣的可以自行研究。 CopyOnWriteArrayList CopyOnWriteArrayList利用CopyOnWrite思想，即在写时复制一份副本进行修改，修改完成后，再将新值赋值给旧值，为保证线程安全，需要在所有的写操作加悲观锁或者乐观锁，而读操作不必加锁，这就使得读写分离，读读不互斥，读写不互斥，空间换时间，性能大大提升。 CopyOnWriteArrayList属性中有一个可重入锁，用来保证线程安全访问，还有一个Object类型的数组，用来存放具体的元素。当然，也使用到了反射机制和CAS来保证原子性的修改lock域。 1234567891011121314151617181920212223public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = 8673264195747942595L; // 可重入锁 final transient ReentrantLock lock = new ReentrantLock(); // 对象数组，用于存放元素 private transient volatile Object[] array; // 反射机制 private static final sun.misc.Unsafe UNSAFE; // lock域的内存偏移量 private static final long lockOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = CopyOnWriteArrayList.class; lockOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;lock&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; CopyOnWrite利用写时复制副本加锁修改，而读不加锁的思想达到读写分离的效果，以空间换时间，提升性能。而其弊端也正是其思想的体现： 内存占用问题：CopyOnWrite因为复制副本所以双倍占用内存，可能造成频繁的 Yong GC 和 Full GC。（利用CopyOnWrite机制更新大对象需要注意） 数据一致性问题：CopyOnWrite只保证了数据最终一致性，数据的实时一致性不能保证，所以读数据可能会有一定的延迟。 缺陷决定了CopyOnWriteArrayList使用场景的局限性，CopyOnWriteArrayList适合读多写少，复制数据对象不宜过大的场景。 总的来说，CopyOnWriteArrayList具有以下特征： 是ArrayList的线程安全版本； 有写操作的时候会copy一份数据，然后写完再设置成新的数据； 适用于读多写少的并发场景， 每次add/set都要重新复制数组，这个代价实在太高昂了。 不适用于实时读的场景，拷贝数据、新增元素比较耗时，读取到的数据还可能是旧的（读的时候不加锁）。 在线程x执行get操作的时候并不是直接通过全局array访问数组元素而是通过方法的形参a访问的，a指向的地址和array指向的地址在调用get方法的那一刻是一样的，都指向了堆内存的数组对象。之后改变array指向的地址并不影响get的访问，因为在调用get方法的那一刻形参a指向的内存地址就已经确定了，不会改变。所以读的仍然是旧数组。 还需要注意的一点是：CopyOnWriteArrayList中的COWIterator迭代器没有fail-fast检查。 例如ArrayList在迭代器遍历想删除元素，只能使用迭代器的删除方法，而使用外部ArrayList删除方法会抛ConcurrentModificationException异常，为什么呢？ 因为ArrayList成员变量维护了一个modCount，每次修改操作都会modCount++，而迭代器中也维护了一个expectedModCount，新建迭代器时modCount赋值给expectedModCount，在迭代器遍历时会检查modCount != expectedModCount，不相等则抛出ConcurrentModificationException，在迭代器遍历中调用迭代器外部的修改方法只会更新modCount，不会更新迭代器的expectedModCount，而迭代器内部提供的修改方法既更新了modCount，同时也将最新的modCount值赋值给expectedModCount。 然而这个限制在COWIterator中不存在！在使用COWIterator迭代器遍历时可以调用外部的修改方法，不会抛出异常。这是因为COWIterator迭代器中复制了一份原数组副本，外部修改数组只是修改了原数组，并不会影响迭代器中正在遍历的数组。 同时COWIterator迭代器也不支持调用迭代器内部的修改方法，全都会抛出UnsupportedOperationException。 既然COWIterator迭代器中遍历的数组是一个副本，修改原数组也不会影响到副本，这就出现一个问题：数据的实时一致性。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Java容器各种常用API总结","slug":"2 后端/Java/Java容器/6. Java容器各种常用API总结","date":"2022-01-28T14:34:49.000Z","updated":"2022-06-11T12:33:30.249Z","comments":true,"path":"cdac6497ca5d/","link":"","permalink":"http://rookieyin.github.io/cdac6497ca5d/","excerpt":"先说一下Java中所有容器都有的常用API：size()容器大小，isEmpty()是否为空，clear()清空容器，iterator()返回容器的迭代器（Collection接口下容器才有，Map接口下的没有）。","text":"先说一下Java中所有容器都有的常用API：size()容器大小，isEmpty()是否为空，clear()清空容器，iterator()返回容器的迭代器（Collection接口下容器才有，Map接口下的没有）。 List常用API 插入元素 add(E e)：list尾部插入一个元素； add(int index, E e)：指定位置插入元素； addAll(Collection&lt;? extends E&gt; c)：collection中所有元素插入list尾部，也可以加上参数index，指定插入位置。 查找元素 get(in index)：根据index获取元素； indexOf(Object o)：查找元素第一次出现的index。 删除元素 remove和removeAll方法，前者可以通过指定index或元素删除，后者传入一个collection。 排序 Collections.sort(List&lt;T&gt; list)，可以额外传入一个Comparator参数。 其他 subList(int start, int end)：包含start，不包含end的子列表； toArray()：list转array； toArray(T[] a)：指定array类型，比如 String[] y = x.toArray(new String[0]);。 Set常用API 插入元素 add(E e)：插入单个元素； addAll(Collection&lt;?extends E&gt; c)：插入collection中所有元素。 查找元素 contains(Object o)：判断是否包含元素o； containsAll(Collection&lt;?&gt; c)：判断是否包含collection中所有元素。 删除元素 remove(Object o)删除单个元素，不存在返回false，或者通过removeAll删除collection中元素。 其他 toArray方法，返回Object数组，或者通过toArray(T[] a)返回指定类型数组。 Map常用API 插入元素 put(K key, V value)：插入单个键值对 putIfAbsent(K key, V value)：key对应的值不为null，则put 查找元素 get(K key)：传入key，返回value，key不存在返回null； getOrDefault(K key， V defaultValue)：传入key，返回value，key不存在返回defaultValue。 删除元素 remove(Object key)：删除key remove(Object key, Object value)：删除值为value的key 其他 keySet()：返回所有key组成的集合； values()：返回所有value组成的列表。 Stack常用API 对于栈，我们关注的API有入栈、出栈、获取栈顶元素、栈是否为空、栈大小。其中是否为空和大小，都是统一用isEmpty()和size()，我们重点看下其它3个API。 Vector下的Stack类 peek()返回栈顶元素，push()入栈，pop()删除并返回栈顶元素。 LinkedList作为栈使用 因为LinkedList实现了Queue和Dequeue接口，因此也可以作为栈使用。Dequeue双端队列接口，实现类包括ArrayDequeue、LinkedBlockingDeque、LinkedList等。 和Stack类一样，peek()、push()和pop()分别表示取回栈顶、入栈、出栈操作。 Queue常用API 对于queue一般用offer表示入队列，poll表示出队列，peek表示获取队列第一个元素（即将出队列的）。 queue中add/offer，element/peek，remove/poll对比 add()和offer() add()和offer()都是向队列中添加一个元素。一些队列有大小限制，因此如果想在一个满的队列中加入一个新项，调用 add() 方法就会抛出一个 unchecked 异常，而调用 offer() 方法会返回 false。因此就可以在程序中进行有效的判断！ poll()和remove() remove() 和 poll() 方法都是从队列中删除第一个元素。如果队列元素为空，调用remove() 的行为与 Collection 接口的版本相似会抛出异常，但是新的 poll() 方法在用空集合调用时只是返回 null。因此新的方法更适合容易出现异常条件的情况。 element()和peek() element() 和 peek() 用于在队列的头部查询元素。与 remove() 方法类似，在队列为空时， element() 抛出一个异常，而 peek() 返回 null。 LinkedList中的部分方法总结 由于LinkedList实现了Queue和Dequeue接口，因此可以同时作为stack、queue和dequeue。LinkedList类中操作元素的方法非常之多，下面稍作对比：push：加载链表头；peek：从链表头取；pop：从链表头出；offer：从链表尾加；poll：从链表头出；remove：从链表头出。总结：拿数据都是从链表头拿，插入push从头插，offer从尾插。 排序常用API 对于List接口，一般直接使用Collections.sort(list)即可对list进行排序 Collections.sort()也可以传入一个Comparator指定排序规则 对于Set接口，可以通过TreeSet实现排序，举个例子： 1234567891011121314151617181920212223public class App &#123; public static void main( String[] args ) &#123; Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(&quot;1&quot;); set.add(&quot;2&quot;); set.add(&quot;5&quot;); set.add(&quot;4&quot;); set.add(&quot;3&quot;); System.out.println(set.toString()); Set&lt;String&gt; sortSet = new TreeSet&lt;String&gt;(new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o2.compareTo(o1);//降序排列 &#125; &#125;); sortSet.addAll(set); System.out.println(sortSet.toString()); //也可以使用下面方式 Set&lt;String&gt; sortSet = new TreeSet&lt;String&gt;((o1, o2) -&gt; o2.compareTo(o1)); Set&lt;String&gt; sortSet = new TreeSet&lt;String&gt;(Comparator.reverseOrder()); TreeSet&lt;PersonObj&gt; objects = new TreeSet&lt;&gt;(((o1, o2) -&gt;Integer.compare(o2.getAge(), o1.getAge()))); &#125;&#125; 对于Arrays，可以直接通过Arrays.sort(arr)升序排序，也可以额外传入一个Comparator，比如Arrays.sort(arr, Collections.reverseOrder())。 遍历方法总结 遍历List for循环，利用index遍历listfor(int i = 0; i &lt; list.size(); ++i)； forEach遍历，比如for(Integer item : list)； Iterator遍历，比如Iterator&lt;Integer&gt; iter = list.iterator();while(iter.hashNext)&#123;System.out.println(iter.next())&#125;。 遍历Set forEach遍历，比如for(Integer item : set); 迭代器遍历：和List一样。 遍历Map 遍历entrySet()，比如for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet())； 需要注意的是，遍历之前需要检查是否非空，否则抛出异常。 遍历key集合，比如for (Integer key : map.keySet()) ； 迭代器遍历，比如Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator();，当然也可以用keySet的迭代器遍历； 通过forEach配合lambda表达式遍历：map.forEach((k, v) -&gt; System.out.println(&quot;key = &quot; + k + &quot;, value = &quot; + v));，其底层还是通过entrySet遍历的。 注：推荐使用entrySet，而不是keySet遍历，因为keySet遍历实际上遍历了2次。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Map接口","slug":"2 后端/Java/Java容器/5. Map接口","date":"2022-01-27T14:34:49.000Z","updated":"2022-06-11T12:32:58.723Z","comments":true,"path":"04f89728d40f/","link":"","permalink":"http://rookieyin.github.io/04f89728d40f/","excerpt":"本文主要介绍Map接口下的HashMap，TreeMap，HashTable，LinkedHashMap，ConcurrentHashMap五个类。 对比这5种Map结构，其中HashMap和ConcurrentHashMap最为常用，前者用于单线程，后者用于多线程。 TreeMap和LinkedHashMap可以看做两种有特殊用途的Map结构，前者是基于红黑树构造的有序Map，后者在HashMap的基础上多维护了一个双向链表，记录Map中元素顺序（有插入顺序和访问顺序两种，可用于实现LRUCache之类的需求）。","text":"本文主要介绍Map接口下的HashMap，TreeMap，HashTable，LinkedHashMap，ConcurrentHashMap五个类。 对比这5种Map结构，其中HashMap和ConcurrentHashMap最为常用，前者用于单线程，后者用于多线程。 TreeMap和LinkedHashMap可以看做两种有特殊用途的Map结构，前者是基于红黑树构造的有序Map，后者在HashMap的基础上多维护了一个双向链表，记录Map中元素顺序（有插入顺序和访问顺序两种，可用于实现LRUCache之类的需求）。 HashMap HashMap实现了Map接口，主要用来存放键值对，它基于哈希表的 Map 接口实现，是常用的 Java 集合之一，是非线程安全的。 其特点如下： JDK1.8 之前 HashMap 底层是数组和链表 ，之后使用数组+链表+红黑树。 哈希冲突：采用拉链法，数组中每一格代表链表，遇到冲突的哈希值，将其加入链表中即可。 数组扩容：HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍 。 并且， HashMap 总是使用 2 的幂作为哈希表的大小（因为计算数组下标采用“与”操作(n-1)&amp;hash）。 是否扩容由loadFactor参数控制，当size&gt;=threshold时，进行数组扩容。其中threshold = capacity * loadFactor，loadFactor称之为加载因子，默认值为0.75。扩容机制的详细介绍，可参考https://zhuanlan.zhihu.com/p/114363420。 这里大概总结下扩容的过程： 先重新建立一个数组，然后把原来数组中元素，放到新数组对应位置； 链表中的插入，采用的是头插法，上图中原来3在7前面，但是扩容后，7在3前面。 允许放入key为null的元素，也允许插入value为null的元素，会将key为null的元素放到index=0处。 TreeMap Java TreeMap实现了SortedMap接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。其特性如下： 底层实现：TreeMap底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。 线程不安全，是非同步的。 HashTable 其实现和HashMap十分类似，但是它是一个过时类，不建议使用，下面将其和HashMap进行对比： 实现：两者类似，都是数组+链表。 Null值：HashMap的key和value都可以是Null，但是HashTable不允许key-value为空。 线程安全：HashTable大部分方法都有synchronized修饰是线程安全的，而HashMap多线程下存在安全问题。 LinkedHashMap 大多数情况下，只要不涉及线程安全问题，Map基本都可以使用HashMap，不过HashMap有一个问题，就是迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序。HashMap的这一缺点往往会带来困扰，因为有些场景，我们期待一个有序的Map。 LinkedHashMap继承自HashMap，其底层除了有和HashMap一样的数组+链表结构外，还额外维护了一个双向链表，用于保存元素加入顺序，可以认为是HashMap+LinkedList。其特性如下： 和HashMap.Entry相比，其Entry中还有Entry&lt;K,V&gt; before和Entry&lt;K,V&gt;after两个属性，记录该Entry在链表中位置。 LinkedHashMap中具有accessOrder属性，默认为false，表示链表按照插入顺序维护，若为true，链表则按照访问顺序维护。 应用：可以用来实现LRUCache，即基于LRU算法的Cache。 它也是非线程安全的。 ConcurrentHashMap 前面提到单线程下大多数情况首选HashMap，但是在多线程场景下ConcurrentHashMap更为适用。 JDK1.7 其底层存储结构如下图所示： ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 Segment 的个数一旦初始化就不能改变，默认 Segment 的个数是 16 个，你也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发。 JDK1.8 JDK1.8后其底层存储结构由 Segment 数组 + HashEntry 数组 + 链表 进化成了 Node 数组 + 链表 / 红黑树 ，如下图所示： 当冲突链表达到一定长度时，链表会转换成红黑树。 这也导致了JDK1.8和JDK1.7中ConcurrentHashMap的另外一个区别是： Java7 中 ConcruuentHashMap 使用的分段锁，也就是每一个 Segment 上同时只有一个线程可以操作；而 Java8 中的 ConcruuentHashMap 使用的 Synchronized 锁加 CAS 的机制。 参考资料 https://pdai.tech/md/java/collection/java-map-TreeMap&amp;TreeSet.html https://javaguide.cn/java/collection/java-collection-questions-02 https://www.jianshu.com/p/6c95f8216950 https://www.cnblogs.com/xiaoxi/p/6170590.html https://mp.weixin.qq.com/s/AHWzboztt53ZfFZmsSnMSw","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Collection子接口之Queue","slug":"2 后端/Java/Java容器/4. Collection子接口之Queue","date":"2022-01-26T14:34:49.000Z","updated":"2022-06-11T12:30:35.622Z","comments":true,"path":"b00da1522087/","link":"","permalink":"http://rookieyin.github.io/b00da1522087/","excerpt":"Queue是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。 Queue接口下面又一个子接口Deque，是双端队列， 在队列的两端均可以插入或删除元素。 ArrayDeque和LinkedList实现了Deque接口，PriorityQueue和LinkedList实现了Queue接口。下面主要介绍ArrayDeque和PriorityQueue两个类。","text":"Queue是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。 Queue接口下面又一个子接口Deque，是双端队列， 在队列的两端均可以插入或删除元素。 ArrayDeque和LinkedList实现了Deque接口，PriorityQueue和LinkedList实现了Queue接口。下面主要介绍ArrayDeque和PriorityQueue两个类。 ArrayDeque 从名字可以看出ArrayDeque底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即循环数组(circular array)，也就是说数组的任何一点都可能被看作起点或者终点。ArrayDeque是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入null元素。 如上图所示，head指向首端第一个有效元素，tail指向尾端第一个可以插入元素的空位。因为是循环数组，所以head不一定总等于0，tail也不一定总是比head大。 ProorityQueue PriorityQueue 是在 JDK1.5 中被引入的, 其与 Queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。 元素大小的评判可以通过元素本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器。 Java中PriorityQueue实现了Queue接口，不允许放入null元素；其通过堆实现，具体说是通过完全二叉树(complete binary tree)实现的小顶堆(任意一个非叶子节点的权值，都不大于其左右子节点的权值)，也就意味着可以通过数组来作为PriorityQueue的底层实现。 其特点总结如下： PriorityQueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据。 PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。 PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。 PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。 参考资料 https://pdai.tech/md/java/collection/java-collection-PriorityQueue.html https://javaguide.cn/java/collection/java-collection-questions-01","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Collection子接口之Set","slug":"2 后端/Java/Java容器/3. Collection子接口之Set","date":"2022-01-25T14:34:49.000Z","updated":"2022-06-11T12:30:45.699Z","comments":true,"path":"e633493f51d0/","link":"","permalink":"http://rookieyin.github.io/e633493f51d0/","excerpt":"Set接口下的三种类HashSet、LinkedHashSet、TreeSet和Map接口中的HashMap、LinkedHashMap、TreeMap是一一对应的。前者基本上都是对后者的包装。","text":"Set接口下的三种类HashSet、LinkedHashSet、TreeSet和Map接口中的HashMap、LinkedHashMap、TreeMap是一一对应的。前者基本上都是对后者的包装。 HashSet HashSet是对HashMap的简单包装，对HashSet的函数调用都会转换成合适的HashMap方法，因此HashSet的实现非常简单，只有不到300行代码。 1234567891011121314151617//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123; ...... private transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125; LinkedHashSet LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说LinkedHashSet里面有一个LinkedHashMap(适配器模式)。 1234567891011121314public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; ...... // LinkedHashSet里面有一个LinkedHashMap public LinkedHashSet(int initialCapacity, float loadFactor) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125; TreeSet TreeSet也只是对TreeMap进行了包装，里面有一个TreeMap。 1234567891011121314151617// TreeSet是对TreeMap的简单包装public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable&#123; ...... private transient NavigableMap&lt;E,Object&gt; m; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public TreeSet() &#123; this.m = new TreeMap&lt;E,Object&gt;();// TreeSet里面有一个TreeMap &#125; ...... public boolean add(E e) &#123; return m.put(e, PRESENT)==null; &#125; ......&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Collection子接口之List","slug":"2 后端/Java/Java容器/2. Collection子接口之List","date":"2022-01-24T14:34:49.000Z","updated":"2022-06-11T12:31:18.293Z","comments":true,"path":"88548635ce75/","link":"","permalink":"http://rookieyin.github.io/88548635ce75/","excerpt":"本文主要介绍List接口下的ArrayList和LinkedList两个类。至于Vector类，其实现和ArrayList十分相似，底层都是Object[]，主要区别在于Vector是线程安全的，里面所有方法都被synchronized修饰。 尽量减少使用Vector，尽管它是线程安全的，但是和ArrayList相比，效率大大降低。","text":"本文主要介绍List接口下的ArrayList和LinkedList两个类。至于Vector类，其实现和ArrayList十分相似，底层都是Object[]，主要区别在于Vector是线程安全的，里面所有方法都被synchronized修饰。 尽量减少使用Vector，尽管它是线程安全的，但是和ArrayList相比，效率大大降低。 ArrayList ArrayList实现了List接口，是顺序容器，即元素存放的数据与放进去的顺序相同，允许放入null元素，底层通过数组实现。除该类未实现同步外，其余跟Vector大致相同。每个ArrayList都有一个容量(capacity)，表示底层数组的实际大小，容器内存储元素的个数不能多于当前容量。当向容器中添加元素时，如果容量不足，容器会自动增大底层数组的大小。其特点如下： 底层通过数组实现，允许放入null元素； 数组容量不够时可以动态扩容（调用grow()方法约为原大小1.5倍，代价较大，应尽量避免）； 实现了RandomAccess接口，支持随机访问； size()，isEmpty()，get()，set()方法都在常数时间内完成； 为追求效率，ArrayList没有实现同步(synchronized) ，如需用到多线程，可用Vector代替。 注： 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。 LinkedList LinkedList同时实现了List接口和Deque接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列(Queue)，同时又可以看作一个栈(Stack)。当你需要使用栈或者队列时，可以考虑使用LinkedList，一方面是因为Java官方已经声明不建议使用Stack类，更遗憾的是，Java里根本没有一个叫做Queue的类(它是个接口名字)。关于栈或队列，现在的首选是ArrayDeque，它有着比LinkedList(当作栈或队列使用时)有着更好的性能。其特点如下： 底层通过双向链表实现 所有和下标相关的操作都是线性时间 为追求效率LinkedList没有实现同步(synchronized)，如果需要多个线程并发访问，可以先采用Collections.synchronizedList()方法对其进行包装。 参考资料 https://pdai.tech/md/java/collection/java-collection-ArrayList.html https://pdai.tech/md/java/collection/java-collection-LinkedList.html https://javaguide.cn/java/collection/arraylist-source-code/","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Java集合概述","slug":"2 后端/Java/Java容器/1. Java集合概述","date":"2022-01-23T14:34:49.000Z","updated":"2022-06-11T12:31:26.365Z","comments":true,"path":"38694dd49f4c/","link":"","permalink":"http://rookieyin.github.io/38694dd49f4c/","excerpt":"Java集合，也叫作容器，主要由Collection和Map两大顶层接口转化而来，其中Collection下面又有List，Queue和Set三大接口。Java集合框架图如下图所示：","text":"Java集合，也叫作容器，主要由Collection和Map两大顶层接口转化而来，其中Collection下面又有List，Queue和Set三大接口。Java集合框架图如下图所示： Collection接口 List接口 ArrayList：基于动态数组实现，支持随机访问。 Vector：和ArrayList类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问（ JDK1.6 之前为循环链表，JDK1.7 取消了循环 ）。 Set接口 HashSet：底层采用HashMap保存元素，支持快速查找 。 TreeSet：基于红黑树实现（有序，唯一），可以范围查找。 LinkedHashSet：是HashSet的子类，内部通过LinkedHashMap实现的。 Queue接口 PriorityQueue：基于堆结构实现优先队列。 ArrayQueue： 基于可变长的数组和双指针来实现。 LinkedList：它也实现了Queue接口。 Map接口 TreeMap：基于红黑树实现的。 HashMap： JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间 。 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 参考链接 https://pdai.tech/md/java/collection/java-collection-all.html https://javaguide.cn/java/collection/java-collection-questions-01","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"Java抽象类与接口","slug":"2 后端/Java/Java基础知识/1 Java抽象类与接口","date":"2022-01-22T14:34:49.000Z","updated":"2022-06-11T13:14:17.347Z","comments":true,"path":"bffbbbcd67c3/","link":"","permalink":"http://rookieyin.github.io/bffbbbcd67c3/","excerpt":"抽象类和接口都是OOP的抽象表现。两者有相似的地方，也有非常本质的区别，本文简单介绍下Java中的抽象类和接口。","text":"抽象类和接口都是OOP的抽象表现。两者有相似的地方，也有非常本质的区别，本文简单介绍下Java中的抽象类和接口。 抽象类 看抽象类之前先了解下抽象方法。所谓抽象方法，就是用abstract修饰的方法，其特殊之处在于只需要给出方法定义，无需具体实现，方法的具体实现交由子类完成。 抽象类：就是用abstract修饰的类。抽象类中的方法可以是抽象方法，也可以是非抽象方法。抽象类的本质在于：对若干种事物的共同本质进行抽象，有点道生一，一生二，二生三，三生万物的意思再里面。 比如：苹果、葡萄、菠萝、猕猴桃等等都有一个共同属性，即它们都是水果，那么我们可以从这些物品里面里面抽象出一个“水果”的概念。 那么抽象类和普通类有什么区别呢？ 抽象类不能new 一个对象 抽象方法必须是public或者protected，因为如果是private，那么不能被子类继承，子类就无法实现该抽象方法。缺省情况下，默认为public。 如果一个类继承于一个抽象类，则该子类必须实现父类的抽象方法。如果子类不实现，则也需要将该方法定义为抽象方法。 接口 看完抽象类，接下来看看接口。前面提到，抽象类是对事物进行抽象，接口则不同，它是对方法的抽象（这一点是抽象类和接口之间最本质的区别）。 什么叫做对方法的抽象？比如手机、电脑、平板、MP3都有播放音乐的功能，那么我们可以抽象出一个“播放音乐”的接口，实现了该接口的类都具备播放音乐的功能。 在Java中，接口通过interface关键字标识，比如public interface InterfaceA&#123; &#125;。在接口中，我们可以定义哪些东西呢？ 变量 接口中的变量，隐式指定为（并且只能是）public static final变量 方法 接口中的方法，隐式指定为（并且只能是）public abstract方法，因此不能有具体实现 另外，在Java中一个类允许实现多个接口，并且如果一个类实现了某个接口，必须实现该接口中的所有方法。这是抽象类和接口的两个重要区别。 总结 前面介绍了Java中的抽象类和接口，它们都是OOP中抽象特征的体现，这里简单总结下二者之间的区别： 设计本质：抽象类是对事务的抽象（大家都具有某种特性），而接口是对方法的抽象（大家都具有某种功能）。 语法 抽象类通过继承(extend)来使用，接口通过实现(implement)来使用，一个类只能继承自一个父类，但是可以实现多个接口。 抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是public static final类型的； 接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法； 抽象类可以提供成员方法的实现细节，而接口中只能存在public abstract 方法。 参考资料 https://www.cnblogs.com/dolphin0520/p/3811437.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"抽象类","slug":"抽象类","permalink":"http://rookieyin.github.io/tags/%E6%8A%BD%E8%B1%A1%E7%B1%BB/"},{"name":"接口","slug":"接口","permalink":"http://rookieyin.github.io/tags/%E6%8E%A5%E5%8F%A3/"}]},{"title":"Java泛型","slug":"2 后端/Java/Java基础知识/2 Java泛型","date":"2022-01-21T14:34:49.000Z","updated":"2022-06-11T12:03:42.988Z","comments":true,"path":"b28795f96353/","link":"","permalink":"http://rookieyin.github.io/b28795f96353/","excerpt":"泛型是个啥 所谓泛型，“泛”即宽泛，也就是宽泛的类型，专业一点也叫作“参数化类型”。当使用泛型的时候，意味着我们的代码对类型没有严格要求，可以是Integer，可以是String，也可以是任意其他类型，通常用个T表示。","text":"泛型是个啥 所谓泛型，“泛”即宽泛，也就是宽泛的类型，专业一点也叫作“参数化类型”。当使用泛型的时候，意味着我们的代码对类型没有严格要求，可以是Integer，可以是String，也可以是任意其他类型，通常用个T表示。 泛型的目的在于：我们能够写出适用于任何类型的模板代码。举个例子，JDK中的ArrayList类，如果按照如下方式编写： 12345678public class ArrayList &#123; //用Object数组存储 private Object[] array; private int size; public void add(Object e) &#123;...&#125; public void remove(int index) &#123;...&#125; public Object get(int index) &#123;...&#125;&#125; 如果用上述ArrayList存储String类型，会有这么几个缺点： （1）需要强制转换类型；（2）不方便，容易出错。例如，代码可能要这样写： 1234ArrayList list = new ArrayList();list.add(&quot;Hello&quot;);// 获取到Object，必须强制转型为String:String first = (String) list.get(0); 但是如果我们用上泛型，就能构建了一个能用于任何类型的模板： 1234567public class ArrayList&lt;T&gt; &#123; private T[] array; private int size; public void add(T e) &#123;...&#125; public void remove(int index) &#123;...&#125; public T get(int index) &#123;...&#125;&#125; 现在我们可以轻松构建存储任意类型的ArrayList，使用时也不需要进行强制类型转换： 12ArrayList&lt;Integer&gt; intList = new ArrayList&lt;Integer&gt;();ArrayList&lt;String&gt; strList = new ArrayList&lt;String&gt;(); 泛型怎么用 前面我们介绍了什么是泛型，以及泛型有什么用，那么泛型有哪些用法呢？ Java中泛型有3种使用方式：泛型类、泛型接口、泛型方法。 泛型类 123456789101112131415161718class 类名称 &lt;泛型标识：可以随便写任意标识号，标识指定的泛型的类型&gt;&#123; private 泛型标识 /*（成员变量类型）*/ var; ..... &#125;&#125;//就是把原来的具体类型都换成泛型标识Tclass Example&lt;T&gt;&#123; private T val; public Example(T val)&#123; this.val = val; &#125; public T getVal()&#123; return val; &#125;&#125; 泛型接口 和泛型类的用法基本一样。 1234//定义一个泛型接口public interface Generator&lt;T&gt; &#123; public T next();&#125; 泛型方法 泛型方法也比较简单：普通方法的参数、返回值都是具体类型，如果把它们都改成泛型标识，就得到了一个泛型方法。 下面举个例子： 12345678910111213141516171819class DataHolder&lt;T&gt;&#123; T item; public void setData(T t) &#123; this.item=t; &#125; public T getData() &#123; return this.item; &#125; /** * 泛型方法 * @param e */ public &lt;E&gt; void PrinterInfo(E e) &#123; System.out.println(e); &#125;&#125; 需要注意的是：泛型方法既可以存在于泛型类中，也可以存在于非泛型类中。泛型方法和泛型类的区别在于：泛型方法是在调用该方法时才指定具体类型，而泛型类是在new一个实例的时候指定具体类型。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"泛型","slug":"泛型","permalink":"http://rookieyin.github.io/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"Java基本数据类型","slug":"2 后端/Java/Java基础知识/3 Java基本数据类型","date":"2022-01-20T14:34:49.000Z","updated":"2022-06-11T12:03:53.952Z","comments":true,"path":"a6ecc8595f35/","link":"","permalink":"http://rookieyin.github.io/a6ecc8595f35/","excerpt":"本文简单聊一聊Java中基本数据类型的相关知识，主要包括： Java中基本数据类型的基础知识，包括种类、占用字节数、范围等 基本类型对应的包装类型 不同数据类型之间的转换","text":"本文简单聊一聊Java中基本数据类型的相关知识，主要包括： Java中基本数据类型的基础知识，包括种类、占用字节数、范围等 基本类型对应的包装类型 不同数据类型之间的转换 基本数据类型 下表总结了Java中8种基本数据类型的基本信息： 基本类型 位数 字节 默认值 取值范围 byte 8 1 0 -128 ~ 127 short 16 2 0 -32768 ~ 32767 int 32 4 0 -2147483648 ~ 2147483647 long 64 8 0L -9223372036854775808 ~ 9223372036854775807 char 16 2 ‘u0000’ 0 ~ 65535 float 32 4 0f 1.4E-45 ~ 3.4028235E38 double 64 8 0d 4.9E-324 ~ 1.7976931348623157E308 boolean 1 false true、false 注：boolean具体占用多少字节，依赖于JVM厂商的具体实现。 另外，Java 的每种基本类型所占存储空间的大小不会像其他大多数语言那样随机器硬件架构的变化而变化。这种所占存储空间大小的不变性是 Java 程序比用其他大多数语言编写的程序更具可移植性的原因之一 包装类型 Java中8种基本数据类型都有其对应的包装类型： Byte、Short、Integer、Long、Float、Double、Character、Boolean 。 基本类型 V.S 包装类型 有了基本类型，为什么还要包装类型呢？Java是OO语言，开发中用到的最多的还是对象。基本数据类型和包装类型之间的区别如下： 默认值，包装类型，不赋值的情况下为null，而基本类型有非null默认值； 泛型，包装类型可以用于泛型，基本类型不行； 存放位置，对于局部变量，基本类型存放于栈，对于类成员变量，基本类型存放于堆。包装类型是对象，我们知道对象基本都是存放在堆中的； 占用空间，根据存放位置，我们就可以知道，基本类型相较于包装类型，占用空间很少。 常量池技术 Java中大部分包装类型都使用了常量池技术。 Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True or False。 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。 只有超出对应范围才会去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。 下面是一个例子： 123456Integer a = 10;Integer b = 10;System.out.println(a == b);//trueInteger c = 345;Integer d = 345;System.out.println(c == d);//false 不过下面的代码，会输出false： 123Integer i1 = 40;Integer i2 = new Integer(40);System.out.println(i1==i2); 因为 Integer i1=40 这一行代码会发生装箱，也就是说这行代码等价于 Integer i1=Integer.valueOf(40) 。因此，i1 直接使用的是常量池中的对象。而Integer i2 = new Integer(40) 会直接创建新的对象。 下面我们再了解下Java的自动装箱、拆箱技术。 自动装/拆箱 装箱：基本类型包装成对应的包装类型； 拆箱：包装类型转换成对应的基本类型。 比如：Integer i = 10;会自动完成装箱，new一个Integer对象；而int n = i;会自动完成拆箱，把Integer对象的值赋给n。通过反编译字节码，可以发现Java自动装/拆箱的原理为： 装箱，就是调用包装类的valueOf()方法； 拆箱，就是调用包装类的xxxValue()方法。 不过需要注意的是： 如果频繁拆装箱的话，也会严重影响系统的性能。我们应该尽量避免不必要的拆装箱操作。 类型转换 下图展示了各种数据类型中的合法转换： 其中实现表示数据不会丢失，虚线表示可能有数据丢失。常见的类型转换有两种： 运算时自动转换 当一个二元运算符作用于两个数时，两个操作数首先被转换为同一类型，转换的原则如下： （1）如果两个操作数之中有一个为double类型，另一个转换为double类型； （2）否则，如果两个操作数之中有一个为float类型，另一个被转换为float类型； （3）否则，如果两个操作数之中有一个为long类型，另一个被转换为long类型； （4）否则，两个操作数都被转换为int类型。 强制转换 比如float a = 1.5; int b = (int)a;强制转换。 参考资料 https://javaguide.cn/java/basis/java-basic-questions-01.html https://blog.csdn.net/Pan_Yang_/article/details/81008058","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"数据类型","slug":"数据类型","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"Java日期类总结","slug":"2 后端/Java/Java基础知识/4 Java日期类总结","date":"2022-01-19T14:34:49.000Z","updated":"2022-06-11T12:04:03.791Z","comments":true,"path":"5b5e534ec125/","link":"","permalink":"http://rookieyin.github.io/5b5e534ec125/","excerpt":"JDK8之前——旧时间日期类 java.lang.System类 System类提供了一个公共的静态方法currentTimesMillis()来返回当前时间距离1970年1月1日0时0分0秒之间以毫秒为单位的时间差，也叫时间戳。","text":"JDK8之前——旧时间日期类 java.lang.System类 System类提供了一个公共的静态方法currentTimesMillis()来返回当前时间距离1970年1月1日0时0分0秒之间以毫秒为单位的时间差，也叫时间戳。 1234public static void main(String[] args)&#123; long time = System.currentTimeMillis(); System.out.println(time);// 打印：1652875534552&#125; java.util.Date 和 java.sql.Date java.util.Date java.util.Date的构造函数主要有下面4种： 1234public Date() &#123;&#125;//系统当前时间戳public Date(long date) &#123;&#125;//从1970年1月1日0时开始的毫秒数public Date(int year, int month, int date)&#123;&#125;//传入年（最小1900）月（0-11）日（1-31）参数public Date(int year, int month, int date, int hrs, int min, int sec) &#123;&#125;//年月日时分秒，秒可选参数，同样都是从0开始 常用的方法有2个toString()和getTime()： 123Date date = new Date();System.out.println(date.toString());// Wed May 18 20:17:23 CST 2022System.out.println(date.getTime());// 1652876243161 java.sql.Date 除了java.sql.Date之外，还有java.sql.Time和java.sql.Timestamp。它们3个都是继承自java.util.Date类，主要用于处理数据库相关的日期格式，这里简单介绍下java.sql.Date。 java.sql.Date常用的构造器就是public Date(long date)()，传一个毫秒时间戳。 java.sql.Date和java.util.Date最主要的区别就是，截取了时间信息，只保留日期信息： 123java.sql.Date date = new java.sql.Date(1652876243161L);// 传入时间戳System.out.println(date.toString());//2022-05-18System.out.println(date.getTime());//1652876243161 java.sql.Date和java.util.Date之间的转换？ 12345678// 方式一： 多态的做法，强转Date date1 = new java.sql.Date(1652876243161L);java.sql.Date date2 = (java.sql.Date)date1;// 方式二：构造函数传参Date date3 = new Date();java.sql.Date date4 = new java.sql.Date(date3.getTime());System.out.println(date4.toString()); java.text.SimpleDateFormat类 这个类主要用于日期的格式化和解析，即字符串和日期之间的相互转换。下面通过一个例子，看看如何创建SimpleDateFormat对象，以及如何解析和格式化日期。 1234567891011121314151617181920212223// 1.实例化：使用默认的构造器SimpleDateFormat sdf = new SimpleDateFormat();// 2.创建Date对象Date date = new Date();System.out.println(date); // Wed May 18 20:45:51 CST 2022// 3.格式化String date2 = sdf.format(date); //参数是Date类型的System.out.println(date2); // 22-5-18 下午8:45// 4.解析String str = &quot;22-5-18 下午8:45&quot;;Date date3 = sdf.parse(str);System.out.println(date3);//Wed May 18 20:45:00 CST 2022//***************************//使用带参的构造器//hh:mm:ss表示12小时制，HH:mm:ss表示24小时制SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;);String s = simpleDateFormat.format(new Date());System.out.println(s);//2022-05-18 08:45:51//解析String s1 = &quot;2022-05-18 08:45:51&quot;;Date date4 = simpleDateFormat.parse(s1);System.out.println(date4);//Wed May 18 08:45:51 CST 2022 java.util.Calendar日历类 Calendar是一个抽象基类， 通过Calendar对象，我们可以像有个“日历”一样使用日期数据。比如，某个日期是那一年中的第几天？是那个月份的第几天？是那一周的第几天？等等。我们还可以通过Calendar对象实现一些简单的计算，比如add操作，给日期加几天或者减几天等等。 因为Calendar是抽象类，我们不能直接new一个日历对象，需要通过getInstance()获取一个日历对象，该方法默认返回一个GregorianCalendar实例。下面我们通过一个例子，简单了解下Canlendar的使用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//获取一个日历实例Calendar cal = Calendar.getInstance(); // GregorianCalendarSystem.out.println(&quot;Calendar&#x27;s toString() is : &quot; + cal + &quot;\\n&quot;);System.out.println(&quot;Time zone is: &quot; + cal.getTimeZone() + &quot;\\n&quot;);//通过getTime获取时间戳，返回Date对象Date date = cal.getTime();//Current date and time in Date&#x27;s toString() is : Wed May 18 21:07:49 CST 2022System.out.println(&quot;Current date and time in Date&#x27;s toString() is : &quot; + date + &quot;\\n&quot;);// 获取各种field信息//Year : 2022System.out.println(&quot;Year : &quot; + cal.get(Calendar.YEAR));//Month : 4，注意月份是从0开始，4表示5月System.out.println(&quot;Month : &quot; + cal.get(Calendar.MONTH));//Day of Month : 18System.out.println(&quot;Day of Month : &quot; + cal.get(Calendar.DAY_OF_MONTH));//Day of Week : 4，周日是1,4表示星期三System.out.println(&quot;Day of Week : &quot; + cal.get(Calendar.DAY_OF_WEEK));//Day of Year : 138System.out.println(&quot;Day of Year : &quot; + cal.get(Calendar.DAY_OF_YEAR));//Week of Year : 21System.out.println(&quot;Week of Year : &quot; + cal.get(Calendar.WEEK_OF_YEAR));//Week of Month : 3System.out.println(&quot;Week of Month : &quot; + cal.get(Calendar.WEEK_OF_MONTH));//Day of the Week in Month : 3System.out.println(&quot;Day of the Week in Month : &quot; + cal.get(Calendar.DAY_OF_WEEK_IN_MONTH));//Hour : 9，12小时制System.out.println(&quot;Hour : &quot; + cal.get(Calendar.HOUR));//AM PM : 1System.out.println(&quot;AM PM : &quot; + cal.get(Calendar.AM_PM));//Hour of the Day : 21，24小时制System.out.println(&quot;Hour of the Day : &quot; + cal.get(Calendar.HOUR_OF_DAY));//Minute : 7System.out.println(&quot;Minute : &quot; + cal.get(Calendar.MINUTE));//Second : 49System.out.println(&quot;Second : &quot; + cal.get(Calendar.SECOND));// 加上若干天，可以是负数Calendar calTemp;calTemp = (Calendar) cal.clone();calTemp.add(Calendar.DAY_OF_YEAR, -365);//365 days ago, it was: Tue May 18 21:07:49 CST 2021System.out.println(&quot;365 days ago, it was: &quot; + calTemp.getTime());//加上若干个小时calTemp = (Calendar) cal.clone();calTemp.add(Calendar.HOUR_OF_DAY, 11);//After 11 hours, it will be: Thu May 19 08:07:49 CST 2022System.out.println(&quot;After 11 hours, it will be: &quot; + calTemp.getTime());// Roll，回滚若干个小时calTemp = (Calendar) cal.clone();calTemp.roll(Calendar.HOUR_OF_DAY, 11);System.out.println(&quot;Roll 11 hours, it will be: &quot; + calTemp.getTime());System.out.println(); JDK8之后——新时间日期类 为什么引进新日期类 JDK 1.0中包含了一个java.util.Date类，但是它的大多数方法已经在JDK 1.1引入Calendar类之后被弃用了。而Calendar并不比Date好多少。它们面临的问题是： 可变性：像日期和时间这样的类应该是不可变的。 偏移性：Date中的年份是从1900开始的，而月份都从0开始。 格式化：格式化只对Date有用，Calendar则不行。 此外，它们也不是线程安全的；不能处理闰秒等。 JDK8中引进了新的时间API是java.time，新的 java.time 中包含了所有关于本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。历史悠久的 Date 类新增了 toInstant() 方法，用于把 Date 转换成新的表示形式。这些新增的本地化时间日期 API 大大简化了日期时间和本地化的管理。 LocalDate、LocalTime和LocalDateTime LocalDate、LocalTime、LocalDateTime 类是其中较重要的几个类，它们的实例是不可变的对象，分别表示使用 ISO-8601日历系统的日期、时间、日期和时间。它们提供了简单的本地日期或时间，并不包含当前的时间信息，也不包含与时区相关的信息。 LocalDate代表IOS格式（yyyy-MM-dd）的日期,可以存储 生日、纪念日等日期。 LocalTime表示一个时间，而不是日期。 LocalDateTime是用来表示日期和时间的，这是一个最常用的类之一。 同样，使用一个类还是从如何实例化和有什么方法使用开始。常用方法如下： 方法 描述 now() / now(ZoneId zone) 静态方法，根据当前时间创建对象或者指定时区 of() 静态方法，根据指定日期/时间创建对象 getDayOfMonth()/getDayOfYear() 获取所在月份中第几天（1~31）/所在年中第几天（1 ~ 366） getDayOfWeek() 获得星期几，返回枚举值，比如“WEDNESDAY”，可以通过getValue()转成3 getMonth() 获得月份，返回枚举值，比如“MAY”，同样可以通过getValue()转成5 getMonthValue()/getYear() 获得月份的值，比如“18”，表示第18天 getHour()/getMinute()/getSecond() 返回小时、分钟和秒 withDayOfMonth()/withDayOfYear()/withMonth()/withYear() 将月份天数、年份天数、月份、年份修改为指定的值并返回新的对象 plusDays()/plusWeeks()/plusMonths()/plusYears()/plusHours() 向当前对象添加几天、几周、几个月、几年、几小时 minusMonths()/minusWeeks()/minusDays()/minusYears()/minusHours() 从当前对象减去几天、几周、几个月、几年、几小时 Instant类 Instant类类似于Date类， java.time包通过值类型Instant提供机器视图，不提供处理人类意义上的时间单位。Instant表示时间线上的一点，而不需要任何上下文信息，例如，时区。概念上讲，它只是简单的表示自1970年1月1日0时0分0秒（UTC）开始的秒数。因为java.time包是基于纳秒计算的，所以Instant的精度可以达到纳秒级。 Instant的实例化和常用方法如下： 方法 说明 now() 静态方法，返回默认UTC时区的Instant类的对象 ofEpochMilli(long EpochMilli) 静态方法，返回在1970-01-01 00:00:00基础上加上指定毫秒数之后的Instant类的对象 atOffset(ZoneOffset offset) 结合即时的偏移来创建一个 OffsetDateTime toEpochMilli() 返回1970-01-01 00:00:00到当前时间的毫秒数，即为时间戳 1234567891011121314151617@Testpublic void test2()&#123; // now()：获取本初子午线当地的标准时间 Instant instant = Instant.now(); System.out.println(instant); // 2019-10-31T06:01:04.921252200Z // 在UTC时区的基础上加上8个时区（北京时间） OffsetDateTime offsetDateTime = instant.atOffset(ZoneOffset.ofHours(8)); System.out.println(offsetDateTime); // 2019-10-31T14:01:04.921252200+08:00 // 获取时间戳 System.out.println(instant.toEpochMilli()); // 1572501664921 // ofEpochMilli()：通过给定的时间戳，获取Instant的实例 Instant instant1 = Instant.ofEpochMilli(1572415933220L); System.out.println(instant1); // 2019-10-30T06:12:13.220Z&#125; DateTimeFormatter类 DateTimeFormatter类类似于SimpleDateFormat类，用于格式化与解析日期或时间。java.time.format.DateTimeFormatter 类：该类提供了三种格式化方法： 预定义的标准格式。如：ISO_LOCAL_DATE_TIME;ISO_LOCAL_DATE;ISO_LOCAL_TIME 本地化相关的格式。如：ofLocalizedDateTime(FormatStyle.LONG) 自定义的格式。如：ofPattern(“yyyy-MM-dd HH:mm:ss”)，常用是这种。 方 法 描 述 ofPattern(String pattern) 静态方法，返回一个指定字符串格的DateTimeFormatter format(TemporalAccessor t) 格式化一个日期、时间，返回字符串 parse(CharSequence text) 将指定格式的字符序列解析为一个日期、时间 12345678910111213141516171819202122232425262728293031@Testpublic void testDateTimeFormatter()&#123; // 实例化方式一 预定义的标准格式。如：`ISO_LOCAL_DATE_TIME;ISO_LOCAL_DATE;ISO_LOCAL_TIME` DateTimeFormatter formatter = DateTimeFormatter.ISO_LOCAL_DATE_TIME; LocalDateTime localDateTime = LocalDateTime.now(); // 格式化：将日期转换为字符串，需要传入一个TemporalAccessor类型的，而LocalDate、LocalTime和LocalDateTime都是 String str1 = formatter.format(localDateTime); System.out.println(localDateTime); // 2019-10-31T14:16:15.801854 System.out.println(str1); // 2019-10-31T14:16:15.801854 // 使用标准格式的格式化出来结果是：2019-10-31T14:16:15.801854 // 解析：解析的字符串也必须是标准格式的字符创 TemporalAccessor parse = formatter.parse(&quot;2020-10-31T14:16:15.801854&quot;); System.out.println(parse); // &#123;&#125;,ISO resolved to 2020-10-31T14:16:15.801854 // 实例化方式二：本地化相关的格式 DateTimeFormatter formatter1 = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.SHORT);// 使用FormatStyle.SHORT进行格式化 // 格式化 String str2 = formatter1.format(localDateTime); System.out.println(str2); // 格式化后的格式：2019/10/31 下午2:22 // 实例化方式三：自定义格式 DateTimeFormatter formatter2 = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 格式化 String str3 = formatter2.format(LocalDateTime.now()); System.out.println(str3);//2022-05-18 22:10:32 // 解析 TemporalAccessor parse1 = formatter2.parse(&quot;2019-10-31 02:30:29&quot;); System.out.println(parse1);&#125; 参考资料 https://www3.ntu.edu.sg/home/ehchua/programming/java/DateTimeCalendar.html https://segmentfault.com/a/1190000020869634","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"日期","slug":"日期","permalink":"http://rookieyin.github.io/tags/%E6%97%A5%E6%9C%9F/"}]},{"title":"Java字符串","slug":"2 后端/Java/Java基础知识/5 Java字符串","date":"2022-01-18T14:34:49.000Z","updated":"2022-06-11T12:06:24.323Z","comments":true,"path":"50afd504dd87/","link":"","permalink":"http://rookieyin.github.io/50afd504dd87/","excerpt":"本文大部分内容转自：深入理解Java String类型","text":"本文大部分内容转自：深入理解Java String类型 String的不可变性 String类部分代码如下： 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; 可以看到String类被final关键字修饰，表明String类不可以被继承。同时存储数据的char数组也被final关键字修饰，表示String的值不可以修改。 为什么 Java 要这样设计？ 保证 String 对象安全性，避免 String 被篡改。 保证 hash 值不会频繁变更。 可以实现字符串常量池。通常有两种创建字符串对象的方式，一种是通过字符串常量的方式创建，如 String str=&quot;abc&quot;; 另一种是字符串变量通过 new 形式的创建，如 String str = new String(&quot;abc&quot;)。 使用第一种方式创建字符串对象时，JVM 首先会检查该对象是否在字符串常量池中，如果在，就返回该对象引用，否则新的字符串将在常量池中被创建。这种方式可以减少同一个值的字符串对象的重复创建，节约内存。 String str = new String(&quot;abc&quot;) 这种方式，首先在编译类文件时，&quot;abc&quot; 常量字符串将会放入到常量结构中，在类加载时，&quot;abc&quot; 将会在常量池中创建；其次，在调用 new 时，JVM 命令将会调用 String 的构造函数，同时引用常量池中的 &quot;abc&quot; 字符串，在堆内存中创建一个 String 对象；最后，str 将引用 String 对象。 String的性能考量 字符串拼接 字符串常量拼接，编译器会将其优化成一个常量字符串。 123456public static void main(String[] args) &#123; // 本行代码在 class 文件中，会被编译器直接优化为： // String str = &quot;abc&quot;; String str = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;; System.out.println(&quot;str = &quot; + str);&#125; 字符串变量的拼接，编译器会优化成StringBuilder的方式。 12345678public static void main(String[] args) &#123; String str = &quot;&quot;; for(int i=0; i&lt;1000; i++) &#123; // 本行代码会被编译器优化为： // str = (new StringBuilder(String.valueOf(str))).append(i).toString(); str = str + i; &#125;&#125; 但是，每次循环都会生成一个新的 StringBuilder 实例，同样也会降低系统的性能。 字符串拼接的正确方案： 如果需要使用字符串拼接，应该优先考虑 StringBuilder 的 append 方法替代使用 + 号。 如果在并发编程中，String 对象的拼接涉及到线程安全，可以使用 StringBuffer。但是要注意，由于 StringBuffer 是线程安全的，涉及到锁竞争，所以从性能上来说，要比 StringBuilder 差一些。 字符串分割 String 的 split() 方法使用正则表达式实现其强大的分割功能。而正则表达式的性能是非常不稳定的，使用不恰当会引起回溯问题，很可能导致 CPU 居高不下。 所以，应该慎重使用 split() 方法，可以考虑用 String.indexOf() 方法代替 split() 方法完成字符串的分割。如果实在无法满足需求，你就在使用 Split() 方法时，对回溯问题加以重视就可以了。 String.intern 在每次赋值的时候使用 String 的 intern 方法，如果常量池中有相同值，就会重复使用该对象，返回对象引用，这样一开始的对象就可以被回收掉。 在字符串常量中，默认会将对象放入常量池；在字符串变量中，对象是会创建在堆内存中，同时也会在常量池中创建一个字符串对象，复制到堆内存对象中，并返回堆内存对象引用。 如果调用 intern 方法，会去查看字符串常量池中是否有等于该对象的字符串，如果没有，就在常量池中新增该对象，并返回该对象引用；如果有，就返回常量池中的字符串引用。堆内存中原有的对象由于没有引用指向它，将会通过垃圾回收器回收。 注： 使用 intern 方法需要注意：一定要结合实际场景。因为常量池的实现是类似于一个 HashTable 的实现方式，HashTable 存储的数据越大，遍历的时间复杂度就会增加。如果数据过大，会增加整个字符串常量池的负担。 String、StringBuffer和StringBuilder的对比 三者都是final类，都不允许被继承； String类长度是不可变的，StringBuffer和StringBuilder类长度是可以改变的； StringBuffer类是线程安全的，StringBuilder不是线程安全的； String是不可变的对象，因此每次在对String类进行改变的时候都会生成一个新的string对象，然后将指针指向新的string对象，所以经常要改变字符串长度的话不要使用string，因为每次生成对象都会对系统性能产生影响，特别是当内存中引用的对象多了以后，JVM的GC就会开始工作，性能就会降低； 三者的使用策略，可总结为： 如果要操作少量的数据，用String ；单线程操作大量数据，用StringBuilder ；多线程操作大量数据，用StringBuffer。 不要使用String类的”+”来进行频繁的拼接，因为那样的性能极差的，应该使用StringBuffer或StringBuilder类，这在Java的优化上是一条比较重要的原则。 StringBuilder一般使用在方法内部来完成类似”+”功能，因为是线程不安全的，所以用完以后可以丢弃。StringBuffer主要用在全局变量中。 相同情况下使用 StirngBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。而在现实的模块化编程中，负责某一模块的程序员不一定能清晰地判断该模块是否会放入多线程的环境中运行，因此：除非确定系统的瓶颈是在 StringBuffer上，并且确定你的模块不会运行在多线程模式下，才可以采用StringBuilder；否则还是用StringBuffer。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"String","slug":"String","permalink":"http://rookieyin.github.io/tags/String/"}]},{"title":"MySQL调优","slug":"2 后端/MySQL/13. MySQL调优","date":"2021-12-20T12:38:14.000Z","updated":"2022-06-10T05:27:14.651Z","comments":true,"path":"f651ec7154f8/","link":"","permalink":"http://rookieyin.github.io/f651ec7154f8/","excerpt":"MySQL调优 1 使用Explain进行分析 Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有: select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数","text":"MySQL调优 1 使用Explain进行分析 Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有: select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 2 优化数据访问 减少请求的数据量 只返回必要的列: 最好不要使用 SELECT * 语句。 只返回必要的行: 使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 减少服务器端扫描的行数 最有效的方式是使用索引来覆盖查询 3 重构查询方式 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 1DELEFT FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH); 12345rows_affected = 0do &#123; rows_affected = do_query( &quot;DELETE FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000&quot;)&#125; while rows_affected &gt; 0 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有: 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 1234SELECT * FROM tabJOIN tag_post ON tag_post.tag_id=tag.idJOIN post ON tag_post.post_id=post.idWHERE tag.tag=&#x27;mysql&#x27;; 123SELECT * FROM tag WHERE tag=&#x27;mysql&#x27;;SELECT * FROM tag_post WHERE tag_id=1234;SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"Explain 命令怎么用","slug":"2 后端/MySQL/12. Explain命令怎么用","date":"2021-12-19T12:38:14.000Z","updated":"2022-06-10T05:25:13.019Z","comments":true,"path":"7d57ba8dc7c3/","link":"","permalink":"http://rookieyin.github.io/7d57ba8dc7c3/","excerpt":"Explain 命令怎么用 MySQL提供的EXPLAIN命令，可以输出SQL语句的执行计划，帮助我们分析优化SQL语句。EXPLAIN命令用法十分简单，只需要在SQL语句前面加上EXPLAIN即可。","text":"Explain 命令怎么用 MySQL提供的EXPLAIN命令，可以输出SQL语句的执行计划，帮助我们分析优化SQL语句。EXPLAIN命令用法十分简单，只需要在SQL语句前面加上EXPLAIN即可。 可参考这篇文章 id：SELECT 查询的标识符， 每个 SELECT 都会自动分配一个唯一的标识符 select_type：SELECT查询的类型 SIMPLE：表示此查询不包含UNION查询或子查询 PRIMARY：表示此查询是最外层查询 UNION：表示此查询是UNION的第二或随后的查询 DEPENDENT UNION： UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT：UNION的结果 SUBQUERY：子查询中的第一个SELECT DEPENDENT SUBQUERY：子查询中第一个SELECT，取决于外面的查询，即子查询依赖于外层查询结果 table：查询涉及到的表或衍生表 partitions：匹配的分区 type: 查询类型，它提供了判断查询是否高效的重要依据依据。通过 type 字段，我们判断此次查询是 全表扫描 还是 索引扫描 等 。 system： 表中只有一条数据，这个类型是特殊的 const 类型 。 const： 针对主键或唯一索引的等值查询扫描，最多只返回一行数据。const 查询速度非常快，因为它仅仅读取一次即可。 eq_ref： 此类型通常出现在多表的 join 查询，表示对于前表的每一个结果，都只能匹配到后表的一行结果。并且查询的比较操作通常是 =，查询效率较高。 ref： 此类型通常出现在多表的 join 查询，针对于非唯一或非主键索引，或者是使用了 最左前缀 规则索引的查询。 range： 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录。这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中。当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL，并且 key_len 字段是此次查询中使用到的索引的最长的那个。 index： 表示全索引扫描(full index scan)，和 ALL 类型类似，只不过 ALL 类型是全表扫描，而 index 类型则仅仅扫描所有的索引，而不扫描数据。index 类型通常出现在：所要查询的数据直接在索引树中就可以获取到，而不需要扫描数据。当是这种情况时，Extra 字段 会显示 Using index。 all： 表示全表扫描，这个类型的查询是性能最差的查询之一。通常来说，我们的查询不应该出现 ALL 类型的查询，因为这样的查询在数据量大的情况下，对数据库的性能是巨大的灾难。如一个查询是 ALL 类型查询，那么一般来说可以对相应的字段添加索引来避免。 possible_keys：此次查询中可能选用的索引 key：此次查询中确切使用到的索引. key_len：查询优化器使用的索引字节数，可以用来评估组合索引是否完全被使用，或只有最左部分字段被使用到 ref：哪个字段或常数与 key 一起被使用，比如下面这个语句： 1EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.`id` = order_info.`user_id` AND user_info.`name` = &#x27;xys&#x27; 第一行中const表示name_index索引使用了常量’xys’，第二行中test.user_info.id表示user_product_detail_index和user_info表中的id字段一起使用了。 rows: 显示此查询一共扫描了多少行， 这个是一个估计值，通常rows越少越好。 filtered: 针对预估的需要读取行数，经过搜索条件过滤后剩余记录条数的百分比。 extra: 额外的信息，常见的有一下几种： Using filesort：表示MySQL需要额外的排序操作，不能通过索引顺序达到排序效果。 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大。 Using index： “覆盖索引扫描”，表示查询在索引树中就可查找所需数据，不用扫描表数据文件，往往说明性能不错。 Using temporary： 查询有使用临时表，一般出现于排序，分组和多表 join 的情况，查询效率不高，建议优化。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"九大排序算法总结","slug":"4 算法/九大排序算法总结","date":"2021-12-19T05:45:52.000Z","updated":"2022-06-01T12:44:38.132Z","comments":true,"path":"20925e201721/","link":"","permalink":"http://rookieyin.github.io/20925e201721/","excerpt":"本文简单总结一下九大排序算法的思路，并给出java版本代码。","text":"本文简单总结一下九大排序算法的思路，并给出java版本代码。 冒泡排序 核心： 每次比较相邻两个元素，大的放后面，这样一轮下来，数组中最大的元素就跑到最后面去了，就像河底的气泡冒到水面一样。 示意图： 代码： 12345678910111213141516171819202122232425262728293031public static void bubbleSort(int[] arr)&#123; //复杂度：O(n^2) for(int i = 1; i &lt; arr.length; ++i)&#123; for(int j = 0; j &lt; arr.length - i ; ++j)&#123; //采用&gt;，排序稳定 if(arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; &#125;&#125;//带标记的冒泡排序public static void bubbleSortWithFlag(int[] arr)&#123; boolean flag; for(int i = 1; i &lt; arr.length; ++i)&#123; flag = false; for(int j = 0; j &lt; arr.length - i ; ++j)&#123; if(arr[j] &gt; arr[j+1])&#123; flag = true; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; //flag为false，说明数组已经排好序 if(!flag) return; &#125;&#125; 插入排序 核心： 假设数组左半部分是有序的，将右半部分元素，逐一插入左半部分适当位置 示意图： 代码： 1234567891011121314public static void insertSort(int[] arr)&#123; //两重循环，O(n^2)时间复杂度 for(int i = 1; i &lt; arr.length; ++i)&#123; int j = i - 1; int temp = arr[i]; //对于每个元素，向左找第一个小于等于（带等号，排序算法稳定）自己的元素 while(j &gt;= 0 &amp;&amp; arr[j] &gt; temp)&#123; arr[j+1] = arr[j]; j--; &#125; //该元素放到第一个小于等于自己的元素后面 arr[j+1] = temp; &#125;&#125; 选择排序 核心： 每次遍历数组，记录最小元素所在位置，然后将该元素和数组（无序部分）前面元素交换。因此一共需要遍历n次，时间复杂度O(n^2)。 示意图： 代码： 1234567891011121314public static void selectSort(int[] arr)&#123; for(int i = 0; i &lt; arr.length - 1; ++i)&#123; int minIndex = i; for(int j = i + 1; j &lt; arr.length; ++j)&#123; //不带等号，保证排序稳定性 if(arr[j] &lt; arr[minIndex]) minIndex = j; &#125; //交换arr[i]和arr[maxIndex] int temp = arr[i]; arr[i] = arr[minIndex]; arr[minIndex] = temp; &#125;&#125; 快速排序 核心： 分治思想，选取一个基准值，数组中比基准值小的放左边，比基准值大的放右边。然后基准值左右两部分再分别排序。 注：基准值的选取有多种方式，直接最左边元素作为基准值、随机基准值、三数取中基准值等，另外快排还有一些优化方法。这里对这些内容均不作介绍。 示意图： 代码： 12345678910111213141516171819202122232425public static void fastSort(int[] arr, int start, int end)&#123; if(start &gt;= end) return; int l = start, r = end; int p = arr[l];//最左边元素作为基准值 while(l &lt; r)&#123; //从右往左找第一个小于基准值的数 while(r &gt; l &amp;&amp; arr[r] &gt;= p)&#123; r--; &#125; if(r &gt; l)&#123; arr[l++] = arr[r]; &#125; //从左往右找第一个大于基准值的数 while(l &lt; r &amp;&amp; arr[l] &lt; p)&#123; l++; &#125; if(l &lt; r)&#123; arr[r--] = arr[l]; &#125; &#125; arr[l] = p; fastSort(arr, start, l-1); fastSort(arr, l+1, end);&#125; 堆序 核心： ① 初始化堆: 将数列a[1…n]构造成最大堆。 ② 交换数据: 将a[1]和a[n]交换，使a[n]是a[1…n]中的最大值；然后将a[1…n-1]重新调整为最大堆。 接着，将a[1]和a[n-1]交换，使a[n-1]是a[1…n-1]中的最大值；然后将a[1…n-2]重新调整为最大值。 依次类推，直到整个数列都是有序的。 示意图： 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041public static void heapSort(int[] arr)&#123; int temp; //时间复杂度O(n*log n)，排序不稳定 for(int i = 0; i &lt; arr.length - 1; ++i)&#123; maxHeap(arr,arr.length-i-1); temp = arr[0]; arr[0] = arr[arr.length-i-1]; arr[arr.length-i-1] = temp; &#125;&#125;//这里采用自底向上调整最大堆//如果采用自顶向下调整最大堆，就需要采用递归方式public static void maxHeap(int[] arr, int end)&#123; int temp, cur; if(end%2 == 1)&#123;//最后一个节点是左孩子 cur = (end-1)/2; if(arr[2*cur+1] &gt; arr[cur])&#123; temp = arr[cur]; arr[cur] = arr[2*cur+1]; arr[2*cur+1] = temp; &#125; cur--; &#125;else&#123;//最后一个孩子是右孩子 cur = (end-2)/2;//父节点index &#125; while(cur &gt;= 0)&#123; //对比左孩子 if(arr[2*cur+1] &gt; arr[cur])&#123; temp = arr[cur]; arr[cur] = arr[2*cur+1]; arr[2*cur+1] = temp; &#125; //对比右孩子 if(arr[2*cur+2] &gt; arr[cur])&#123; temp = arr[cur]; arr[cur] = arr[2*cur+2]; arr[2*cur+2] = temp; &#125; cur--; &#125;&#125; 归并排序 核心： 分治思想，大问题拆成小问题。先把左半部分排好序，再把右半部分排好序，然后合并两个有序数组。 示意图： 代码： 1234567891011121314151617181920212223242526272829303132public static void mergeSort(int[] arr, int start, int end)&#123; if(start &gt;= end) return; //自下而上不好理解，这里采用自上而下归并，复杂度O(n*logn) int mid = (start+end)/2; mergeSort(arr, start, mid); mergeSort(arr, mid+1, end); merge(arr, start, mid, end);&#125;public static void merge(int[] arr, int start, int mid, int end)&#123; int[] temp = new int[end-start+1];//临时数组 int i = start; int j = mid + 1; int count = 0; while(i &lt;= mid &amp;&amp; j &lt;= end)&#123; //带等号，排序算法稳定 if(arr[i] &lt;= arr[j])&#123; temp[count++] = arr[i++]; &#125;else&#123; temp[count++] = arr[j++]; &#125; &#125; while(i &lt;= mid)&#123; temp[count++] = arr[i++]; &#125; while(j &lt;= end)&#123; temp[count++] = arr[j++]; &#125; for(int t = 0; t &lt; temp.length; ++t)&#123; arr[start+t] = temp[t]; &#125;&#125; Shell排序 核心： 插入排序的改进——分组插入，核心思想在于：距离gap的元素放到一组，每组分别执行插入排序，然后gap=gap/2，再分组，执行插入排序，重复上述操作，直至gap=1。 注：希尔排序复杂度和gap的选取有关，原始希尔排序初始gap为数组长度的一半，然后每次减半，最坏时间复杂度为O(n^2)。 示意图： 代码： 123456789101112131415161718192021222324public static void shellSort(int[] arr)&#123; //步长每次减半，最坏时间复杂度为O(n^2)，不稳定 for(int gap = arr.length/2; gap &gt;= 1; gap = gap/2)&#123; for(int i = 0; i &lt; gap; ++i) //每个分组分别进行插入排序 groupSort(arr, i, gap); &#125;&#125;public static void groupSort(int[] arr, int start, int gap)&#123; //插入排序 while(start &lt; arr.length)&#123; int minIndex = start; int cur = start + gap; while(cur &lt; arr.length)&#123; if(arr[cur] &lt; arr[minIndex]) minIndex = cur; cur += gap; &#125; int temp = arr[start]; arr[start] = arr[minIndex]; arr[minIndex] = temp; start += gap; &#125;&#125; 桶排序 核心： 建立若干个桶，第2个桶中数据大于第一个桶，第3个大于第2个，依次类推。把数组中数据放到桶中，然后把每个桶中的数据排好序，就得到了有序数组。显然，桶数量越多，空间复杂度越高，但是时间复杂度越低。 示意图： 代码： 123456789101112131415161718public static void bukcetSort(int[] arr)&#123; int maxVal = Integer.MIN_VALUE; for(int item : arr)&#123; maxVal = Math.max(maxVal, item); &#125; //方便起见，数组最大值作为桶数量 int[] buckets = new int[maxVal+1]; for(int item : arr)&#123; buckets[item]++; &#125; int index = 0; for(int i = 0; i &lt; buckets.length; ++i)&#123; while(buckets[i] &gt; 0)&#123; arr[index++] = i; buckets[i]--; &#125; &#125;&#125; 基数排序 核心： 将整数按位分割，先按照个位数排序，再按照十位数排序，再按照百位数排序。 示意图： 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** 获取数组a中最大值** 参数说明: * a -- 数组* n -- 数组长度*/private static int getMax(int[] a) &#123;int max;max = a[0];for (int i = 1; i &lt; a.length; i++)if (a[i] &gt; max)max = a[i];return max;&#125;/** 对数组按照&quot;某个位数&quot;进行排序(桶排序)** 参数说明: * a -- 数组* exp -- 指数。对数组a按照该指数进行排序。** 例如，对于数组a=&#123;50, 3, 542, 745, 2014, 154, 63, 616&#125;；* (01) 当exp=1表示按照&quot;个位&quot;对数组a进行排序* (02) 当exp=10表示按照&quot;十位&quot;对数组a进行排序* (03) 当exp=100表示按照&quot;百位&quot;对数组a进行排序* ...*/private static void countSort(int[] a, int exp) &#123; //int output[a.length]; // 存储&quot;被排序数据&quot;的临时数组 int[] output = new int[a.length]; // 存储&quot;被排序数据&quot;的临时数组 int[] buckets = new int[10]; // 将数据出现的次数存储在buckets[]中 for (int i = 0; i &lt; a.length; i++) buckets[ (a[i]/exp)%10 ]++; // 更改buckets[i]。目的是让更改后的buckets[i]的值，是该数据在output[]中的位置。 for (int i = 1; i &lt; 10; i++) buckets[i] += buckets[i - 1]; // 将数据存储到临时数组output[]中 for (int i = a.length - 1; i &gt;= 0; i--) &#123; output[buckets[ (a[i]/exp)%10 ] - 1] = a[i]; buckets[ (a[i]/exp)%10 ]--; &#125; // 将排序好的数据赋值给a[] for (int i = 0; i &lt; a.length; i++) a[i] = output[i]; output = null; buckets = null;&#125;/** 基数排序** 参数说明: * a -- 数组*/public static void radixSort(int[] a) &#123; int exp; // 指数。当对数组按各位进行排序时，exp=1；按十位进行排序时，exp=10；... int max = getMax(a); // 数组a中的最大值 // 从个位开始，对数组a按&quot;指数&quot;进行排序 for (exp = 1; max/exp &gt; 0; exp *= 10) countSort(a, exp);&#125; 排序算法总结 参考资料 Java全站知识体系","categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"MySQL锁机制","slug":"2 后端/MySQL/11. MySQL锁机制","date":"2021-12-18T12:38:14.000Z","updated":"2022-06-10T05:24:46.361Z","comments":true,"path":"fddcef8b88e0/","link":"","permalink":"http://rookieyin.github.io/fddcef8b88e0/","excerpt":"MySQL锁机制 在“MySQL事务”一文中，我们知道并发事务下会带来脏读、脏写、不可重复读、幻读等问题。解决这些问题的方式有两种： 一致性非锁定读或者叫快照读：其实现方式就是我们常说的MVCC。 所有普通的SELECT语句在已提交读和可重复读两种隔离级别下都是采用一致性非锁定读。 锁定读：一般情况下，使用MVCC可以解决读-写操作并发执行时带来的问题，但是某些场景下，我们必须采用加锁的方式才能解决这些并发问题。","text":"MySQL锁机制 在“MySQL事务”一文中，我们知道并发事务下会带来脏读、脏写、不可重复读、幻读等问题。解决这些问题的方式有两种： 一致性非锁定读或者叫快照读：其实现方式就是我们常说的MVCC。 所有普通的SELECT语句在已提交读和可重复读两种隔离级别下都是采用一致性非锁定读。 锁定读：一般情况下，使用MVCC可以解决读-写操作并发执行时带来的问题，但是某些场景下，我们必须采用加锁的方式才能解决这些并发问题。 1 InnoDB中的锁 MySQL支持多种存储引擎，不同引擎对锁的支持也是不一样的。对于MyISAME、MEMORY和MERGE这些存储引擎来说，它们只支持表级锁，而且这些存储引擎并不支持事务，因此当使用这些存储引擎的表加锁时，在同一时刻只允许一个会话对表进行写操作。 InnoDB和其他存储引擎相比，支持的锁功能要强大很多，同时支持表级锁和行级锁。 表级锁：占用资源少，但是一下子锁住了一张表，降低系统并发能力 行级锁：占用资源多，但是一次值锁住几条记录，并发能力强 1.1 多粒度锁 我们知道锁有两种类型：共享锁（S锁）和排它锁（X锁），InnoDB中提供了多粒度锁的支持。所谓多粒度，就是说我们既可以给整个表加上S锁或者X锁，也可以给表中某几行记录加上S锁或者X锁。 给行记录加锁很容易： 如果行被某个事务加了S锁，那么其他事务可以加S锁，但是不能加X锁 如果行被某个事物加了X锁，那么其他事务既不能加S锁，也不能加X锁 给整个表加锁就比较复杂了： 因为我们不仅需要判断表是否被加了表级锁，还需要判断表中是否有记录被加了锁。此时就需要遍历表中所有记录，代价显然是十分高昂的。 为了解决这个问题，InnoDB中提出了意向锁的概念： 意向共享锁（IS）：事务想获得表中某几行的共享锁 意向排它锁（IX）：事务想获得表中某几行的排它锁 也就是说： 当事务想给表中某几条记录加共享锁的时候，先给这张表加IS锁，然后再给行记录加S锁 当事务想给表中某几条记录加排它锁的时候，先给这张表加IX锁，然后再给行记录加X锁 总之，意向锁存在的目的是：当我们想添加表级别S锁和X锁时，可以快速判断表中的记录是否有被加锁。因此意向锁之间都是兼容的，它只是用来帮助其他事务判断能否添加表级锁。 1.2 全局锁 1.2.1 使用方法 全局锁，就是锁定整个数据库，执行下面这条命令，就可以让整个数据库处于只读状态： 1flush tables with read lock 这时其他所有线程的写、删除、更新操作都会被阻塞。执行下面命令，释放全局锁： 1unlock tables 1.2.2 应用场景 全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。 举个例子大家就知道了。 在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。 如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更细，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。 那么，有可能出现这样的顺序： 先备份了用户表的数据； 然后有用户发起了购买商品的操作； 接着再备份商品表的数据。 也就是在备份用户表和商品表之间，有用户购买了商品。 这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。 所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。 加全局锁又会带来什么缺点呢？ 加上全局锁，意味着整个数据库都是只读状态。 那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？ 有的，如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。 因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。 备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。 InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。 但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。 1.3 表级锁 表级别的S锁、X锁 在对某个表进行增删改查语句时，是不会对这个表添加S、X锁的。 当对表执行如ALTER等DDL语句时，会添加锁，此时如果有其他增删改查事务请求会被阻塞。不过这里添加的表级锁并不是InnoDB中的表级S、X锁，而是在server层使用的一种元数据锁（MDL）。 InooDB中的表级锁其实十分“鸡肋”，一般只会在一些特殊情况下用到，比如系统崩溃恢复时。InnoDB的厉害之处在于提供了更细粒度的行级锁。 表级别IS、IX锁 前面也说过，当事务想向表中某些记录添加X或S锁时，会先给表添加IX或IS锁。 表级别AUTO-INC锁 自增锁。MySQL中可以给某个列设置自增属性，之后在插入记录时可以不指定该列的值。InnoDB实现递增的方式有两种： 使用AUTO-INC锁：执行插入语句前加一个锁，语句执行结束后释放锁。 采用轻量级锁：在为插入语句生成AUTO_INCREMENT 修饰的列的值时获取这个轻量级锁， 然后在生成本次插入语句需要用到的AUTO_INCREMENT 修饰的列的值之后，就把该轻量级锁释放掉， 而不需要等到整个插入语句执行完后才释放锁。 当插入数据数量确定时使用轻量级锁，否则使用自增锁。 元数据锁MDL 元数据锁，顾名思义，它适合DDL相关的。我们不需要显示的使用MDL，数据库会自动给表加上MDL： 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁。 MDL保证用户在执行CRUD操作时，数据库结构不会发生改变，当事务结束后，自动释放MDL锁。 不过需要注意的是如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景： 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁； 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突； 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞， 那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？ 这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。 1.4 行级锁 Record Lock 也就是我们前面提到的记录锁，官方名称叫作LOCK_REC_NOT_GAP，这里称之为“正经记录锁”。 正经记录锁是有S锁和X锁之分的，当一个事务获得S锁后，其他事务可以获得S锁，但是不能获得X锁。当一个事务获得X锁后，其他事务S、X锁都不能获得。 Gap Lock 我们知道MySQL在可重复读的隔离级别下可以在很大程度上解决幻读现象。解决方案有两种：MVCC和加锁。但是加锁方案有一个问题就是，在事务执行第一次读取操作时，那些幻影记录尚不存在，我们无法给这些记录加上正经记录锁。为此，InnoDB中设计了Gap Lock锁，这里称之为gap锁。下图展示了给number值为8的记录添加一个gap锁： 上图中的gap锁表明：number值在（3，8）之间的数据禁止被立即插入，需要等gap锁释放。那么很快我们发现如何禁止立即 插入number值在区间20到正无穷的数据呢？这时候就要用到数据页中的两条伪记录了。 Next-Key Lock Record Lock和Gap Lock的结合体，既能锁住当前记录，也能禁止立即插入间隙数据。如下图所示： Insert Intention Lock 一个事务在插入一条记录时，需要判断插入位置是否已经被别的事务加了gap锁。如果有的话，插入事务不仅要等待gap锁的释放，还需要在内存中生成一个锁结构，称之为Insert Intention Lock，插入意向锁。 隐式锁 正常情况下，执行Insert语句时不需要在内存中生成锁结构的（有gap锁除外），但是这可能导致脏读、脏写等问题。在InnoDB中，设计了一种非常巧妙的方法，不用加锁就可以避免这个问题。其底层是依赖于表的事务id隐藏列来实现的。 场景1：对于聚簇索引记录来说，有一个trx_id隐藏列，该隐藏列记录着最后改动该记录的事务的事务id。在新插入一条记录后，这条记录trx_id的值就是当前插入事务的id。 如果新来一个事务T要读或者更新这条未被提交的记录，T事务首先会看一下该记录中trx_id值代表的事务是否处于活跃状态： 如果处于活跃状态，那么T事务会帮助插入事务创建一个X锁的锁结构，并且该锁的状态为进行中；然后再为自己创建一个锁结构，锁结构状态为阻塞，之后自己进入等待状态。 场景2：对于二级索引记录来说，本身并没有trx_id隐藏列，但是二级索引页面的Page Header中有一个PAGE_MAX_TRX_ID属性，表示对该页面做改动的最大的事务id。如果PAGE_MAX_TRX_ID值小于当前活跃事务列表中的最小值，那么说明对当前页面的所有修改都已经提交了。否则需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记录，在重复场景1的做法。 2 锁的存储结构 对一条记录加锁的本质就是在内存中创建一个锁结构与之关联，不过为了节约空间，并不是每个锁都会单独分配一个内存结构。如果多个锁符合下面这些条件，就可以放到同一个锁结构中： 在同一个事务中进行加锁操作 被加锁的记录在同一个页面中 加锁的类型是一样的 等待状态是一样的 下图展示了InnoDB中锁的结构： 关于锁每部分的详细信息，这里就不做过多介绍了。 3 死锁 这部分主要摘自这里 3.1 概述 死锁是指：两个或两个以上的事务执行过程中，因争夺资源而造成一种互相等待的现象。 比如T1事务占有第1行的X锁，T2事务占有第2行的X锁，然后T1事务希望申请第2行的S锁，T2事务希望申请第1行的S锁。此时，就会出现T1等待T2释放第2行X锁，T2等待T1释放第1行X锁这种相互等待的现象。 超时机制 解决死锁的一种方案就是：超时，即事务被阻塞时间超过一定阈值后，对事务进行回滚。 超时机制虽然简单，但是若超时事务已经更新了很多行，此时回滚代价就很大。 等待图 除了超时机制，当前数据库还都普遍采用等待图的方式进行死锁检测，InnoDB也是采用这种方法。 wait-for graph要求数据库保存以下两种信息： 锁的信息链表 事务等待链表 通过上述链表可以构造一张图，如果这个图中存在回路，就代表存在死锁。 等待图是一种更为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，如果存在则有死锁，通常来说InnoDB会选择回滚undo量最小的事务。 3.2 死锁示例 创建一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引： 1234567CREATE TABLE `t_order` ( `id` int NOT NULL AUTO_INCREMENT, `order_no` int DEFAULT NULL, `create_date` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_order` (`order_no`) USING BTREE) ENGINE=InnoDB ; 然后，先 t_order 表里现在已经有了 6 条记录： 假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下： 可以看到，两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。 这里在查询记录是否存在的时候，使用了 select ... for update 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。 如果没有使用 select ... for update 语句，而使用了单纯的 select 语句，如果是两个订单号一样的请求同时进来，就会出现两个重复的订单，有可能出现幻读，如下图： 3.3 为什么发生死锁 可重复读隔离级别下，是存在幻读的问题。 Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁，它是记录锁和间隙锁的组合。 Record Loc，记录锁，锁的是记录本身； Gap Lock，间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。 普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读，如果要在查询时对记录加行锁，可以使用下面这两个方式： 123456789begin;//对读取的记录加共享锁select ... lock in share mode;commit; //锁释放begin;//对读取的记录加排他锁select ... for update;commit; //锁释放 行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁。 比如，下面事务 A 查询语句会锁住(2, +∞]范围的记录，然后期间如果有其他事务在这个锁住的范围插入数据就会被阻塞。 next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁，我之前也写一篇加锁规则，详细可以看这篇「我做了一天的实验！ (opens new window)」 需要注意的是，如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。 所以在线上千万不要执行没有带索引条件的 update 语句，不然会造成业务停滞，我有个读者就因为干了这个事情，然后被老板教育了一波，详细可以看这篇「完蛋，公司被一条 update 语句干趴了！ (opens new window)」 回到前面死锁的例子，在执行下面这条语句的时候： 1select id from t_order where order_no = 1008 for update; 因为 order_no 不是唯一索引，所以行锁的类型是间隙锁，于是间隙锁的范围是（1006, +∞）。那么，当事务 B 往间隙锁里插入 id = 1008 的记录就会被锁住。 因为当我们执行以下插入语句时，会在插入间隙上再次获取插入意向锁。 1insert into t_order (order_no, create_date) values (1008, now()); 插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 select ... for update 语句并不会相互影响。 案例中的事务 A 和事务 B 在执行完后 select ... for update 语句后都持有范围为(1006,+∞）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。 3.4 避免死锁 死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 当发生超时后，就出现下面这个提示： 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 当检测到死锁后，就会出现下面这个提示： 上面这个两种策略是「当有死锁发生时」的避免方式。 我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一下来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"undo log详解","slug":"2 后端/MySQL/10. undo log详解","date":"2021-12-17T12:38:14.000Z","updated":"2022-06-10T05:23:24.741Z","comments":true,"path":"2a06983ca4ed/","link":"","permalink":"http://rookieyin.github.io/2a06983ca4ed/","excerpt":"undo log详解 在介绍事务实现原理时候，我们简单了解过undo log，它可以帮助我们实现事务的原子性。本文把undo log拎出来，详细介绍一下。 在事务的执行过程中，可能遇到各种错误，此时为了保证事务的原子性，我们需要回滚当前事务已经执行的修改。那么怎么回滚这些修改呢？一种直接的方法就是，每次执行insert、delete、update语句时，我们都要留一手，用某种机制记录下数据修改前的样子，这样当我们需要回滚时，我们就能将修改的数据恢复原样。这就是undo log需要实现的功能。","text":"undo log详解 在介绍事务实现原理时候，我们简单了解过undo log，它可以帮助我们实现事务的原子性。本文把undo log拎出来，详细介绍一下。 在事务的执行过程中，可能遇到各种错误，此时为了保证事务的原子性，我们需要回滚当前事务已经执行的修改。那么怎么回滚这些修改呢？一种直接的方法就是，每次执行insert、delete、update语句时，我们都要留一手，用某种机制记录下数据修改前的样子，这样当我们需要回滚时，我们就能将修改的数据恢复原样。这就是undo log需要实现的功能。 1 Undo log格式 1.1 insert对应的undo log 对于insert操作，对应的undo log很简单，我们只需要记录插入数据的主键信息即可。当需要回滚时，我们只需要根据其主键信息把它删除即可。其格式如下图所示： 看到这里，我们可能有一个疑惑：undo日志是如何和数据记录对应上的？也就是说，我们要回滚时，如何找到目标记录对应的undo log？ 这里就要提到数据记录中的隐藏字段：roll_pointer了。我们知道对于任意一张表，MySQL会自动创建两个隐藏字段roll_point和trx_id，分别表示回滚指针和事务id。其中roll_pointer就是一个指向undo log的指针。 假如，我们在某个事务中向表中插入两条数据，此时会生成如下图所示的undo log： 1.2 delete对应的undo log 在“InnoDB数据的存储”一文中，我们知道每一行数据对应一个record，它们以链表形式存储在page中，这个链表称之为“正常链表”。Page Header中还有一个PAGE_FREE属性，对于被删除的记录，其实也是以链表形式连接在一起的，称之为“垃圾链表”。 假设某一时刻，页面中记录分布情况如下图所示： 假设现在准备使用DELETE语句删除正常记录链表中最后一条记录，这个过程需要经历两个阶段： 阶段1：delete_mark阶段，将记录的delete_flag标识位设置成1，其他的不做修改 阶段2：purge阶段，当删除语句所在事务提交后，会有专门线程来真正把记录删除，即移动到垃圾链表中。 为什么不在事务提交后，立即移动到垃圾链表？因为MVCC中可能会用到，详情看“InnoDB中的MVCC”一文。 在事务提交前，只会经历阶段1，一旦事务提交了，我们就不需要回滚该操作了，因此设计undo日志格式时只需要考虑阶段1即可。InnoDB中设计了一种类型为TRX_UNDO_DEL_MARK_REC的undo log，来处理这些场景。其格式如下图所示： 其中有2个特别的字段：trx_id和roll_pointer，用于存储旧记录的trx_id和roll_pointer。这样作的一个好处，就是可以通过undo日志的roll_pointer找到上一次对该记录修改时产生的undo log，也就是形成了我们常说的版本链（实现MVCC的基础）。 1.3 update对应的undo log 对于update操作，更新主键和不更新主键两种情况有着截然不同的处理方案。 1.3.1 不更新主键 不更新主键，又可以细分为被更新的列所占用空间不变和发生变化两种情况。 就地更新 只有当所有要更新的列占用空间都不变时，才能使用就地更新。 所谓就地更新，就是在旧记录上直接修改对应列的值。 删除后插入 如果有任何一列更新前后占用空间大小不一致，就需要使用该种更新方式，即先删除旧记录，再插入一条新记录。 注意，这里的删除和前文提到的delete_mark不同，是真正删除，即把该记录移到垃圾链表中。 对于不更新主键的情况，InnoDB设计了一种类型为TRX_UNDO_EXIST_REC的undo日志，其结构如下图所示： 1.3.2 更新主键 由于记录在页面中是按照主键升序排列的，如果我么更新了主键，那么更新前后该记录可能相隔很远，甚至隔了好几个页面。 对于这种情况，InnoDB在聚簇索引中分了两步进行处理： 步骤1：将旧记录进行delete_mark操作，和前文介绍delete undo log一致 步骤2：根据更新后各列值，插入一条新的记录 2 Undo log的存储 2.1 FIL_PAGE_UNDO_LOG页面 undo log和数据库中的表一样，它是存储在系统表空间或者单独的undo log表空间中，用一种类型为FIL_PAGE_UNDO_LOG的页来专门存储undo log信息。其通用结构如下图所示： 其中Undo Page Header是undo 页面特有的，其结构如下图所示： TRX_UNDO_PAGE_TYPE：准备存储什么类型的undo log TRX_UNDO_PAGE_START：当前页面从什么位置开始存储undo日志，即第一条undo log的偏移量 TRX_UNDO_PAGE_FREE：与上面一条相对应，表示最后一条undo日志结束位置的偏移量 TRX_UNDO_PAGE_NODE：页面链表结构，指向下一个undo 页面，下面马上用到。 2.2 Undo页面链表 一个事务中可能生成多条undo log，这些undo log在一个页面中可能放不下，因此通过前文提到的TRX_UNDO_PAGE_NODE属性将这些页面连成链表，如下图所示： 在一个事务中可能会混合执行insert、update、delete语句，生成不同类型的undo log，但是一个页面只能存储一种类型undo log，因此系统中会有多条undo 页面链表，如下图所示： 另外，在InnoDB中，对普通表和临时表进行改动生成的undo log要分别记录，因此一个事务最多有4个以Undo页面为节点组成的链表，如下图所示： 读到这里，我们发现前面提到的都是“一个事务”，难道每个事务都有自己单独的undo 链表？ 是这样的，为了提高undo日志的写入效率，不同事务有自己单独的undo链表，如下图所示： 3 Undo log的写入 在InnoDB中，每个Undo页面链表都对应着一个段，称为Undo Log Segment，链表中每个页面都是从这个段中申请的。所以在Undo页面列表的第一个页面中设计了一个名为Undo Log Segment Header的属性，其中包含了该链表对应的段信息。如下图所示： 可以看到和普通undo 页相比，链表第一个页面多了一个Undo Log Segment Header，其具体结构如下： TRX_UNDO_STATE：表示本Undo页面列表的状态，可能为 活跃状态：有一个活跃事务，正在向该undo链表中写日志 被缓存状态：处于该状态的Undo 页面链表等待之后被其他事务重用 等待被释放状态：对于insert 链表，如果事务提交后，该链表不能被重用，就处于该状态 等待被purge状态：对于update链表，如果事务提交后，该链表不能被重用，就处于该状态 PREPARED状态，处于此状态的Undo页面链表用于存储处于prepare阶段的事务产生的日志（分布式事务中的概念） TRX_UNDO_LAST_LOG：最后一个Undo Log Header的位置 TRX_UNDO_FSEG_HEADER：本链表对应的段的Segment Header信息 TRX_UNDO_PAGE_LIST：Undo页面链表的及节点。 InnoDB中undo log的写入方式十分简单，就是一条紧挨着一条，写入page中。不过undo链表第一个页面有所不同，还多了一个Undo Log Header属性，记录了undo log分组相关信息。因此一个真实undo链表可能是这样的：","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"redo log详解","slug":"2 后端/MySQL/9. redo log详解","date":"2021-12-16T12:38:14.000Z","updated":"2022-06-10T05:21:44.114Z","comments":true,"path":"3f95ffdd49a0/","link":"","permalink":"http://rookieyin.github.io/3f95ffdd49a0/","excerpt":"redo log详解 之前学习事务的时候，介绍过redo log，其核心功能就是服务器宕机后进行数据恢复。本文把它单独拎出来，详细介绍一下。 在了解Redo log更具体内容之前，我们先回答一个问题：为什么要有redo log？ 学习过BufferPool，我们知道InnoDB读取/更新数据操作都是在BufferPool中进行的，在某个时间点统一将BufferPool中的脏页同步到磁盘中。但是如果系统发生故障，宕机了，BufferPool中还有脏页没来得及同步到磁盘中，这时就会发生数据丢失。 为了避免这种情况，我们就需要一种机制，保存BufferPool中数据更新的操作，在系统恢复时，帮助我们恢复宕机前没来得及同步的脏页数据。这就是redo log要完成的功能。 也就是说，对于更新操作，我们不仅要更新BufferPool中的数据，我们还要将该更新操作记录到redo log中。为了节约空间，redo log中记录的是物理页的变化。比如，某个事务将系统表空间第100号页面中偏移量为1000处的字节从1更改为2，我们只需要进行如下记录： “将第0号表空间第100号页面中偏移量为1000处的值改为2”。","text":"redo log详解 之前学习事务的时候，介绍过redo log，其核心功能就是服务器宕机后进行数据恢复。本文把它单独拎出来，详细介绍一下。 在了解Redo log更具体内容之前，我们先回答一个问题：为什么要有redo log？ 学习过BufferPool，我们知道InnoDB读取/更新数据操作都是在BufferPool中进行的，在某个时间点统一将BufferPool中的脏页同步到磁盘中。但是如果系统发生故障，宕机了，BufferPool中还有脏页没来得及同步到磁盘中，这时就会发生数据丢失。 为了避免这种情况，我们就需要一种机制，保存BufferPool中数据更新的操作，在系统恢复时，帮助我们恢复宕机前没来得及同步的脏页数据。这就是redo log要完成的功能。 也就是说，对于更新操作，我们不仅要更新BufferPool中的数据，我们还要将该更新操作记录到redo log中。为了节约空间，redo log中记录的是物理页的变化。比如，某个事务将系统表空间第100号页面中偏移量为1000处的字节从1更改为2，我们只需要进行如下记录： “将第0号表空间第100号页面中偏移量为1000处的值改为2”。 1 Redo log格式 InnoDB中针对不同场景，设计了多种类型的redo日志，大部分类型的结构如下图所示： type：日志类型，MySQL5.7.22中，InnoDB一共设计了53中日志类型 space ID：表空间ID page number：页号 data：这条日志的具体内容 2 怎么存？ 2.1 Min-Transaction InnoDB中redo log并不是以每一条log作为最小恢复单位，而是将redo log划分成一个个不可分割的组，以组为最小单位进行恢复。在数据恢复时，对于一组日志，要么把整组日志都恢复（组是完整的），要么整组日志都不恢复（组是不完整的）。 那怎么知道一组日志是不是完整的呢？InnoDB中在每组redo log末尾添加一个特殊类型的日志MLOG_MULTI_REC_END，如下图所示： 这样在系统崩溃后重新启动进行数据恢复时，只有解析到类型为MLOG_MULTI_REC_END的redo log，才认为是一组完整的日志。 看到这里我们有两个问题： 为什么要分组？ 一条SQL更新语句可能会生成很多条redo 日志，比如一个插入操作，可能要同时更新聚簇索引、二级索引、max row id等各种不同页数据，如果出现页分裂，生成的日志数量就更多了。下图展示了需要页分裂的插入过程： InnoDB的设计者认为，向某个B+树中插入一条记录的过程必须是原子的，不能说插入一半之后就停止了。比如在悲观插入（带有页分裂的插入）过程中，新的页面分配好了，数据也复制好了，新的记录也已经插入了，但是没有向内节点插入一条目录项。那么这个过程也就是不完整的，就会形成一棵不正确的B+树。 因此，我们需要将一条语句的具体执行过程进行分组，每个分组包含若干个不可分割的过程，每个分组称之为min-transaction。 怎么分组？ 前面我们提到，分组是按照min-transaction进行的，那么什么是min-transaction呢？InnoDB的设计者把对底层页面进行一次原子访问的过程称之为一个min-transaction（MTR）。这样一个事务可以包含若干条语句，每一条语句又包含若干个MRT，如下图所示： 2.2 写入过程 2.2.1 log buffer 存储格式 和Buffer Pool一样，InnoDB为了解决磁盘速度过慢的问题引入了redo log buffer，写入redo log时，先写入buffer，然后再统一刷新到磁盘中。 为了更好地管理redo log，InnoDB把生成的redo log存放在512字节的页中（和数据页、索引页差不多），这里称之为block，其格式如下： LOG_BLOCK_HDR_NO：每一个block 都有一个大于0 的唯一编号，该属性就表示该编号值。 LOG_BLOCK_HDR_DATA_LEN：表示block 中已经使用了多少字节， 初始值为12 (因为log block body从第12 个字节处开始)。随着往block中写入的日志越来越多，该属性值也跟着增长。如果log block body已经被全部写满，那么该属性的值被设置为512。 LOG_BLOCK_FIRST_REC_GROUP： 一个MTR 会生成多条redo 日志记录，这个MTR 生成的这些redo日志记录被称为一个redo日志记录组( redo log record group)。LOG_BLOCK_FIRST_REC_GROUP就代表该block中第一个MTR 生成的redo日志记录组的偏移量， 其实也就是这个block中第一个MTR 生成的第一条redo日志记录的偏移量(如果一个MTR 生成的redo日志横跨了好多个block，那么最后一个block 中的LOG_BLOCK_FIRST_REC_GROUP属性就表示这个MTR 对应的redo日志结束的地方，也就是下一个MTR 生成的时0 日志开始的地方) 。 LOG_BLOCK_CHECKPOINT_NO：表示checkpoint 的序号，checkpoint是后续内容的重点， 现在先不用消楚它的意思，少安毋躁。 LOG_BLOCK_CHECKSUM：表示该block的校验值，用于正确性校验。 log buffer就是内存中若干个连续的redo log block，在系统启动时候就申请好了，默认大小为16MB。 写入log buffer 向log buffer中写入redo 日志的过程是顺序写入的，当该block的空闲空间用完了，再写入下一个block。InnoDB中提供了一个全局变量buf_free，致命后续写入的redo 日志应该写到log buffer的哪个位置，如下图所示： 2.2.2 log file 刷盘时机 在哪些情况下会将log buffer中的数据刷新到磁盘中呢？ log buffer空间不足时：当前写入的log占满总空间50%时，会进行刷盘操作 事务提交：为了保证事务的持久性，事务提价后，必须将buffer中数据刷新到磁盘，否则发生系统崩溃，会丢失修改 刷新脏页前：将某个脏页刷新到磁盘前，会保证先将该脏页对应的redo日志刷新到磁盘中 后台线程：后台有一个线程，以大概1s一次的频率进行buffer刷盘操作 正常关闭服务器时 做checkpoint时 文件格式 磁盘上的redo日志文件不止一个，而是以一个日志文件组的形式出现的。文件组中每个文件大小、格式都是一样的，由下面两个部分组成： 前2048字节：4个block，存储管理信息 其余字节：存储log buffer中的block镜像 这里重点前4个block中的信息，其格式如下图所示： log file header：描述文件日志的整体属性 checkpoint1：记录check point相关属性 checkpoint2：和checkpoint1格式一样 2.3 log sequence number（LSN） 自系统运行开始，就在不断修改页面，也就意味着会不断生成redo日志，redo日志数量是在不断增加的。InnoDB中设计了一个lsn变量，用来表示写入的日志总量。 lsn的初始值是8704： 当某个mtr产生的一组redo日志较小，还未占满整个block时，写入多少字节日志，lsn的值就增加多少。 当某个mtr产生的一组redo日志很大，一个block放不下时，lsn得到还要额外增加block header和block trailer所占字节数，如下图所示： 2.3.1 lsn和文件偏移量对应关系 lsn的初始值为8704，redo日志文件组中偏移量起始值为2048。因此两者对应关系如下图所示： 2.3.2 flushed_to_disk_lsn redo日志是先写到log buffer中，之后才会被刷新到磁盘的redo日志文件中，因此还需要一个变量表示buffer中哪些log已经被刷新到磁盘了，这个变量就是buf_next_to_write。 2.3.3 flush链表中的lsn buffer pool中的脏页是记录在flush链表中，第一次修改某个页面时，会将该页面的控制块放到flush链表的头部。也就是说，flush链表是按照页面第一次修改时间进行排序的。 当修改某个页面时，会更改页面对应控制块中的两个属性信息： oldest_modification：第一次修改该页面，MTR结束时对应的lsn值 newest_modification：最新一次修改该页面，MTR结束时对应的lsn值 2.4 checkpoint redo log的数量是不断增加的，但是redo日志文件组的容量是有限的，因此我们必须要循环利用redo日志文件组中的文件。 哪些文件可以被重用呢？显然当buffer pool中的脏页已经被刷新到磁盘时，这些脏页对应的redo日志就没有用了，这些日志占用的空间就可以复用。 那么我们怎么知道哪些脏页对应的redo log已经没有用了呢？InnoDB中设计了一个名为checkpoint_lsn的全局变量，表示当前系统中可以被覆盖的redo 日志总量是多少。这个变量的初始值也是8704。 checkpoint信息会被记录在redo日志文件的文件头中，我们把一次更新checkpoint信息的过程称之为“执行一次checkpoint”。 执行一次checkpoint的过程可以分成2个步骤： 计算当前系统中可以被覆盖的redo日志对应的lsn值最大是多少 将checkpoint_lsn、checkpoin_lsn对应的文件偏移量以及此次checkpoint编号写入日志文件管理信息中（checkpoint1或者checkpoint2中）。InnoDB中规定，checkpoint_no是偶数时写入checkpoint1中，是奇数就写入checkpoint2中。 执行完一次checkpoin，redo日志文件组中各个lsn值关系可能如下： 3 怎么恢复？ 当系统崩溃重启动后，我们如何利用redo log来恢复没来得及刷新到磁盘的脏页数据呢？ 3.1 确定起点 对于lsn值小于checkpoint_lsn的redo日志来说，它们是可以被覆盖的，也就是说这些redo日志对应的脏页已经被刷新到磁盘中了，自然也就没有必要恢复它们 对于lsn值大于checkpoint_lsn的redo日志，我们不能确定这些日志对应的脏页是否已经被刷盘了 因此恢复的起点就是checkpoint_lsn对应的redo日志开始恢复。 我们知道redo日志文件头中有两个checkpoint，我们只需要将两种中checkpoint_no读取出来，取值大者即可。 3.2 确定终点 redo日志文件是顺序写入的，写满了一个block再写下一个block。 普通block的log block header中有一个名为LOG_BLOCK_HDR_DATA_LEN属性，记录了该block中使用了多少空间。对于被填满的block，该值为512。如果某block该值小于512，那么该block就是崩溃恢复中需要扫描的最后一个block。 3.3 恢复数据 一种直接的方式就是：从起点到终点，按顺序恢复每一条redo 日志记录的信息。 不过InnoDB在此基础上进行了一些优化： 使用哈希表 根据redo日志的space ID和page number属性计算哈希值，把具有相同表空间id和页号的日志放到一起，按照生成顺序链接，如下图所示： 这样可以一次性修复一整个页面，避免多次读取页面的随机IO，加快恢复速度。 跳过已经刷新到磁盘中的页面 对于lsn不小于checkpoint_lsn的redo 日志对应的在那个也也是有可能已经刷新到磁盘了（最后一次checkpoint后执行过刷新脏页的操作）。对于这些日志，崩溃恢复时，就没有必要再次进行恢复了。 那么如何判断这些页面已经更新过了呢？ 在数据页的FileHeader中有一个称为FIL_PAGE_LSN属性，该属性记载了最近一次修改页面时对应的lsn值（即flush链表控制块中的newest_modification值）。如果该值大于checkpoint_lsn，说明这些页面在最后一次checkpoint之后，被刷新到磁盘，也就不需要被恢复了。这进一步提高了崩溃恢复的速度。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"MySQL的binlog","slug":"2 后端/MySQL/8. MySQL的binlog","date":"2021-12-15T12:38:14.000Z","updated":"2022-06-10T05:19:14.596Z","comments":true,"path":"b15c79e9cdee/","link":"","permalink":"http://rookieyin.github.io/b15c79e9cdee/","excerpt":"MySQL的binlog MySQL中的日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中比较重要的还要属 二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）。 在“MySQL事务”一文中，介绍了重做日志和回滚日志的相关知识，包括如何通过redo log实现事务的持久性，通过undo log实现事务的原子性。本文主要介绍binlog相关知识。","text":"MySQL的binlog MySQL中的日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中比较重要的还要属 二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）。 在“MySQL事务”一文中，介绍了重做日志和回滚日志的相关知识，包括如何通过redo log实现事务的持久性，通过undo log实现事务的原子性。本文主要介绍binlog相关知识。 1 概述 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 因此不管用什么存储引擎， 只要发生了表数据更新，都会产生 binlog 日志。 那 binlog 到底是用来干嘛的？ 恢复 某些数据的恢复需要二进制文件，例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time恢复。 复制 数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。 审计 用户可以通过查看二进制日志信息，判断是否有对数据库进行注入攻击。 在InnoDB中，binlog默认是没有启动的，需要手动指定参数log-bin来启动。启动该选项会对数据库整体性能有所影响，但是带来的损失十分有限。 2 记录格式 binlog有3中记录格式，从MySQL5.1开始可以通过binlog_format参数来指定： statement：和早期版本一样，记录的是日志的逻辑。 这种格式可能存在一些问题，比如undate_time=now()，这里会获取当前系统时间，导致主从库之间不一致。 row：记录表的行更改情况，更改前后的数据都记录下来了。 这样就能保证同步数据的一致性，通常情况下都是指定为row，这样可以为数据库的恢复与同步带来更好的可靠性。 但是使用ROW格式可能占用更大的磁盘空间，而由于复制是采用传输二进制日志方式实现的，因此复制的网络开销也有所增加。 mixed：这种设定下MySQL默认采用statement格式记录binlog，但是在一些情况下会使用ROW格式，这些情况有： 表的存储引擎为NDB，这时对表的DML操作都会以ROW格式记录； 使用了UUID()、USER()、CURRENT_USER()等不确定函数； 使用了insert delay语句； 使用了用户定义函数； 使用了临时表。 3 写入机制 binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。 因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache。 我们可以通过binlog_cache_size参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap），因此cache的大小不能太大也不能太小。 binlog日志刷盘流程如下 ： 上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快 上图的 fsync，才是将数据持久化到磁盘的操作 write和fsync的时机，可以由参数sync_binlog控制，默认是0。为0的时候，表示每次提交事务都只write，由系统自行判断什么时候执行fsync。 虽然性能得到提升，但是机器宕机，page cache里面的 binlog 会丢失。 为了安全起见，可以设置为1，表示每次提交事务都会执行fsync，就如同 redo log 日志刷盘流程 一样。 最后还有一种折中方式，可以设置为N(N&gt;1)，表示每次提交事务都write，但累积N个事务后才fsync。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"MySQL索引","slug":"2 后端/MySQL/7. MySQL索引","date":"2021-12-14T12:38:14.000Z","updated":"2022-06-10T05:18:29.260Z","comments":true,"path":"d7c79caa873a/","link":"","permalink":"http://rookieyin.github.io/d7c79caa873a/","excerpt":"MySQL索引 1 索引概述 索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。 索引的作用就相当于目录的作用。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。","text":"MySQL索引 1 索引概述 索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。 索引的作用就相当于目录的作用。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。 当然，使用索引也是需要代价的，比如创建和维护索引就需要耗费很多时间。下面总结了使用索引的优缺点： 优点 加快检索速度 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，也就不需要创建临时表(B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表)。 将随机 I/O 变为顺序 I/O(B+Tree 索引是有序的，也就将相邻的数据都存储在一起)。 创建唯一索引，可以保证数据库表中每一行的唯一性 缺点 创建和维护索引需要耗费时间 索引需要使用物理文件存储，会耗费一定的物理空间 若索引太多，应用程序的性能会受到影响。而索引太少，对查询性能又会产生影响。因此在实际生产活动中，要根据业务情况，合理创建索引。 2 InnoDB中的索引 因为B+树具有高扇出性，因此高度通常在2~4层，也就是说查找某一键值对应的行记录时只需要2到4次IO即可。B+树索引可以分为聚集索引、辅助索引和联合索引，下面分别进行介绍。 2.1 聚集索引 聚集索引即按照表的逐渐构造一棵B+树，同时叶子节点中存放的为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。 上图展示了聚集索引的存储结构，需要注意的是：聚集索引的存储并不是物理上连续的，而是通过指针，实现逻辑上的连续。这里说到的连续有两个： 不同页，通过双向链表链接，页按照主键顺序排列； 页中的行数据，也是按照主键顺序排列，每一行数据也是通过链表连接到一起的。 下面总结了使用聚集索引的优缺点： 优点 对于主键的排序查找和范围查找速度非常快 叶子节点中的数据就是全数据，一次查找即可获得所有列的数据 缺点 依赖有序数据：如果索引列是字符串或者UUID之类的，比较难比较，插入和查找的速度会慢一点 更新代价大：索引列数据被修改的话，那么对应的索引也要修改，而且聚集索引叶子节点存放了整行数据，修改代价会比较大，所以一般禁止修改主键。 2.2 辅助索引 辅助索引，或者称之为二级索引，常见的二级索引包括唯一索引、普通索引、前缀索引、全文索引等。和聚集索引不同，二级索引的叶子节点包含的不是行数据而是主键值，如下图所示： 辅助索引的存在并不影响数据在聚集索引中的组织，每张表中可以有多个辅助索引。如果希望通过辅助索引查询非索引列数据，需要二次检索： 先在辅助索引中，检索，得到对应行主键； 根据步骤1得到的主键，到聚集索引中检索行数据。 这里引申出一个“覆盖索引”的概念。 覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。 辅助索引的优点是：更新代价比聚集索引小，因为叶子节点中只存放了主键。它的缺点是： 和聚集索引一样，它也依赖于有序的数据。 如果索引列没有覆盖查询数据，需要二次查询。 2.3 联合索引 联合索引就是：把多个列放到一起，建立索引，其本质上也是一个二级索引。比如将c2列和c3列建立联合索引，此时B+树建立规则为： 先把各个记录和页按照c2列进行排序； 如果两条记录c2列值相等，再按照c3列进行排序。 为c2、c3列建立的联合索引示意图如下： 此时索引的目录项包含三个值：主键、c1、c2 2.4 其他概念 2.4.1 回表 从前文我们知道，二级索引的数据页的目录项中只包含：主键和索引字段，那么如果我们需要查询非索引字段怎么办呢？此时就需要进行回表操作，到聚簇索引中获取目标字段。 所谓回表就是：首先通过二级索引获取目标数据的主键，然后拿着合法主键再到聚簇索引中获取目标字段。 2.4.2 覆盖索引 所谓覆盖索引，就是我们索引字段刚好包含我们需要查询的字段。举个例子：比如我们在c2、c3列上建立联合索引，现执行如下查询语句： 1select c1, c2 from demo where c1 = 1 and c2 = 2; 此时，我们直接在二级索引中就能获取我们需要的所有字段，无需执行回表操作，大大提高查询性能。 2.4.3 Cardinality 通过SHOW INDEX命令可以查看表的索引信息，其中有一个名为Cardinality的字段。Cardinality表示索引中不重复记录数量的一个预估值。在实际应用中，Cardinality/n_rows_in_table的值应当尽可能接近1，这样使用B+树索引才有意义。对于地区、类型、性别字段等，它们的取值范围通常很小，对这些字段添加索引没有太大意义，甚至影响系统性能。 不同存储引擎，对索引的实现不同，因此对于Cardinality值的计算和更新策略也是不同的。下面介绍InnoDB中Cardinality值的计算与更新策略。 计算方法 InnoDB内部通过采样的方法计算cardinality： 取B+树中所有叶子节点数量，记为A； 随机从B+树中取8个叶子节点，统计每个页中不同记录数，记为P1,…,P8； 根据采样信息，计算cardinality=（P1+P2+…+P8）*A/8 更新策略 表中1/16的数据已经发生过变化 这种策略表示，自上一次统计Cardinality信息后，表中1/16数据已经发生过变化，这时需要更新。 stat_modified_counter &gt; 2000000000 这种策略考虑的是如果表中某一行数据频繁地发生变动超过若干次，进行更新。 当执行一些SQL语句，比如ANALYZE TABLE，SHOW INDEX时会触发引擎去重新计算cardinality，因此当表中数据量很大时，这些命令执行速度较慢。 3 索引的使用 3.1 注意事项 选择合适的字段创建索引 不为NULL的字段 被作为条件频繁查询的字段 频繁需要排序的字段 被经常用于连接的字段 被频繁更新的字段，建立索引时要慎重 尽可能考虑建立联合索引，而不是单列索引 因为索引是占用磁盘空间的，索引过多，无论是维护、存储的代价都比价大。另外使用联合索引可能形成覆盖索引，提升查询性能。 注意避免索引的冗余 比如建立（a，b）联合索引，就不需要再给a单独建立索引了。 在字符串类型的字段上使用索引，要考虑使用前缀索引 3.2 常见索引失效场景 使用左或者左右模糊匹配 因为B+树索引按照索引值有序排列，只能根据前缀进行比较。需要注意的是，如果要查询的数据都在二级索引里面（覆盖索引），此时也会用到索引查询。只不过此时索引查询方式为全树扫描，而不是范围查询。因为和全表扫描相比，扫描整个二级索引树代价更低。举个例子：select * from s where name like &quot;%xxx&quot;，表s中只有id和name字段，id为主键，name字段构建了二级索引。 对索引字段使用函数，比如LENGTH函数等 不过MySQL8.0之后增加了函数索引。 对索引进行表达式计算，比如where id + 1 = 10 如果将其改为where id = 10 - 1就可以走索引。 对索引进行隐式类型转换 如果索引字段是字符串类型， 但是在条件查询中，输入的参数是整型的话，你会在执行计划的结果发现这条语句会走全表扫描。 比如phone类型为varchar，查询语句select * from t_user where phone = 1300000001;会进行全表扫描。 但是如果索引字段是整型类型，查询条件中的输入参数即使字符串，是不会导致索引失效，还是可以走索引扫描。 因为 MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。 联合索引非最左匹配 建立联合索引（a，b，c），如果查询条件只包含b或c或bc，那么不会走索引。因为建立联合索引时，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。 where子句中的or 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 因为or的两个条件只要满足1个即可，只有1个有索引没意义。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"MySQL的缓存机制","slug":"2 后端/MySQL/6. MySQL的缓存机制","date":"2021-12-13T12:38:14.000Z","updated":"2022-06-10T05:17:30.709Z","comments":true,"path":"52b102c1181c/","link":"","permalink":"http://rookieyin.github.io/52b102c1181c/","excerpt":"MySQL的缓存机制 本文简单总结下MySQL中的缓存机制，具体来说是，使用InnoDB作为作为存储引擎时的各种缓存机制。主要包含三个方面： MySQL层——查询缓存：作用不大，高版本mysql已经去掉了这个功能。 InooDB层——buffer pool：很重要，是保证InnoDB高性能的核心功能之一，也是本文的重点介绍对象。 三大日志文件的缓存：binglog、redolog和undolog三个日志文件，写文件时，先写到缓存，然后再刷盘。","text":"MySQL的缓存机制 本文简单总结下MySQL中的缓存机制，具体来说是，使用InnoDB作为作为存储引擎时的各种缓存机制。主要包含三个方面： MySQL层——查询缓存：作用不大，高版本mysql已经去掉了这个功能。 InooDB层——buffer pool：很重要，是保证InnoDB高性能的核心功能之一，也是本文的重点介绍对象。 三大日志文件的缓存：binglog、redolog和undolog三个日志文件，写文件时，先写到缓存，然后再刷盘。 1 查询缓存 具体可以参考：这篇博客 1.1 概述 MySQL查询缓（QC：QueryCache）在MySQL 4.0.1中引入， 5.6中默认禁用，5.7中被deprecated（废弃）以及8.0版本被Removed 。查询缓存存储SELECT语句的文本以及发送给客户机的结果集，如果再次执行相同的SQL，Server端将从查询缓存中检索结果返回给客户端，而不是再次解析执行SQL，查询缓存在session之间共享，因此，一个客户端生成的缓存结果集，可以响应另一个客户端执行同样的SQL。 可以通过query_cache_size和query_cache_type来配置缓存。如下图所示，开启缓存后，收到查询请求后，先看缓存中有没有，有的话直接从缓存中返回查询结果，没有的话再去数据库里面取。 那如何判断缓存中是否缓存了本次查询呢？ 通过SQL文本是否完全一致来判断，包括大小写，空格等所有字符完全一模一样才可以共享，共享好处是可以避免硬解析，直接从QC获取结果返回给客户端，下面的两个SQL是不共享滴，因为一个是from，另一个是From。 1234--SQL 1select id, balance from account where id = 121;--SQL 2select id, balance From account where id = 121; 1.2 为什么弃用 主要还是带来的收益很小，更新操作需要锁缓存，很多场景下反而会降低数据库并发能力。 The query cache is deprecated as of MySQL 5.7.20, and is removed in MySQL 8.0. Deprecation includes query_cache_type，可以看到从MySQL 5.6的默认禁用，5.7的废弃以及8.0的彻底删除，Oracle也是综合了各方面考虑做出了这样的选择。 QueryCache的特性对业务场景要求过于苛刻，与实际业务很难吻合，而且开启之后，对数据库并发度和处理能力都会降低很多，下面总结下为何MySQL从Disabled-&gt;Deprecated-&gt;Removed QueryCache的主要原因。 同时查询缓存碎片化还会导致服务器的负载升高，影响数据库的稳定性，在Oracle官方搜索QueryCache可以发现，有很多Bug存在，这也就决定了MySQL 8.0直接果断的Remove了该特性。 2 Buffer Pool 我们知道数据库中的数据是存在磁盘中，磁盘的IO速度是很慢的，如果每次查询都需要到磁盘里面去取数据，会严重影响数据库性能。因此必然需要建立缓存，把数据库中的数据加载到缓存中，需要的时候，先到缓存中找，缓存中没有，再去磁盘中找。 2.1 InnoDB缓存池概述 Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB 。 可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。 InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。 在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。 Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。 为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。 控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，如下图： 上图中控制块和缓存页之间灰色部分称为碎片空间（因为可能剩余一点空间，不够存放一对控制块和缓存页）。 查询一条记录，就只需要缓冲一条记录吗？ 不是的。 当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。 2.2 Buffer Pool的管理 2.2.1 空闲页管理 Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。 那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。 所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）。 Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。 有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。 2.2.2 页定位 前面提到，当我们需要访问某个页的数据时先要到缓存中去找，那么我们怎么知道页在不在缓存中呢？难道要遍历缓存中的所有页？ 回头想想，我们其实是根据表空间号+页号来定位一个页的，也就相当于表空间号+页号是一个key( 键) ，缓冲页控制块就是对应的value(值)。怎么通过一个key 来快速找到一个value呢？当然是哈希表了！ 因此我们可以用“表空间号+页号”作为key，用缓冲页控制块作为value来创建一个hash表。在需要访问某个页的数据时，先从哈希表中根据表空间号和页号看看是否有对应的缓冲页。如果有，直接使用缓存中的即可，如果没有，再去数据库中找该页，并把它加载到缓冲区中的某个空闲页。 2.2.3 脏页管理 设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。 那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。 有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。 2.3.4 页换入换出 我们知道缓存空间是有限的，如果缓存满了，但是我们要访问的页不在缓存中该怎么办呢？这时我们就要淘汰掉缓存中的某些页。那具体该淘汰那些缓存页呢？ 一个经典的方法就是LRU，即淘汰最近最少使用的页。简单的 LRU 算法的实现思路是这样的： 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。 至此，我们知道缓存池中通过3种类型链表来管理数据页： 空闲页：用空闲页链表来链接所有空闲页，需要的时候从链表中取一个即可； 干净页：缓存了数据，但是页数据没有被更改，位于LRU链表中； 脏页：缓存了数据，并且页中数据被修改了，脏页同时存在于LRU链表和Flush链表。 MySQL中使用的是增强版LRU，因为简单的LRU存在预读问题和全表扫描问题。 预读问题 InnoDB提供了一个看起来很贴心的服务——预读。所谓预读，就是InnoOB 认为执行当前的请求时，可能会在后面读取某些页面， 于是就预先把这些页面加载到Buffer Pool 中。根据触发方式的不同，预读又可以细分为下面两种： 线性预读：InnoDB提供了一个系统变量innodb_read_ahead_threshold，如果顺序访问的某个区的页面超过该值，会触发一次异步读取下一个区中全部的页面到 Buffer Pool 中的请求。 随机预读：如果某个区的13 个连续的页面都被加载到了Buffer Pool 中， 无论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其他页面到Buffer Pool中的请求。可以通过innodb-random-read ahead 系统变量打开该功能，它的默认值为OFF ，也就意味着InnoDB 并不会默认开启随机预法的功能。 预读本来是好事， 但是可能这些被提前加载进来的数据页，并没有被访问，相当于这个预读是白做了，这个就是预读失效。 并且如果此时Buffer Pool剩余容量不大的话，预读的内容会挤掉很多LRU链表尾部的元素，降低缓存命中率。 全表扫描 有的小伙伴可能会写一些需要进行全表扫描的语句（比如在没有建立合适的索引或者压根儿没有WHERE 子句的查询时）。全表扫描意味着什么？意味着我们可能要加载很多数据到缓存中，这时候如果缓存空闲空间不够话，可能要淘汰很多页。但是全表扫描的数据，在后面的查询中很可能用不到，这时候我们又要重新把需要的页加载到缓存中。 改进LRU InnoDB将LRU链表划分成两部分：old区域和yong区域，如下图所示： young区域：存储热数据。 预读的页加载到young区，当预读数据被真正使用时，才加载到old区。 old区域：存储冷数据，默认占总空间的37%。 这种方案可以很好的解决预读问题，但是对于全表扫描的问题该如何解决呢？ 在进行全表扫描时，虽然首次加载到Buffer Pool 中的页放到了old 区域的头部， 但是后续会被马上访问到，每次进行访问时又会把该页放到young 区域的头部， 这样仍然会把那些使用频率比较高的页面给&quot;排挤&quot; 下去。 LRU的young区存储的时热点数据，全表扫描问题的本质在于，一些非热点数据，把yong区的热点数据给挤出去了。那我们只要提高数据进入young区的门槛就能很好解决该问题。InnoDB是这样做的，进入到 young 区域条件增加了一个停留在 old 区域的时间判断。具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间： 如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从 old 区域移动到 young 区域的头部； 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部； 这个间隔时间是由 innodb_old_blocks_time 控制的，默认是 1000 ms。 也就说，只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部，很明显，在一次全表扫描的过程中，多次访问一个页面（也就是读取同一个页面中的多条记录）的时间不会超过1s。 另外，InnoDB 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。 2.3.5 其他 多个Buffer pool：在Buffer Pool 特别大并且多线程并发访问盘特别高的情况下，单一的Buffer Pool 可能会影响请求的处理速度.所以在Buffer Pool 特别大时，可以把它们拆分成若干个小的Buffer Pool ，每个Buffer Pool 都称为一个实例。它们都是独立的——独立地申请内存空间、独立地管理各种链表等等，在多线程并发访问时并不会相互影响， 从而提高了并发处理能力。我们可以在服务器启动的时候通过设置innodb_buffer_pool_instances的值来修改Buffer PooI 实例的个数。 buffer chunk：在MySQL 5 .7 .5版本之前，只能在服务器启动时通过配置innodb_buffer_pool_size 启动选项来调整Buffer Poo1 的大小，在服务器运行过程中是不允许调整该值的。 不过设计MySQL 的大叔在MySQL 5.7.5 以及之后的版本中，支持了在服务器运行过程中调整Buffer Poo1 大小的功能。但是有一个问题，就是每次重新调整Buffer Poo1 的大小时，都需要重新向操作系统申请一块连续的内存空间，然后将旧Buffer Poo1 中的内容复制到这一块新空间，这是极其耗时的。 所以，设计MySQL 的大叔决定不再一次性为某个Buffer Poo1 实例向操作系统申请一大片连续的内存空间，而是以一个chunk 为单位向操作系统申请空间。也就是说， 一个Buffer Pool实例其实是由若干个chunk 组成的。一个chunk 就代表一片连续的内存空间， 里面包含了若干缓冲页与其对应的控制块。 3 日志文件buffer 3.1 binlog cache 对于binglog数据，也是先将日志写到缓存中，然后等事务提交后，再写入磁盘。 分配内存：首先为每个session分配独立内存空间，用来存储二进制日志的缓存，可以通过binlog_cache_log设置缓存大小； 临时文件：当缓存大小超过binlog_cache_log后，会将数据写入大小为max_binlog_cache_size的临时文件； 临时文件存放于tmpdir目录下，以&quot;ML&quot;开头； 执行多语句事务时，如果缓存数据超过max_binlog_cache_size+binlog_cache_log，会报错。 刷盘：事务提交后，将binglog cache和binlog临时文件中所有数据写入磁盘。 3.2 redo log 3.2.1 buffer结构 redo log中数据存储方式是：把MTR（Min-Transaction，不可分割的一组日志）生成的redo日志放在大小为512字节的页中，称之为block。因此，redo log缓存也有着同样地存储格式，如下图所示： 在服务器启动时就向操作系统申请了一片连续空间，称之为redo log buffer。 3.2.2 数据写入 向log buffer中写入redo日志的过程是顺序写入的，也就是先写前面的block，当该block写满了，再写下一个block。InnoDB中存储了一个全局变量buf_free，用来指示下一条日志应该写到哪里，如下图所示： 3.2.3 刷盘时机 遇到下面这些情况，会将buffer中的数据刷新到磁盘中： log buffer空间不足 事务提交 后台有一个线程，大约每秒一次的频率将buffer中数据刷新到磁盘 正常关闭服务器时 做checkpoint时 3.3 undo log undo log数据存储在表空间中，因此它的缓存和数据页缓存一样，依靠前文提到的buffer pool实现的。我们看前文提到的buffer pool结构图中，其中有一项就是undo log页。 参考资料 https://xiaolincoding.com/mysql/buffer_pool/buffer_pool.html https://segmentfault.com/a/1190000038554542 《MySQL是怎样运行的》","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"InnoDB中的MVCC","slug":"2 后端/MySQL/5. InnoDB中的MVCC","date":"2021-12-12T12:38:14.000Z","updated":"2022-06-10T05:17:41.298Z","comments":true,"path":"f7547b80614e/","link":"","permalink":"http://rookieyin.github.io/f7547b80614e/","excerpt":"InnoDB中的MVCC 1 MVCC概述 MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制。我们知道数据库并发场景有3种： 读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 为了在这些场景中实现事务的隔离性，避免脏读、脏写、幻读、不可重复读等现象，一种常规的操作就是加悲观锁，让事务串行执行。但是这种方式会大大削弱系统的并发能力。 多版本并发控制（MVCC）就是一种用来解决读-写冲突的无锁并发控制 。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读 。","text":"InnoDB中的MVCC 1 MVCC概述 MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制。我们知道数据库并发场景有3种： 读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 为了在这些场景中实现事务的隔离性，避免脏读、脏写、幻读、不可重复读等现象，一种常规的操作就是加悲观锁，让事务串行执行。但是这种方式会大大削弱系统的并发能力。 多版本并发控制（MVCC）就是一种用来解决读-写冲突的无锁并发控制 。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读 。 2 MVCC实现原理 MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 2个隐式字段，undo日志 ，Read View 来实现的。 在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改 2.1 隐藏字段 对于InnoDB来说，一张表除了我们定义的字段外，数据库会自动添加一些隐藏字段，其中就包括： DB_TRX_ID：表示最后一次插入或更新该行的事务id，每一次改动都会把该事务的id赋值给trix_id隐藏列。 DB_ROLL_POINTER：回滚指针，我们知道为了实现原子性，数据库依赖于undo log进行回滚。每一条更新语句都会被记录在回滚日志中，而该指针就是指向更新改行的undo log。 下面举个例子： 比如一个有个事务插入person表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL 现在来了一个事务1对该记录的name做出了修改，改为Tom 在事务1修改该行(记录)数据时，数据库会先对该行加排他锁 然后把该行数据拷贝到undo log中，作为旧记录，即在undo log中有当前行的拷贝副本 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它 事务提交后，释放锁 又来了个事务2修改person表的同一个记录，将age修改为30岁 操作和步骤2类似，加锁，写入undo log，修改，提交事务，释放锁。 从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表 ，也就是我们常说的版本链。我们之后会利用这个记录的版本链来控制并发事务访问相同记录时的行为，我们把这种机制称之为多版本并发控制。 2.2 Read View 我们知道事务的隔离级别有4个，对于READ UNCOMMITTED 隔离级别的事务来说，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了; 对于使用SERIALIZABLE 隔离级别的事务来说， 设计lnnoDB 的大叔规定使用加锁的方式来访问记录；对于使用READ COMMITTED 和REPEATABLE READ 隔离级别的事务来说，都必须保证读到已经提交的事务修改过的记录. 也就是说假如另一个事务已经修改了记录但是尚未提交，则不能直接读取最新版本的记录。为此，设计lnnoDB 的大叔提出了ReadView （有的地方翻译成“一致性视图”）的概念。 Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大) ReadView中包含4个比较重要的内容： m_low_limit_id：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见 m_up_limit_id：活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见 m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中） m_creator_trx_id：创建该 Read View 的事务 ID 有了这个ReadView后，在访问某条记录时， 只需要对比该版本的trx_id，即可判断是否可见： 如果某个版本的数据对当前事务不可见，那就顺着版本链找到下一个版本的数据，并继续判断记录的可见性：依此类推，直到版本链中的最后一个版本.如果记录的最后一个版本也不可见，就意味着该条记录对当前事务完全不可见， 查询结果就不包含该记录。 3 其他问题 3.1 RC和RR下MVCC的差异 在事务隔离级别 RC 和 RR （InnoDB 存储引擎的默认事务隔离级别）下，InnoDB 存储引擎使用 MVCC（非锁定一致性读），但它们生成 Read View 的时机却不同 ： 在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表) 在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表） 3.2 二级索引和MVCC 我们知道， 只有在聚簇索号问录中才有trx_id 和roll_pointer 隐藏列。如果某个查询语句是使用二级索引来执行查询的， 该如何判断可见性呢？比如SELECT name FROM hero WHERE name = ‘刘备’，大致可以分成2步： 二级索引页面的Page Header中有一个名为PAGE_MAX_TRX_ID的属性，每当对该页面中的记录执行增删改操作时，如果执行该操作的事务的事务id 大于PAGE_MAX_TRX_ID属性值，就会把PAGE_MAX_TRX_ID属性设置为执行该操作的事务的事务id。这也就意味着PAGE_MAX_TRX_ID 属性值代表着修改该二级索引页面的最大事务id是什么。当select语句访问某个二级索引记录时，首先会看一下对应的ReadView的m_up_limit_id是否大于该页面的PAGE_MAX_TRX_ID属性值。如果是，说明该页面中的所有记录都对该ReadView可见; 否则就得执行步骤2 。在回表之后再判断可见性。 利用二级索引记录中的主键值进行回表操作， 得到对应的聚簇索引记录后再按照前面讲过的方式找到对该ReadView可见的第一个版本，然后判断该版本中相应的二级索引列的值是否与利用该二级索引查询时的值相同。本例中就是判断找到的第个可见版本的name 值是不是“刘备”。如果是， 就把这条记录发送给客户端（如果WHERE 子句中还有其他搜索条件的话还需继续判断)）， 否则就跳过该记录。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"MySQL事务","slug":"2 后端/MySQL/4. MySQL事务","date":"2021-12-11T12:38:14.000Z","updated":"2022-06-10T05:15:12.555Z","comments":true,"path":"06aa555bdbf7/","link":"","permalink":"http://rookieyin.github.io/06aa555bdbf7/","excerpt":"MySQL事务 何为事务？事务即一组操作，这组操作要么都执行，要么都不执行。事务是数据库区别文件系统的重要特性之一。数据库中引入事务的主要目的在于：事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以确保所有修改都已经保存，或者所有修改都不被保存。","text":"MySQL事务 何为事务？事务即一组操作，这组操作要么都执行，要么都不执行。事务是数据库区别文件系统的重要特性之一。数据库中引入事务的主要目的在于：事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以确保所有修改都已经保存，或者所有修改都不被保存。 1 事务概述 1.1 ACID特性 关系型数据库（例如：MySQL、SQL Server、Oracle 等）事务都有 ACID 特性： 原子性（Atomicity） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 1.2 事务分类 扁平事务：所有操作处于同一层次，其所有操作都是原子的，要么都执行，要么都回滚。它是最简单，但是实际生产环境中使用最频繁的事务。 带有保存点的扁平事务：在扁平事务中指定一些保存点，允许每次回滚到某个保存点。 链式事务：可以看作保存点事务的一种变体，相当于把原来带若干个保存点的扁平事务，从保存点拆分成若干个小事务，然后把这些小事务链到一起。其本质是：将提交事务和下一个事务的开始合并成一个原子操作，这样系统崩溃时，可以回滚到最近执行完的小事务时的状态。 目的：解决带保存点扁平事务，保存点不能持久化的问题； 和保存点扁平事务的区别：链式事务只能回滚到最近一次保存点（相当于小事务），而带保存点的扁平事务可以回滚到任意保存点。 嵌套事务：在一个根事务中调用子事务，同样子事务中可以调用子子事务，以此类推。需要注意的是，InnoDB不支持该类型事务。 分布式事务：事务中的操作需要访问不同网络节点。比如将“ATM机上从招行储蓄卡向工行储蓄卡转账”看做一个事务，那么该事务设计到ATM、招行数据库、工行数据库三个不同节点。 2 事务隔离级别 2.1 并发事务带来的问题 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题： 脏读：使用未提交数据。当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改：同时写。指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 不可重复读： 读的过程中数据被修改。指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读： 幻读与不可重复读类似， 指当事务不是独立执行时发生的一种现象。例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检索范围为只读，这样就避免了幻读。 注：注意幻读和不可重复读的区分，幻读指 前后多次读取，数据总量不一致 ，不可重复读指 前后多次读取，数据内容不一致 。 2.2 隔离级别 SQL标准定义了4中隔离级别： READ-UNCOMMITTED ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE ： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 InnoDB默认支持的隔离级别是REPEATABLE-READ，但是与标准SQL不同的是，InNoDB存储引擎在REPEATABLE-READ事务隔离级别下，使用Next-Key Lock锁算法，因此避免幻读的产生。所以说，InNoDB在默认的REPEATABLE-READ下的事务隔离级别已经达到了SQL标准的 SERIALIZABLE隔离级别。 3 事务实现原理 以MySQL的InnoDB为例： 使用 redo log(重做日志) 保证事务的持久性 ； 使用 undo log(回滚日志) 来保证事务的原子性； 通过 锁机制、MVCC 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。 3.1 redo log 3.1.1 redo概述 重做日志用来实现事务的持久性，由两部分组成：一是内存中的重做日志缓存，它是易失的；二是重做日志文件，它是持久的。当 MySQL 实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。 MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log file 里。 如上图所示，每提交一个事务，buffer都应该执行一次fsync操作，将缓存中的数据写入file中。但是InnoDB允许用户手工设置非持久性的情况发生，以提高数据库的性能。即当事务提交时，日志不写入重做日志文件，而是等待一个时间周期后再执行fsync操作。下面介绍下redo的刷盘策略。 3.1.2 刷盘策略 InnoDB存储引擎为刷盘策略提供了参数 innodb_flush_log_at_trx_commit，它支持3种策略： 0 ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作，这个操作仅在master thread中完成，而在master thread中每1秒进行一次重做日志文件的fsync操作。 1 ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）。 2 ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入文件系统的缓存中，不进行fsync。这种情况下数据库宕机不会丢失数据，操作系统宕机会丢失文件系统cache中的数据。 注： 当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘。 3.1.3 对比binlog binlog和redo log看起来都是记录了对于数据库操作的日志，但是两者存在很多区别： binglog是MySQL数据库上层产生的，redo log是InnoDB存储引擎中产生的； binlog记录的时SQL语句（逻辑日志），redo log记录的是页更改信息（物理日志）； binlog只在事务提交完成后进行一次写入，而redo log是随着事务的进行而不断写入。 3.1.4 log block 在InnoDB存储引擎中，重做日志（包括缓存和文件）都是以512字节大小的块方式进行存储的，称之为重做日志块。若一个页中产生的重做日志数量大于512字节，就需要分割成多个重做日志块进行存储。每个存储块包含3个部分：日志块头（12字节）、日志块尾（8字节）和日志数据（492字节）。 3.1.5 log group 硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。 文件组只是1个逻辑上的概念，并没有1个实际物理文件来表示log group信息。 3.1.6 LSN LSN（Log Sequence Number），代表日志序列号。在InnoDB中，LSN占用8个字节，且单调递增，它可以表示3中含义： 重做日志写入的总量 比如当前重做日志LSN的值为1000，有1个事务写入了100字节的日志，那么LSN的值变成1100。 checkpoint的位置 表示已经刷新到磁盘页上的LSN。 页的版本 在每个页的头部，有一个值FIL_PAGE_LSN，记录了该页的LSN。在页中，LSN表示该页最后刷新时LSN的大小 通过SHOW ENGINE INNODB STATUS可以查看LSN的情况。 LSN的一个重要功能就是用于数据恢复。InnoDB存储引擎在启动时不管上次数据库连接是否正常关闭，都会尝试进行恢复操作。具体做法就是：对比checkpoint（即磁盘页上的LSN）和重做日志上的LSN，如果两者不一致，比如checkpoint为1000，而重做日志LSN为1300，则恢复1000~1300之间的数据。 3.2 undo log undo log是回滚日志，用于事务执行失败或者用户发起ROLLBACK时的会滚操作。所有事务的修改操作都会先记录到这个回滚日志中，然后再进行操作。undo log具有以下特性： undo log是逻辑日志，只能将数据库逻辑地恢复到原来的样子，但是数据库的页结构可能发生了很大变化。在回滚时，InnoDB执行的其实是一个相反操作，比如要回滚一条INSERT语句时，会执行一条DELETE语句。 undo log存放在数据库内部的一个特殊段，称之为undo segment，它位于共享表空间内。 在使用undo log进行回滚时，也会产生redo log。 undo log可以分为两种：insert undo和undate undo。insert undo log只对产生该条记录的事务可见，事务commit后即可删除，而undate undo 则不行。因为undate undo是对delete和update操作产生的日志，该日志可能需要提供MVCC机制，因此不能在事务提交后立即删除，而是由purge线程进行最后删除。 注：对于delete操作产生的undo log其实是将该条数据的del_flag字段置为1；对于update操作，是将该条数据的del_flag操作置为1，再插入一条新数据。 3.3 两阶段提交 两阶段提交是为了解决binglog和redo log之间一致性问题而提出的一种方案。 3.3.1 数据不一致问题 在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样。 我们以update语句为例，假设id=2的记录，字段c值是0，把字段c值更新成1，SQL语句为update T set c=1 where id=2。 假设执行过程中写完redo log日志后，binlog日志写期间发生了异常，会出现什么情况呢？ 由于binlog没写完就异常，这时候binlog里面没有对应的修改记录。因此，之后用binlog日志恢复数据时，就会少这一次更新，恢复出来的这一行c值是0，而原库因为redo log日志恢复，这一行c值是1，最终数据不一致。 3.3.2 解决方案 为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。 原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。 使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。 注：如果redo log阶段更新出错，是否会回滚？不会，因为MySQL发现该事务存在于binlog中，即使redo log处于准备阶段，也不会进行回滚。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"InnoDB数据的存储","slug":"2 后端/MySQL/3. InnoDB数据的存储","date":"2021-12-10T12:38:14.000Z","updated":"2022-06-10T05:14:23.896Z","comments":true,"path":"f4457fe10c6c/","link":"","permalink":"http://rookieyin.github.io/f4457fe10c6c/","excerpt":"InnoDB数据的存储 我们知道MySQL可以分成两层，数据的读取和写入工作是由底层存储引擎负责的。本文主要介绍InnoDB底层是如何存放数据的。","text":"InnoDB数据的存储 我们知道MySQL可以分成两层，数据的读取和写入工作是由底层存储引擎负责的。本文主要介绍InnoDB底层是如何存放数据的。 1 InnoDB逻辑存储结构 如下图所示，InnoDB中所有数据都被逻辑地存放在一个空间，称之为表空间。表空间又由段、区、页组成。 表空间 默认情况下，InnoDB将所有表都放在同一个表空间，也可以通过参数innodb_file_per_table，将每张表放到一个单独表空间。 段 表空间由各个段组成，常见的段有数据段、索引段、回滚段等。在InnoDB中，数据是存放在主键B+树索引的叶子节点中，因此数据段即为B+树索引叶子节点，索引段即为B+树索引非叶子节点。 区 区是由连续页组成的空间，任何情况下区的大小都固定为1MB。默认情况下InnoDB页大小为16KB，因此1个区有64个连续页。需要注意的一点是，在每个段开始的时候，先用32个页大小的碎片页来存放数据，在使用完这些碎片页之后才申请64个连续页。这样做的目的在于，对于一些小表来说，可以节省磁盘空间。 页 页是InnoDB磁盘管理的最小单位，InnoDB中每个页默认大小为16KB。InnoDB中常见的页类型有：数据页、undo页、系统页、事务缓存页、插入缓冲位图页、插入缓冲空闲列表页、未压缩的二进制大对象页、压缩的二进制大对象页。 行 InnoDB是面向行存储的，即页中的数据是逻辑上一行接一行排列的，实际上是通过链表相连。 2 InnoDB行记录格式 InnoDB提供Compact和Redundant两种格式来存放行记录数据。Redundant是为了兼容以前版本而保留的，在MySQL5.1之后默认的行格式是Compact。 2.1 Compact行记录格式 Compact是MySQL5.0中引入的，其设计目标在于高效地存储数据（一个页中存放的行数据越多，越高效）。 变长字段长度列表**：列长度小于255字节，用1字节表示，若大于255字节，用2字节表示。它有一下特点： 逆序存放，比如值为01 04 03分别表示第3、2、1列边长字段占用字节数为1、4、3个字节。 变长字段的值为NULL，长度列表里面不会记录其字节数为0。 问题：怎么知道什么时候1字节表示1列，什么时候2字节表示1列？ 详情可看文末。 NULL标志位：通常大小为1字节，将所有没有被NOT NULL修饰的列放到一起（节约空间），然后和标志位二进制值一一对应，二进制值为1，代表该列值为NULL，为0，代表不为NULL。需要注意的是，这里也是逆序存放。下面看一个例子：一张表有4列，第2列被NOT NULL修饰，此时他们和NULL标志位的对应关系如下图所示： 记录头信息：一共占用40字节空间，如下表所示： 真实数据列 隐藏列：InnoDB的每张表都默认被添加了一些隐藏列：db_row_id，db_trx_id和db_roll_ptr，分别表示行ID，事务ID和回滚指针。如果用户建表时指定了表主键，则不会创建db_row_id隐藏列。这3个隐藏列放在真实数据列的最前面。 NULL值：如果某字段数据为NULL，则不被存储。 char(M)：指定字符数的字段，如果真实数据长度不够，会用0x20填充。还需要注意的一点是，如果char字段采用的是变长编码字符集时，该列占用的字节数会被加到变长字段长度列表，并且char(M)至少占用M个字节，即char(10)使用utf8字节符集时，该列存储的数据占用的字节长度范围为10~30。 即使我们向该列中存储一个空字符串也会占用10 字节，这主要是希望在将来更新该列时， 在新值的字节长度大于旧值的字节长度但不大于10 个字节时，可以在该记录处直接更新，而不是在存储空间中再重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片。 2.2 Redundant 行记录格式 Redundant是MySQL5.0之前使用的一种行格式，其结构如下图所示： 字段长度偏移列表：1个或2个字节长度，它和Compact相比有2处不同： 没有“变长”两个字，也就是说所有列的长度信息都会存储在这里 多了“偏移”两个字，它存储的时各个字段的偏移量，字段长度需要计算两个偏移量之间的差值获取 问题：什么时候1个字节，什么时候2个字节？ 当记录的真实数据占用的字节数不大于127，每个列对应的偏移量占1个字节 为什么是127，不是225？因为最高位被看作NULL标志位，如果为1，表示该列为NULL。 当记录的真实数据占用的字节数大于127，不大于32767，每个列对应的偏移量占2个字节 有没有记录的真实数据大于3 2767 的情况呢？有， 不过此时记录的一部分已经存放到了所谓的溢出页中。 问题：那怎么知道用的是1字节表示长度还是2字节表示长度呢？ 记录头中有一个1byte_offs_flag属性，1表示使用1字节，0表示使用2字节。 记录头信息：一共48个字节 真实数据 Null值的处理：varchar不占用空间，char占用，用0x00填充。 char(M)：无论是定长字符集还是变长字符集，char(M)占用的空间是M乘以该字符集下每个字符最多占用字节数。比如对于utf8字符集，char(10)直接占用30字节空间。 2.3 行溢出数据的存储 InnoDB的页大小是16KB，也就是16384个字节，如果一行记录中某列占用字节数大于16284，那么这一页空间连一行数据都存不下。因此，对于占用存储空间非常多的列需要单独存储。对于Compact和Redundant类型，溢出列的记录方式如下图所示： 如上图所示，该行记录只存储溢出列前768个字节，其余数据放到其他页中存储，然后用20字节的指针指向页地址。 那么什么时候列会产生溢出呢？通过简单的计算可以得出溢出的临界点为8099，即列空间大小小于8099不会溢出，如果大于等于8099就会溢出。 2.4 Compressed和Dynamic行记录格式 我现在使用的MySQL 版本是5.7，其默认行格式就是DYNAMIC 。 这两个行格式与COMPACT 行格式挺像，只不过在处理溢出列的数据时有点儿分歧：它们不会在记录的真实数据处存储该溢出列真实数据的前768 字节，而是把该列的所有真实数据都存储到溢出页中，只在记录的真实数据处存储20 字节大小的指向溢出页的地址(当然，这20 字节还包括真实数据占用的字节数)。如下图所示： 总之，Redundant是一种比较原始的行格式，它是非紧凑的，而compact、dynamic和compressed行格式是较新的，它们是紧凑的（即占用空间小）。 3 InnoDB数据页结构 如上图所示，一个InnoDB数据页大致可以分成7个部分，下表简单描述了这些部分的大致功能： 3.1 File Header File Header用来记录页的一些头信息，8个部分，共占用38个字节。 3.2 Page Header Page Header里面存放一些页的状态信息，有14个部分，共占用56个字节。 3.3 Infimum和Supremurm记录 在InnoDB中，每各页中会有两个虚拟记录，用来限定记录的边界，即最小、最大记录。页面中任何记录的主键值都大于Infimum记录，都小于suprememurm记录。因此这两条伪记录分别处于记录链表的头部和尾部。 3.4 User Record和Free Space User Record：即存储行记录的内容，所有记录链表相连 Free Space：即空闲空间，所有空闲空间也是个链表数据结构。一条记录被删除后，该空间会被加入到空闲列表中。 下图展示了页中每条记录的存放方式： 从上图可以看出，记录按照主键从小到大形成了一个单向链表。 3.5 Page directory 从名字就可以看出来，这部分存放的时一个目录。从前面我们知道，所有记录是通过链表主键递增顺序一个个串在一起的，因此要查找某个记录，就需要顺序遍历链表。 Page目录存在的目的就是，帮助我们根据行记录的逐渐，快速定位该条记录所在位置。 Page 目录中存在很多指向页中记录的指针，这个指针称之为槽，如下图所示： 上图中有2个槽，槽将所有记录分成了两组，槽指向的是分组中主键值最大的那条记录，即分组的最后一条记录。关于槽，有以下几点需要注意： 槽中记录的时地址偏移量，而不是绝对地址。 槽指向的记录中n_owned数值为该分组中记录总数，分组中其余记录的n_owned值为0。 每个槽占用2字节，按照对应记录的大小顺序排列。槽对应记录的主键越小，它的位置越靠近File Trailer。 下图展示了一个记录数更多的示例： 当需要查找某条记录时，先通过二分法确定该记录所在分组对应的槽，然后遍历该分组中的记录。 3.6 File Trailer InnoDB的数据是存储在磁盘上的，但是磁盘速度太慢了，需要以页为单位把数据加载到内存中处理。如果该页在内存中被修改了，那么在修改后的某个时间还需要把数据刷新到磁盘中。 但是，如果刷新过程中，断电了咋办？为了检测页的完整性，InnoDB在页的末尾增加了File Trailer部分（8个字节），可以分成2部分： 前4个字节：代表页的校验和。 这个部分与File Header 中的校验和相对应.每当一个页面在内存中发生修改时，在刷新之前就要把页面的校验和算出来。因为File Header 在页面的前边，所以File Header 中的校验和会被首先刷新到磁盘，当完全写完后，校验和也会被写到页的尾部.如果页面刷新成功，则页首和页尾的校验和应该是一致的。如果刷新了一部分后断电了，那么File Header 中的校验和就代表着己经修改过的页，而Fi1e Trai1er 中的校验和代表着原先的页， 二者不同则意味着刷新期间发生了错误。 后4个字节：最后修改时对应的LSN的后4个字节。正常情况下应该与File Header 部分的FIL_PAGE_LSN 的后4 字节相同。 4 拓展问题 Compact行记录格式下，如何确定“变长字段长度列表”长度是1字节还是2字节？ 用1字节还是2字节来表示变长字段的真实数据占用的字节数， InnoDB 有它的一套规则。为了更清楚的描述这套规则，我们引入W、M和L这几个符号： W：表示所使用的字符集中，一个字符最多占用W个字节。对于utf8字符集，W就是3；对于gbk字符集，W就是2；对于ascii字符集，W就是1。 M：字段类型VARCHAR(M)中的M，表示最多存储M个字符。 L：该字段实际存储的字符串占用的字节数。 判断1字节还是2字节的规则如下： 如果M×W≤255M\\times W\\leq 255M×W≤255，那么使用1字节 如果M×W&gt;255M\\times W &gt; 255M×W&gt;255，分两种情况 如果L≤127L\\leq 127L≤127，则用1字节来表示真实数据占用的字节数 如果L&gt;127L&gt;127L&gt;127，则用2字节来表示真实数据占用的字节数 问什么是127？因为如果用2字节表示长度，对于某个字节怎么知道它是一个字段长度还是半个字段长度？如果该字节第一位为0，说明该字节表示的是完整字节段长度，否则说明它表示的是半个字段长度。 **总之：**如果变长字段允许存储的最大字节数M×WM\\times WM×W超过255，并且真实数据占用的字节数L超过127，则使用2字节表示真实数据占用的字节数，否则使用1字节。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"MySQL数据类型","slug":"2 后端/MySQL/2. MySQL数据类型","date":"2021-12-09T12:38:14.000Z","updated":"2022-06-10T05:11:45.424Z","comments":true,"path":"87c401808af7/","link":"","permalink":"http://rookieyin.github.io/87c401808af7/","excerpt":"MySQL数据类型 1 字段类型 1.1 整型 MySQL中可以表示整型数据的类型有5种：TINYINT， SMALLINT，MEDIUMINT，INT和BIGINT，分别占用1、2、3、4、8个字节。 所有类型都可以设置成unsigned。 需要注意的是INT(11)这类描述中的“11”指的是交互工具中显示宽度为11，不会对数据占用空间和表示范围造成任何影响。","text":"MySQL数据类型 1 字段类型 1.1 整型 MySQL中可以表示整型数据的类型有5种：TINYINT， SMALLINT，MEDIUMINT，INT和BIGINT，分别占用1、2、3、4、8个字节。 所有类型都可以设置成unsigned。 需要注意的是INT(11)这类描述中的“11”指的是交互工具中显示宽度为11，不会对数据占用空间和表示范围造成任何影响。 1.2 浮点数 FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。 float(M, D)和double(M, D)，分别占用4个和8个字节 M表示总位数，如果插入数据的位数超过M，则报错。 D表示小数点后的精度，如果插入数据的精度超过D，则四舍五入插入。 decimal(M, D)，占用空间取决于M和D，如果M&gt;D，为M+2否则为D+2 float、double类型存在精度丢失问题，即写入数据库的数据未必是插入数据库的数据，而decimal无论写入数据中的数据是多少，都不会存在精度丢失问题。因为decimal是以字符串形式进行保存的； 为什么float/double可能存在精度丢失问题？ 因为计算机存储数据都是要先转化成二进制再存储，而将小数转成二进制有时候可能得到一个无穷数，这时候计算机就会对其进行截断保存（mysql中float截取前32位，double截取前64位）。 decimal(M,D)的规则和float/double相同，但区别在float/double在不指定M、D时默认按照实际精度 （由计算机硬件和操作系统决定） 来处理而decimal在不指定M、D时默认为decimal(10, 0)。 1.3 字符串 char：固定长度字符串， 其长度范围为0 ~ 255个字符且与编码方式无关，无论字符实际长度是多少，都会按照指定长度存储，不够的用空格补足； varchar(n)：为可变长度字符串，在utf8编码的数据库中其长度范围为0 ~ 21844个字符，在gbk编码下长度范围为0~32765。 不同编码下长度范围是咋算的？ MySQL要求一个行的定义长度不能超过65535即64K； 对于未指定varchar字段not null的表，会有1个字节专门表示该字段是否为null； varchar(M)，当M范围为0&lt;=M&lt;=255时会专门有一个字节记录varchar型字符串长度，当M&gt;255时会专门有两个字节记录varchar型字符串的长度，把这一点和上一点结合，那么65535个字节实际可用的为65535-3=65532个字节； 所有英文无论其编码方式，都占用1个字节，但对于gbk编码，一个汉字占两个字节，因此最大M=65532/2=32766；对于utf8编码，一个汉字占3个字节，因此最大M=65532/3=21844，上面的结论都成立； 举一反三，对于utfmb4编码方式，1个字符最大可能占4个字节，那么varchar(M)，M最大为65532/4=16383，可以自己验证一下 注： 上面是表中只有varchar型数据的情况，如果表中同时存在int、double、char这些数据，需要把这些数据所占据的空间减去，才能计算varchar(M)型数据M最大等于多少。 BLOB和TEXT BLOB和TEXT都是为存储很大的数据而设计的数据类型，分别采用二进制和字符方式存储，前者主要用于存储图片、音频等二进制文件。 与其他类型不同，MySQL把每个BLOB和TEXT值当做一个独立的对象去处理。当BLOB和TEXT值太大时，InnoDB会使用专门的“外部”存储区域来进行存储，此时每个值在行内需要1~4个字节存储一个指针，然后在外部存储区域存储实际的值。 它只对每个列的最前max_sort_length个字节而不是整个字符串做排序。同样的，MySQL也不能将BLOB或TEXT列全部长度的字符串进行索引。 Text V.S varchar 两者之间的联系在于： 当varchar(M)的M大于某些数值时，varchar会自动转为text。当然两个也存在区别： 单行64K空间，varchar只能利用63352个字节，但是text可以利用全部65535个； text可以指定text(M)，但是没有任何作用； text不允许有默认值，varchar可以。 1.4 时间和日期 MySQL中表示时间的类型有date，time，year，datetime和timestamp，分别占用3，3，1，8，4个字节。其中date、time和year不带具体小时分钟等，因此datetime和timestamp最常使用。下面对比下这两种类型： datetime和timestamp存储日期的格式都是“yyyy-MM-dd HH:mm:ss”，前者8个字节，后者4个字节。 datetime与timestamp能存储的时间范围也不同，datetime的存储范围为1000-01-01 00:00:00——9999-12-31 23:59:59，timestamp存储的时间范围为19700101080001——20380119111407。 datetime默认值为空，当插入的值为null时，该列的值就是null；timestamp默认值不为空，当插入的值为null的时候，mysql会取当前时间。 datetime存储的时间与时区无关，timestamp存储的时间及显示的时间都依赖于当前时区。 1.5 类型的选择 char和varchar VARCHAR是最常见的字符串类型。VARCHAR节省了存储空间，所以对性能也有帮助。但是，由于行是可变的，在UPDATE时可能使行变得比原来更长，这就导致需要做额外的工作。如果一个行占用的空间增长，并且在页内没有更多的空间可以存储，MyISAM会将行拆成不同的片段存储；InnoDB则需要分裂页来使行可以放进页内。 什么时候使用varchar？ 字符串的最大长度比平均长度大很多； 列的更新很少，所以碎片不是问题 ； 使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储。 当存储CHAR值时，MySQL会删除所有的末尾空格。CHAR值会根据需要采用空格进行填充以方便比较。 什么时候使用char？ CHAR适合存储很短的字符串，或者所有值都接近同一个长度，如密码的MD5值。 对于经常变更的数据，CHAR也比VARCHAR更好，因为CHAR不容易产生碎片。 varchar(5)和varchar(200) 使用VARCHAR(5)和VARCHAR(200)存储&quot;hello&quot;的空间开销是一样的。 但是更长的列会消耗更多的内存，因为MySQL通常会分配固定大小的内存块来保存内部值。尤其是使用内存临时表进行排序或其他操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。所以最好的策略是只分配真正需要的空间。 选择标识符 整数类型通常是标识列的最佳选择，因为它们很快并且可以使用AUTO_INCREMENT。 如果可能，应该避免使用字符串类型作为标识列，因为它们很耗空间，并且比数字类型慢。 对于完全随机的字符串也需要多加注意，例如MD5(),SHA1()或者UUID()产生的字符串。这些函数生成的新值会任意分布在很大的空间内，这会导致INSERT以及一些SELECT语句变得很慢： 因为插入值会随机的写入到索引的不同位置，所以使得INSERT语句更慢。这会导致页分裂、磁盘随机访问。 SELECT语句会变的更慢，因为逻辑上相邻的行会分布在磁盘和内存的不同地方。 随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的局部性原理失效。 varchar长度怎么选? varchar需要多长就设置多长，不必考虑2的多少次幂的问题，但是不能想分配多少就分配多少，设置过大，会浪费内存。因为读取数据时候，需要预分配内存，如果n设置的很大，需要分配很大的内存空间。另外，如果遇到了varchar(256)这种情况，可以设置为varchar(255)呢，明显节省了一个存储长度的字节呀。 参考资料 https://pdai.tech/md/db/sql-mysql/sql-mysql-theory.html https://www.cnblogs.com/xrq730/p/8446246.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"一条SQL语句的执行","slug":"2 后端/MySQL/1. 一条SQL语句的执行","date":"2021-12-08T12:38:14.000Z","updated":"2022-06-10T05:11:09.835Z","comments":true,"path":"9f9bc781c9c3/","link":"","permalink":"http://rookieyin.github.io/9f9bc781c9c3/","excerpt":"一条SQL语句的执行 本篇文章会分析下一个 sql 语句在 MySQL 中的执行流程，包括 sql 的查询在 MySQL 内部会怎么流转，sql 语句的更新是怎么完成的。 在分析之前我会先带着你看看 MySQL 的基础架构，知道了 MySQL 由那些组件组成以及这些组件的作用是什么，可以帮助我们理解和解决这些问题。","text":"一条SQL语句的执行 本篇文章会分析下一个 sql 语句在 MySQL 中的执行流程，包括 sql 的查询在 MySQL 内部会怎么流转，sql 语句的更新是怎么完成的。 在分析之前我会先带着你看看 MySQL 的基础架构，知道了 MySQL 由那些组件组成以及这些组件的作用是什么，可以帮助我们理解和解决这些问题。 1 MySQL基础架构 下图展示了MySQL的一个简要架构图： 简单来说，MySQL主要分为Server层和存储引擎层： Server层： 主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。 （MySQL 8.0 版本后“查询缓存”被移除，因为这个功能不太实用）。 存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。 下面详细介绍一下Server层的几个基本组件： 连接器 连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。 主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即使管理员修改了该用户的权限，该用户也是不受影响的。 查询缓存 查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。 连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。 MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。 所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。 MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。 分析器 MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步： 第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。 第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。 完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。 优化器 优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。 执行器 当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。 2 语句分析 2.1 查询语句 说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下： 1select * from tb_student A where A.age=&#x27;18&#x27; and A.name=&#x27; 张三 &#x27;; 结合上面的说明，我们分析下这个语句的执行流程： 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id=‘1’。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。 接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案： 先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。 先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。 那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。 这里有一个索引下推的知识点需要了解， 索引下推（index condition pushdown ）简称ICP，在Mysql5.6的版本上推出，用于优化查询。 正常数据查询过程如下： MySQL 存储引擎层只把满足索引键值对应的整行表记录一条一条取出，并且上传给 MySQL 服务层 MySQL 服务层对接收到的数据，使用 SQL 语句后面的 where 条件过滤，直到处理完最后一行记录，再一起返回给客户端。 使用ICP后，查询流程为： MySQL 存储引擎层，先根据过滤条件中包含的索引键确定索引记区间，再在这个区间的记录上使用包含索引键的其他过滤条件进行过滤，之后规避掉不满足的索引记录，只根据满足条件的索引记录回表取回数据上传到 MySQL 服务层。 MySQL 服务层对接收到的数据，使用 where 子句中不包含索引列的过滤条件做最后的过滤，然后返回数据给客户端。 ICP 就是把以上索引扫描和索引过滤合并在一起处理，过滤后的记录数据下推到存储引擎后的一种索引优化策略。这样做的优点如下： 减少了回表的操作次数。 减少了上传到 MySQL SERVER 层的数据。 ICP 默认开启，可通过优化器开关参数关闭 ICP：optimizer_switch=‘index_condition_pushdown=off’ 或者是在 SQL 层面通过 HINT 来关闭。 2.2 更新语句 以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下： 1update tb_student A set A.age=&#x27;19&#x27; where A.name=&#x27; 张三 &#x27;; 其实这条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块是 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下： 先查询到张三这一条数据，如果有缓存，也是会用到缓存。 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。 更新完成。 注1：这里还忽略了一些操作，undo log的写入。在事务执行过程中，InnoDB会把每一条数据的修改记录写入回滚日志中。 注2：这里还有一个知识点就是“两阶段提交”，第二步中写完redo log，进行prepare状态，然后写binlog，最后redo log变成提交状态。具体信息可以参看另一篇文章“MySQL事务”。 参考资料 https://javaguide.cn/database/mysql/how-sql-executed-in-mysql.html https://xiaolincoding.com/mysql/base/how_select.html","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"}]},{"title":"An Empirical Study of Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/22. An Empirical Study of Graph Contrastive Learning ","date":"2021-11-27T05:38:35.000Z","updated":"2022-06-10T11:38:12.765Z","comments":true,"path":"debd25f73abb/","link":"","permalink":"http://rookieyin.github.io/debd25f73abb/","excerpt":"https://arxiv.org/pdf/2109.01116 https://github.com/GraphCL/PyGCL An Empirical Study of Graph Contrastive Learning ，2021，NIPS( Datasets and Benchmarks track ) 总结：一篇实验型综述，尝试通过实验对现有GCL方法有效性进行解释，并总结出一些通用的结论。另外，作者写了一个GCL库PyGCL，里面封装了一些标准化的GCL组件。","text":"https://arxiv.org/pdf/2109.01116 https://github.com/GraphCL/PyGCL An Empirical Study of Graph Contrastive Learning ，2021，NIPS( Datasets and Benchmarks track ) 总结：一篇实验型综述，尝试通过实验对现有GCL方法有效性进行解释，并总结出一些通用的结论。另外，作者写了一个GCL库PyGCL，里面封装了一些标准化的GCL组件。 1. 简介 1.1 摘要 Graph Contrastive Learning (GCL) establishes a new paradigm for learning graph representations without human annotations. Although remarkable progress has been witnessed recently, the success behind GCL is still left somewhat mysterious. In this work, we first identify several critical design considerations within a general GCL paradigm, including augmentation functions, contrasting modes, contrastive objectives, and negative mining techniques. Then, to understand the interplay of different GCL components, we conduct extensive, controlled experiments over a set of benchmark tasks on datasets across various domains. Our empirical studies suggest a set of general receipts for effective GCL, e.g., simple topology augmentations that produce sparse graph views bring promising performance improvements; contrasting modes should be aligned with the granularities of end tasks. In addition, to foster future research and ease the implementation of GCL algorithms, we develop an easy-to-use library PyGCL, featuring modularized CL components, standardized evaluation, and experiment management. We envision this work to provide useful empirical evidence of effective GCL algorithms and offer several insights for future research. 图对比学习（GCL）构建了一种新的无需人工标注的图表示学习模式。虽然最近GCN方法取得了很大进展，但是GCL成功的背后还隐藏这很多秘密。本文，我们首先确定了在通用GCL框架下，模型设计时需要考虑的几个关键要素，包括增强函数，对比模式，对比目标以及负采样技术。然后为了了解GCL不同组件之间的相互作用，我们在多个领域多个标准数据集上进行了大量可控实验。我们通过实证研究提出了一些通用策略，可以有效提高GCL性能，比如生成稀疏图视角的简单的拓扑增强可以带来很可观的性能提升，对比模式应该和最终任务的粒度对齐。另外，为了促进未来的研究和简化GCL算法的实现，我们开发了一种简单易用的库PyGCL，具有模块化CL组件，标准化评估标准和实验管理。我们希望这项工作能够为有效GCL算法提供经验证据，并为未来的研究提供一些见解。 1.2 本文工作 背景： GNN虽然作为图结构数据学习中非常重要的一种架构，但是现有的GNNs基本都是（半）监督方法，依赖大量有标签数据。最近几年受对比学习在各种领域成功应用的启发，GCL也得到了很大发展。 动机： 现有GCL方法取得了不错效果，但是从方法角度来看这些模型，它们之间的差别非常小。并且现有的工作只提供了model-level的评价，缺乏对GCL成功背后原因的探索。 本文工作： 对于一个通用GCL框架，作者从（1）增强函数；（2）对比模式；（3）对比目标；（4）负采样；四个组件入手，分析现有GCL方法成功的原因，并尝试回答下面三个问题： 在一个有效GCL方法中，哪个组件贡献最大？ 各个组件的不同设计是如何影响模型性能的？ 作者在研究这些问题时得出了一些结论，可以帮助设计有效的GCL算法： 采用拓扑增强生成稀疏图视角效果最好，并且同时使用拓扑增强和特征增强可以进一步提高模型性能。 总的来说，相同尺度的对比模式是可取的，并且对比模式应该根据下游任务的粒度进行选取。 InfoNCE损失可以带来稳定、一致的性能收益，但是需要大量的负样本。 最近提出的一些无需显示负采样的目标函数有很大潜力，可以在影响模型性能的情况下减小计算代价。 现有的基于嵌入相似性的负挖掘策略并不能给GCL带来很大的性能提升。 除此之外，作者搞了个GCL库PyGCL，里面提供了模块化的GCL组件、标准评估方法和实验管理工具。 2. 通用GCL框架 如上图1所示，GCL的训练步骤如下： 增强， 在每一轮训练前，先通过执行随机增强，生成输入图的不同视角。具体来说，采样两个增强函数t1,t2∼Tt_1,t_2\\sim \\mathcal Tt1​,t2​∼T，用于生成图视角G1~=t1(G)\\tilde{\\mathcal G_1}=t_1(\\mathcal G)G1​~​=t1​(G)和G2~=t2(G)\\tilde{\\mathcal G_2}=t_2(\\mathcal G)G2​~​=t2​(G)。 编码， 然后用一个参数共享的图编码器f(⋅)f(\\cdot)f(⋅)学习两个视角的节点嵌入，分别表示为U=f(X~1,A~1)U=f\\left(\\widetilde{\\boldsymbol{X}}_{1}, \\widetilde{\\boldsymbol{A}}_{1}\\right)U=f(X1​,A1​) 和V=f(X~2,A~2)V=f\\left(\\widetilde{\\boldsymbol{X}}_{2}, \\widetilde{A}_{2}\\right)V=f(X2​,A2​)。 Readout， 再通过一个readout函数r(⋅)r(\\cdot)r(⋅)就能得到两个图视角的图嵌入，分别表示为s1=r(U)s_{1}=r(\\boldsymbol{U})s1​=r(U) 和s2=r(V)s_{2}=r(\\boldsymbol{V})s2​=r(V)。 对比， 对于锚点viv_ivi​，根据不同的对比模式可以确定一个正样本集合P(vi)={pi}i=1P\\mathcal{P}\\left(\\boldsymbol{v}_{i}\\right)=\\left\\{\\boldsymbol{p}_{i}\\right\\}_{i=1}^{P}P(vi​)={pi​}i=1P​和一个负样本集合Q(vi)={qi}i=1Q\\mathcal{Q}\\left(\\boldsymbol{v}_{i}\\right)=\\left\\{\\boldsymbol{q}_{i}\\right\\}_{i=1}^{Q}Q(vi​)={qi​}i=1Q​。如果不采用特别的负采样技术，负样本就是两个视角中其他不同节点的嵌入。然后利用对比目标J\\mathcal JJ训练模型，最大化锚点和负样本之间的距离。 2.1 设计空间 作者将一个通用GCL框架划分成下面4部分，构成整个GCL的设计空间： 数据增强： 可以划分成拓扑增强和特征增强两类。 拓扑增强： Edge Removing；Edge Adding；Edge Flipping；Node Dropping；Subgraph Induced；Graph Diffusion。 特征增强： Feature Masking；Feature Dropout。 对比模式： 常用的对比模式有，local-local；local-global；global-global三种。对于node-level下游任务只能使用前面两种，graph-level任务三种都可以。 对比目标： Information Noice Contrastive Estimation (InfoNCE)；Jensen-Shannon Divergence (JSD) ；Triplet Margin loss ™ ； the Bootstrapping Latent loss (BL) ；Barlow Twins (BT) loss ；VICReg loss 。前三种依赖负样本，后三种则不需要显示负样本。 负挖掘技术： 本文作者考虑下面四种负采样技术，Hard Negative Mixing (HNM) ；Debiased Contrastive Learning (DCL)；Hardness-Biased Negative Mining (HBNM)；Conditional Negative Mining (CNM) 。 2.2 代表性GCL方法 作者这里对现有GCL方法进行了总结，如上表1所示。可以从下面三个维度区分这些方法： Dual branches vs. single branch. 大部分方法都是遵循SIMCLR中的dual-branch架构，即通过增强函数生成两个不同的图视角。一些global-local模式的CL方法比如DGI、GMI采用的single-branch架构。 Stronger augmentations. 和GRACE、GraphCL不同，GCA提出一种自适应增强策略。 Variants of contrasting modes. 3. 实验 3.1 实验设置 配置： 在各种中型、大型数据集上进行大量实验。为了公平起见，数据集预处理基本采用DGI、GRACE等一众现有GCL方法中使用的策略。实验主要分成（1）无监督节点分类；（2）无监督图分类；两大类，首先通过GCL方法学习节点嵌入，然后统一利用DGI中使用的线性分类器执行分类任务。 数据集： 作者采用社交网络、学术网络、生物分子网络以及知识图谱等多种领域的数据集，详细信息如下表2所示： 实现细节： 对于节点分类任务采用GCN作为编码器，对于图分类任务使用GIN作为编码器，映射函数统一使用MLP。为了确保得出的结论有说服力，作者首先对整个设计空间进行了彻底搜索，选出比较具有代表性的结果，来揭示常见的、有用的做法。为了控制变量，作者尽可能多的固定一些变量，比如GNN编码器的结构、嵌入维度、epochs数量、激活函数等等。 3.2 数据增强 控制变量： 对比模式采用InfoNCE，对比目标local-local，不采用负采样。 Observation 1：拓扑增强对模型性能影响非常大，并且使用生成更稀疏图的增强函数可以提高模型性能。 如上表3所示，可以得出如下结论：（1）使用拓扑增强时，模型性能非常依赖于具体增强策略的选择，有的可以显著提高模型性能，有的反而会降低模型性能。（2）和丢边增强策略（ER、MDK、ND、PPR和RWS）相比，增加边（EA）效果大部分情况下会差一点。（3）对于节点分类任务，RWS能取得更好表现，而对于图分类任务，ND能取得更好表现（这一点没啥价值，也不太准确）。 为了研究增强视角稀疏程度对模型性能的影响，作者对ND、ER和EA三种增强策略进行参数敏感性实验，结果如下图2所示： 从图2(a)(b)中可以看出，增大丢边或者丢节点的概率，模型表现总体来说是会变好的。从图2©可以看出增大加边的概率模型性能总体来说会变差。这种结果和实际结果是相符合的，即现实世界中大多数图都是稀疏图。如果增加太多边，会引入过多语义无关的噪声，降低学习到的节点嵌入质量。 Observation 2. 特征增强可以给GCL方法带来额外好处，并且同时适用结构增强和特征增强，GCL性能会更好。 仔细观察上图，可以有下面几点发现： 特征增强大部分情况下都远远弱于结构增强。（很多其他文章中也有提到类似的结果） 联合使用结构增强和特征增强，效果往往会更好。 Observation 3：确定性增强策略要联合随机增强策略一起使用。 如上图4所示，单独使用确定性增强方案PPR或者MKD，性能往往较差，如果联合使用FD、ND这种随机增强策略，性能会得到大幅提升。 3.3 对比模式、目标 控制变量： 增强策略采用ND+FM，不采用负采样技术，评价对比模式和对比目标。 Observation 4： 相同尺度的对比模式通常比较好，并且不同粒度的下游任务需要使用不同的对比模式。 观察上表4可以发现：对于node-level任务，使用local-local对比模式效果更好；对于graph-level任务，使用global-global对比模式效果更好。 Observation 5：在所有基于负样本的目标函数中，使用InfoNCE效果往往更好。 作者尝试做了一些解释，但是比较笼统，这里不详细介绍了。 Observation 6：BL和BT不仅无需负采样，降低计算代价，还可以显著提升模型性能。 上图展示的是使用不同目标损失，模型内存占用情况。 3.5 负采样 控制变量：增强策略采用ND+FM，对比模式采用L-L，目标损失采用InfoNCE，评价负采样策略。 Observation 7： 现有的基于计算嵌入相似度的负采样技术给GCL带来的增益很小。 如上图6所示，在某些情况下，负采样技术可以提高模型性能，但是提升的并不多。现有负采样技术中，基本都是通过计算样本嵌入间的内积决定是否采样。但是由于GCL是完全按照无监督方式训练的，训练过程中没有接触到类别信息。在现有的对比模式下，对于某个锚点，模型目标就是将所有其他不同表示推开，不管他们语义上有什么关系。因此负采样带来的收益不大。另外，通过GNN编码得到的嵌入，倾向于相邻节点有相似嵌入，这也影响了基于嵌入相似度负采样技术的效果。 上图展示了，样本和锚点之间相似度和正负样本数量之间的分布关系。可以看到随着相似度的增大，正样本越来越多，这导致hard negative sample中可能会选到很多正样本，即false negative。因此基于嵌入相似度的这些负采样技术存在两个阻碍：1. 就是前面提到的false negative samples；2.模型训练前期，学习到的嵌入质量很差，导致选择到的负样本里面有很多false negative samples. 4. 总结 下面是作者总结的他们的工作存在的不足之处，以及为后续研究提出的一些建议。 限制： 设计空间有限，作者的控制变量实验只针对他们提出的四个组件，还有很多其他因素没有考虑进来。 下游任务有限，只探讨了节点分类和图分类两种下游任务。 缺乏理论证明，文章所有结论都是从实验结果中提炼出来，缺乏理论说服力。 建议： 自适应增强策略，不过这个方向已经挺多文章了 设计模型是要考虑下游任务 结构感知负采样","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"综述","slug":"综述","permalink":"http://rookieyin.github.io/tags/%E7%BB%BC%E8%BF%B0/"}]},{"title":"InfoGCL: Information-Aware Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/21.InfoGCL Information-Aware Graph Contrastive Learning","date":"2021-11-27T05:34:34.000Z","updated":"2022-06-10T11:36:44.795Z","comments":true,"path":"4d8fadbd8370/","link":"","permalink":"http://rookieyin.github.io/4d8fadbd8370/","excerpt":"https://arxiv.org/pdf/2110.15438 InfoGCL: Information-Aware Graph Contrastive Learning ，2021，NIPS 总结：本质上还是一种自适应GCL方法。现有的GCL方法基本都是被精心设计，用于某种特定的数据集或者图学习任务。GCL主要由增强、编码和对比三部分构成，而每个组件都有很多种可选项，因此当我们拿到某种特定图学习任务中，我们很难寻找这些组件间的最优组合，来设计一个最优GCL模型。本文作者就是针对这个问题，提出了三条准则，称之为“InfoGCL principle”，分别对应GCL中三个组件。按照作者提出的三条准则来，我们就能设计出用于特定任务的最优GCL模型。","text":"https://arxiv.org/pdf/2110.15438 InfoGCL: Information-Aware Graph Contrastive Learning ，2021，NIPS 总结：本质上还是一种自适应GCL方法。现有的GCL方法基本都是被精心设计，用于某种特定的数据集或者图学习任务。GCL主要由增强、编码和对比三部分构成，而每个组件都有很多种可选项，因此当我们拿到某种特定图学习任务中，我们很难寻找这些组件间的最优组合，来设计一个最优GCL模型。本文作者就是针对这个问题，提出了三条准则，称之为“InfoGCL principle”，分别对应GCL中三个组件。按照作者提出的三条准则来，我们就能设计出用于特定任务的最优GCL模型。 1. 简介 1.1 摘要 Various graph contrastive learning models have been proposed to improve the performance of learning tasks on graph datasets in recent years. While effective and prevalent, these models are usually carefully customized. In particular, although all recent researches create two contrastive views, they differ greatly in view augmentations, architectures, and objectives. It remains an open question how to build your graph contrastive learning model from scratch for particular graph learning tasks and datasets. In this work, we aim to fill this gap by studying how graph information is transformed and transferred during the contrastive learning process and proposing an information-aware graph contrastive learning framework called InfoGCL. The key point of this framework is to follow the Information Bottleneck principle to reduce the mutual information between contrastive parts while keeping task relevant information intact at both the levels of the individual module and the entire framework so that the information loss during graph representation learning can be minimized. We show for the first time that all recent graph contrastive learning methods can be unified by our framework. We empirically validate our theoretical analysis on both node and graph classification benchmark datasets, and demonstrate that our algorithm significantly outperforms the state-of-the-arts. 最近几年，研究人员提出了各种图对比学习模型用于提高图数据集上学习任务的性能。虽然大多数方法都很有效，但是这些方法通常都是精心定制的。尤其是，虽然最近这些GCL方法都是成成两个对比视角，但是它们在增强、架构和目标函数上差异很大。如何从头构建一个用于某个特定图学习任务和数据集的GCL模型仍然是一个开放性问题。本文，我们旨在通过研究对比学习过程中图信息是如何转换和转移的，并提出一种信息感知GCL框架称之为InfoGCL，来填补这一空白。InfoGC框架的关键在于其遵循Information Bottleneck原则，在减少对比项之间互信息的同时，可以保持各个模块和整个框架的任务相关信息完整性，来最小化图表示学习期间的信息损失。我们首次展示了最近所有GCL方法都能统一到我们提出的框架中。我们在节点分类和图分类的标准数据集上的实验证明了我们的理论分析，并且我们的方法要优于SOTA方法。 1.2 本文工作 背景： 受对比学习在视觉和语言领域成功应用的启发，最近几年研究人员提出了很多种GCL方法。虽然这些方法性能很好，但是它们的增强策略、架构、对比目标都存在差异。并且这些GCL模型都是被精心设计的，用于某个特定图学习任务或者数据集。 动机： GCL方法中包含很多组件，比如数据增强和数据编码，并且这些组件有很多可选项，这些众多变体导致难以设计出有效、鲁棒性强的模型。本文作者解决的问题就是：如何设计一种高鲁棒性GCL框架，可以用于各种图学习任务。 本文工作： 信息瓶颈（IB）是表示学习中一条重要原则，它鼓励从任务相关信息中学习表示，同时抑制从任务无关信息中学习表示。作者将IB拓展到GCL中，提出了信息感知图对比学习框架InfoGCL。作者提出了在GCL中寻找最优模块的切实可行原则，并证明了这些原则可以统一目前所有的图对比学习方法：（1）增强视角需要尽肯能包含任务相关信息，并且不同视角之间共享的信息要尽可能少；（2）编码器要任务相关，并且尽可能简单；（3）对比模式在完成对比后要尽可能保持更多的任务相关信息。（看到这里，个人觉得这三条规则有点扯。）另外作者还调查了负采样在GCL中的角色，认为负采样技术不是必须的，尤其在图数据不是很稀疏的情况下。最后，实验表明作者提出的InfoGCL方法无论在node-level还是graph-level任务中都表现优秀。 2. 方法 上图1展示了一种常规的GCL框架，作者将它分成三部分：增强、编码和对比。其实还有个负采样，也比较重要。但是最近CV中一些工作表明显示负采样可有可无，GCL中也有一些相关研究。作者在后面弄了一个discussion单独讨论GCL中的负采样。 图1中三个组件可选项都有很多，导致最终的GCL模型有很多选择。针对如何设计一个用于特定图学习任务或者数据集的GCL方法，作者尝试回答下面三个问题：（1）什么样的增强视角是最优的？（2）什么样的编码器是最优的？（3）什么样的对比模式是最优的？ 2.1 数据增强 数据增强的目标就是通过一些转换方法得到新的数据，但是这些转换不会影响数据本质上的语义标签。本文作者针对的还是GCL中常用的4种增强手段：Node dropping，Edge perturbation，Attribute masking和Subgraph sampling。为了寻找最适合某种下游任务的增强策略，作者提出了一个“optimal augmented views”推论。 具体来说，作者认为最优增强视角应该尽可能包含任务相关信息，并且不同视角之间共享的信息必须是任务相关的。基于这个动机，作者得出如下推论： Corollary 1. (Optimal Augmented Views) For a downstream task TTT whose goal is to predict a semantic label yyy, the optimal views, vi∗v_i^{*}vi∗​ , vj∗v_j^{*}vj∗​, generated from the input graph G are the solutions to the following optimization problem : \\begin{align} \\left(\\mathbf{v}_{i}^{*}, \\mathbf{v}_{j}^{*}\\right)=&amp; \\underset{\\mathbf{v}_{i}, \\mathbf{v}_{j}}{\\arg \\min } I\\left(\\mathbf{v}_{i} ; \\mathbf{v}_{j}\\right)\\\\ \\text { s.t. } &amp; I\\left(\\mathbf{v}_{i} ; y\\right)=I\\left(\\mathbf{v}_{j} ; y\\right) \\\\ &amp; I\\left(\\mathbf{v}_{i} ; y\\right)=I(\\mathcal{G} ; y) \\end{align} 第一行公式表示最小化两个视角间共享信息，第二行表示两个视角包含相同数量任务相关信息，第三行表示两个视角包含的任务相关信息要和输入图包含的信息量一致。（这块作者说附录中有证明，原文没找到附录）如下图2所示： 2.2 编码器 GCL中编码器的作用就是学习两个视角的节点或图嵌入，可以选择的类型有很多，比如GCN、GAT、GIN等等。同样地，为了选取最优编码器，作者提出了一个“optimal view encoder”推论。 具体来说，作者认为最优编码器生成的表示应该包含两个视角共享的所有信息，同时保证这些信息都是任务相关的。基于这个动机，作者提出如下推论： Corollary 2. (Optimal View Encoder) Given the optimal views, $v^∗_i $, vjxv_j^xvjx​ , for a downstream task TTT whose goal is to predict a semantic label yyy, the optimal view encoder for view vi∗v^∗_ivi∗​ is the solution to the following optimization problem: fi∗=arg⁡min⁡fiI(fi(vi∗);vi∗) s.t. I(fi(vi∗);vj∗)=I(vi∗;vj∗)\\begin{gathered} f_{i}^{*}=\\underset{f_{i}}{\\arg \\min } I\\left(f_{i}\\left(\\mathbf{v}_{i}^{*}\\right) ; \\mathbf{v}_{i}^{*}\\right) \\\\ \\text { s.t. } I\\left(f_{i}\\left(\\mathbf{v}_{i}^{*}\\right) ; \\mathbf{v}_{j}^{*}\\right)=I\\left(\\mathbf{v}_{i}^{*} ; \\mathbf{v}_{j}^{*}\\right) \\end{gathered} fi∗​=fi​argmin​I(fi​(vi∗​);vi∗​) s.t. I(fi​(vi∗​);vj∗​)=I(vi∗​;vj∗​)​ 公式1最小化视角和嵌入之间共享的信息量，公式2表示两个视角间共享的信息，在两个视角嵌入之间依旧共享。如下图3所示： 2.3 对比模式 对比模式可以表示成(ci(⋅),cj(⋅))(c_i(\\cdot),c_j(\\cdot))(ci​(⋅),cj​(⋅))，其中ci(⋅)c_i(\\cdot)ci​(⋅)和cj(⋅)c_j(\\cdot)cj​(⋅)分别表示聚合操作。作者总结5中对比模式：global-global，local-global，local-local，multi-scale，hybrid-mode。其中multi-scale表示将一个视角的图表示和另一个视角的中间表示对比，hybrid-mode表示同时使用global-global和local-global。为了寻找最优对比模式，作者提出了一个“optimal contrastive mode”推论。 具体来说，作者认为最优的对比模式在聚合节点表示后应该能保留大部分任务相关信息。基于这个动机提出了如下推论： Corollary 3. (Optimal Contrastive Mode) Given the latent representations, zi∗z^∗_izi∗​ , zj∗z^∗_jzj∗​, extracted by the optimal view encoders, i.e., zi∗=fi∗(vi∗)z^∗_i = f^∗_i (v^∗_i )zi∗​=fi∗​(vi∗​), zj∗=fj∗(vj∗)z^∗_j = f^∗_j (v^∗_j)zj∗​=fj∗​(vj∗​) , and a downstream task T with label y, the optimal contrastive mode is the solution to the following optimization problem, where cic_ici​, cjc_jcj​ are the aggregation operations applied to the latent representations: (ci∗,cj∗)=arg⁡min⁡(ci,cj)−I(ci(zi∗);cj(zj∗))\\left(c_{i}^{*}, c_{j}^{*}\\right)=\\underset{\\left(c_{i}, c_{j}\\right)}{\\arg \\min }-I\\left(c_{i}\\left(\\mathbf{z}_{i}^{*}\\right) ; c_{j}\\left(\\mathbf{z}_{j}^{*}\\right)\\right) (ci∗​,cj∗​)=(ci​,cj​)argmin​−I(ci​(zi∗​);cj​(zj∗​)) 2.4 InfoGCL 基于上述分析，作者提出了几条规则，只要按照这些规则来，我们就能为我们的图数据和任务设计一个最优的GCL模型，作者称之为“InfoGCL Principle”。因为在真实世界中，由于数据噪声、模型限制等原因，作者只能单独为每个节点设计最佳解决方案，并且实际应用中这种最优只是近似最优。 命题1： 给定任务TTT，标签为yyy，以及一系列增强策略{q1(⋅),q2(⋅),⋅⋅⋅}\\{q_1(\\cdot),q_2(\\cdot),\\cdot\\cdot\\cdot\\}{q1​(⋅),q2​(⋅),⋅⋅⋅}，vi,vj\\mathbf v_i,\\mathbf v_jvi​,vj​表示生成的两个视角，qi(⋅)q_i(\\cdot)qi​(⋅)和qj(⋅)q_j(\\cdot)qj​(⋅)表示推荐的最优增强策略，这两个策略会最大化I(vi;y)+I(vj;y)−I(vi;vj)I\\left(\\mathbf{v}_{i} ; y\\right)+I\\left(\\mathbf{v}_{j} ; y\\right)-I\\left(\\mathbf{v}_{i} ; \\mathbf{v}_{j}\\right)I(vi​;y)+I(vj​;y)−I(vi​;vj​)，即图2中A+B+DA+B+DA+B+D区域。 命题2： 给定任务TTT，标签为yyy，以及一系列编码器{fi1(⋅),fi2(⋅),⋅⋅⋅}\\{f_i^1(\\cdot),f_i^2(\\cdot),\\cdot\\cdot\\cdot\\}{fi1​(⋅),fi2​(⋅),⋅⋅⋅}，zi\\mathbf z_izi​表示视角vi\\mathbf v_ivi​的输出，最优编码器应该要最大化vi,zi,y\\mathbf v_i,\\mathbf z_i,yvi​,zi​,y之间的互信息。对于vj\\mathbf v_jvj​视角同理。 命题3： 给定任务TTT，标签为yyy，提取出的表示zi,zjz_i,z_jzi​,zj​以及一系列聚合操作{c1(⋅),c2(⋅),⋅⋅⋅}\\{c_1(\\cdot),c_2(\\cdot),\\cdot\\cdot\\cdot\\}{c1​(⋅),c2​(⋅),⋅⋅⋅}，最优对比模式(ci,cj)(c_i,c_j)(ci​,cj​)应该最大化ci(zi),cj(zj),yc_i(\\mathbf z_i),c_j(\\mathbf z_j),yci​(zi​),cj​(zj​),y之间的互信息。 2.5 负采样扮演的角色 现有的GCL方法非常依赖于负样本选取（不准确，有些方法也是不依赖于显示负采样），但是视觉领域对比学习的最新进展表明显示的负采样不是必须的。作者遵循SimSiam中的方法，重新定义了损失函数： L=−1N∑n=1Nzi,n∥zi,n∥⋅zj,n∥zj,n∥\\mathcal{L}=-\\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\mathbf{z}_{i, n}}{\\left\\|\\mathbf{z}_{i, n}\\right\\|} \\cdot \\frac{\\mathbf{z}_{j, n}}{\\left\\|\\mathbf{z}_{j, n}\\right\\|} L=−N1​n=1∑N​∥zi,n​∥zi,n​​⋅∥zj,n​∥zj,n​​ 这种损失函数可以避免显示负采样。和GCL中最近一篇工作比较类似，不同的是本文作者同时关注与节点分类和图分类任务。 3. 实验 3.1 数据集 这块作者不太严谨，Cora和Citeseer搞反了。 3.2 实验结果 3.3 InfoGCL Principle 作者发现他们提出的InfoGCL Principle可以统一现有的GCL方法：最近所有GCL方法的都能划分成作者提出的三个阶段，虽然他们架构不同，但是都implicitly遵循InfoGCL Principle。下面作者从InfoGCL Principle角度，对现有的GCL方法进行解释，实验在附录中。 GCA，在下游任务中使用图增强比不使用图增强性能更好，因为使用图增强可以实现更小的I(vi;vj)I(v_i;v_j)I(vi​;vj​)，即命题1。 GCA，使用不同的增强方式，模型性能更好，因为两种增强方式可以进一步减小I(vi;vj)I(v_i;v_j)I(vi​;vj​)，即命题1。 GCA，node dropping和subgraph sampling更通用一些，因为和属性mask，边扰动相比，它们对图语义的影响更小，I(vi;y)I(v_i;y)I(vi​;y)和I(vj;y)I(v_j;y)I(vj​;y)更大，即命题1。 GCA，edge perturbation对社交网络有效，但是对分子网络有负面影响。因为社交网络的语义信息对边扰动比较robust，但是某些分子网络的语义非常依赖局部结构，对变扰动很敏感，会导致I(vi;y)I(v_i;y)I(vi​;y)大幅降低。 MVGRL，node-graph对比模式往往比其他对比模式好。因为node-graph对比可以提取更多图结构信息，有利于任务标签的预测，即命题3.（这个不太明白，感觉有点扯） 3.4 负样本消融 在图分类数据集上负采样对模型性能几乎不产生影响，在三个节点分类数据集上负采样会提高模型性能。通过对比表1中数据集统计，可以发现这三个节点分类数据集拓扑结构和节点特征（one-hot）都更加稀疏。因此，作者猜测对于拓扑结构或者节点特征非常稀疏的数据集，负采样可以提高模型性能。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"自适应","slug":"自适应","permalink":"http://rookieyin.github.io/tags/%E8%87%AA%E9%80%82%E5%BA%94/"}]},{"title":"Deep Graph Infomax","slug":"3 论文笔记/图学习/对比学习/20.Deep Graph Infomax","date":"2021-10-28T09:27:23.000Z","updated":"2021-11-27T06:11:33.646Z","comments":true,"path":"18558809c1ed/","link":"","permalink":"http://rookieyin.github.io/18558809c1ed/","excerpt":"https://arxiv.org/pdf/1809.10341 https://github.com/PetarV-/DGI Deep Graph Infomax ，2019，ICLR 总结：图对比学习的鼻祖。作者首次提出基于互信息的无监督图表示学习方法DGI，用于节点分类任务。DGI通过最大化local表示和global表示之间的互信息来节点表示。作者还从理论上证明了最大化DGI的目标函数和图表示学习中的最大化互信息是等价的。","text":"https://arxiv.org/pdf/1809.10341 https://github.com/PetarV-/DGI Deep Graph Infomax ，2019，ICLR 总结：图对比学习的鼻祖。作者首次提出基于互信息的无监督图表示学习方法DGI，用于节点分类任务。DGI通过最大化local表示和global表示之间的互信息来节点表示。作者还从理论上证明了最大化DGI的目标函数和图表示学习中的最大化互信息是等价的。 1. 简介 1.1 摘要 We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs—both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning. 我们展示了DGI模型，一种通用的无监督图表示学习方法。DGI依赖于最大化patch表示和对应高层级图表示之间的互信息。学习到的patch表示融合了节点周围感兴趣的子图，因此可以在下游node-wise学习任务中复用。和现有的GCNs无监督方法相比，DGI不依赖于随机游走目标，并且同时适用于transductive和inductive设定。我们在各种节点分类标准数据集上证明了其出色的表现，并且有时候其性能还要优于有监督学习。 1.2 本文工作 背景： 最近几年，虽然GNNs被广泛用于各种图学习任务，并且取得了很大成功，但是这些方法大多数都是有监督的，依赖于大量有标签数据。因此，发展无监督图学习方法对许多任务来说是很重要的。 动机： 现有的无监督图学习方法都依赖于基于随机游走的目标函数，有时候甚至直接通过重构邻接矩阵来学习图表示。虽然随机游走很强大，但是也存在很大局限性，即过度强调邻近信息，并且模型性能过于依赖超参数的选择。 本文工作： 作者首次提出一种基于互信息的无监督图学习方法DGI（以前的都是基于随机游走或者邻接矩阵重构）。 2. 方法 DGI： 可以看作local-global对比学习方法，通过最大化node representation和graph representation之间的互信息来学习最终的节点嵌入。 2.1 符号定义 h⃗\\vec hh表示节点嵌入： 为了得到图嵌入，需要定义一个readout函数R:RN×F→RF\\mathcal R:\\mathbb R^{N\\times F}\\rightarrow\\mathbb R^FR:RN×F→RF，这样图表示可以定义为s⃗=R(E(X,A))\\vec{s}=\\mathcal{R}(\\mathcal{E}(\\mathbf{X}, \\mathbf{A}))s=R(E(X,A))。 为了最大化节点和图之间的互信息，需要定义一个判别器：D:RF→R\\mathcal D:\\mathbb R^F\\rightarrow\\mathbb RD:RF→R，D(h⃗i,s⃗)\\mathcal D(\\vec h_i,\\vec s)D(hi​,s)表示两者之间的互信息。 单图设定下，为了获取负样本需要定义一个扰动函数C:RN×F×RN×N→RM×F×RM×M\\mathcal{C}: \\mathbb{R}^{N \\times F} \\times \\mathbb{R}^{N \\times N} \\rightarrow \\mathbb{R}^{M \\times F} \\times \\mathbb{R}^{M \\times M}C:RN×F×RN×N→RM×F×RM×M，扰动后的图表示为(X~,A~)=C(X,A)(\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})=\\mathcal{C}(\\mathbf{X}, \\mathbf{A})(X,A)=C(X,A)。 得到节点嵌入和正负样本图嵌入后，模型的优化目标定义为： L=1N+M(∑i=1NE(X,A)[log⁡D(h⃗i,s⃗)]+∑j=1ME(X~,A~)[log⁡(1−D(h~→j,s⃗))])\\mathcal{L}=\\frac{1}{N+M}\\left(\\sum_{i=1}^{N} \\mathbb{E}_{(\\mathbf{X}, \\mathbf{A})}\\left[\\log \\mathcal{D}\\left(\\vec{h}_{i}, \\vec{s}\\right)\\right]+\\sum_{j=1}^{M} \\mathbb{E}_{(\\tilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})}\\left[\\log \\left(1-\\mathcal{D}\\left(\\overrightarrow{\\widetilde{h}}_{j}, \\vec{s}\\right)\\right)\\right]\\right) L=N+M1​(i=1∑N​E(X,A)​[logD(hi​,s)]+j=1∑M​E(X~,A)​[log(1−D(hj​,s))]) 2.2 DGI流程 通过图扰动函数得到一个负样本图：(X~,A~)∼C(X,A)(\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}}) \\sim \\mathcal{C}(\\mathbf{X}, \\mathbf{A})(X,A)∼C(X,A) 图编码器计算原始图节点嵌入：H=E(X,A)={h⃗1,h⃗2,…,h⃗N}\\mathbf{H}=\\mathcal{E}(\\mathbf{X}, \\mathbf{A})=\\left\\{\\vec{h}_{1}, \\vec{h}_{2}, \\ldots, \\vec{h}_{N}\\right\\}H=E(X,A)={h1​,h2​,…,hN​} 图编码器计算扰动图节点嵌入：H~=E(X~,A~)={h~→1,h~→2,…,h~→M}\\widetilde{\\mathbf{H}}=\\mathcal{E}(\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})=\\left\\{\\overrightarrow{\\widetilde{h}}_{1}, \\overrightarrow{\\widetilde{h}}_{2}, \\ldots, \\overrightarrow{\\widetilde{h}}_{M}\\right\\}H=E(X,A)={h1​,h2​,…,hM​} 通过Readout函数计算图嵌入：s⃗=R(H)\\vec{s}=\\mathcal{R}(\\mathbf{H})s=R(H) 通过最大化L=1N+M(∑i=1NE(X,A)[log⁡D(h⃗i,s⃗)]+∑j=1ME(X~,A~)[log⁡(1−D(h~→j,s⃗))])\\mathcal{L}=\\frac{1}{N+M}\\left(\\sum_{i=1}^{N} \\mathbb{E}_{(\\mathbf{X}, \\mathbf{A})}\\left[\\log \\mathcal{D}\\left(\\vec{h}_{i}, \\vec{s}\\right)\\right]+\\sum_{j=1}^{M} \\mathbb{E}_{(\\tilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})}\\left[\\log \\left(1-\\mathcal{D}\\left(\\overrightarrow{\\widetilde{h}}_{j}, \\vec{s}\\right)\\right)\\right]\\right)L=N+M1​(∑i=1N​E(X,A)​[logD(hi​,s)]+∑j=1M​E(X~,A)​[log(1−D(hj​,s))])更新图编码器参数。 模型框架如下图1所示： ## 2.3 理论证明 这部分，作者展示了DGI目标函数和图表示学习中互信息在理论上的关联。 实力有限，大家可以看原文！ 3. 实验 3.1 实验设定 3.1.1 Transductive 使用Cora、Citeseer和Pubmed三个数据集，图编码器采用单层GCN : E(X,A)=σ(D^−12A^D^−12XΘ)\\mathcal{E}(\\mathbf{X}, \\mathbf{A})=\\sigma\\left(\\hat{\\mathbf{D}}^{-\\frac{1}{2}} \\hat{\\mathbf{A}} \\hat{\\mathbf{D}}^{-\\frac{1}{2}} \\mathbf{X} \\Theta\\right) E(X,A)=σ(D^−21​A^D^−21​XΘ) 其中A^=A+IN\\hat{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}_{N}A^=A+IN​表示带自环的邻接矩阵，D^\\hat{\\mathbf D}D^表示对应的度矩阵，非线性函数σ\\sigmaσ使用ReLU，隐藏层维度512（pubmed中由于内存原因，维度为256）。 扰动函数C\\mathcal CC：保留原始图邻接矩阵不变，即A~=A\\widetilde A=AA=A，将特征矩阵XXX进行随机row-wise shuffle。 3.1.2 Inductive 一、单个图（Reddit） 和GraphSAGE-GCN类似，采用平均池化传播规则： MP(X,A)=D^−1A^XΘ\\mathrm{MP}(\\mathbf{X}, \\mathbf{A})=\\hat{\\mathbf{D}}^{-1} \\hat{\\mathbf{A}} \\mathbf{X} \\Theta MP(X,A)=D^−1A^XΘ 编码器采用带skip connections的三层平均池化模型： MP~(X,A)=σ(XΘ′∥MP⁡(X,A))E(X,A)=MP^3(MP2^(MP^1(X,A),A),A)\\widetilde{\\mathrm{MP}}(\\mathrm{X}, \\mathrm{A})=\\sigma\\left(\\mathrm{X} \\Theta^{\\prime} \\| \\operatorname{MP}(\\mathrm{X}, \\mathrm{A})\\right) \\quad \\mathcal{E}(\\mathrm{X}, \\mathrm{A})=\\widehat{\\mathrm{MP}}_{3}\\left(\\widehat{\\mathrm{MP}_{2}}\\left(\\widehat{\\mathrm{MP}}_{1}(\\mathrm{X}, \\mathbf{A}), \\mathrm{A}\\right), \\mathbf{A}\\right) MP(X,A)=σ(XΘ′∥MP(X,A))E(X,A)=MP3​(MP2​​(MP1​(X,A),A),A) 另外，在大型数据集上，作者采用minibatch方式训练模型，每次按照10,10,25个邻居采样子图，每个子图包含1+10+100+2500=2611个节点。 二、多个图（PPI） 受GAT的启发，编码器采用dense skip 连接： H1=σ(MP1(X,A))H2=σ(MP2(H1+XWskip ,A))E(X,A)=σ(MP3(H2+H1+XWskip ,A))\\begin{aligned} \\mathbf{H}_{1} &amp;=\\sigma\\left(\\mathrm{MP}_{1}(\\mathbf{X}, \\mathbf{A})\\right) \\\\ \\mathbf{H}_{2} &amp;=\\sigma\\left(\\mathrm{MP}_{2}\\left(\\mathbf{H}_{1}+\\mathbf{X W}_{\\text {skip }}, \\mathbf{A}\\right)\\right) \\\\ \\mathcal{E}(\\mathbf{X}, \\mathbf{A}) &amp;=\\sigma\\left(\\mathrm{MP}_{3}\\left(\\mathbf{H}_{2}+\\mathbf{H}_{1}+\\mathbf{X} \\mathbf{W}_{\\text {skip }}, \\mathbf{A}\\right)\\right) \\end{aligned} H1​H2​E(X,A)​=σ(MP1​(X,A))=σ(MP2​(H1​+XWskip ​,A))=σ(MP3​(H2​+H1​+XWskip ​,A))​ 其中WskipW_{skip}Wskip​表示可学习映射矩阵，MPMPMP和前文中定义的一样。在多图场景下，不在使用扰动函数创建负样本，而是随机选取训练集中其他图作为负样本。 3.1.3 其他 Readout函数： 所有节点平均值，R(H)=σ(1N∑i=1Nh⃗i)\\mathcal{R}(\\mathbf{H})=\\sigma\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\vec{h}_{i}\\right)R(H)=σ(N1​∑i=1N​hi​) 判别器： 采用一个简单的双线性评分函数，D(h⃗i,s⃗)=σ(h⃗iTWs⃗)\\mathcal{D}\\left(\\vec{h}_{i}, \\vec{s}\\right)=\\sigma\\left(\\vec{h}_{i}^{T} \\mathbf{W} \\vec{s}\\right)D(hi​,s)=σ(hiT​Ws) 其他： 学习率0.001，采用Adam SGC优化器，patience设置为20。 3.2 结果","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Motif-based Graph Self-Supervised Learning forMolecular Property Prediction","slug":"3 论文笔记/图学习/对比学习/19.Motif-based Graph Self-Supervised Learning forMolecular Property Prediction","date":"2021-10-15T12:43:20.000Z","updated":"2021-11-27T05:48:26.156Z","comments":true,"path":"e9edfb23e5c9/","link":"","permalink":"http://rookieyin.github.io/e9edfb23e5c9/","excerpt":"https://arxiv.org/pdf/2110.00987 Motif-based Graph Self-Supervised Learning forMolecular Property Prediction，2021，NIPS 总结：作者提出了一种基于motif的多层级生成式自监督预训练方法——MGSSL，用于分子图属性预测。具体来说，作者先利用一种分子碎片化算法将原始图打碎，得到不同类型的motifs，然后把这些motifs看作节点，并连接到一起构成一棵motif树（这里和我之前看过的一篇超图方法比较类似，先构建子图，然后将子图看做节点，在子图间添加边，构成一张超图）。然后利用GNNs学习到的节点嵌入对这棵树进行重构。另外，为了捕获分子图中多尺度信息，作者设计的MGSSL框架是多层级的。即在进行motif-tree生成的同时，对节点类型和边类型进行预测，最小化两者的交叉熵损失。","text":"https://arxiv.org/pdf/2110.00987 Motif-based Graph Self-Supervised Learning forMolecular Property Prediction，2021，NIPS 总结：作者提出了一种基于motif的多层级生成式自监督预训练方法——MGSSL，用于分子图属性预测。具体来说，作者先利用一种分子碎片化算法将原始图打碎，得到不同类型的motifs，然后把这些motifs看作节点，并连接到一起构成一棵motif树（这里和我之前看过的一篇超图方法比较类似，先构建子图，然后将子图看做节点，在子图间添加边，构成一张超图）。然后利用GNNs学习到的节点嵌入对这棵树进行重构。另外，为了捕获分子图中多尺度信息，作者设计的MGSSL框架是多层级的。即在进行motif-tree生成的同时，对节点类型和边类型进行预测，最小化两者的交叉熵损失。 1. 简介 1.1 摘要 Predicting molecular properties with data-driven methods has drawn much attention in recent years. Particularly, Graph Neural Networks (GNNs) have demonstrated remarkable success in various molecular generation and prediction tasks. In cases where labeled data is scarce, GNNs can be pre-trained on unlabeled molecular data to first learn the general semantic and structural information before being finetuned for specific tasks. However, most existing self-supervised pre-training frameworks for GNNs only focus on node level or graph-level tasks. These approaches cannot capture the rich information in subgraphs or graph motifs. For example, functional groups (frequently-occurred subgraphs in molecular graphs) often carry indicative information about the molecular properties. To bridge this gap, we propose Motif-based Graph Self-supervised Learning (MGSSL) by introducing a novel self-supervised motif generation framework for GNNs. First, for motif extraction from molecular graphs, we design a molecule fragmentation method that leverages a retrosynthesis-based algorithm BRICS and additional rules for controlling the size of motif vocabulary. Second, we design a general motif-based generative pre-training framework in which GNNs are asked to make topological and label predictions. This generative framework can be implemented in two different ways, i.e., breadth-first or depth-first. Finally, to take the multi-scale information in molecular graphs into consideration, we introduce a multi-level self-supervised pre-training. Extensive experiments on various downstream benchmark tasks show that our methods outperform all state-of-the-art baselines. 最近几年，利用数据驱动的方法预测分子属性备受关注。尤其是GNNs，在各种分子生成、预测任务中取得了很大成功。在有标签数据稀少的场景下，GNNs可以现在无标签分子数据上进行预训练，学习通用的语义和结构信息，然后在具体任务上进行微调。但是现有的大多数自监督预训练GNNs框架只关注节点层级或者图层级任务，这些方法不能捕获丰富的子图或者motif信息。比如，functional groups（分子图中经常出现的子图）经常携带有感分子性质的的指示信息。为了弥补这一缺陷，我们提出了Motif-based兔子监督学习方法MGSSL，一种新的自监督motif生成GNNs框架。首先，为了从分子图中提取motif信息，我们设计了一种分子碎片化方法，利用一种基于逆合成算法BRICS和额外的规则控制motif的大小。然后我们设计了一种通用的基于motif的生成式预训练框架，要求GNNs进行拓扑和标签预测。该框架可以以广度优先和深度优先两种方式实现。最后，为了考虑分子图的多尺度信息，我们引入了多层次自监督预训练。各种下游标准任务上的大量实验证明了我们提出的方法有SOTA方法。 1.2 本文工作 背景： GNNs最近几年被广泛用于各种分子预测任务，并且取得了很大成功，但是GNNs也存在一个弊端，即data-hungry。为了解决这个问题，受NLP和CV中相关方法的启发，研究人员提出了自监督GNNs。在标签稀少场景下，GNNs首先在大规模无标签数据集上进行预训练，然后再针对具体任务进行微调。 动机： 作者认为现有的GCL方法是次优的，因为他们没有捕获graph motifs中蕴含的丰富信息。虽然也有些方法用motif来搞对比学习，但是它们都没有考虑motif的拓扑信息。 本文工作：作者提出了Motif-based Graph Self-Supervised Learning方法MGSSL和多层级自监督预训练框架。 2. 方法 作者提出的MGSSL框架如下图所示： 框架包含三部分：分子碎片化，motif生成和多层级自监督预训练。 2.1 分子碎片化 所谓碎片化，分成两步： 把一张分子图拆分成若干个碎片，每个碎片即代表一个motif。 然后把每个motif当做一个节点，在motif之间加上边，构成一个motif tree。 用符号表示即：G=(V,E)G=(V,E)G=(V,E)表示一张分子图，T(G)=(V,E,X)\\mathcal{T(G)=(V,E,X)}T(G)=(V,E,X)表示一棵标签树，其中V={M1,...,Mn}\\mathcal V=\\{M_1,...,M_n\\}V={M1​,...,Mn​}表示节点集合，E\\mathcal EE和X\\mathcal XX分别表示边集合和motifs嵌入，每个motif Mi=(Vi,Ei)M_i=(V_i,E_i)Mi​=(Vi​,Ei​)是GGG的一个子图。 上述第1步拆分分子图方法有很多，但是需要实现下面4个目标： 所有motif MiM_iMi​的并集要和图GGG等价，即∪iVi=V且∪iEi∪E=E\\cup_iV_i=V且\\cup_iE_i\\cup\\mathcal E=E∪i​Vi​=V且∪i​Ei​∪E=E。 不同motif之间不能有交集，即Mi∩Mj=∅M_i\\cap M_j=\\emptyMi​∩Mj​=∅。 生成的motif必须有语义意义，比如化学领域中的functional group。 生成的motif必须在数据集中是频繁出现的，这样基于这些motif预训练的GNNs才能推广到下游具体任务。 作者提出的基于BRICS碎片化方法如下图2所示： 作者首先使用Breaking of Retrosynthetically Interesting Chemical Substructures算法将图打碎。BRICS定义了16条规则，将分子中和化学反应相匹配的化学键打破，然后在断点两端添加一个虚拟原子（上图2中蓝色小点），表示不同片段可以通过该点连接到一起。BRICS算法旨在保留具有结构和功能价值的分子组分，比如芳香环。 由于BRICS定义的规则中化学反应有限，所以有时候分子图拆分的不够细，只能得到很少片段； 虽然BRICS生成了很多motifs，但是这些motifs很多都是同一个underlying structure的变体。这导致最终得到的motif vocabulary虽然很大（超过100K个片段），但是这些片段在数据集中出现的次数不超过5次。 为了解决上述问题，作者对BRICS算法进行了改进。具体来说，作者对BRICS输出的片段进行二次分解，分解规则如下： 当一端原子在环上，而另一端不在环上时，打破化学键； 选择具有三个或者更多邻居的原子作为新的motif，并打破相邻的键。 第一条规则可以减少环变体的数量，第二条规则可以打破侧链。实验表明，这两条规则可以有效减小motif vocabulary的大小，并提高生成的motifs在数据集中出现的频次。 2.2 moitf（tree）生成 本文作者提出的MGSSL框架是一种生成式自监督学习方法。通过2.1小节介绍的分子碎片化算法，我们可以得到一棵真实的motif-tree。这一步的工作就是，利用GNNs学习到的节点嵌入生成一棵motif-tree，GNNs学习的目标就是让生成的tree和2.1节碎片化得到的tree尽可能相似。 用符号语言描述就是： 给定一张分子图G=(V,E)G=(V,E)G=(V,E)和GNN模型fθf_\\thetafθ​，首先将分子图拆分成motif tree T(G)=(V,E,X)\\mathcal{T(G)=(V,E,X)}T(G)=(V,E,X)。 然后用GNN模型对motif tree进行最大似然建模p(T(G);θ)p(\\mathcal T(G);\\theta)p(T(G);θ)，表示motifs是如何被标记和连接的。 预训练GNNs的目标就是最大化motif trees的似然估计，即 θ∗=argmax⁡θp(T(G);θ)\\theta^{*}=\\operatorname{argmax}_{\\theta} p(\\mathcal{T}(G) ; \\theta)θ∗=argmaxθ​p(T(G);θ)。 这里和前人graph generation工作类似，作者使用自回归方式来构建motif tree。 注：自回归模型是一种常用的深度生成模型，大概思想就是用前i步生成的数据指导第i步数据的生成。详细内容可以参考这篇博客。 具体来说，用π\\piπ表示motif的顺序，iπi^\\piiπ表示id为i的motif在置换π\\piπ中的位置。这样p(T(G);θ)p(\\mathcal T(G);\\theta)p(T(G);θ)就可以表示成所有可能的置换π\\piπ下的期望： p(T(G);θ)=Eπ[pθ(Vπ,Eπ)]p(\\mathcal{T}(G) ; \\theta)=\\mathbb{E}_{\\pi}\\left[p_{\\theta}\\left(\\mathcal{V}^{\\pi}, \\mathcal{E}^{\\pi}\\right)\\right] p(T(G);θ)=Eπ​[pθ​(Vπ,Eπ)] 其中Vπ\\mathcal V^\\piVπ表示在π\\piπ这种排列下各个motif的标签，Eπ\\mathcal E^\\piEπ表示在π\\piπ这种排列下motifs之间相连的边。为了方便起见，作者假设所有可能的排列π\\piπ概率相同，在下文公式中会忽略掉上标π\\piπ。给定一种排列顺序，生成motif tree T(G)\\mathcal T(G)T(G)的概率可以分解成： log⁡pθ(V,E)=∑i=1∣V∣log⁡pθ(Vi,Ei∣V&lt;i,E&lt;i)\\log p_{\\theta}(\\mathcal{V}, \\mathcal{E})=\\sum_{i=1}^{|\\mathcal{V}|} \\log p_{\\theta}\\left(\\mathcal{V}_{i}, \\mathcal{E}_{i} \\mid \\mathcal{V}_{&lt;i}, \\mathcal{E}_{&lt;i}\\right) logpθ​(V,E)=i=1∑∣V∣​logpθ​(Vi​,Ei​∣V&lt;i​,E&lt;i​) 在第i步，使用前面1~i步已经生成的motif来指导第i个motif的生成。上面公式描述的其实就是一个自回归生成过程。 下面作者提出了BFS和DFS两种生成方式（和树的广度优先、深度优先一样），如下图3所示： 在DFS规则下，先进行topological预测，即该节点是否有孩子节点。如果需要为其生成孩子节点，则再预测新生成的节点的label。然后重复这一过程。 在BFS规则下，按层生成新的motif节点，对于每一层，MGSSL分别进行一次拓扑预测和结构预测。 在每一步，新加入的motif节点会接收来自其他已经生成的所有motif节点的信息进行预测。在motif tree的构建过程中，信息通过message向量hijh_{ij}hij​进行传播。 具体来说，Et^\\hat{\\mathcal E_t}Et​^​表示在t时刻motif tree中的边信息，xix_ixi​表示visited motif i在时刻t的embedding。message向量hi,jh_{i,j}hi,j​的计算方法如下： hi,j=GRU⁡(xi,{ hk,i}(k,i)∈E^t,k≠j)\\mathrm{h}_{i, j}=\\operatorname{GRU}\\left(x_{i},\\left\\{\\mathrm{~h}_{k, i}\\right\\}_{(k, i) \\in \\hat{\\mathcal{E}}_{t}, k \\neq j}\\right) hi,j​=GRU(xi​,{ hk,i​}(k,i)∈E^t​,k​=j​) 其中GRU表示Gated Recurrent Unit（一种比较古老的序列预测模型，我没有仔细研究）： si,j=∑(k,i)∈E^t,k≠j hk,izi,j=σ(Wzxi+Uzsi,j+bz)rk,i=σ(Wrxi+Ur hk,i+br)h~i,j=tanh⁡(Wxi+U∑k=N(i)\\jrk,i⊙hk,i)hi,j=(1−zij)⊙sij+zij⊙h~i,j\\begin{aligned} &amp;s_{i, j}=\\sum_{(k, i) \\in \\hat{\\mathcal{E}}_{t}, k \\neq j} \\mathrm{~h}_{k, i} \\\\ &amp;z_{i, j}=\\sigma\\left(\\mathrm{W}^{z} x_{i}+\\mathrm{U}^{z} s_{i, j}+b^{z}\\right) \\\\ &amp;r_{k, i}=\\sigma\\left(\\mathrm{W}^{r} x_{i}+\\mathrm{U}^{r} \\mathrm{~h}_{k, i}+b^{r}\\right) \\\\ &amp;\\tilde{\\mathrm{h}}_{i, j}=\\tanh \\left(\\mathrm{W} x_{i}+U \\sum_{k=\\mathcal{N}(i) \\backslash j} r_{k, i} \\odot \\mathrm{h}_{k, i}\\right) \\\\ &amp;\\mathrm{h}_{i, j}=\\left(1-z_{i j}\\right) \\odot s_{i j}+z_{i j} \\odot \\tilde{\\mathrm{h}}_{i, j} \\end{aligned} ​si,j​=(k,i)∈E^t​,k​=j∑​ hk,i​zi,j​=σ(Wzxi​+Uzsi,j​+bz)rk,i​=σ(Wrxi​+Ur hk,i​+br)h~i,j​=tanh⎝⎜⎛​Wxi​+Uk=N(i)\\j∑​rk,i​⊙hk,i​⎠⎟⎞​hi,j​=(1−zij​)⊙sij​+zij​⊙h~i,j​​ 得到消息向量后，开始进行拓扑预测和标签预测： 拓扑预测 当MGSSL访问motif i时需要进行二分预测，即motif i是否有孩子节点。预测概率计算方法如下： pt=σ(Ud⋅τ(W1dxi+W2d∑(k,i)∈E^thk,i))p_{t}=\\sigma\\left(U^{d} \\cdot \\tau\\left(W_{1}^{d} x_{i}+W_{2}^{d} \\sum_{(k, i) \\in \\hat{\\mathcal{E}}_{t}} h_{k, i}\\right)\\right) pt​=σ⎝⎜⎛​Ud⋅τ⎝⎜⎛​W1d​xi​+W2d​(k,i)∈E^t​∑​hk,i​⎠⎟⎞​⎠⎟⎞​ 标签预测 下式计算的是父亲motif i生成的孩子motif j的标签 qj=softmax⁡(Ulτ(Wlhij))q_{j}=\\operatorname{softmax}\\left(U^{l} \\tau\\left(W^{l} h_{i j}\\right)\\right) qj​=softmax(Ulτ(Wlhij​)) 假设p^t∈{0,1}\\hat p_t\\in\\{0,1\\}p^​t​∈{0,1}和q^j\\hat q_jq^​j​分别表示真实拓扑结构和标签信息，那么motif generation损失就定义上述两个预测的交叉熵损失： Lmotif =∑tLtopo (pt,p^t)+∑jLpred (qj,q^j)\\mathcal{L}_{\\text {motif }}=\\sum_{t} \\mathcal{L}_{\\text {topo }}\\left(p_{t}, \\hat{p}_{t}\\right)+\\sum_{j} \\mathcal{L}_{\\text {pred }}\\left(q_{j}, \\hat{q}_{j}\\right) Lmotif ​=t∑​Ltopo ​(pt​,p^​t​)+j∑​Lpred ​(qj​,q^​j​) 2.3 多层级自监督预训练 为了捕获分子图中的多尺度信息，MGSSL被设计成如上图1所示的层次框架，包含Atom-level和Motif-level两个任务。所谓Atom-level，即利用GNNs学习到的节点/边嵌入，来预测原子类型和边类型，两者的交叉熵损失分别定义为Latom\\mathcal L_{atom}Latom​和Lbond\\mathcal L_{bond}Lbond​。 为了避免在连续预训练过程中出现灾难遗忘，作者统一了多层次任务，以最小化如下混合损失为目标： Lssl =λ1Lmotif +λ2Latom +λ3Lbond ,\\mathcal{L}_{\\text {ssl }}=\\lambda_{1} \\mathcal{L}_{\\text {motif }}+\\lambda_{2} \\mathcal{L}_{\\text {atom }}+\\lambda_{3} \\mathcal{L}_{\\text {bond }}, Lssl ​=λ1​Lmotif ​+λ2​Latom ​+λ3​Lbond ​, 3. 实验 1. 基础实验 从上图4可以看到作者提出的MGSSL方法收敛更快，效果更好。 2. Base GNN对模型的影响 3. 分子碎片化方法消融 上图横坐标为分子碎片化后得到的motif vocabulary大小，纵轴为模型性能。可以看到作者提出的碎片化方法得到的vocabulary大小适中，并且取得了最优效果。 4. 多层级自监督消融 上表第1行表示只使用motif-level损失，第2行表示使用motif-level和atom-level损失，第3行表示完整损失。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"自监督学习","slug":"自监督学习","permalink":"http://rookieyin.github.io/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}]},{"title":"Distance-wise Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/18.Distance-wise Graph Contrastive Learning","date":"2021-10-06T09:09:44.000Z","updated":"2021-11-27T05:48:00.972Z","comments":true,"path":"60fc6ab88bd5/","link":"","permalink":"http://rookieyin.github.io/60fc6ab88bd5/","excerpt":"https://arxiv.org/pdf/2012.07437 Distance-wise Graph Contrastive Learning，2020，arxiv preprint 总结：在半监督图学习任务中，作者通过实验发现，CL对模型性能的提升主要集中在那些远离有标签数据的节点上。基于这个发现，作者认为现有的这些GCL方法，GL和Graph Learning的结合方式是不协调的，提出了一种新的半监督图对比学习方法DwGCL。具体来说，作者根据节点的PageRank值进行distance-wise augmentation，根据TIG（作者自己定义的一个东西）值选取Contrastive Pair，最后利用KL散度定义了模型的损失函数。总的来说，个人认为这篇文章切入角度很有趣，其动机让人耳目一新，和其他论文有很大区别。不过比较可惜的是，从实验结果来看，DwGCL带来的性能提升并不多，平均大概有1%，但是DwGCL模型和其他GCL方法相比更复杂，感觉得不偿失。","text":"https://arxiv.org/pdf/2012.07437 Distance-wise Graph Contrastive Learning，2020，arxiv preprint 总结：在半监督图学习任务中，作者通过实验发现，CL对模型性能的提升主要集中在那些远离有标签数据的节点上。基于这个发现，作者认为现有的这些GCL方法，GL和Graph Learning的结合方式是不协调的，提出了一种新的半监督图对比学习方法DwGCL。具体来说，作者根据节点的PageRank值进行distance-wise augmentation，根据TIG（作者自己定义的一个东西）值选取Contrastive Pair，最后利用KL散度定义了模型的损失函数。总的来说，个人认为这篇文章切入角度很有趣，其动机让人耳目一新，和其他论文有很大区别。不过比较可惜的是，从实验结果来看，DwGCL带来的性能提升并不多，平均大概有1%，但是DwGCL模型和其他GCL方法相比更复杂，感觉得不偿失。 1. 简介 1.1 摘要 Contrastive learning (CL) has proven highly effective in graph-based semi-supervised learning (SSL), since it can efficiently supplement the limited task information from the annotated nodes in graph. However, existing graph CL (GCL) studies ignore the uneven distribution of task information across graph caused by the graph topology and the selection of annotated nodes. They apply CL to the whole graph evenly, which results in an incongruous combination of CL and graph learning. To address this issue, we propose to apply CL in the graph learning adaptively by taking the received task information of each node into consideration. Firstly, we introduce Group PageRank to measure the node information gain from graph and find that CL mainly works for nodes that are topologically far away from the labeled nodes. We then propose our Distance-wise Graph Contrastive Learning (DwGCL) method from two views: (1) From the global view of the task information distribution across the graph, we enhance the CL effect on nodes that are topologically far away from labeled nodes; (2) From the personal view of each node’s received information, we measure the relative distance between nodes and then we adapt the sampling strategy of GCL accordingly. Extensive experiments on five benchmark graph datasets show that DwGCL can bring a clear improvement over previous GCL methods. Our analysis on eight graph neural network with various types of architecture and three different annotation settings further demonstrates the generalizability of DwGCL. 在图学习领域，对比学习已经被证明是一种高效的半监督学习方法，可以在有效地从图标记节点中补充有限的任务信息。但是，现有的GCL方法忽略了图拓补结构和标记节点导致图中信息分布不均匀的问题，只是单纯的将CL方法应用到整张图上，而这种结合方式是不协调的。为了解决这个问题，我们提出通过考虑每个节点接收到的人物信息，将CL自适应地应用到图学习中。首先，我们引入Group PageRank计算每个节点从图中能获取多少信息，发现CL主要适用于那些在拓扑结构上远离有标签节点的节点。然后我们提出了Distance-wise Graph Contrastive Learning（DwGCL）。DwGCL从两个角度出发：（1）global view，即考虑任务信息在整张图上的分布，我们在那些远离有标签节点的节点上增强CL效应；（2）person view，即考虑每个节点接收到的信息，我们测量节点之间的相对距离，然后相应地使用GCL的采样策略。5个标准图数据集上的大量实验表明，和现有GCL方法相比，DwGCL能带来显著的性能提升。通过对8中不同GNN和3中不同标注设置下实验结果的分析，我们进一步证明了DwGCL的通用性。 1.2 本文工作 背景： GNNs能有效利用图拓扑结构中的关系信息解决各类图问题。虽然在半监督任务中GNN依旧可以从有限标签中学习不错的知识，但是忽略了大量无标签节点中蕴藏的信息，这限制了其在半监督任务中的性能。最近很多方法引入对比学习来解决半监督图学习任务，比如DGI、GRACE、GraphCL等等。 动机： 当学习GNNs时，任务信息会从有标签节点传播到无标签节点。但是由于有标签节点分布不均匀，因此建模能力随着距离有标签节点越来越远而变差。如下图1所示： 现有的GCL方法都忽略了图信息在图中分布不均匀的问题，单纯地将对比学习用到整个图上，这种结合方式是不协调的。 本文工作： 为了解决这个问题，作者提出了DwGCL方法，通过考虑任务信息分布来更灵活地将CL应用到图学习中。 2. 方法 2.1 动机 先在这部分介绍下Group PageRank以及GCL相关知识，为后面DwGCL的介绍做准备。 2.1.1 Group PageRank PageRank是一种常用来计算节点重要性的算法，公式如下： πpr=(1−α)A′πpr+αI\\pi_{p r}=(1-\\alpha) \\boldsymbol{A}^{\\prime} \\pi_{p r}+\\alpha \\boldsymbol{I} πpr​=(1−α)A′πpr​+αI 其中A′=AD−1A^{\\prime}=A D^{-1}A′=AD−1，DDD表示度矩阵，I∈RnI\\in\\mathbb R^nI∈Rn表示转移概率，通常用1/n1/n1/n填充，α∈(0,1]\\alpha\\in(0,1]α∈(0,1]表示随机游走restart概率。 本文作者希望计算的是一群节点（属于同一个类别的所有有标签节点）的影响力，所以作者改造了一个Group PageRank算法： πgpr(c)=(1−α)A′πgpr+αIc\\boldsymbol{\\pi}_{g p r}(c)=(1-\\alpha) \\boldsymbol{A}^{\\prime} \\boldsymbol{\\pi}_{g p r}+\\alpha \\boldsymbol{I}_{\\boldsymbol{c}} πgpr​(c)=(1−α)A′πgpr​+αIc​ 其中c∈[0,k)c\\in[0,k)c∈[0,k)表示类别index，Ic∈RnI_c\\in\\mathbb R^nIc​∈Rn表示转移概率： Ici{1∣Lc∣, if the i-th node is a labeled node of class c0, otherwise \\boldsymbol{I}_{c}^{i}\\left\\{\\begin{array}{ll} \\frac{1}{\\left|\\boldsymbol{L}_{c}\\right|}, &amp; \\text { if the } i \\text {-th node is a labeled node of class } c \\\\ 0, &amp; \\text { otherwise } \\end{array}\\right. Ici​{∣Lc​∣1​,0,​ if the i-th node is a labeled node of class c otherwise ​ 其中LcL_cLc​表示类别ccc下有标签节点数量。作者首先单独计算每个类别的Group PageRank向量，然后合起来作为最终Group PageRank矩阵Z∈Rn∗kZ \\in \\mathbb{R}^{n * k}Z∈Rn∗k。Zi,jZ_{i,j}Zi,j​表示类别i向节点j提供的监督信息。在实际应用中，Group PageRank矩阵ZZZ可以并行计算： Z=α(E−(1−α)A′)−1I∗Z=\\alpha\\left(E-(1-\\alpha) A^{\\prime}\\right)^{-1} \\boldsymbol{I}^{*} Z=α(E−(1−α)A′)−1I∗ 其中EEE为单位矩阵，I∗∈Rn∗kI^*\\in\\mathbb R^{n*k}I∗∈Rn∗k表示所有IcI_cIc​的组合。 2.1.2 TIG值 通过Group PageRank矩阵ZZZ，我们可以知道每种类型有标签节点对无标签节点的影响力。此外，作者还想了解这些信息对下游任务能起到多大作用。 作者定义Topology Information Gain（TIG）表示节点从有标签节点那里获取到的有用信息。理想状态下，每个无标签节点获取到的信息应该集中于某一个类别，这样就能轻松预测其标签。所以对于节点iii，其TIG值计算方法如下： Zi,c∗=12Zi,c(1+XiPcT∥Xi∥∥Pc∥),Pc=1∣Lc∣∑i∈LcXi\\begin{array}{c} Z_{i, c}^{*}=\\frac{1}{2} Z_{i, c}\\left(1+\\frac{X_{i} \\mathcal{P}_{c}^{T}}{\\left\\|\\boldsymbol{X}_{i}\\right\\|\\left\\|\\mathcal{P}_{c}\\right\\|}\\right), \\mathcal{P}_{c}=\\frac{1}{\\left|L_{c}\\right|} \\sum_{i \\in \\boldsymbol{L}_{c}} \\boldsymbol{X}_{i} \\end{array} Zi,c∗​=21​Zi,c​(1+∥Xi​∥∥Pc​∥Xi​PcT​​),Pc​=∣Lc​∣1​∑i∈Lc​​Xi​​ Ti=max⁡(Zi∗)−λ(∑c=0k−1Zi,c∗)−max⁡(Zi∗)k−1\\begin{array}{c} T_{i}=\\max \\left(\\boldsymbol{Z}_{i}^{*}\\right)-\\lambda \\frac{\\left(\\sum_{c=0}^{k-1} \\boldsymbol{Z}_{i, c}^{*}\\right)-\\max \\left(\\boldsymbol{Z}_{i}^{*}\\right)}{k-1} \\end{array} Ti​=max(Zi∗​)−λk−1(∑c=0k−1​Zi,c∗​)−max(Zi∗​)​​ 其中max(⋅)max(·)max(⋅)表示最大值函数，λ\\lambdaλ表示对来自其他类别信息的惩罚因子，Pc\\mathcal P_cPc​表示这个节点类别的原型表示。作者假设每个未标记节点对来自不同类别的信息都有自己的特殊偏好，所以使用节点嵌入XiX_iXi​和类别原型Pc\\mathcal P_cPc​之间的余弦相似度来调整前面计算的PageRank值ZiZ_iZi​。 得到TIG值后，现在就可以探究CL在图上的工作机制了。作者在CORA数据集上，使用GCN作为编码器进行了一组实验。 作者将测试集节点按照TIG值大小，从小到大排列，然后分成4组。然后在这4组数据对CL进行消融实验，结果如下图2所示： 可以看到，随着TIG值不断增大，节点能接收到更多有用信息，GNN的性能越来越好，但是CL给模型带来的提升却越来越小。这说明：“CL主要提升的是在拓扑结构上远离有标签数据的那部分无标签节点上的性能”。 2.2 Distance-wise图对比学习 基于2.1节的实验以及分析，作者提出了一种图对比学习方法，以distance-wise方式将CL整合到图学习中。 具体来说，在图学习中最终要的两个组件就是：数据增强和负样本采样。作者针对这两个部分分别提出了distance-wise增强和distance-wise负采样。除了这两点外，作者还提出为不同的子图分配不同的对比损失权重。这样那些接受到少量有效监督信息的节点可以从CL中得到更多补充信息。 2.2.1 Distance-wise增强 传统GCL数据增强策略大体可以分成：随机和启发式两类，但是这两类方法都没有考虑不同节点能获取到的有效监督信息量是不同的。作者提出的增强策略考虑下面两方面因素： TIG值：TIG值越低的节点，被选中实施数据增强的概率越大。 考虑节点增强的扩散，作者通过降低增强节点周围子图的概率来动态调整选择概率。 具体增强策略伪代码如下： 这部分伪代码有点复杂，我没有细看，只是大概了解了其思想。 2.2.2 Distance-wise正/负采样 现有的对比学习，对于某个锚点，要么将其余所有样本作为负样本，要么将不同类别的所有样本作为负样本。本文作者基于节点间的距离，为锚点选取合适的z正/负样本。对于链各个节点之间的距离，作者从3个方面考虑： 全局拓扑距离。节点的PageRank值包含了全局拓扑信息和标记信息，作者计算两个节点PageRank值之间的KL散度作为全局拓扑距离： Di,jg=KL⁡(pi,pj), with pi=NORM⁡(Zi∗)\\boldsymbol{D}_{i, j}^{g}=\\operatorname{KL}\\left(\\boldsymbol{p}_{i}, \\boldsymbol{p}_{j}\\right), \\text { with } \\quad p_{i}=\\operatorname{NORM}\\left(Z_{i}^{*}\\right) Di,jg​=KL(pi​,pj​), with pi​=NORM(Zi∗​) 局部拓扑距离。作者将两个节点之间的mini jump hop数作为局部拓扑距离。 节点嵌入距离，即两个节点嵌入间的余弦距离。 因此两个节点间的最终距离定义为： Di,j=S(Di,jg)+λ1 S(Di,jl)+λ2 S(Di,je)\\boldsymbol{D}_{i, j}=\\mathrm{S}\\left(\\boldsymbol{D}_{i, j}^{g}\\right)+\\lambda_{1} \\mathrm{~S}\\left(\\boldsymbol{D}_{i, j}^{l}\\right)+\\lambda_{2} \\mathrm{~S}\\left(\\boldsymbol{D}_{i, j}^{e}\\right) Di,j​=S(Di,jg​)+λ1​ S(Di,jl​)+λ2​ S(Di,je​) 其中S(⋅)S(·)S(⋅)表示缩放函数，将范围缩放到[0,1][0,1][0,1]之间。得到所有节点之间的距离后，开始进行正/负采样工作。 具体来说，对于锚点节点iii，其对应的正样本集合就是距离iii最近的若干节点，负样本集合就是距离iii不远不近的那些节点： Pi=Ri[0:post⁡end],Ni=Ri[negt⁡beg: negt end ]\\boldsymbol{P}_{i}=\\boldsymbol{R}_{i}\\left[0: \\operatorname{post}_{e n d}\\right], \\boldsymbol{N}_{i}=\\boldsymbol{R}_{i}\\left[\\operatorname{negt}_{b e g}: \\text { negt }_{\\text {end }}\\right] Pi​=Ri​[0:postend​],Ni​=Ri​[negtbeg​: negt end ​] 2.3 DwGCL目标函数 2.3.1 有监督损失 F(⋅)\\mathcal F(·)F(⋅)表示GNN编码器，对于有标签节点其交叉熵损失定义为： t=F(X,A,θ)LCE=−1∣L∣∑i∈L∑c=0k−1yilog⁡p(tic,τ)\\begin{aligned} t &amp;=\\mathcal{F}(\\boldsymbol{X}, \\boldsymbol{A}, \\theta) \\\\ \\mathcal{L}_{C E} &amp;=-\\frac{1}{|\\boldsymbol{L}|} \\sum_{i \\in \\boldsymbol{L}} \\sum_{c=0}^{k-1} \\boldsymbol{y}_{i} \\log p\\left(\\boldsymbol{t}_{i}^{c}, \\tau\\right) \\end{aligned} tLCE​​=F(X,A,θ)=−∣L∣1​i∈L∑​c=0∑k−1​yi​logp(tic​,τ)​ 其中tit_iti​表示节点iii的嵌入向量，θ\\thetaθ表示GNN参数。 2.3.2 无监督损失 除了有监督损失，DwGCL还包含3中无监督损失：self-consistency损失、正样本对的对比损失和负样本对的对比损失。 self-consistency损失定义如下： Lsi=KL(F(Xp,Ap,θ)i,F(X,A,θ~)i)\\mathcal{L}_{s}^{i}=\\mathrm{KL}\\left(\\mathcal{F}\\left(\\boldsymbol{X}_{\\boldsymbol{p}}, \\boldsymbol{A}_{\\boldsymbol{p}}, \\boldsymbol{\\theta}\\right)_{i}, \\mathcal{F}(\\boldsymbol{X}, \\boldsymbol{A}, \\widetilde{\\boldsymbol{\\theta}})_{i}\\right) Lsi​=KL(F(Xp​,Ap​,θ)i​,F(X,A,θ)i​) 即增强前后节点嵌入间的KL散度。需要注意的是θ~\\widetilde \\thetaθ完全复制自θ\\thetaθ，但是不进行反向传播。同样地，定义下面两个对比损失： Lpi=1∣Pi∣∑j∈PiKL(F(Xp,Ap,θ)i,F(XA,θ~)j)Lni=1∣Ni∣∑j∈NiKL(F(Xp,Ap,θ)i,F(XA,θ~)j)\\begin{aligned} \\mathcal{L}_{p}^{i} &amp;=\\frac{1}{\\left|\\boldsymbol{P}_{i}\\right|} \\sum_{j \\in \\boldsymbol{P}_{i}} \\mathrm{KL}\\left(\\mathcal{F}\\left(\\boldsymbol{X}_{\\boldsymbol{p}}, \\boldsymbol{A}_{\\boldsymbol{p}}, \\boldsymbol{\\theta}\\right)_{i}, \\mathcal{F}(\\boldsymbol{X} \\boldsymbol{A}, \\widetilde{\\boldsymbol{\\theta}})_{j}\\right) \\\\ \\mathcal{L}_{n}^{i} &amp;=\\frac{1}{\\left|\\boldsymbol{N}_{i}\\right|} \\sum_{j \\in \\boldsymbol{N}_{i}} \\mathrm{KL}\\left(\\mathcal{F}\\left(\\boldsymbol{X}_{\\boldsymbol{p}}, \\boldsymbol{A}_{\\boldsymbol{p}}, \\boldsymbol{\\theta}\\right)_{i}, \\mathcal{F}(\\boldsymbol{X} \\boldsymbol{A}, \\widetilde{\\boldsymbol{\\theta}})_{j}\\right) \\end{aligned} Lpi​Lni​​=∣Pi​∣1​j∈Pi​∑​KL(F(Xp​,Ap​,θ)i​,F(XA,θ)j​)=∣Ni​∣1​j∈Ni​∑​KL(F(Xp​,Ap​,θ)i​,F(XA,θ)j​)​ 这样完整的无监督损失可以表示成： LUi=Lsi+μ1Lpi−μ2Lni\\mathcal{L}_{U}^{i}=\\mathcal{L}_{s}^{i}+\\mu_{1} \\mathcal{L}_{p}^{i}-\\mu_{2} \\mathcal{L}_{n}^{i} LUi​=Lsi​+μ1​Lpi​−μ2​Lni​ 和现有GCL方法不同，作者在使用无监督损失的时候，根据接收到的监督信息，给不同子图分配不同的权重。具体来说基于TIG值，给每个节点分配一个不同的CL权重wjiwj_iwji​。权重计算方式如下： wi=wmin⁡+12(wmax⁡−wmin⁡)(1+cos⁡(Rank⁡(Ti)nπ))\\boldsymbol{w}_{i}=w_{\\min }+\\frac{1}{2}\\left(w_{\\max }-w_{\\min }\\right)\\left(1+\\cos \\left(\\frac{\\operatorname{Rank}\\left(\\boldsymbol{T}_{i}\\right)}{n} \\pi\\right)\\right) wi​=wmin​+21​(wmax​−wmin​)(1+cos(nRank(Ti​)​π)) 这样整个模型的最终损失定义为： L=LCE+1n∑i=0n−1wiLUi\\mathcal{L}=\\mathcal{L}_{C E}+\\frac{1}{n} \\sum_{i=0}^{n-1} \\boldsymbol{w}_{i} \\mathcal{L}_{U}^{i} L=LCE​+n1​i=0∑n−1​wi​LUi​ 3. 实验 3.1 实验结果 3.1.1 对比实验 3.1.2 DwGCL的泛化能力 使用不同类型GNNs作为图编码器，实验结果如下图3所示： 3.1.3 消融实验 对DwGCL的不同组件进行消融，结果如下表3所示： 3.2 案例分析 3.2.1 DwGCL可以增强图中那些under-represented节点的CL效果 从上图4实验结果可以看到，在TIG值比较小的时候，和普通GCL相比，DwGCL可以显著提高模型性能。 3.2.2 DwGCL可以有效缓解过平滑问题 感觉比较扯，效果也不明显。 3.2.3 样本大小和样本难度之间的权衡 Contrastive Pair的采样在对比学习中十分重要。从上图5可以看到，负样本和锚点间距离太远或者太近都不好，这是符合常理的。因为太远了，两者太容易被区分，太近了两者太相似起不到对比的作用，都会影响对比学习的效果。另外，起初负样本数量越大，模型性能越好，但是大到一定数量反而会降低模型性能。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Towards Robust Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/17.Towards Robust Graph Contrastive Learning","date":"2021-10-05T09:11:10.000Z","updated":"2021-10-05T09:33:36.977Z","comments":true,"path":"af7c8be16de8/","link":"","permalink":"http://rookieyin.github.io/af7c8be16de8/","excerpt":"https://arxiv.org/pdf/2102.13085 Towards Robust Graph Contrastive Learning，2021，arxiv preprint 总结：作者提出一种对抗增强策略，然后基于此提出了一种鲁棒性更强的图对比学习方法GROC。robust这个点感觉可以做，这方面文章暂时不多，不过个人感觉这篇文章写得不太行，有点乱，关键点没有介绍清楚。","text":"https://arxiv.org/pdf/2102.13085 Towards Robust Graph Contrastive Learning，2021，arxiv preprint 总结：作者提出一种对抗增强策略，然后基于此提出了一种鲁棒性更强的图对比学习方法GROC。robust这个点感觉可以做，这方面文章暂时不多，不过个人感觉这篇文章写得不太行，有点乱，关键点没有介绍清楚。 1. 简介 1.1 摘要 We study the problem of adversarially robust self-supervised learning on graphs. In the contrastive learning framework, we introduce a new method that increases the adversarial robustness of the learned representations through i) adversarial transformations and ii) transformations that not only remove but also insert edges. We evaluate the learned representations in a preliminary set of experiments, obtaining promising results. We believe this work takes an important step towards incorporating robustness as a viable auxiliary task in graph contrastive learning. 我们研究了图上的对抗鲁棒自监督学习。在对比学习框架中，我们提出了一种新的方法，通过（1）对抗转换；（2）同时删除、插入边进行转换来增加表示学习的对抗鲁棒性。我们在多组实验中评估了学习到的表示，得到了很不错的结果。我们相信这项工作朝着将鲁棒性作为图对比学习中可行的额辅助任务迈出重要一步。 1.2 本文工作 背景： 加入给定足够多的的有标签数据，深度学习模型在各个领域都能取得最优表现。但是当有标签数据十分有限的时候呢？情况可能就并非如此了。在互联网时代，解决问题的关键不是获取数据，而是标记数据，而这往往代价昂贵。最近，研究人员视图通过自监督学习来解决这个问题，其中对比学习方法最近得到了很多关注。对比学习尝试对原始数据施加一个转换，但是不改变其本质。对比学习的目标就是让同一样本在不同转化下的表示向量尽可能相似。 动机： 有研究表明即使高精度神经网络模型也容易受到对抗攻击干扰，是不稳定的，难以用于对可靠性要求比较高的领域。因此构建robust模型是深度学习领域很重要的一个话题。“Adversarial self-supervised contrastive learning”这篇论文里证明了在对比学习中使用对抗转换可以学习robust表示。虽然在学习领域也广泛存在对抗攻击问题，但是至今还没有和利用对抗转换学习robust representation相关的研究。作者希望对这方面问题进行相关探索。说白了就是：借鉴“Adversarial self-supervised contrastive learning”这篇文章思想，将其拓展到图领域。 本文工作： 作者首次将对抗转换整合到图对比学习框架中，提出了图鲁棒对比学习框架GROC。通过实验证明了，GROC在面对对抗攻击时具有很高的鲁棒性。 2. GROC 2.1 常规图对比 给定图G=(V,X,A)\\mathcal{G}=(V, X, A)G=(V,X,A)，模型目标就是在无标签情况下利用对比学习训练一个编码器fθ(⋅)f_\\theta(·)fθ​(⋅)。首先定义一个transformations集合TTT，使用两种转换τ1,τ2∈T\\tau_1,\\tau_2\\in Tτ1​,τ2​∈T，生成输入图G\\mathcal GG的两个新视角。z1=fθ(τ1(v))z_1=f_\\theta(\\tau_1(v))z1​=fθ​(τ1​(v))，z2=fθ(τ2(v))z_2=f_\\theta(\\tau_2(v))z2​=fθ​(τ2​(v))，Neg⁡(v)={τ1(u)∣u∈V\\{v}}∪{τ2(u)∣u∈V\\{v}}\\operatorname{Neg}(v)=\\left\\{\\tau_{1}(u) \\mid u \\in V \\backslash\\{v\\}\\right\\} \\cup\\left\\{\\tau_{2}(u) \\mid u \\in V \\backslash\\{v\\}\\right\\}Neg(v)={τ1​(u)∣u∈V\\{v}}∪{τ2​(u)∣u∈V\\{v}}表示节点vvv对应的负样本集合。节点vvv对比损失定义如下： L(v,τ1,τ2)=−log⁡exp⁡(σ(z1,z2)/t)exp⁡(σ(z1,z2)/t)+∑u∈Neg(v)exp⁡(σ(z1,fθ(u))/t)\\mathcal{L}\\left(v, \\tau_{1}, \\tau_{2}\\right)=-\\log \\frac{\\exp \\left(\\sigma\\left(z_{1}, z_{2}\\right) / t\\right)}{\\exp \\left(\\sigma\\left(z_{1}, z_{2}\\right) / t\\right)+\\sum_{u \\in N e g(v)} \\exp \\left(\\sigma\\left(z_{1}, f_{\\theta}(u)\\right) / t\\right)} L(v,τ1​,τ2​)=−logexp(σ(z1​,z2​)/t)+∑u∈Neg(v)​exp(σ(z1​,fθ​(u))/t)exp(σ(z1​,z2​)/t)​ 上面的损失函数一视角1中节点为锚点和视角2进行对比，反过来可以定义类似的L(v,τ2,τ1)\\mathcal{L}\\left(v, \\tau_{2}, \\tau_{1}\\right)L(v,τ2​,τ1​)。这样整个图的对比损失定义为： 12n∑v∈V[L(v,τ1,τ2)+L(v,τ2,τ1)]\\frac{1}{2 n} \\sum_{v \\in V}\\left[\\mathcal{L}\\left(v, \\tau_{1}, \\tau_{2}\\right)+\\mathcal{L}\\left(v, \\tau_{2}, \\tau_{1}\\right)\\right] 2n1​v∈V∑​[L(v,τ1​,τ2​)+L(v,τ2​,τ1​)] 2.2 作者方法 如前文图1所示，作者把τi∈T\\tau_i\\in Tτi​∈T拆成两步，即τi=τi′∘τi′′\\tau_i=\\tau_i&#x27;\\circ\\tau_i&#x27;&#x27;τi​=τi′​∘τi′′​。对于τi′\\tau_i&#x27;τi′​使用随机feature masking，对于τ2′′\\tau_2&#x27;&#x27;τ2′′​使用基于边的数据转换。对于τi′\\tau_i&#x27;τi′​没什么好说的，就是正常的feature masking。对于τ2′′\\tau_2&#x27;&#x27;τ2′′​分下面两步： 第一步：edge removal，在执行完τi′\\tau_i&#x27;τi′​后，先利用公式1计算对比损失，搞一次初步的forward-backward，得到边的梯度值，然后去除那些梯度值小的边。 第二步：edge insertion，定义一个候选集S+S^+S+，先给这些边加到图里面取，并给他们分配一个非0权重，然后经过第一步初步的forward-backward后，保留候选集中部分梯度值大的边，其余的丢掉。 注：梯度值？边的梯度值？ 这块关于如何增、删边作者说的不是很清楚，基本思想是利用梯度信息指导边的删除与增加。算法伪代码如下图所示： 3. 实验 作者在5个数据集上进行节点分类实验，结果如下表1、2所示： he其中1~5表示施加扰动（对抗攻击）的等级。可以看到所有模型都是不稳定的，施加扰动后模型性能大幅下降。但是GROC模型和其他方法相比，鲁棒性更强。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"对抗攻击","slug":"对抗攻击","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}]},{"title":"Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning","slug":"3 论文笔记/图学习/对比学习/16.Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning","date":"2021-10-04T12:43:50.000Z","updated":"2021-10-04T12:47:47.507Z","comments":true,"path":"d09f7c96cb68/","link":"","permalink":"http://rookieyin.github.io/d09f7c96cb68/","excerpt":"https://arxiv.org/pdf/2009.07111 Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning ，2020，AAAI 总结：作者提出了一种半监督图对比学习方法CG3\\text{CG}^3CG3。模型比较特别的点有两个：一是和传统对比学习方法中增强策略不同，CG3\\text{CG}^3CG3不改变原始图的结构或属性信息，而是从local和global两个不同维度学习节点嵌入，然后进行对比；二是CG3\\text{CG}^3CG3的目标函数同时包含对比损失、生成损失和交叉熵分类损失。从实验结果来看，模型的实验性能是不错的，不过可能存在的一个确定就是损失函数太复杂了，训练起来代价可能比较高。","text":"https://arxiv.org/pdf/2009.07111 Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning ，2020，AAAI 总结：作者提出了一种半监督图对比学习方法CG3\\text{CG}^3CG3。模型比较特别的点有两个：一是和传统对比学习方法中增强策略不同，CG3\\text{CG}^3CG3不改变原始图的结构或属性信息，而是从local和global两个不同维度学习节点嵌入，然后进行对比；二是CG3\\text{CG}^3CG3的目标函数同时包含对比损失、生成损失和交叉熵分类损失。从实验结果来看，模型的实验性能是不错的，不过可能存在的一个确定就是损失函数太复杂了，训练起来代价可能比较高。 1. 简介 1.1 摘要 Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a handful of labeled data to the remaining massive unlabeled data via a graph. As one of the most popular graph-based SSL approaches, the recently proposed Graph Convolutional Networks (GCNs) have gained remarkable progress by combining the sound expressiveness of neural networks with graph structure. Nevertheless, the existing graph-based methods do not directly address the core problem of SSL, i.e., the shortage of supervision, and thus their performances are still very limited. To accommodate this issue, a novel GCN-based SSL algorithm is presented in this paper to enrich the supervision signals by utilizing both data similarities and graph structure. Firstly, by designing a semi-supervised contrastive loss, improved node representations can be generated via maximizing the agreement between different views of the same data or the data from the same class. Therefore, the rich unlabeled data and the scarce yet valuable labeled data can jointly provide abundant supervision information for learning discriminative node representations, which helps improve the subsequent classification result. Secondly, the underlying determinative relationship between the data features and input graph topology is extracted as supplementary supervision signals for SSL via using a graph generative loss related to the input features. Intensive experimental results on a variety of real-world datasets firmly verify the effectiveness of our algorithm compared with other state-of-the-art methods. 基于图的半监督方法（SSL）的目标是通过图将少量有标签数据的标签迁移到其余大量无标签数据上。GCNs作为最流行的graph-based SSL方法之一，它将神经网络的良好性能与图结构相结合，取得了显著进展。但是现有的graph-based方法并没有直接解决SSL的核心问题，即缺少监督，因此模型表现不佳。为了解决这个问题，本文提出了一种新的GCN-based SSL算法，通过利用数据相似性和图结构来丰富监督信号。首先，设计一个半监督对比损失，通过最大化相同数据不同视角下的一致性来提升节点表示质量。因此丰富的无标签数据和少量但是珍贵的有标签数据可以联合到一起，提供丰富的监督信息用于学习高质量节点表示，帮助提高后续分类准确度。其次，通过使用与输入特征相关的图生成损失，提取数据特征和输入图拓扑信息之间的潜在决定性关系作为SSL的补充监督信号。和SOTA方法相比，多个现实数据集上的大量实验证明了我们的算法的优越性。 1.2 本文工作 背景： 过去几十年，半监督学习SSL得到越来越多的关注，并且很多算法在其相关领域取得了很大的成功。对于graph-based SSL算法，所有有标签和无标签数据表示成节点形式，他们之间的关系通过边描述。因此图领域中半监督问题就是将少部分有标签节点的标签迁移到其余大量无标签节点中。以前常用的一种方法就是利用正则化图拉普拉斯来强制特征空间中相似节点有相同的节点标签。最近几年，关于这个问题的研究方向转移到学习you判别力的网络嵌入，研究人员提出了很多GCN相关算法，并证明了GCNs的性能优于传统方法。 动机： 虽然这几年来基于图的SSL方法取得了显著进展，但是它们并没有解决SSL的核心问题：“监督不足”。也就是说，这些方法并没有给模型带来更多的监督信号，可能拼的更多的是强大性能。作者希望能够充分利用数据本身携带的监督信息，设计一种有效的基于GCNs的SSL算法。 本文工作： 作者提出了一种新的graph-based SSL算法“Contrastive GCNs with Graph Generation（CG3CG^3CG3）”。具体来说，进行local-global对比学习的同时，利用那小部分有标签数据计算分类损失，然后把两个损失放到一起进行联合优化。 2. 方法 作者提出的CG3\\mathrm{CG}^{3}CG3框架如下图1所示： 2.1 构建对比视角 构建两个不同的views是对比学习中关键一步，这部分介绍下作者是如何构建对比视角的。 如上图1前半部分所示，和其他对比学习方法不同，作者没有改变图结构或者节点属性，而是从local和global两个维度分别学习节点表示，然后进行local-global对比。 local view： 作者采用一个2层GCN作为这部分模型骨架 Hϕ1=A^σ(A^XW(0))W(1)\\mathbf{H}^{\\phi_{1}}=\\hat{\\mathbf{A}} \\sigma\\left(\\hat{\\mathbf{A}} \\mathbf{X} \\mathbf{W}^{(0)}\\right) \\mathbf{W}^{(1)} Hϕ1​=A^σ(A^XW(0))W(1) 其中A^=D~−12A~D~−12,A~=A+I,D~ii=∑jA~ij\\hat{\\mathbf{A}}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}}, \\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}, \\tilde{\\mathbf{D}}_{i i}=\\sum_{j} \\tilde{\\mathbf{A}}_{i j}A^=D~−21​A~D~−21​,A~=A+I,D~ii​=∑j​A~ij​，Hϕ1\\mathbf{H}^{\\phi_{1}}Hϕ1​表示学习到的local view下的节点表示。 global view： 使用的是层次图神经网络HGCN，Hϕ1\\mathbf{H}^{\\phi_{1}}Hϕ1​为最终学习到的global view节点表示。 2.2 对比损失 这块没什么特别的，和其他对比学习类似。对于无标签节点的无监督对比损失，采用InfoNCE作为对比损失： 视角1作为锚点和视角2对比 Lucϕ1(xi)=−log⁡exp⁡(⟨hiϕ1,hiϕ2⟩)∑j=1nexp⁡(⟨hiϕ1,hjϕ2⟩)\\mathcal{L}_{u c}^{\\phi_{1}}\\left(\\mathbf{x}_{i}\\right)=-\\log \\frac{\\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{i}^{\\phi_{2}}\\right\\rangle\\right)}{\\sum_{j=1}^{n} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{j}^{\\phi_{2}}\\right\\rangle\\right)} Lucϕ1​​(xi​)=−log∑j=1n​exp(⟨hiϕ1​​,hjϕ2​​⟩)exp(⟨hiϕ1​​,hiϕ2​​⟩)​ 视角2作为锚点和视角1对比 Lucϕ2(xi)=−log⁡exp⁡(⟨hiϕ2,hiϕ1⟩)∑j=1nexp⁡(⟨hiϕ2,hjϕ1⟩)\\mathcal{L}_{u c}^{\\phi_{2}}\\left(\\mathbf{x}_{i}\\right)=-\\log \\frac{\\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{2}}, \\mathbf{h}_{i}^{\\phi_{1}}\\right\\rangle\\right)}{\\sum_{j=1}^{n} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{2}}, \\mathbf{h}_{j}^{\\phi_{1}}\\right\\rangle\\right)} Lucϕ2​​(xi​)=−log∑j=1n​exp(⟨hiϕ2​​,hjϕ1​​⟩)exp(⟨hiϕ2​​,hiϕ1​​⟩)​ 这样总的对比损失就是上面两者之和： Lsc=12l∑i=1l(Lscϕ1(xi)+Lscϕ2(xi))\\mathcal{L}_{s c}=\\frac{1}{2 l} \\sum_{i=1}^{l}\\left(\\mathcal{L}_{s c}^{\\phi_{1}}\\left(\\mathbf{x}_{i}\\right)+\\mathcal{L}_{s c}^{\\phi_{2}}\\left(\\mathbf{x}_{i}\\right)\\right) Lsc​=2l1​i=1∑l​(Lscϕ1​​(xi​)+Lscϕ2​​(xi​)) 因为，作者的模型是半监督的，还有少部分节点是有标签的。对这部分有标签节点，其对比损失定义为： Lscϕ1(xi)=−log⁡∑k=1l1[yi=yk]exp⁡(⟨hiϕ1,hkϕ2⟩)∑j=1lexp⁡(⟨hiϕ1,hjϕ2⟩)Lscϕ2(xi)=−log⁡∑k=1l1[yi=yk]exp⁡(⟨hiϕ2,hkϕ1⟩)∑j=1lexp⁡(⟨hiϕ2,hjϕ1⟩)\\begin{array}{c} \\mathcal{L}_{s c}^{\\phi_{1}}\\left(\\mathbf{x}_{i}\\right)=-\\log \\frac{\\sum_{k=1}^{l} \\mathbb{1}_{\\left[y_{i}=y_{k}\\right]} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{k}^{\\phi_{2}}\\right\\rangle\\right)}{\\sum_{j=1}^{l} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{j}^{\\phi_{2}}\\right\\rangle\\right)} \\\\ \\mathcal{L}_{s c}^{\\phi_{2}}\\left(\\mathbf{x}_{i}\\right)=-\\log \\frac{\\sum_{k=1}^{l} \\mathbb{1}_{\\left[y_{i}=y_{k}\\right]} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{2}}, \\mathbf{h}_{k}^{\\phi_{1}}\\right\\rangle\\right)}{\\sum_{j=1}^{l} \\exp \\left(\\left\\langle\\mathbf{h}_{i}^{\\phi_{2}}, \\mathbf{h}_{j}^{\\phi_{1}}\\right\\rangle\\right)} \\end{array} Lscϕ1​​(xi​)=−log∑j=1l​exp(⟨hiϕ1​​,hjϕ2​​⟩)∑k=1l​1[yi​=yk​]​exp(⟨hiϕ1​​,hkϕ2​​⟩)​Lscϕ2​​(xi​)=−log∑j=1l​exp(⟨hiϕ2​​,hjϕ1​​⟩)∑k=1l​1[yi​=yk​]​exp(⟨hiϕ2​​,hkϕ1​​⟩)​​ 需要注意，这里的正负样本就是根据标签判断的，负样本不再无脑选取其余所有节点。这样半监督对比就是有监督和无监督损失之和： Lssc=Luc+Lsc\\mathcal{L}_{s s c}=\\mathcal{L}_{u c}+\\mathcal{L}_{s c} Lssc​=Luc​+Lsc​ 2.3 生成损失 这部分作者相当于把传统的基于图重构的无监督图学习方法整合到他这个框架里面了。 具体来说就是利用前面两个视角中得到的节点表示，对图结构进行重构然后和原始图进行对比，得到一个重构损失。 为了尽可能从节点表示重构原始图结构，定义如下条件概率： p(G∣Hϕ1,Hϕ2)=∏i,jp(eij∣Hϕ1,Hϕ2)p\\left(\\mathcal{G} \\mid \\mathbf{H}^{\\phi_{1}}, \\mathbf{H}^{\\phi_{2}}\\right)=\\prod_{i, j} p\\left(e_{i j} \\mid \\mathbf{H}^{\\phi_{1}}, \\mathbf{H}^{\\phi_{2}}\\right) p(G∣Hϕ1​,Hϕ2​)=i,j∏​p(eij​∣Hϕ1​,Hϕ2​) 对于节点iii和节点jjj之间存在边eije_{ij}eij​的概率，作者只考虑和hih_ihi​、hjh_jhj​有关，因此有p(eij∣Hϕ1,Hϕ2)=p(eij∣hiϕ1,hjϕ2)p\\left(e_{i j} \\mid \\mathbf{H}^{\\phi_{1}}, \\mathbf{H}^{\\phi_{2}}\\right)=p\\left(e_{i j} \\mid \\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{j}^{\\phi_{2}}\\right)p(eij​∣Hϕ1​,Hϕ2​)=p(eij​∣hiϕ1​​,hjϕ2​​)。 在实际应用中，把上面的条件概率参数化成一个逻辑模型： p(G∣Hϕ1,Hϕ2)=∏i,jp(eij∣hiϕ1,hjϕ2)=∏i,jδ([hiϕ1,hjϕ2]w)p\\left(\\mathcal{G} \\mid \\mathbf{H}^{\\phi_{1}}, \\mathbf{H}^{\\phi_{2}}\\right)=\\prod_{i, j} p\\left(e_{i j} \\mid \\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{j}^{\\phi_{2}}\\right)=\\prod_{i, j} \\delta\\left(\\left[\\mathbf{h}_{i}^{\\phi_{1}}, \\mathbf{h}_{j}^{\\phi_{2}}\\right] \\mathbf{w}\\right) p(G∣Hϕ1​,Hϕ2​)=i,j∏​p(eij​∣hiϕ1​​,hjϕ2​​)=i,j∏​δ([hiϕ1​​,hjϕ2​​]w) 其中δ(⋅)\\delta(·)δ(⋅)表示logistic函数，www为可学习参数。这样生成损失就可以定义成Lg2=−p(G∣Hϕ1,Hϕ2)\\mathcal{L}_{g^{2}}=-p\\left(\\mathcal{G} \\mid \\mathbf{H}^{\\phi_{1}}, \\mathbf{H}^{\\phi_{2}}\\right)Lg2​=−p(G∣Hϕ1​,Hϕ2​)。 2.4 模型训练 作者将两个视图下的节点表示结合到一起作为最终节点嵌入： O=λϕ1Hϕ1+(1−λϕ1)Hϕ2\\mathbf{O}=\\lambda^{\\phi_{1}} \\mathbf{H}^{\\phi_{1}}+\\left(1-\\lambda^{\\phi_{1}}\\right) \\mathbf{H}^{\\phi_{2}} O=λϕ1​Hϕ1​+(1−λϕ1​)Hϕ2​ 然后利用有标签数据进行分类，得到如下交叉熵损失： Lce=−∑i=1l∑j=1cYijln⁡Oij\\mathcal{L}_{c e}=-\\sum_{i=1}^{l} \\sum_{j=1}^{c} \\mathbf{Y}_{i j} \\ln \\mathbf{O}_{i j} Lce​=−i=1∑l​j=1∑c​Yij​lnOij​ 至此CG3\\text{CG}^3CG3的损失函数定义为交叉熵损失、对比损失和生成损失三者之和： L=Lce+λsscLssc+λg2Lg2\\mathcal{L}=\\mathcal{L}_{c e}+\\lambda_{s s c} \\mathcal{L}_{s s c}+\\lambda_{g^{2}} \\mathcal{L}_{g^{2}} L=Lce​+λssc​Lssc​+λg2​Lg2​ 模型伪代码如下： 3. 实验 3.1 基础实验 下表2展示的是6个数据集上半监督节点分类实验结果。 为了验证CG3\\text{CG}^3CG3在标签更稀疏场景下的性能，作者分别设置不同标签比例进行实验，结果如下表3、4、5所示： 3.2 消融实验 CG3\\text{CG}^3CG3模型包含三种类型损失函数，作者针对这些损失函数进行了消融实验，结果如下表6所示： 另外，作者为了进一步验证CG3\\text{CG}^3CG3的性能，使用t-SNE对模型学习到的节点嵌入进行可视化：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"半监督学习","slug":"半监督学习","permalink":"http://rookieyin.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}]},{"title":"Multi-Level Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/15.Multi-Level Graph Contrastive Learning","date":"2021-10-04T05:39:59.000Z","updated":"2021-10-04T05:45:17.685Z","comments":true,"path":"3c9695579edc/","link":"","permalink":"http://rookieyin.github.io/3c9695579edc/","excerpt":"https://arxiv.org/pdf/2107.02639 Multi-Level Graph Contrastive Learning ，2021，arxiv preprint 总结：论文比较简单，作者提出一种新的图对比学习方法MLGCL。本文主要有两个创新点：一是提出了一种新的增强策略，即从节点特征空间生成KNN图作为新视角和原始图进行对比；二是提出了multi-level对比损失，即同时进行node-node和graph-graph对比。通过实验可以发现MLGCL中KNN增强、node-node对比和graph-graph对比都起到了很重要的作用，缺一不可。","text":"https://arxiv.org/pdf/2107.02639 Multi-Level Graph Contrastive Learning ，2021，arxiv preprint 总结：论文比较简单，作者提出一种新的图对比学习方法MLGCL。本文主要有两个创新点：一是提出了一种新的增强策略，即从节点特征空间生成KNN图作为新视角和原始图进行对比；二是提出了multi-level对比损失，即同时进行node-node和graph-graph对比。通过实验可以发现MLGCL中KNN增强、node-node对比和graph-graph对比都起到了很重要的作用，缺一不可。 1. 简介 1.1 摘要 Graph representation learning has attracted a surge of interest recently, whose target at learning discriminant embedding for each node in the graph. Most of these representation methods focus on supervised learning and heavily depend on label information. However, annotating graphs are expensive to obtain in the real world, especially in specialized domains (i.e. biology), as it needs the annotator to have the domain knowledge to label the graph. To approach this problem, self-supervised learning provides a feasible solution for graph representation learning. In this paper, we propose a Multi-Level Graph Contrastive Learning (MLGCL) framework for learning robust representation of graph data by contrasting space views of graphs. Specifically, we introduce a novel contrastive view - topological and feature space views. The original graph is first-order approximation structure and contains uncertainty or error, while the kNN graph generated by encoding features preserves high-order proximity. Thus kNN graph generated by encoding features not only provide a complementary view, but is more suitable to GNN encoder to extract discriminant representation. Furthermore, we develop a multi-level contrastive mode to preserve the local similarity and semantic similarity of graph-structured data simultaneously. Extensive experiments indicate MLGCL achieves promising results compared with the existing state-of-the-art graph representation learning methods on seven datasets. 最近图表示学习得到了很多人的关注，它旨在为图中每个节点学习一个可判别的嵌入。现有的大多数图表示学习方法基本都是关注有监督学习，过度依赖标签信息。然而在现实世界中，图数据标记代价非常昂贵，比如在生物领域，数据标记需要大量领域相关知识。为了解决这个问题，自监督学习为图表示学习提供了一种可行的方案。本文我们提出了一种多层级图对比学习框架MLGCL，通过对比图数据的不同视角来学习robust表示。具体来说，我们提出了一种新的对比视角——拓扑和特征空间视角。原始图是一阶近似结构，并且包含不确定性和误差，但是通过编码节点特征得到的KNN图蕴含高阶邻近性。因此通过编码特征生成的KNN图不仅可以作为一种对比视图，而且更适合GNN编码器提取有判别能力的表示。此外，我们设计了一种多层级对比模式，可以同时保留图结构数据的局部相似性和语义相似性。大量实验表明，和SOTA图表示学习方法相比，MLGCL可以取得令人满意的结果。 1.2 本文工作 背景： 图表示学习在图学习领域应用广泛，传统的图表示学习方法包括DeepWalk、Line等等。近些年，随着GNNs的不断发展，GNNs被广泛用于各种图数据分析任务。大多数用于图表示学习的GNNs都是有监督模式，过度依赖于标签信息，但是数据标记任务往往代价昂贵。因此自监督和无监督图学习方法得到了越来越多的关注。其中基于重构的无监督方法比如DNGR、SDNE等，基于对比学习的自监督方法比如DGI、MVGRL、GraphCL等等。 动机： 大多数模型都假设有边相连的两个节点很可能属于同一个类别，即同质性。但是现实世界的图数据存在不确定性和误差，导致不同类型的节点间也可能存在边。这一现象导致GNN在有些情况下表现的不好。因此通过特征相似性构建KNN图或删除不同类型节点间的边是可行的方法，基于此研究人员提出了GEN、PTDNet等方法。受这些方法启发，作者设计了一种多层级图对比学习框架。 本文工作： 作者提出了一种多层级图对比学习框架MLGCL，通过对比原始图和KNN图学习稳固的节点表示。 2. 方法 如上图2所示，作者提出MLGCL包含下列组件： GDA： 图数据增强，由输入图生成两个相关图用于对比。本文作者使用KNN图作为增强视角和原始图对比。 GNN Encoder： 图编码器，学习节点嵌入用于下游任务。 MLP： 将节点表示从嵌入空间映射到对比空间。 Pool： 池化所有节点表示，计算图表示。 Loss 函数： 作者提出的对层级损失函数同时保留低层级“local”和高层级“global”一致性。 2.1 数据增强 给定输入图G(A,X)G(A,X)G(A,X)，首先使用GNN编码器从结构信息中提取节点特征ZZZ，然后使用k近邻算法基于ZZZ构建KNN图Gf(Af,X)G_f(A_f,X)Gf​(Af​,X)。构建KNN图步骤如下： 基于节点特征ZZZ，计算相似度矩阵SSS。相似度计算方法可以采用欧氏距离、余弦距离等等。 对于每个节点，选取top-k相似节点，在它们之间添加边，最终得到KNN图的邻接矩阵AfA_fAf​。 常用相似度计算方法有： 马氏距离： 其中M是个版正定矩阵，起到逆协方差矩阵的作用 Sij=(xi−xj)TM(xi−xj)S_{i j}=\\sqrt{\\left(x_{i}-x_{j}\\right)^{T} M\\left(x_{i}-x_{j}\\right)} Sij​=(xi​−xj​)TM(xi​−xj​)​ 余弦距离 Sij=xi⋅xj∣xi∣∣xj∣S_{i j}=\\frac{x_{i} \\cdot x_{j}}{\\left|x_{i}\\right|\\left|x_{j}\\right|} Sij​=∣xi​∣∣xj​∣xi​⋅xj​​ 高斯核 Sij=e−∥xi−xj∥22σ2S_{i j}=e^{-\\frac{\\left\\|x_{i}-x_{j}\\right\\|^{2}}{2 \\sigma^{2}}} Sij​=e−2σ2∥xi​−xj​∥2​ 2.2 编码器 采用2层GNN作为图编码器，可表示为： Zl+1=f(A,X)=σ(A~ZlWl)Z^{l+1}=f(A, X)=\\sigma\\left(\\widetilde{A} Z^{l} W^{l}\\right) Zl+1=f(A,X)=σ(AZlWl) 分别得到两个视图中节点表示ZaZ_aZa​和ZbZ_bZb​后，利用图池化层P(⋅):RN×d⟼RdP(·): \\mathbb{R}^{N \\times d} \\longmapsto \\mathbb{R}^{d}P(⋅):RN×d⟼Rd计算图表示： c=P(H)=σ(1N∑i=1Nhi)c=P(H)=\\sigma\\left(\\frac{1}{N} \\sum_{i=1}^{N} h_{i}\\right) c=P(H)=σ(N1​i=1∑N​hi​) 另外为了分别进行node-level和graph-level对比，在计算两种对比损失之前都执行了一次MLP操作 gϕ(⋅)g_\\phi(·)gϕ​(⋅)和gφ(⋅):RN×d⟼RN×dg_\\varphi(·):\\mathbb{R}^{N \\times d} \\longmapsto \\mathbb{R}^{N \\times d}gφ​(⋅):RN×d⟼RN×d。 2.3 多层级损失 如前文图2所示，MLGCL同时进行了node-level和graph-level对比，因此损失函数也包含两部分： node-level对比 给定正例对(zi,zj)(z_i,z_j)(zi​,zj​)，其损失函数定义如下： Lnode (zia,zib)=log⁡exp⁡((zia)Tzib/τ)∑j=1,j≠iKexp⁡((zia)Tzib/τ)+exp⁡((zia)Tzja/τ)+exp⁡((zia)Tzjb/τ)\\mathcal{L}_{\\text {node }}\\left(z_{i}^{a}, z_{i}^{b}\\right)=\\log \\frac{\\exp \\left(\\left(z_{i}^{a}\\right)^{T} z_{i}^{b} / \\tau\\right)}{\\sum_{j=1, j \\neq i}^{K} \\exp \\left(\\left(z_{i}^{a}\\right)^{T} z_{i}^{b} / \\tau\\right)+\\exp \\left(\\left(z_{i}^{a}\\right)^{T} z_{j}^{a} / \\tau\\right)+\\exp \\left(\\left(z_{i}^{a}\\right)^{T} z_{j}^{b} / \\tau\\right)} Lnode ​(zia​,zib​)=log∑j=1,j​=iK​exp((zia​)Tzib​/τ)+exp((zia​)Tzja​/τ)+exp((zia​)Tzjb​/τ)exp((zia​)Tzib​/τ)​ 同样地，我们还可以定义Lnode (zib,zia)\\mathcal{L}_{\\text {node }}\\left(z_{i}^{b}, z_{i}^{a}\\right)Lnode ​(zib​,zia​)。这样整个节点级对比损失定义为： Lnode =Lnode (zia,zib)+Lnode (zib,zia)\\mathcal{L}_{\\text {node }}=\\mathcal{L}_{\\text {node }}\\left(z_{i}^{a}, z_{i}^{b}\\right)+\\mathcal{L}_{\\text {node }}\\left(z_{i}^{b}, z_{i}^{a}\\right) Lnode ​=Lnode ​(zia​,zib​)+Lnode ​(zib​,zia​) graph-level对比 给定正例对(sa,sb)(s^a,s^b)(sa,sb)和负例对(sa,s~a),(sa,s~b)(s^a,\\widetilde s^a),(s^a,\\widetilde s^b)(sa,sa),(sa,sb)，对比损失定义为： Lgraph (sa,sb)=log⁡exp⁡((sa)Tsb/τ)exp⁡((sa)Tsb/τ)+exp⁡((sa)Ts~a/τ)+exp⁡((sa)Ts~b/τ)\\mathcal{L}_{\\text {graph }}\\left(s^{a}, s^{b}\\right)=\\log \\frac{\\exp \\left(\\left(s^{a}\\right)^{T} s^{b} / \\tau\\right)}{\\exp \\left(\\left(s^{a}\\right)^{T} s^{b} / \\tau\\right)+\\exp \\left(\\left(s^{a}\\right)^{T} \\tilde{s}^{a} / \\tau\\right)+\\exp \\left(\\left(s^{a}\\right)^{T} \\tilde{s}^{b} / \\tau\\right)} Lgraph ​(sa,sb)=logexp((sa)Tsb/τ)+exp((sa)Ts~a/τ)+exp((sa)Ts~b/τ)exp((sa)Tsb/τ)​ 对于负样本的生成是通过随机shuffle特征得到邻接矩阵A~\\widetilde AA和A~f\\widetilde A_fAf​得到的。对于另外一个视角同样可以定义Lgraph (sb,sa)\\mathcal{L}_{\\text {graph }}\\left(s^{b}, s^{a}\\right)Lgraph ​(sb,sa)。这样整个图层级对比损失定义为： Lgraph =Lgraph (sa,sb)+Lgraph (sb,sa)\\mathcal{L}_{\\text {graph }}=\\mathcal{L}_{\\text {graph }}\\left(s^{a}, s^{b}\\right)+\\mathcal{L}_{\\text {graph }}\\left(s^{b}, s^{a}\\right) Lgraph ​=Lgraph ​(sa,sb)+Lgraph ​(sb,sa) MLGCL的整体损失就定义为两者之和： L=Lnode +λLgraph \\mathcal{L}=\\mathcal{L}_{\\text {node }}+\\lambda \\mathcal{L}_{\\text {graph }} L=Lnode ​+λLgraph ​ 3. 实验 3.1 基础实验 如上表3、4所示，即使和有监督方法相比，作者提出MLGCL在7个数据集上基本都取得了最优表现。 3.2 消融实验 作者使用Edge Perturbation，Attribute Masking和Graph Diffusion作为增强策略，分别表示为MLGCL-edge，MLGCL-mask和MLGCL-L&amp;G。实验结果如下表5所示： 对比各个实验结果可以发现，MLGCL中无论是KNN图增强策略，node-node对比还是graph-graph对比都是必不可少的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Adversarial Graph Augmentation to Improve Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/14.Adversarial Graph Augmentation to Improve Graph Contrastive Learning","date":"2021-10-03T08:34:09.000Z","updated":"2021-10-03T08:40:20.654Z","comments":true,"path":"e88ce417fc34/","link":"","permalink":"http://rookieyin.github.io/e88ce417fc34/","excerpt":"https://arxiv.org/pdf/2106.05819 https://github.com/susheels/adgcl Adversarial Graph Augmentation to Improve Graph Contrastive Learning，2021，arxiv preprint 总结：作者提出了一种对抗图对比学习框架AD-GCL，其实可以看做一种自适应数据增强GCL。具体来说，和其他自适应数据增强不同（在DA策略集合中选取最优组合），作者针对某一种数据增强策略，把数据增强看做一个可学习过程，用GNN-based augmenter学习一个最优增强策略。以Drop Edge这种数据增强策略为例，在AD-GCL框架下，我们不需要预先设计好增强策略的各种超参，而是利用一个augmenter自动学习最优超参。2021年CVPR有一篇名为“AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations from Self-Trained Negative Adversaries”的文章，这篇文章感觉又是把CV里面的策略搬到图学习中。","text":"https://arxiv.org/pdf/2106.05819 https://github.com/susheels/adgcl Adversarial Graph Augmentation to Improve Graph Contrastive Learning，2021，arxiv preprint 总结：作者提出了一种对抗图对比学习框架AD-GCL，其实可以看做一种自适应数据增强GCL。具体来说，和其他自适应数据增强不同（在DA策略集合中选取最优组合），作者针对某一种数据增强策略，把数据增强看做一个可学习过程，用GNN-based augmenter学习一个最优增强策略。以Drop Edge这种数据增强策略为例，在AD-GCL框架下，我们不需要预先设计好增强策略的各种超参，而是利用一个augmenter自动学习最优超参。2021年CVPR有一篇名为“AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations from Self-Trained Negative Adversaries”的文章，这篇文章感觉又是把CV里面的策略搬到图学习中。 1. 简介 1.1 摘要 Self-supervised learning of graph neural networks (GNN) is in great need because of the widespread label scarcity issue in real-world graph/network data. Graph contrastive learning (GCL), by training GNNs to maximize the correspondence between the representations of the same graph in its different augmented forms, may yield robust and transferable GNNs even without using labels. However, GNNs trained by traditional GCL often risk capturing redundant graph features and thus may be brittle and provide sub-par performance in downstream tasks. Here, we propose a novel principle, termed adversarial-GCL (AD-GCL), which enables GNNs to avoid capturing redundant information during the training by optimizing adversarial graph augmentation strategies used in GCL. We pair AD-GCL with theoretical explanations and design a practical instantiation based on trainable edge-dropping graph augmentation. We experimentally validate AD-GCL1 by comparing with the state-of-the-art GCL methods and achieve performance gains of up-to 14% in unsupervised, 6% in transfer, and 3% in semi-supervised learning settings overall with 18 different benchmark datasets for the tasks of molecule property regression and classification, and social network classification. 由于现实世界的图数据广泛存在标签稀疏问题，因此GNN下的自监督学习用处很大。图对比学习GCL通过最大化同一个图不同增强形式之间的一致性，可以让GNNs在不需要使用标签的情况下变大强大、可迁移。但是，使用传统GCL训练GNNs经常会捕获冗余的图特征，这使得GNNs可能很脆弱，并且在下游任务中表现不佳。在这里我们提出了一种新的原理，称为AD-GCL。通过使用对抗图增强策略，可以避免GNN在训练过程中捕获冗余信息。我们将AD-DGL和理论解释结合到一起，并基于可训练edge-dropping图增强设计了一个实例。在18个不同数据集上，我们通过实验证明了AD-GCL的有效性。和SOTA GCL方法相比，在无监督设定下获得了最高14%，在迁移设定下最高6%，在半监督设定下最高3%的性能提升。 1.2 本文工作 背景： 图表示学习在很多应用中都展现了其强大能力，但是现有的大部分GNNs都采用端到端的有监督训练方式，需要大量有标签数据。然而，数据表及往往代价昂贵。虽然也有一些传统无监督图学习方法，但是它们基本都是通过重构输入图的结构来学习节点表示，过度强调了节点邻近性。近两年，研究用于GNNs的自监督学习成了最近十分热门的方向之一，尤其是图对比学习的研究。 动机： GCL通过最大化样本不同增强形式间的一致性（最大化两者间互信息）来学习节点表示。但是有研究发现这种方式存在风险：可能会使得编码器捕获和下有任务无关的冗余信息。这种冗余信息可以帮助模型实现InfoMax，但是可能严重降低模型在下游任务中的性能。针对这个问题，作者想到了另外一种技术IB（information bottleneck），可以让编码器捕捉minimal sufficient information用于下游任务。但是基于IB的GNNs需要下游任务相关的知识，而这可能无法获取到。作者希望提出一种新的GCL框架，在下游任务知识不可知的情况下，训练一个不含冗余信息的GNNs。 本文工作： 作者将GCL和对抗训练结合到一起，提出了如下图1所示的AD-GCL框架。AD-GCL主要针对于graph-level任务，但是这个思想也可以拓展到node-level任务中。 具体来说AD-GCL包含两个组件： GNN编码器： 右边蓝色方框，学习节点表示 GNN-based增强器： 左下角黄色方框，学习合适的增强策略 另外，作者设计了AD-GCL的实例化模型，不仅通过大量实验证明了AD-GCL的有效性，还提供了AD-GCL的相关理论解释。 2. 方法 2.1 动机&amp;理论 2.1.1 动机 现有对比学习方法基本都是遵循如下InfoMax原则： InfoMax: max⁡fI(G;f(G)), where G∼PG. \\text { InfoMax: } \\max _{f} I(G ; f(G)), \\quad \\text { where } G \\sim \\mathbb{P}_{\\mathcal{G}} \\text {. } InfoMax: fmax​I(G;f(G)), where G∼PG​. 在CV中已经有研究表明，和图像标签完全无关的表示也能最大化互信息，但是这种表示对于图像分类任务完全没用。同样地问题也出现在图标学习中。为了观察这一现象，作者进行了如下实验。 作者设计了两组实验： 按照普通GCL目标，即InfoMax，训练GNN 按照普通GCL目标训练GNN，但是同时再GNN后面追加一个分类器，使用随机标签进行有监督训练 训练完毕后，为了测试这两个GNN是否保证了互信息最大化，作者分别对比了两个GNN输出的所有图表示。作者发现任意两个输出之间的差异都大于1个数字精度。这表明两个GNN都能保持输入图和输出图表示之间的一一对应，即保证互信息最大化。 作者进一步在下游任务中使用真实标签测试两个GNN编码器。作者在上述两个GNN编码器上施加两个线性分类器来预测真实标签。两个分类器具有相同的架构、超参和初始化。两个模型表现如下图所示： 可以发现，在GCL中也存在这个问题。 2.1.2 理论分析 GDA定义： 对于图g∈Gg\\in\\mathcal Gg∈G，T(G)T(G)T(G)表示对于G的一种图数据增强策略，可以将这种增强策略看做定义在G\\mathcal GG上，条件为GGG的分布。我们用t(g)∈Gt(g)\\in\\mathcal Gt(g)∈G表示T(G)T(G)T(G)的一个实例。 给定两种GDA T1T_1T1​和T2T_2T2​，GCL的目标就是： GDA-GCL: max⁡fI(f(t1(G));f(t2(G))), where G∼PG,ti(G)∼Ti(G),i∈{1,2}(5)\\text { GDA-GCL: } \\max _{f} I\\left(f\\left(t_{1}(G)\\right) ; f\\left(t_{2}(G)\\right)\\right), \\text { where } G \\sim \\mathbb{P}_{\\mathcal{G}}, t_{i}(G) \\sim T_{i}(G), i \\in\\{1,2\\}\\tag 5 GDA-GCL: fmax​I(f(t1​(G));f(t2​(G))), where G∼PG​,ti​(G)∼Ti​(G),i∈{1,2}(5) 在实际应用中我们通常根据领域知识和经验预定义好增强策略，但是选取了不合适的GDA会严重影响模型在下游任务中的表现。 和其他预定义GDA的GCL方法不同，作者受GIB的启发，把GDA的选取看做一个学习过程，让编码器fff捕获minimal sufficient information。作者基于此想法，定义了一个新的原则AD-GCL： AD-GCL: min⁡T∈Tmax⁡fI(f(G);f(t(G))), where G∼PG,t(G)∼T(G)(6)\\text { AD-GCL: } \\quad \\min _{T \\in \\mathcal{T}} \\max _{f} I(f(G) ; f(t(G))), \\quad \\text { where } G \\sim \\mathbb{P}_{\\mathcal{G}}, t(G) \\sim T(G)\\tag 6 AD-GCL: T∈Tmin​fmax​I(f(G);f(t(G))), where G∼PG​,t(G)∼T(G)(6) 其中T\\mathcal TT表示一个GDA family（即一种GDA策略，比如drop edge/mask feature/subgraph等等）。T\\mathcal TT表示不同GDAs TΦ(⋅)GDAs\\ T_\\Phi(·)GDAs TΦ​(⋅)构成的集合，Φ\\PhiΦ为这种增强策略下的参数，TΦ(⋅)∈TT_\\Phi(·)\\in\\mathcal TTΦ​(⋅)∈T表示在参数Φ\\PhiΦ下的一种具体GDA。 这里用通俗点的语言解释下GDA family：通常我们都是预先定义其超参，以drop edge为例，比如设置0.5的概率保留边。但是如果我们把drop edge看做一个可学习过程，让模型去学习这个超参，那么此时drop edge这种增强策略就可以表示成T\\mathcal TT，T0.5T_{0.5}T0.5​表示按照0.5概率保留边，T0.8T_{0.8}T0.8​表示按照0.8概率保留边。这只是1个简化的例子，实际模型比这个会复杂很多，如前文图1黄色方框所示。 AD-GCL定义的min-max准则旨在训练编码器即使在GDA非常激进的情况下依旧能最大化原始图和增强图之间的互信息。和GDA-GCL相比，AD-GCL将原始图看做锚点，同时让增强图尽可能远离锚点。这种自动搜索T∈TT\\in\\mathcal TT∈T的方法可以节省很多用于评估不同GDA组合上付出的努力。 原文还对AD-GCL准则进行了理论分析，提出了一个定理。这块比较复杂，又能里的可以看原文。作者提出的定理有两个结论： AD-GCL可以保证一个模型捕获到下游任务无关信息的上界（即minimal） AD-GCL可以保证一个学习到的表示和标签支架互信息的下界（即sufficient） 2.2 Edge Perturbation实例化AD-GCL 如上图1所示，AD-GCL有两个目标函数： 最大化原始图和增强图之间互信息来优化编码器fff。 最小化互信息来优化增强策略T(G)T(G)T(G)。 给定图G=(V,E)G=(V,E)G=(V,E)，TΦ(G)T_\\Phi(G)TΦ​(G)表示参数Φ\\PhiΦ下的一个增强策略，t(G)∼TΦ(G)t(G)\\sim T_\\Phi(G)t(G)∼TΦ​(G)表示增强后的一个图。对于每条边e∈Ee\\in Ee∈E，在增强过程中被删除的概率为pe∼Bernoulli(we)p_e\\sim Bernoulli(w_e)pe​∼Bernoulli(we​)，服从伯努利分布，当且仅当pe=1p_e=1pe​=1时，边eee被保留。 伯努利分布的参数wew_ewe​通过一个GNN计算得到，称之为GNN-augmenter。具体计算方法如下： ωe=MLP⁡([hu(K);hz(K)]), where e=(u,z) and {hv(K)∣v∈V}= GNN-augmenter (G)(7)\\omega_{e}=\\operatorname{MLP}\\left(\\left[h_{u}^{(K)} ; h_{z}^{(K)}\\right]\\right), \\quad \\text { where } e=(u, z) \\text { and }\\left\\{h_{v}^{(K)} \\mid v \\in V\\right\\}=\\text { GNN-augmenter }(G)\\tag 7 ωe​=MLP([hu(K)​;hz(K)​]), where e=(u,z) and {hv(K)​∣v∈V}= GNN-augmenter (G)(7) 为了能够端到端训练T(G)T(G)T(G)，作者使用 Gumbel-Max reparametrization trick 将离散的pep_epe​转换成[0,1][0,1][0,1]间的连续变量。具体来说令pe=Sigmoid⁡((log⁡δ−log⁡(1−δ)+ωe)/τ)p_{e}=\\operatorname{Sigmoid}((\\log \\delta-\\left.\\left.\\log (1-\\delta)+\\omega_{e}\\right) / \\tau\\right)pe​=Sigmoid((logδ−log(1−δ)+ωe​)/τ)，其中δ∼ Uniform (0,1)\\delta \\sim \\text { Uniform }(0,1)δ∼ Uniform (0,1)。 由前面理论分析可知，一个合理的GDA应该保留一定数量和下游任务相关的信息。因此drop edge下的GDA不能太激进，删掉过多的边。为了防止GDA过于激进，作者在目标函数中增加一个边的限制项： min⁡Φmax⁡ΘI(fΘ(G);fΘ(t(G)))+λreg⁡EG[∑e∈Fωe/∣E∣], where G∼PG,t(G)∼TΦ(G)(8)\\min _{\\Phi} \\max _{\\Theta} I\\left(f_{\\Theta}(G) ; f_{\\Theta}(t(G))\\right)+\\lambda_{\\operatorname{reg}} \\mathbb{E}_{G}\\left[\\sum_{e \\in F} \\omega_{e} /|E|\\right], \\text { where } G \\sim \\mathbb{P}_{\\mathcal{G}}, t(G) \\sim T_{\\Phi}(G)\\tag 8 Φmin​Θmax​I(fΘ​(G);fΘ​(t(G)))+λreg​EG​[e∈F∑​ωe​/∣E∣], where G∼PG​,t(G)∼TΦ​(G)(8) I(fΘ(G);fΘ(t(G)))→I^=1m∑i=1mlog⁡exp⁡(sim⁡(zi,1,zi,2))∑i′=1,i′≠imexp⁡(sim⁡(zi,1,zi′,2))(9)I\\left(f_{\\Theta}(G) ; f_{\\Theta}(t(G))\\right) \\rightarrow \\hat{I}=\\frac{1}{m} \\sum_{i=1}^{m} \\log \\frac{\\exp \\left(\\operatorname{sim}\\left(z_{i, 1}, z_{i, 2}\\right)\\right)}{\\sum_{i^{\\prime}=1, i^{\\prime} \\neq i}^{m} \\exp \\left(\\operatorname{sim}\\left(z_{i, 1}, z_{i^{\\prime}, 2}\\right)\\right)}\\tag 9 I(fΘ​(G);fΘ​(t(G)))→I^=m1​i=1∑m​log∑i′=1,i′​=im​exp(sim(zi,1​,zi′,2​))exp(sim(zi,1​,zi,2​))​(9) 算法伪代码如下图所示： 3. 实验 3.1 实验结果 作者提出两种类型AD-GCL： AD-GCL-FIX： 固定正则化权重λreg=5\\lambda_{reg}=5λreg​=5 AD-GCL-OPT： 用验证集从{0.1,0.3,0.5,1.0,2.0,5.0,10.0}\\{0.1,0.3,0.5,1.0,2.0,5.0,10.0\\}{0.1,0.3,0.5,1.0,2.0,5.0,10.0}中选取最合适的 NAD-GCL表示使用不带adversarial的edge dropping作为增强策略。同样有NAD-GCL-FIX和NAD-GCL-OPT两个版本。F-GIN表示使用全监督的GIN模型。所有情况下，作者的方法都取得了最优效果。 值得一提的时，GraphCL需要人工选择最优增强策略组合，而实验结果表明使用AD-GCL方法，这种选择不是必要的。另外，对比AD-GCL-FIX和AD-GCL-OPT，可以发现两者性能相差不多，说明AD-GCL对λreg\\lambda_{reg}λreg​的选取是不敏感的。 作者在实验中发现，下游任务中使用不同分类器，会导致模型性能不同。InfoGraph和GraphCL原文使用非线性SVM模型作为分类器，得到的实验结果比表1中的结果要好。下表2是使用SVM作为分类器的实验结果： 3.2 Case Study 3.2.1λreg\\lambda_{reg}λreg​对模型的影响 这部分更丰富的实验可以看原文附录。 3.2.2 迁移学习 现在一个数据集上利用自监督学习进行预训练，然后在其他数据集上微调。结果如下表3： 3.2.3 半监督学习 先在某个数据集上利用自监督学习进行预训练，然后在相同数据集上使用10%标签进行有监督微调。结果如下表4：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"SelfGNN: Self-supervised Graph Neural Networks without explicit negative sampling","slug":"3 论文笔记/图学习/对比学习/13.SelfGNN Self-supervised Graph Neural Networks without explicit negative sampling","date":"2021-10-02T08:21:48.000Z","updated":"2021-10-02T08:26:37.140Z","comments":true,"path":"5981167fc012/","link":"","permalink":"http://rookieyin.github.io/5981167fc012/","excerpt":"https://arxiv.org/pdf/2103.14958 https://github.com/zekarias-tilahun/SelfGNN SelfGNN: Self-supervised Graph Neural Networks without explicit negative sampling，2021，WWW 总结：作者提出了隐式负采样GCL模型SelfGNN。创新意义不强，纯粹把CV中一种最新的、非常牛的对比学习技术BYOL弄到图对比学习里面来了。主要创新点有两个：一是借鉴CV中隐式CL方法，将其拓展到GCL方法中；二是借鉴CV中数据增强技术，提出4种用于图数据的特征增强（FA）方法，取得了和常用的拓扑增强（TA）方法相当的性能，但是不需要额外的计算代价（TA计算复杂度通常为O(N3)O(N^3)O(N3)）。文章实验比较丰富，实验结果也挺好的。","text":"https://arxiv.org/pdf/2103.14958 https://github.com/zekarias-tilahun/SelfGNN SelfGNN: Self-supervised Graph Neural Networks without explicit negative sampling，2021，WWW 总结：作者提出了隐式负采样GCL模型SelfGNN。创新意义不强，纯粹把CV中一种最新的、非常牛的对比学习技术BYOL弄到图对比学习里面来了。主要创新点有两个：一是借鉴CV中隐式CL方法，将其拓展到GCL方法中；二是借鉴CV中数据增强技术，提出4种用于图数据的特征增强（FA）方法，取得了和常用的拓扑增强（TA）方法相当的性能，但是不需要额外的计算代价（TA计算复杂度通常为O(N3)O(N^3)O(N3)）。文章实验比较丰富，实验结果也挺好的。 1. 简介 1.1 摘要 Real world data is mostly unlabeled or only few instances are labeled. Manually labeling data is a very expensive and daunting task. This calls for unsupervised learning techniques that are powerful enough to achieve comparable results as semi-supervised/supervised techniques. Contrastive self-supervised learning has emerged as a powerful direction, in some cases outperforming supervised techniques. In this study, we propose, SelfGNN, a novel contrastive self-supervised graph neural network (GNN) without relying on explicit contrastive terms. We leverage Batch Normalization, which introduces implicit contrastive terms, without sacrificing performance. Furthermore, as data augmentation is key in contrastive learning, we introduce four feature augmentation (FA) techniques for graphs. Though graph topological augmentation (TA) is commonly used, our empirical findings show that FA perform as good as TA. Moreover, FA incurs no computational overhead, unlike TA, which often has 𝑂(𝑁3)time complexity, 𝑁 – number of nodes. Our empirical evaluation on seven publicly available real-world data shows that, SelfGNN is powerful and leads to a performance comparable with SOTA supervised GNNs and always better than SOTA semi-supervised and unsupervised GNNs. The source code is available at https://github.com/zekarias-tilahun/SelfGNN. 现实世界的数据大多数都是无标签或只有少量有标签，而人工标记数据往往代价昂贵，这要求我们开发出和半监督/有监督想能相媲美的强大无监督算法。对比自监督学习是一个非常好的研究方向，在某些场景下其性能已经超过有监督技术。 本文我们提出了一种新的对比自监督图神经网络SelfGNN，它不需要依赖明确的对比项。我们利用Batch Normalization技术，可以在不牺牲性能的情况下引入隐含对比项。另外，由于数据增强是对比学习中十分关键的一个步骤，我们提出了四种用于图数据的特征增强技术（FA）。经过图拓扑结构增强技术（TA）经常被使用，我们在研究过程中发现FA的性能和TA一样好。不像TA，FA不会带来额外的计算开销。 我们在多个公共数据集上的实验表明，SelfGNN和SOTA有监督方法性能相当，并且在大部分情况下其性能要优于SOTA半监督/无监督GNNs。模型源码获取链接为https://github.com/zekarias-tilahun/SelfGNN。 1.2 本文工作 背景： 近几年，自监督学习方法发展火热，在无监督学习和有监督学习之间架起了桥梁。在CV和NLP邻域自监督学习取得了很大成功，在某些场景下其性能甚至超过了有监督方法。这些自监督方法是由所谓的对比学习（CL）驱动的，通过最大化同一样本在不同视角下的一致性来学习特征表示。大概从2020年开始，研究人员将CL方法引入图学习领域，陆续进行了很多研究。 动机： CV中最近一些研究提出了不需要明确对比项的CL模型（借助孪生网络的一些东西实现的），但是性能比需要明确对比项的模型更好。因此在CV中，我们已经明确了无论使用explicit负样本还是implicit负样本，CL方法都能取得不弱于有监督方法的性能。但是对于图对比学习，我们还不知道负样本究竟需不需要是显示的。 本文工作： 作者将CV中那些隐式负样本CL模型拓展到图对比学习方法中，提出了隐式负采样GCL方法SelfGNN。虽然借鉴了CV中的隐式CL方法，但是和他们有所不同，SelfGNN中隐式负样本技术借鉴的时BYOL中的一些思想。另外，受CV中增强技术的启发，本文作者提出了4中用于图数据的FA增强技术。和其他GCL方法中常用TA增强技术相比，FA性能和TA相当，但是不需要额外的计算代价。（TA增强通常计算复杂度为O(N3)O(N^3)O(N3)） 2. 方法 2.1 增强策略 数据增强是对比学习中非常重要的一个步骤，图数据增强策略大体可以分两类：topology和feature，本文作者分别为这两类设计了若干种增强策略。 2.1.1 拓扑增强 作者提出了三种拓扑增强策略：基于随机游走的PageRank、基于heat-kernel的PageRank和另外一种基于Katz-index的高阶网络重构技术。三种方法公式如下： HPPR=α(I−(1−α)A~)−1HHK=exp⁡(tAD−1−t)Hkatz=(I−βA~)−1βA~\\begin{array}{c} H^{P P R}=\\alpha(I-(1-\\alpha) \\tilde{A})^{-1} \\\\ H^{H K}=\\exp \\left(t A D^{-1}-t\\right) \\\\ H^{k a t z}=(I-\\beta \\tilde{A})^{-1} \\beta \\tilde{A} \\end{array} HPPR=α(I−(1−α)A~)−1HHK=exp(tAD−1−t)Hkatz=(I−βA~)−1βA~​ 2.1.2 特征增强 前人研究中特征增强主要采用mask或者增加噪声策略。本文作者提出了下面四种特征增强策略： Split： 受CV中图片剪切的启发，将节点特征向量划分成两部分X=X[:,:F/2]X=X[:,: F / 2]X=X[:,:F/2]和X′=X[:,:F/2]X&#x27;=X[:,: F / 2]X′=X[:,:F/2]，分别构成原始数据的两个view。 Standardize： 受CV中缩放的启发，对原始特征施加z-score标准化X′=(XT−xˉs)TX^{\\prime}=\\left(\\frac{X^{T}-\\bar{x}}{s}\\right)^{T}X′=(sXT−xˉ​)T，其中xˉ∈RF×1\\bar x\\in\\mathbb R^{F\\times 1}xˉ∈RF×1，s∈RF×1s\\in\\mathbb R^{F\\times 1}s∈RF×1。虽然特征向量具体数值法神改变，但是X′X&#x27;X′中蕴含的信息和XXX是一致的。 Local Degree Profile： 有些数据集没有节点特征信息，有研究提出利用节点的度信息来构建起特征向量X′∈RN×5X&#x27;\\in\\mathbb R^{N\\times 5}X′∈RN×5。将这种LDP机制作为增强策略，然后用0对LDP生成的特征矩阵进行填充使得X和X’X’X’维度相匹配，即X′∈RN×FX&#x27;\\in\\mathbb R^{N\\times F}X′∈RN×F。 Paste： 这种策略把LDP和X结合到一起，即X′∈RN×(F+5)X&#x27;\\in\\mathbb R^{N\\times(F+5)}X′∈RN×(F+5)。此时需要将原始特征X用0填充，得到X∈RN×(F+5)X\\in\\mathbb R^{N\\times(F+5)}X∈RN×(F+5)。 2.2 模型架构 如上图1所示，作者提出的架构模仿了在对比学习中经常被用到的孪生网络。SelfGNN包含两个并行的网络，左边称之为学生网络，右边称之为老师网络。 两条网络第一个组件都是GNN编码器，左边参数为θ\\thetaθ，右边参数为ϕ\\phiϕ。编码器详细结构如下图2A所示： 需要注意的是，左边和右边网络有两点不同： 左边比右边多一个prediction block，其结构如上图2B所示。这个预测块视图让学生网络生成的向量尽可能和老师网络生成的向量一致，即gθ(X1)≈X2g_\\theta(X_1)\\approx X_2gθ​(X1​)≈X2​。 执行梯度下降时只更新左边网络图编码器参数θ\\thetaθ，右边网络的图编码器采用动量更新机制，即： ϕ←τϕ+(1−τ)θ\\phi \\leftarrow \\tau \\phi+(1-\\tau) \\theta ϕ←τϕ+(1−τ)θ 在这种架构下，模型最终的损失函数定义为均方误差： Lθ=2−2⋅⟨gθ(X1),X2⟩∥gθ(X1)∥F⋅∥X2∥F\\mathcal{L}_{\\theta}=2-2 \\cdot \\frac{\\left\\langle g_{\\theta}\\left(X_{1}\\right), X_{2}\\right\\rangle}{\\left\\|g_{\\theta}\\left(X_{1}\\right)\\right\\|_{F} \\cdot\\left\\|X_{2}\\right\\|_{F}} Lθ​=2−2⋅∥gθ​(X1​)∥F​⋅∥X2​∥F​⟨gθ​(X1​),X2​⟩​ 注：损失函数里为啥乘个2，我也不知道。。。 最后还有个问题需要解决，就是前文提到的TA增强策略在SelfGNN中使用存在两个问题： TA涉及到矩阵变换，时间复杂度为O(N3)O(N^3)O(N3) TA会导致变数量大幅增加，由于显存有限，这是模型就不支持full-batch GNNs。 为了解决这个问题，作者采用ClusterGCN中的子图采样方法。首先使用METIS创建原始的cluster，然后随机merge一些clusters构成batchs。然后不是针对整个图，而是将TAs单独用于每个子图，再用这些子图batchs训练SelfGNN。作者称这种SelfGNN变体为ClusterSelfGNN。 3. 实验 3.1 基础实验 实验一：和原始GNNs进行对比，原始GNNs使用部分标签进行有监督学习 上述实验中，对于原始GNNs，Cora、Citeseer和Pubmed使用的标签比例很小，分别为0.0563、0.0569和0.0030，而其他数据集上的实验都采用的全标签。可以发现，原始GNNs对有标签十分渴望的，在使用标签很少情况下，分类效果很差。 另外，可以发现如前文所说，在大部分情况使用FA增强策略和使用TA增强策略相比，模型性能相差不多。 最后一点就是，在大规模数据集上，使用TA可能导致边数量大幅增加，导致显存不够用。 实验二：前文提到的ClusterSelfGNN可以进一步提高模型性能 ClusterSelfGNN提出的目的主要是解决在SelfGNN中使用TA导致边数量增加，无法用于大规模数据及的问题。如上图3所示，在SelfGNN无法使用的Phisics数据集上，ClusterSelfGNN可以正常使用 实验三：和自监督GNNs对比 这里作者对比了DGI和MVGRL两种方法，结果如下表3所示： 3.2 消融实验 实验一：BatchNorm的作用 避免显示负采样的关键技术就是BatchNorm，这里作者分析了BatchNorm在SelfGNN架构中的作用。实验结果如下图4所示： 实验二：Projection head的作用 在很多CL方法中都适用了projection head，但是作者提出的SelfGNN框架中并没有加入该组件。因为作者在实验中发现，添加这个head并不会显著提高模型性能。实验结果如下图5所示： 实验三：分析Split这种增强技术对扰动是否敏感。 为了回答这个问题，作者在split之前先对特征进行随机置换X=X[:,perm]X=X[:,perm]X=X[:,perm]。 如上图6所示，这种扰动并没有对模型性能产生显著影响。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Prototypical Graph Contrastive Learning","slug":"3 论文笔记/图学习/对比学习/12.Prototypical Graph Contrastive Learning","date":"2021-10-01T14:13:24.000Z","updated":"2021-11-27T06:03:58.362Z","comments":true,"path":"21fc78e48a24/","link":"","permalink":"http://rookieyin.github.io/21fc78e48a24/","excerpt":"https://arxiv.org/pdf/2106.09645 Prototypical Graph Contrastive Learning，2021，arxive preprint 总结：作者提出了一种graph-graph图对比学习方法PGCL，用于无监督图分类任务。和其他图对比学习方法相比，作者最大的创新点就是负样本采样策略和加权对比损失。现有的GCL方法，对于负样本的选取基本都是均匀采样，不考虑负样本和锚点之间的相似度。作者在PGCL中首先对样本进行聚类，计算每个类别的原型向量，然后将和锚点处于不同簇的其他样本视作真负样本，处于相同簇的样本视为假负样本。另外，作者根据样本所在簇的原型和锚点所在簇原型之间距离计算权重用于对比损失的定义。感觉目前学术界对于GCL的研究，基本都是将CV和NLP中对比学习方法拓展到图邻域，可以多多关注CV中对比学习的最新进展。2021ICLR中有一篇名为“ PROTOTYPICAL CONTRASTIVE LEARNING OF UNSUPERVISED REPRESENTATIONS”的CV论文，我没有看着篇文章，不知道和本文是否有联系。","text":"https://arxiv.org/pdf/2106.09645 Prototypical Graph Contrastive Learning，2021，arxive preprint 总结：作者提出了一种graph-graph图对比学习方法PGCL，用于无监督图分类任务。和其他图对比学习方法相比，作者最大的创新点就是负样本采样策略和加权对比损失。现有的GCL方法，对于负样本的选取基本都是均匀采样，不考虑负样本和锚点之间的相似度。作者在PGCL中首先对样本进行聚类，计算每个类别的原型向量，然后将和锚点处于不同簇的其他样本视作真负样本，处于相同簇的样本视为假负样本。另外，作者根据样本所在簇的原型和锚点所在簇原型之间距离计算权重用于对比损失的定义。感觉目前学术界对于GCL的研究，基本都是将CV和NLP中对比学习方法拓展到图邻域，可以多多关注CV中对比学习的最新进展。2021ICLR中有一篇名为“ PROTOTYPICAL CONTRASTIVE LEARNING OF UNSUPERVISED REPRESENTATIONS”的CV论文，我没有看着篇文章，不知道和本文是否有联系。 1. 简介 1.1 摘要 Graph-level representations are critical in various real-world applications, such as predicting the properties of molecules. But in practice, precise graph annotations are generally very expensive and time-consuming. To address this issue, graph contrastive learning constructs instance discrimination task which pulls together positive pairs (augmentation pairs of the same graph) and pushes away negative pairs (augmentation pairs of different graphs) for unsupervised representation learning. However, since for a query, its negatives are uniformly sampled from all graphs, existing methods suffer from the critical sampling bias issue, i.e., the negatives likely having the same semantic structure with the query, leading to performance degradation. To mitigate this sampling bias issue, in this paper, we propose a Prototypical Graph Contrastive Learning (PGCL) approach. Specifically, PGCL models the underlying semantic structure of the graph data via clustering semantically similar graphs into the same group, and simultaneously encourages the clustering consistency for different augmentations of the same graph. Then given a query, it performs negative sampling via drawing the graphs from those clusters that differ from the cluster of query, which ensures the semantic difference between query and its negative samples. Moreover, for a query, PGCL further reweights its negative samples based on the distance between their prototypes (cluster centroids) and the query prototype such that those negatives having moderate prototype distance enjoy relatively large weights. This reweighting strategy is proved to be more effective than the uniform sampling. Experimental results on various graph benchmarks testify the advantages of our PGCL over state-of-the-art methods. 图表示学习在很多现实应用中都非常重要，比如预测分子属性。但是在实际应用中对图数据进行准确标记通常代价十分昂贵。为了解决这个问题，图对比学习通过构造实例判别任务，来拉近正例样本间距离，拉远负样本间距离，用于无监督表示学习。然而对于一个锚点，其负样本是从所有图中通过均匀采样的到的，现有的这些方法存在严重的抽样偏差问题，即负样本可能和锚点样本具有相同的语义结构，从而导致模型性能下降。为了缓解采样偏差问题，本文我们提出了原型图对比学习方法PGCL。具体来说，PGCL通过将语义相似的图进行聚类，来学习图数据潜在的语义结构。然后，给定一个锚点时，从其他clusters中选取负样本，这样可以确保锚点和负样本语义间的差异。另外，对于一个锚点，PGCL进一步根据负样本所在cluster原型和锚点所在cluster原型之间的距离，对所有负样本进行reweight，让原型距离适中的那些负样本簇权重更大。这种reweight操作均匀抽样更有效。不同数据集上的实验表明，PGL比其他SOTA方法优势更大。 1.2 本文工作 背景： 图表示学习在很多实际应用中都有用到，近几年来，研究人员关注最多的方法就是GNNs。但是大部分GNNs都是有监督方法，依赖大量有标签数据。然后，某些领域数据标记需要领域知识，因此标记成本过大。因此，这两年无监督图表示学习方法是一个重要发展方向，研究人员通过最大化local(or global)和global信息间的MI来学习图表示。 动机： 现有的图对比学习方法都存在两个弊端： 全局结构： 现有的GCL方法主要关注于对instance-level结构相似度建模，但是在实际应用中图数据的全局结构更重要。比如MUTAG是一个 致突变芳香族和杂芳香族硝基数据集，可分成7个类别。这些类别分配包含着潜在的全局结构，但是并没有被标记用于提高表示学习性能。 这里我理解的大概意思就是：现有GCL方法在对比的时候只关注instance这个层面，没有站在顶层看整个数据集本身。这个时候只能捕捉到局部结构信息，无法捕捉全局结构信息。 负样本采样偏差： 如下图1所示，现有的GCL方法对于某个锚点负样本的选取，基本都是按照均匀分布进行采样。但是作者认为负样本有“true”，有&quot;false&quot;，还有质量高低之分。我们应该让模型尽量选取质量高的负样本。 本文工作： 作者提出了一种新的图对比学习框架PGCL，首先对所有样本进行聚类，然后基于聚类结果选取负样本，并按照某种策略给负样本分配不同权重，基于这些权重计算对比损失。 2. 方法 首先再明确下，作者本文针对的问题是无监督图分类问题。作者提出的图对比学习方法PGCL有两个重要步骤： 聚类： 聚类的目标有两个，一是将语义相似的图划分到同一组，二是将同一张图的不同视角划分到同一组。 权重分配： 对于每一个锚点样本，选取负样本时不再使用随机均匀采样，而是给第一步聚类得到的所有簇分配一个权重，按照权重大小采样。和目标节点所在簇距离越近的簇权重越大。 上面两个步骤准备完毕后，每一个样本都有其对应的正样本和负样本集合，此时可以进行对比学习了。下图展示了PGCL的框架： 2.1 聚类 给定图GiG_iGi​，zi=fθ(Gi)z_i=f_\\theta(G_i)zi​=fθ​(Gi​)表示通过GNN得到的图表示向量。将所有样本划分成K组，用C∈RK×D={c1,...,ck}C\\in\\mathbb R^{K\\times D}=\\{c_1,...,c_k\\}C∈RK×D={c1​,...,ck​}分别表示每一组数据的原型向量，需要注意的时该原型向量是可训练的（即参与梯度下降的参数）。 这样，给定一个样本GiG_iGi​，及其表示向量ziz_izi​，我们可以按照下列方式计算该样本属于每一组的概率： p(y∣zi)=softmax⁡(C⋅fθ(Gi))(4)p\\left(y \\mid z_{i}\\right)=\\operatorname{softmax}\\left(\\mathbf{C} \\cdot f_{\\theta}\\left(G_{i}\\right)\\right)\\tag 4 p(y∣zi​)=softmax(C⋅fθ​(Gi​))(4) ℓ(pi,qi′)=−∑y=1Kq(y∣zi′)log⁡p(y∣zi)(5)\\ell\\left(p_{i}, q_{i^{\\prime}}\\right)=-\\sum_{y=1}^{K} q\\left(y \\mid z_{i}^{\\prime}\\right) \\log p\\left(y \\mid z_{i}\\right)\\tag 5 ℓ(pi​,qi′​)=−y=1∑K​q(y∣zi′​)logp(y∣zi​)(5) 交换ziz_izi​和zi′z_i&#x27;zi′​位置我们可以得到l(pi′,qi)l(p_{i&#x27;},q_i)l(pi′​,qi​)，这样最终聚类损失定义为： Lconsistency =∑i=1n[ℓ(pi,qi′)+ℓ(pi′,qi)](6)\\mathcal{L}_{\\text {consistency }}=\\sum_{i=1}^{n}\\left[\\ell\\left(p_{i}, q_{i^{\\prime}}\\right)+\\ell\\left(p_{i^{\\prime}}, q_{i}\\right)\\right]\\tag 6 Lconsistency ​=i=1∑n​[ℓ(pi​,qi′​)+ℓ(pi′​,qi​)](6) 优化公式5会存在一种退化解，即将所有样本分配到同一组。为了解决这个问题，将样本尽可能均匀分配到各组，采用如下优化方法： min⁡p,qLconsistency subject to ∀y:q(y∣zi)∈[0,1] and ∑i=1Nq(y∣zi)=NK(7)\\min _{p, q} \\mathcal{L}_{\\text {consistency }} \\text { subject to } \\quad \\forall y: q\\left(y \\mid z_{i}\\right) \\in[0,1] \\text { and } \\sum_{i=1}^{N} q\\left(y \\mid z_{i}\\right)=\\frac{N}{K}\\tag 7 p,qmin​Lconsistency ​ subject to ∀y:q(y∣zi​)∈[0,1] and i=1∑N​q(y∣zi​)=KN​(7) 公式7添加的限制，意味着一个batch中的N个样本要均匀分配到K组。公式7描述的其实是最优传输问题，最终可以转化成如下形式： min⁡p,qLconsistency =min⁡Q∈T⟨Q,−log⁡P⟩−log⁡N(10)\\min _{p, q} \\mathcal{L}_{\\text {consistency }}=\\min _{Q \\in \\mathbf{T}}\\langle Q,-\\log P\\rangle-\\log N\\tag{10} p,qmin​Lconsistency ​=Q∈Tmin​⟨Q,−logP⟩−logN(10) 公式10的最优解可以通过Sinkhorn-Knopp算法解决。 关于这部分的详细内容可以看论文原文和https://lccurious.github.io/2020/01/30/optimal-transport/这篇博客。 2.2 对比 这部分重点介绍作者如何解决现有GCL方法中存在的负样本偏差问题。 作者认为对比学习中不同负样本有真假之分，有些是“true” negative examples，有些是“false”negative examples。怎么区分负样本的真假呢？作者采用的方法很简单，就是利用前面聚类的结果，和锚点处于同一簇的负样本都是“true”，反之为“false”。这样对比损失就定义为： L=−∑i=1nlog⁡exp⁡(zi⋅zi′/τ)exp⁡(zi⋅zi′/τ)+∑j=1N1ci≠cj⋅exp⁡(zi⋅zj′/τ)(12)\\mathcal{L}=-\\sum_{i=1}^{n} \\log \\frac{\\exp \\left(\\boldsymbol{z}_{i} \\cdot \\boldsymbol{z}_{i}^{\\prime} / \\tau\\right)}{\\exp \\left(\\boldsymbol{z}_{i} \\cdot \\boldsymbol{z}_{i}^{\\prime} / \\tau\\right)+\\sum_{j=1}^{N} \\mathbb{1}_{\\mathbf{c}_{i} \\neq \\mathbf{c}_{j}} \\cdot \\exp \\left(\\boldsymbol{z}_{i} \\cdot \\boldsymbol{z}_{j}^{\\prime} / \\tau\\right)}\\tag{12} L=−i=1∑n​logexp(zi​⋅zi′​/τ)+∑j=1N​1ci​​=cj​​⋅exp(zi​⋅zj′​/τ)exp(zi​⋅zi′​/τ)​(12) 其中cic_ici​和cjc_jcj​分别表示GiG_iGi​和GjG_jGj​所处聚类簇的原型向量。另外，作者认为“true”负样本也有质量高低之分。 具体来说，作者认为从直觉上来说理想的负样本所在簇和锚点所在簇之间应该有一个合适的距离，不能太近，也不能太远。如下图3所示： 如果两者相距太远（比如上图紫色点），说明该簇中负样本和锚点之间太容易被区分了，对模型没啥用。反之如果太近（比如上图蓝色点），说明两者过于相似，那这个负样本和正样本差不多了，也不利于模型学习。因此作者重新定义如下对比损失： LReweighted =−∑i=1nlog⁡exp⁡(zi⋅zi′/τ)exp⁡(zi⋅zi′/τ)+Mi∑j=1N1ci≠cj⋅wij⋅exp⁡(zi⋅zj′/τ)(13)\\mathcal{L}_{\\text {Reweighted }}=-\\sum_{i=1}^{n} \\log \\frac{\\exp \\left(z_{i} \\cdot \\boldsymbol{z}_{i}^{\\prime} / \\tau\\right)}{\\exp \\left(\\boldsymbol{z}_{i} \\cdot \\boldsymbol{z}_{i}^{\\prime} / \\tau\\right)+M_{i} \\sum_{j=1}^{N} \\mathbb{1}_{\\mathbf{c}_{i} \\neq \\mathbf{c}_{j}} \\cdot \\boldsymbol{w}_{i j} \\cdot \\exp \\left(\\boldsymbol{z}_{i} \\cdot \\boldsymbol{z}_{j}^{\\prime} / \\tau\\right)}\\tag{13} LReweighted ​=−i=1∑n​logexp(zi​⋅zi′​/τ)+Mi​∑j=1N​1ci​​=cj​​⋅wij​⋅exp(zi​⋅zj′​/τ)exp(zi​⋅zi′​/τ)​(13) 其中wijw_{ij}wij​表示权重，Mi=N∑j=1NwijM_i=\\frac{N}{\\sum_{j=1}^Nw_{ij}}Mi​=∑j=1N​wij​N​表示正则化因子。权重计算方式采用两个原型之间的余弦距离D(ci,cj)=1−ci⋅cj∥ci∥2∥cj∥2\\mathcal D(c_i,c_j)=1-\\frac{\\mathbf{c}_{i} \\cdot \\mathbf{c}_{j}}{\\left\\|\\mathbf{c}_{i}\\right\\|_{2}\\left\\|\\mathbf{c}_{j}\\right\\|_{2}}D(ci​,cj​)=1−∥ci​∥2​∥cj​∥2​ci​⋅cj​​，wijw_{ij}wij​计算方式如下： wij=exp⁡{−[D(ci,cj)−μi]22σi2}(14)\\boldsymbol{w}_{i j}=\\exp \\left\\{-\\frac{\\left[\\mathcal{D}\\left(\\mathbf{c}_{i}, \\mathbf{c}_{j}\\right)-\\mu_{i}\\right]^{2}}{2 \\sigma_{i}^{2}}\\right\\}\\tag{14} wij​=exp{−2σi2​[D(ci​,cj​)−μi​]2​}(14) 至此将对比损失和聚类损失加到一起就是整个模型的损失函数： L=LReweighted +λLConsistency (15)\\mathcal{L}=\\mathcal{L}_{\\text {Reweighted }}+\\lambda \\mathcal{L}_{\\text {Consistency }}\\tag{15} L=LReweighted ​+λLConsistency ​(15) 3. 实验 3.1 对比实验 可以看到，和无监督baselines相比，作者在所有数据集上都取得了最优结果。PGCL性能和有监督方法相比性能相当，在个别数据集上表现更优。 3.2 消融/可视化 不同损失函数： 作者分析了PGCL中聚类和负采样策略的有效性 原型数目K和batch大小N： 作者分析了不同K值和batch size对模型性能的影响 可视化： 作者用t-SNE对学习到的图表示进行了可视化，每个数据集中K都取10","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training","slug":"3 论文笔记/图学习/对比学习/11.GCC Graph Contrastive Coding for Graph Neural Network Pre-Training","date":"2021-09-30T13:50:16.000Z","updated":"2021-11-27T06:03:38.176Z","comments":true,"path":"cd1ebef497f7/","link":"","permalink":"http://rookieyin.github.io/cd1ebef497f7/","excerpt":"https://arxiv.org/pdf/2006.09963 https://github.com/THUDM/GCC GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training，2020，KDD 总结：简单来说，作者提出了一种subgraph-subgraph level图对比学习框架GCC，对GNNs进行预训练后将模型迁移到其他数据集。框架本身就是非常常规的对比学习框架，目标函数也是常规的对比损失，没什么特别之处。值得关注的一点是作者如何生成定义、增强子图的。作者的实验比较丰富，但是实验结果并没有什么亮眼之处。个人感觉，这篇能发顶会主要原因：一是论文写的比较早，应该是第一篇用对比学习来搞图预训练任务的，开创意义比较大；二是作者比较会写论文，文章立意比较高。","text":"https://arxiv.org/pdf/2006.09963 https://github.com/THUDM/GCC GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training，2020，KDD 总结：简单来说，作者提出了一种subgraph-subgraph level图对比学习框架GCC，对GNNs进行预训练后将模型迁移到其他数据集。框架本身就是非常常规的对比学习框架，目标函数也是常规的对比损失，没什么特别之处。值得关注的一点是作者如何生成定义、增强子图的。作者的实验比较丰富，但是实验结果并没有什么亮眼之处。个人感觉，这篇能发顶会主要原因：一是论文写的比较早，应该是第一篇用对比学习来搞图预训练任务的，开创意义比较大；二是作者比较会写论文，文章立意比较高。 1. 简介 1.1 摘要 Graph representation learning has emerged as a powerful technique for addressing real-world problems. Various downstream graph learning tasks have benefited from its recent developments, such as node classification, similarity search, and graph classification. However, prior arts on graph representation learning focus on domain specific problems and train a dedicated model for each graph dataset, which is usually non-transferable to out-of-domain data. Inspired by the recent advances in pre-training from natural language processing and computer vision, we design Graph Contrastive Coding (GCC)1—a self-supervised graph neural network pre-training framework—to capture the universal network topological properties across multiple networks. We design GCC’s pre-training task as subgraph instance discrimination in and across networks and leverage contrastive learning to empower graph neural networks to learn the intrinsic and transferable structural representations. We conduct extensive experiments on three graph learning tasks and ten graph datasets. The results show that GCC pre-trained on a collection of diverse datasets can achieve competitive or better performance to its task-specific and trained-from-scratch counter-parts. This suggests that the pre-training and fine-tuning paradigm presents great potential for graph representation learning. 图表示学习逐渐成为解决现实问题的一种强大技术，许多下游任务都从它的发展中收益，比如节点分类、相似检索、图分类。但是，现有的图表示学习方法大多关注领域相关的特定问题，为每个数据集单独训练一个模型，这个模型都不能迁移到其他领域任务中。受NLP和CV中预训练最新进展的启发，我们设计了Graph Contrastive Coding（GCC）——一种自监督图神经网络预训练架构，可以跨网络捕捉通用的拓扑信息。我们将网络内和跨网络子图判别作为GCC的预训练任务，并通过对比学习使图神经网络可以学习内在的、可迁移的结构表示。我们在10个数据集、3个图学习任务上进行了大量实验，结果表明在不同数据集上对GCC进行预训练可以让模型取得很好的表现。这表示预训练和微调模式在图表示学习领域具有很大潜力。 1.2 本文工作 背景： 过去20年里，网络科学的研究主要集中于在不同网络间发现、提取通用的结构属性。但是在最近几年，由于深度学习取得了很大进展，图学习模式逐渐从发现structural pattern转向图表示学习。而大多数图表示学习方法都是针对于单一任务的，不能迁移到out-of-domain数据和任务。因为本质上图表示学习模型旨在学习一个专用于某个数据集的network-specific structural patterns。 动机： 鉴于（1）现有很多图表示学习方法存在局限性（2）对于common structural pattern discovery在过去已经进行了很多研究，证明了其可行性，作者在想“能不能从网络中学习一个通用的、可迁移的图嵌入？” 本文工作： 在CV和NLP领域也存在类似前文提到的问题，目前为止，最好的一种方法就是在大型数据集上以自监督方式对模型进行预训练，然后在unseen数据集上进行微调。受其启发，本文作者提出了Graph Contrastive Coding（GCC），利用对比学习思想实现跨网络学习结构表示。作者通过大量实验证明了GCC的性能和可迁移性。 2 方法 上图2展示了GCC的整体架构，首先在三个数据集上进行预训练，然后迁移到其他数据集上进行微调。下面首先看一下作者是GNN预训练问题是如何定义的。 2.1 问题定义 对于预训练问题，从概念上来说，给定来自不同domain的图集合，我们希望以自监督方式预训练一个GNN模型，可以在这些不同图之间捕捉结构模式。预训练好的模型可以用于其他不同数据集上的下有任务。 注：这里有一个潜在假设就是，不同图之间确确实实是存在着这样一个通用的、可迁移的结构模式（比如motifs）。 说的正式一点，GNN预训练问题就是学习一个函数fff，将节点映射成一个低维特征向量，这个fff具有以下两个性质： structural similarity： 对于两个具有相似局部拓扑结构的节点，映射出来的特征向量要相似（就是这几年很火的图表示学习的目标） transferability： 能够适用于unseen数据集（即要求模型学习到的时通用的结构模式，这就是传统common structural pattern discovery方法的目标） 总结来说，其实就是把图表示学习问题和传统的结构模式发现问题结合到一起。 因为GCC是个预训练框架，因此下面分预训练和微调两部分介绍该框架。 2.2 预训练 受对比学习在CV和NLP领域成功应用的启发，作者将“subgraph instance discrimination”作为预训练任务（即subgraph-subgraph level 对比），InfoNCE作为学习目标。 预训练任务： 简单点说就是进行subgraph-subgraph level 对比。让每个子图自成一类，自己就是该类别的一个实例。模型需要做的就是输出可以捕获不同子图实例间相似性的表示向量。 学习目标： 这里作者说的比较复杂，其实就是常规的对比学习损失函数。作者采用InfoNCE作为损失函数： L=−log⁡exp⁡(q⊤k+/τ)∑i=0Kexp⁡(q⊤ki/τ)\\mathcal{L}=-\\log \\frac{\\exp \\left(\\boldsymbol{q}^{\\top} \\boldsymbol{k}_{+} / \\tau\\right)}{\\sum_{i=0}^{K} \\exp \\left(\\boldsymbol{q}^{\\top} k_{i} / \\tau\\right)} L=−log∑i=0K​exp(q⊤ki​/τ)exp(q⊤k+​/τ)​ 其中qqq就是锚点，k+k_+k+​就是正样本，{k0,...,k1}\\{k_0,...,k_1\\}{k0​,...,k1​}表示所有正负样本集合。 这篇文章作者扯得比较复杂，其实GCC可以看作一种subgraph-subgraph level的对比学习方法。既然是subgraph-subgraph层对比，那首先就要设计一个子图采样方法，得到输入样本集合。然后要考虑的就是增强策略，即如何为子图生成正负样本。最后当然还需要选取一种GNNs作为图编码器，学习图嵌入。 因此为了构建GCC的每个组件，我们需要解决三个问题： 如何定义subgraph？ 本文作者采用r-ego network方式生成子图，其定义如下： G=(V,E)G=(V,E)G=(V,E)表示一张图，VVV表示节点集合，E⊆V×VE\\subseteq V\\times VE⊆V×V表示边集合。对于顶点vvv，它的r-neighbors定义为Sv={u:d(u,v)≤r}S_v=\\{u:d(u,v)\\leq r\\}Sv​={u:d(u,v)≤r}，其中d(u,v)d(u,v)d(u,v)表示u和v之间的最短距离。（这个应该就是等价于r-hop邻居构成的子图） 下图3最左边，小圆圈里面圈出来的就是两个子图。 如何生成正负样本（即增强策略）？ 在CV中，将同一张图片经两次随机增强（旋转或剪切）后得到的两个增强样本看作similar instance pair（即正样本对）。同样地，在GCC中作者也将同一个子图经过两次 随机增强（本文采用图采样） 后得到的两个增强样本看作正样本对。GCC的图采样包含三个步骤： RWR，从节点vvv看是执行带有restart的随机游走 子图诱导，对于节点vvv，第一步RWR得到的子图表示为S~v\\widetilde S_vSv​，从S~\\widetilde SS诱导得到的子图表示为G~v\\widetilde G_vGv​。 Anonymization，每个子图G~v\\widetilde G_vGv​自成一类，按顺序分配标签{1,2,...,∣S~v∣}\\{1,2,...,|\\widetilde S_v|\\}{1,2,...,∣Sv​∣}。（这一步介绍有点多余，对比学习天生的设置就是这样，加上这一句可以更好理解前面的对比损失） 重复执行前面3个步骤，对于每个节点我们都能得到两个增强子图。下图3中间四张图表示的就是增强后得到的子图。 对于qqq和kkk，哪种graph encoder最合适？ 如下图3所示，给定子图xqx^qxq和xkx^kxk，GCC使用两个编码器fqf_qfq​和fkf_kfk​分别对输入子图进行编码。从理论上来说我们可以采用任何一种GNNs作为编码器，GCC模型对此并不敏感。在实际应用中，作者采用GIN作为图编码器。 另外需要注意的是，如前文所属，作者关注的是模型在预训练过程中学习通用的、可迁移的结构表示。但是现有的大部分GNN模型都需要节点特征/属性作为输入。为了弥补这一差异，作者利用采样子图的图结构来初始化顶点特征。具体来说，作者定义了“generalized positional embedding”： AAA和DDD分别表示子图的邻接矩阵和度矩阵，对正则化的图拉普拉斯矩阵进行特征分解：I−D−1/2AD−1/2=UΛU⊤I-D^{-1 / 2} A D^{-1 / 2}=U \\Lambda U^{\\top}I−D−1/2AD−1/2=UΛU⊤，UUU最上面的特征向量即为generalized positional embedding。 上图3展示了GCC预训练的大致流程。对于训练方式，作者基本是参照何凯明CV里面对比学习模型，在实验中采用了end-to-end和MOCO两种训练方式。 2.3 微调 下游任务 图学习下游任务大致可以分为两类：node-level和graph-level，目标分别为预测节点或图的标签。对于graph-level任务，直接使用GCC对输入图进行编码，得到图表示即可。对于node-level任务，可以使用GCC对节点的r-ego网络进行编码。 微调策略 GCC提供了两种微调策略： Freezing： 微调时冻结GCC中图编码器参数，重新训练一个分类器 Full fine-tuning： 对整个模型参数进行微调，包括编码器和分类器 3. 实验 3.1 基础实验 节点分类： 为了评估GCC，作者将节点的r-ego子图输入到GCC中，然后将得到的节点表示喂给输出层，预测节点标签。实验结果如下表2所示： 图分类： 将原始图输入GCC，得到graph-level表示后，喂给分类器预测图标签。实验结果如下表3所示： Top-k Similarity Search： 采用KDD、ICDM等学术会议的的co-author数据集进行实验。top-k相似度查询的问题定义为：给定两个图G1G_1G1​和G2G_2G2​，从G1G_1G1​中找到和G2G_2G2​中节点uuu最相似的节点vvv。因为similarity search是无监督问题，因此不需要对GCC进行微调。具体来说，作者利用RWR，分别以uuu和vvv为中心节点进行子图采样，然后利用GCC对接点进行编码，最后计算uuu和vvv之间的相似度。实验结果如下表4所示： 3.2 消融实验 预训练的有效性： 如前文表2、表3所示，为了验证GCC的有效性来自于GIN的强大编码能力还是预训练，作者设计了GCC(rand)模型。具体来说，GCC(rand)将其GIN编码器随机初始化一个参数后进行fully fine-tune。可以看到在大部分情况下，GCC(MoCo)的想能要优于GCC(rand)，这证明了预训练是有效的，可以为GIN提供一个号的初始化参数。 对比损失机制： 在CV邻域，MOCO模型比E2E模型性能要好很多，并且负样本越多（即K值越大）性能越好。但是本文发现，在图领域，K值的大小对于模型性能影响并不大，例如MoCo(K=16384)MoCo(K=16384)MoCo(K=16384)和MoCo(K=1024)MoCo(K=1024)MoCo(K=1024)相比性能增加不超过1.0。另外，和E2E相比，MoCo方式训练模型速度更快，如下图6所示： 动量更新中动量值： 所谓动量更新即θk←mθk+(1−m)θq\\theta_k\\leftarrow m\\theta_k+(1-m)\\theta_qθk​←mθk​+(1−m)θq​。从下表5可以看出，在US-Airport数据集中动量值取m=0.999m=0.999m=0.999模型最好，这和CV中MOCO模型是一致的。但是在COLLAB数据集中，似乎m越大模型性能越好。 预训练数据集： 从下图5可以看出，用于预训练的数据集越多，在unseen数据集上的表现越好。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"预训练","slug":"预训练","permalink":"http://rookieyin.github.io/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/"}]},{"title":"GraphCL: Contrastive Self-Supervised Learning of Graph Representations","slug":"3 论文笔记/图学习/对比学习/10.GraphCL Contrastive Self-Supervised Learning of Graph Representations","date":"2021-09-29T10:47:33.000Z","updated":"2021-09-29T10:55:41.810Z","comments":true,"path":"d4b47adfecd7/","link":"","permalink":"http://rookieyin.github.io/d4b47adfecd7/","excerpt":"https://arxiv.org/pdf/2007.08025 https://github.com/Shen-Lab/GraphCL GraphCL: Contrastive Self-Supervised Learning of Graph Representations，2020，NIPS 总结：论文很短，作者提出对比学习框架GraphCL也简单易懂，但是实验结果很不错。作者借鉴类似GraphSAGE里面子图构造方法，首先为每个节点采样L-hop子图，然后对子图添加随机扰动得到不同的view，然后在两个view中进行node-node对比，通过最大化正样本与锚点之间距离、最小化负样本与锚点间的距离来学习节点表示。GraphCL算是图对比学习里的开山之作，后面很多文章都是基于这个方法的进一步拓展和深入。","text":"https://arxiv.org/pdf/2007.08025 https://github.com/Shen-Lab/GraphCL GraphCL: Contrastive Self-Supervised Learning of Graph Representations，2020，NIPS 总结：论文很短，作者提出对比学习框架GraphCL也简单易懂，但是实验结果很不错。作者借鉴类似GraphSAGE里面子图构造方法，首先为每个节点采样L-hop子图，然后对子图添加随机扰动得到不同的view，然后在两个view中进行node-node对比，通过最大化正样本与锚点之间距离、最小化负样本与锚点间的距离来学习节点表示。GraphCL算是图对比学习里的开山之作，后面很多文章都是基于这个方法的进一步拓展和深入。 1.简介 1.1 摘要 We propose Graph Contrastive Learning (GraphCL), a general framework for learning node representations in a self supervised manner. GraphCL learns node embeddings by maximizing the similarity between the representations of two randomly perturbed versions of the intrinsic features and link structure of the same node’s local subgraph. We use graph neural networks to produce two representations of the same node and leverage a contrastive learning loss to maximize agreement between them. In both transductive and inductive learning setups, we demonstrate that our approach significantly outperforms the state-of-the-art in unsupervised learning on a number of node classification benchmarks. 我们提出了图对比学习GraphCL——一种通用的自监督节点表示学习框架。GraphCL通过最大化同一节点局部子图的链路结构和两个内在特征随即扰动版本的表示之间的相似性来学习节点嵌入。我们使用GNNs生成相同节点的两个表示，然后利用对比损失最大化这两个表示之间的一致性。在多种节点分类标准数据集中，无论是transductive还是inductive设定，我们都证明了我们的方法优于当前最优无监督学习模型。 1.2 本文工作 背景： 越来越多领域用图结构作为数据表示形式。但是由于图的复杂性，很少有方法对它进行探索。最近几年，图表示学习作为一种图分析手段得到了研究人员的广泛关注。现有的大部分图表示学习方法都是致力于将通用的神经网络拓展到图数据上，即都属于GNNs和Deep Geometric Learning范畴。这些方法都过度依赖人工标记的有标签数据集，即所谓的有监督形式。虽然有人受NLP中一些方法的启发，提出了DeepWalk、node2vec等无监督方法。但是这些无监督方法都存在同质性假设。其他一些基于自编码器的方法，比如VGAE等，也采用了同质性假设。这些方法虽然在学习强大节点表示方面取得了成功，但是一来同质性假设使这些方法偏向于强调节点的直接邻近性而不是拓扑信息。18年提出的DGI模型，虽然和之前的无监督方法不一样，但是通过最大化输入图的的全局和局部之间的互信息来学习节点表示，需要学习整图的全局表示，代价过大。 动机： 如前文所说，很多情况下人工标记图数据代价过高或不可行，而现有的很多无监督方法过度强调图的同质性，存在很大局限。最近提出的基于互信息的DGI虽然没有这个问题，但是需要计算整图表示，代价过高。作者希望基于对比学习，提出一种更优秀的无监督图表示学习框架。 本文工作： 作者提出了一种通用的图对比学习框架，通过对输入图施加扰动得到不同的view，然后在两个view间进行node-node级对比。（这应该是最早提出这种对比框架的文章，开创性意义比较大。） 2. 方法 作者提出的GraphCL框架非常简单，如上图1所示，包含下列三个组件： 随机扰动： 对每个节点的L-hop子图进行随机扰动，生成两个不同的view。作者本文采用的扰动方式有两种：结构和属性。具体来说按照概率ppp随机丢掉子图中的边，对于节点属性采用dropout。 GNN编码器： 其功能为：学习每个节点uuu，通过扰动后得到的两个L-hop子图的表示 对比损失： 将不同view下同一个节点看做正例对，其余所有节点对看做负例对。对于每个节点uuu，定义如下对比损失： l(u)=l1,2(u)+l2,1(u)l(u)=l_{1,2}(u)+l_{2,1}(u) l(u)=l1,2​(u)+l2,1​(u) 其中li,j(u)l_{i,j}(u)li,j​(u)定义为： li,j(u)=−log⁡exp⁡(s(hu,i,hu,j)/τ)∑v∈B1[v≠u]exp⁡(s(hu,i,hv,i)/τ)+∑v∈Bexp⁡(s(hu,i,hv,j)/τ)l_{i, j}(u)=-\\log \\frac{\\exp \\left(\\mathrm{s}\\left(h_{u, i}, h_{u, j}\\right) / \\tau\\right)}{\\sum_{v \\in \\mathcal{B}} \\mathbb{1}_{[v \\neq u]} \\exp \\left(\\mathrm{s}\\left(h_{u, i}, h_{v, i}\\right) / \\tau\\right)+\\sum_{v \\in \\mathcal{B}} \\exp \\left(\\mathrm{s}\\left(h_{u, i}, h_{v, j}\\right) / \\tau\\right)} li,j​(u)=−log∑v∈B​1[v​=u]​exp(s(hu,i​,hv,i​)/τ)+∑v∈B​exp(s(hu,i​,hv,j​)/τ)exp(s(hu,i​,hu,j​)/τ)​ 其中s(hu,i,hu,j)=hu,i⊤hu,j/∥hu,i∥∥hu,j∥\\mathrm{s}\\left(h_{u, i}, h_{u, j}\\right)=h_{u, i}^{\\top} h_{u, j} /\\left\\|h_{u, i}\\right\\|\\left\\|h_{u, j}\\right\\|s(hu,i​,hu,j​)=hu,i⊤​hu,j​/∥hu,i​∥∥hu,j​∥表示余弦相似度。上述公式分子表示正例对节点间相似度，分母左边表示同视角不同节点组成的负例对（即视角内，inter-view），分母右边表示不同视角不同节点组成的负例对（即视角间，intra-view）。 下面介绍下，每一轮采样1个minibatch节点B\\mathcal BB训练GraphCL的具体步骤： 对于每个节点uuu，用(Xu,Au)(X_u,A_u)(Xu​,Au​)表示该节点的L-hop子图； 按照前文中方法，施加两个随机扰动t1t_1t1​和t2t_2t2​： (X~u,1,A~u,1)∼t1(Xu,Au)\\left(\\widetilde{X}_{u, 1}, \\widetilde{A}_{u, 1}\\right) \\sim t_{1}\\left(X_{u}, A_{u}\\right)(Xu,1​,Au,1​)∼t1​(Xu​,Au​) (X~u,2,A~u,2)∼t2(Xu,Au)\\left(\\widetilde{X}_{u, 2}, \\widetilde{A}_{u, 2}\\right) \\sim t_{2}\\left(X_{u}, A_{u}\\right)(Xu,2​,Au,2​)∼t2​(Xu​,Au​) 使用图编码器，分别计算两个视角下的节点嵌入： hu,1=f(X~u,1,A~u,1)h_{u, 1}=f\\left(\\widetilde{X}_{u, 1}, \\widetilde{A}_{u, 1}\\right)hu,1​=f(Xu,1​,Au,1​) hu,2=f(X~u,2,A~u,2)h_{u, 2}=f\\left(\\widetilde{X}_{u, 2}, \\widetilde{A}_{u, 2}\\right)hu,2​=f(Xu,2​,Au,2​) 利用前文定义的损失函数，更新模型参数： L=1∣B∣∑u∈Bl(u)\\mathcal{L}=\\frac{1}{|\\mathcal{B}|} \\sum_{u \\in \\mathcal{B}} l(u) L=∣B∣1​u∈B∑​l(u) 3. 实验 3.1 实验设置 所有实验中，GraphCL图编码器采用的都是GraphSAGE中的更新规则： hu(l)←(W(l−1))⊤⋅MEAN({hu(l−1)}∪{hv(l−1),∀v∈N(u)})(5)h_{u}^{(l)} \\leftarrow\\left(W^{(l-1)}\\right)^{\\top} \\cdot M E A N\\left(\\left\\{h_{u}^{(l-1)}\\right\\} \\cup\\left\\{h_{v}^{(l-1)}, \\forall v \\in \\mathcal{N}(u)\\right\\}\\right)\\tag 5 hu(l)​←(W(l−1))⊤⋅MEAN({hu(l−1)​}∪{hv(l−1)​,∀v∈N(u)})(5) 所有GNN聚合操作采用的都是： H(l)=A^H(l−1)W(l−1)(6)H^{(l)}=\\hat{A} H^{(l-1)} W^{(l-1)}\\tag 6 H(l)=A^H(l−1)W(l−1)(6) Transductive Learning 对于Citeseer和pumed数据集，采用公式6定义的单层GNN。 对于Cora数据集，采用双层GNN作为编码器： f(X,A)=A^σ(A^XW(0))W(1)f(X, A)=\\hat{A} \\sigma\\left(\\hat{A} X W^{(0)}\\right) W^{(1)} f(X,A)=A^σ(A^XW(0))W(1) Inductive Learning 所有数据集上都适用三层mean-polling编码器： H(1)=σ(A^XW1(0)+XW2(0))H(2)=σ(A^H(1)W1(1)+H(1)W2(1))f(X,A)=A^H(2)W1(2)+H(2)W2(2)\\begin{array}{c} H^{(1)}=\\sigma\\left(\\hat{A} X W_{1}^{(0)}+X W_{2}^{(0)}\\right) \\\\ H^{(2)}=\\sigma\\left(\\hat{A} H^{(1)} W_{1}^{(1)}+H^{(1)} W_{2}^{(1)}\\right) \\\\ f(X, A)=\\hat{A} H^{(2)} W_{1}^{(2)}+H^{(2)} W_{2}^{(2)} \\end{array} H(1)=σ(A^XW1(0)​+XW2(0)​)H(2)=σ(A^H(1)W1(1)​+H(1)W2(1)​)f(X,A)=A^H(2)W1(2)​+H(2)W2(2)​​ 3.2 实验结果","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Contrastive Self-supervised Learning for Graph Classification","slug":"3 论文笔记/图学习/对比学习/9.Contrastive Self-supervised Learning for Graph Classification","date":"2021-09-28T12:49:00.000Z","updated":"2021-09-28T12:52:27.870Z","comments":true,"path":"b6326d38d625/","link":"","permalink":"http://rookieyin.github.io/b6326d38d625/","excerpt":"https://www.aaai.org/AAAI21Papers/AAAI-7017.ZengJ.pdf Contrastive Self-supervised Learning for Graph Classification ，2021，AAAI 总结：这是一篇关于图分类的图对比学习方法。作者在论文中提出了两种框架：CSSL-Pretrain和CSSL-Reg，同时涵盖了图对比学习中两种常见的模式（预训练/无监督或监督）。作者的方法很常规，和现有的一些GCL方法相比创新性并不强，只是直接将CV中对比学习框架搬到图分类任务中。另外，作者的实验结果挺好的。","text":"https://www.aaai.org/AAAI21Papers/AAAI-7017.ZengJ.pdf Contrastive Self-supervised Learning for Graph Classification ，2021，AAAI 总结：这是一篇关于图分类的图对比学习方法。作者在论文中提出了两种框架：CSSL-Pretrain和CSSL-Reg，同时涵盖了图对比学习中两种常见的模式（预训练/无监督或监督）。作者的方法很常规，和现有的一些GCL方法相比创新性并不强，只是直接将CV中对比学习框架搬到图分类任务中。另外，作者的实验结果挺好的。 1. 简介 1.1 摘要 Graph classification is a widely studied problem and has broad applications. In many real-world problems, the number of labeled graphs available for training classification models is limited, which renders these models prone to overfitting. To address this problem, we propose two approaches based on contrastive self-supervised learning (CSSL) to alleviate overfitting. In the first approach, we use CSSL to pretrain graph encoders on widely-available unlabeled graphs without relying on human-provided labels, then finetune the pre-trained encoders on labeled graphs. In the second approach, we develop a regularizer based on CSSL, and solve the supervised classification task and the unsupervised CSSL task simultaneously. To perform CSSL on graphs, given a collection of original graphs, we perform data augmentation to create augmented graphs out of the original graphs. An augmented graph is created by consecutively applying a sequence of graph alteration operations. A contrastive loss is defined to learn graph encoders by judging whether two augmented graphs are from the same original graph. Experiments on various graph classification datasets demonstrate the effectiveness of our proposed methods. 图分类是一个被广泛研究的问题，可以用于各种应用场景。在许多实际问题中，用于训练模型的有标签图的数量有限，导致模型过拟合。为了解决这个问题，作者基于对比自监督学习（CSSL）提出了两种方法来避免过拟合。在第一种方法中，我们使用CSSL在很容易获取的无标签图数据集上对图编码器进行预训练，然后在有标签数据集上对模型进行微调。在第二种方法中，我们基于CSSL设计了一个正则器，可以同时解决有监督和无监督分类任务。为了实现图上的CSSL，给定原始图集合，我们基于原始图进行数据增强来创建增强图。增强图是通过连续应用一系列图修改操作得到的。之后通过判断两个增强图是否来自同一个原始图来定义一个对比损失，以此学习图编码器。在各种图分类数据集上的大量实验证明了我们提出的方法的有效性。 1.2 本文工作 背景： 图分类问题十分重要，有广泛的应用场景。但是经常存有标签图数据过少 的情况，这导致有监督图分类模型会出现过你和问题。 动机： 作者希望基于CSSL，即对比自监督学习，来解决少标签数据下出现的过拟合问题。 本文工作： 作者基于CSSL提出了两种解决方案：CSSL-Pretrain和CSSL-Reg。前者是一种无监督预训练方法，在无监督场景下对GNNs进行预训练，然后在有标签（少量）数据集中微调。后者是一种基于CSSL的正则化方法，通过把对比损失和分类损失放到一起进行联合优化，以降低图编码器在小样本训练数据上存在的过拟合风险。 2. 方法 2.1 图对比 这部分主要介绍作者是如何在图上应用对比学习方法的。对比学习里面主要就两个研究点：一是如何生成用于对比的graph views？二是如何对比，即如何定义对比损失？下面介绍下在作者的方法中这两点都是如何实现的。 2.1.1 图增强 所谓“图增强”，其实说成“图扰动”更合适。顾名思义，就是给输入图添加一些扰动、噪声之类的，生成一张新的图。常见的扰动方法有增删边和节点、mask节点属性、graph diffusion、子图采样等等。 本文作者采用以下4中增强策略： Edge deletion： 随机选取一些边删掉 Node deletion： 随机选取一些节点删掉 Edge addition： 随机选取两个节点，如果两个节点之间不存在边相连，但是两者存在一条路径，则在两者之间添加一条边。 Node addition： 随机选取一个strongly-connected子图SSS，删除SSS中的所有边，然后添加一个节点nnn，将nnn和子图中所有节点相连。如下图1所示，节点1/3/4是输入图的一个子图，把三个节点之间所有边删除，添加一个节点5，和这三个节点相连。 所有增强方式执行示例如下图1所示： 定义好了增强策略，作者的图增强步骤具体如下： 随机选取一种策略o1(⋅)o_1(·)o1​(⋅)用于输入图GGG，得到G1=o1(G)G_1=o_1(G)G1​=o1​(G)； 再随机选取一种策略o2(⋅)o_2(·)o2​(⋅)用于图G1G_1G1​，得到G2=o2(G1)G_2=o_2(G_1)G2​=o2​(G1​)； 重复上述步骤，直到部署达到最大值。 2.1.2 对比损失 通过增强得到输入图的图个视角后，下一步要做的就是制定对比策略，定义对比损失。 和其他对比学习方法一样，作者将从同一个原始图增强得到的两个新图视为正样本对，反之都为负样本对。我们要做的就是训练一个图编码器，让正样本对之间的距离更短，让负样本对之间的距离更长。 具体来说，作者设计的图编码器包含两个模块：一个图嵌入模块f(⋅)f(·)f(⋅)，提取输入图x\\mathbf xx的潜在表示h=f(x)\\mathbf h=f(\\mathbf x)h=f(x)；另一个是MLP g(⋅)g(·)g(⋅)，生成用于预测的潜在表示z=g(h)\\mathbf z=g(\\mathbf h)z=g(h)。对于锚点xi\\mathbf x_ixi​，给定正样本xj\\mathbf x_jxj​和负样本集合xk\\mathbf x_kxk​，和其他对比学习方法一样，对比损失定义为： −log⁡exp⁡(sim⁡(zi,zj)/τ)exp⁡(sim⁡(zi,zj)/τ)+∑kexp⁡(sim⁡(zi,zk)/τ)-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(\\mathbf{z}_{i}, \\mathbf{z}_{j}\\right) / \\tau\\right)}{\\exp \\left(\\operatorname{sim}\\left(\\mathbf{z}_{i}, \\mathbf{z}_{j}\\right) / \\tau\\right)+\\sum_{k} \\exp \\left(\\operatorname{sim}\\left(\\mathbf{z}_{i}, \\mathbf{z}_{k}\\right) / \\tau\\right)} −logexp(sim(zi​,zj​)/τ)+∑k​exp(sim(zi​,zk​)/τ)exp(sim(zi​,zj​)/τ)​ 这里作者为了加速训练，使用了何凯明19年自监督学习方法MOCO中的策略： 关于MOCO方法，可参考https://zhuanlan.zhihu.com/p/102573476部分内容 设置一个样本队列，队列中包含的时最近一个batch的数据。对比的时候，锚点称之为q，从队列中拿的数据称为k。注意q和k所示用的编码器通常参数是不一样的，下面定义了CV里面常用的三种训练方式： 第一种端到端的方式，两个编码器分别执行梯度下降，代价太大，训练太慢了。第三种MoCo左边q对应的编码器执行普通的梯度下降，右边k对应的编码器采用动量更新方式优化参数。动量更新规则为： θk←mθk+(1−m)θq\\theta_{k} \\leftarrow m \\theta_{k}+(1-m) \\theta_{q} θk​←mθk​+(1−m)θq​ 2.2 CSSL-Pretrain 如上图4所示，这种方法就是首先利用前文提到的CSSL方法在无标签数据集上训练一个图编码器，然后把这个图编码器用于有标签数据集进行微调。需要注意的是，微调时网络的分类头要重新训练。 2.3 CSSL-Reg 这种方法类似半监督学习，将对比损失和分类损失合并到一起进行联合优化： L(c)(D,L;W(e),W(c))+λL(p)(D,W(e),W(p))\\mathcal{L}^{(c)}\\left(D, L ; \\mathbf{W}^{(e)}, \\mathbf{W}^{(c)}\\right)+\\lambda \\mathcal{L}^{(p)}\\left(D, \\mathbf{W}^{(e)}, \\mathbf{W}^{(p)}\\right) L(c)(D,L;W(e),W(c))+λL(p)(D,W(e),W(p)) 其中DDD表示用于训练的图，LLL表示这些图的标签，L(c)\\mathcal L^{(c)}L(c)表示分类损失，L(p)\\mathcal L^{(p)}L(p)表示对比损失。 3. 实验 其中CSSL-Freeze表示直接将预训练的GNN用于有标签数据集，不进行微调。 “A1”表示随机执行1中增强策略，“A3”表示连续随机执行三种增强策略，“Specific”表示只使用目标数据集中的图定义对比损失，“all“表示使用所有5个数据集中的图定义对比损失。 上图展示了CSSL-Reg中不同λ\\lambdaλ值对应的模型性能。可以看到刚开始随着λ\\lambdaλ增大，模型性能有所提升，因为对比损失可以防止模型过拟合。但是λ\\lambdaλ过大反而会影响模型性能。 另外，足总和研究了不同类型增强策略对模型性能的影响，结果如上表4所示。可以看到，随机选取增强策略性能最好。因为随机使用增强策略，可以让模型更难以判别两个增强图是否来自同一个原始图。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"预训练","slug":"预训练","permalink":"http://rookieyin.github.io/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/"}]},{"title":"Motif-Driven Contrastive Learning of Graph Representations","slug":"3 论文笔记/图学习/对比学习/8.Motif-Driven Contrastive Learning of Graph Representations","date":"2021-09-28T02:34:48.000Z","updated":"2021-09-28T02:41:10.508Z","comments":true,"path":"7981ac0a697d/","link":"","permalink":"http://rookieyin.github.io/7981ac0a697d/","excerpt":"https://ojs.aaai.org/index.php/AAAI/article/view/17986/17791 https://arxiv.org/pdf/2012.12533 Motif-Driven Contrastive Learning of Graph Representations，2021，AAAI-21 Student Papers and Demonstrations 总结：文章动机挺好的，希望通过motif来采样语义信息更丰富的子图来执行GCL，用于GNN的预训练。而且本文实验做的很丰富，实验结果看起来也挺好的。不过，文章写得有点乱（好像是本科生写的），看起来有点费劲，个人感觉有些地方描述的不太准确，而且有点冗余。对于这篇文章有两点思考：1. 作者这种motif学习方式可不可行？有没有道理？而且作者用的数据集是分子数据集，在其他类型数据集中，这种方法可不可行？2. 个人感觉利用子图进行对比学习是一个挺好的方向，有没有其他和motif类似的子图生成方法？","text":"https://ojs.aaai.org/index.php/AAAI/article/view/17986/17791 https://arxiv.org/pdf/2012.12533 Motif-Driven Contrastive Learning of Graph Representations，2021，AAAI-21 Student Papers and Demonstrations 总结：文章动机挺好的，希望通过motif来采样语义信息更丰富的子图来执行GCL，用于GNN的预训练。而且本文实验做的很丰富，实验结果看起来也挺好的。不过，文章写得有点乱（好像是本科生写的），看起来有点费劲，个人感觉有些地方描述的不太准确，而且有点冗余。对于这篇文章有两点思考：1. 作者这种motif学习方式可不可行？有没有道理？而且作者用的数据集是分子数据集，在其他类型数据集中，这种方法可不可行？2. 个人感觉利用子图进行对比学习是一个挺好的方向，有没有其他和motif类似的子图生成方法？ 1. 简介 1.1 摘要 Pre-training Graph Neural Networks (GNN) via self-supervised contrastive learning has recently drawn lots of attention. However, most existing works focus on node-level contrastive learning, which cannot capture global graph structure. The key challenge to conducting subgraph-level contrastive learning is to sample informative subgraphs that are semantically meaningful. To solve it, we propose to learn graph motifs, which are frequently-occurring subgraph patterns (e.g. functional groups of molecules), for better subgraph sampling. Our framework MotIf-driven Contrastive leaRning Of Graph representations (MICRO-Graph) can: 1) use GNNs to extract motifs from large graph datasets; 2) leverage learned motifs to sample informative subgraphs for contrastive learning of GNN. We formulate motif learning as a differentiable clustering problem, and adopt EM-clustering to group similar and significant subgraphs into several motifs. Guided by these learned motifs, a sampler is trained to generate more informative subgraphs, and these subgraphs are used to train GNNs through graph-to-subgraph contrastive learning. By pretraining on the ogbg-molhiv dataset with MICRO-Graph, the pre-trained GNN achieves 2.04% ROC-AUC average performance enhancement on various downstream benchmark datasets, which is significantly higher than other state-of-the-art self-supervised learning baselines. 最近通过自监督对比学习的预训练GNN得到了很多关注。但是，现有的工作大多关注于node-level对比学习，无法捕捉全局图结构。对于subgraph-level对比学习，其关键是如何采样具有语义信息的子图。为了解决这个问题，我们提出通过学习graph motif来实现更好的子图采样。我们提出的框架MICRO-Graph可以：（1）利用GNNs从大型图数据集中提取motifs；（2）利用学习到的motifs采样蕴含丰富信息的子图用于GNN的对比学习。具体来说，我们将motif学习看做一个可微聚类问题，并利用EM-clustering将相似的、有意义的子图划分成不同的motif。在这些学习到的motifs的指导下，训练一个sampler用于生成蕴含信息更丰富的子图，然后讲这些生成的子图用于GNN的对比学习中。通过ogbg-molhiv数据集预训练模型后，得到的GNN在其他各种标准数据集中的性能得到了平均2.04%的提升。 1.2 本文工作 背景： 最近GNNs在图表示学习领域展现了其强大的能力，为了进一步提高GNNs在没有数据标签情况下的能力，人们提出了很多采用自监督方式预训练GNNs的方法。预训练好的GNNs只需经过少量微调步骤就能用于相同领域下的其他数据集中，并取得很好的表现。 动机： 现有的GCL方法大多都是进行node-level对比，不利于捕捉全局图信息，因此subgraph-level对比是一种比较好的选择，但是如何采样informative子图是一个很大的挑战。作者受motif相关研究的启发，希望利用motif来更好地采样子图用于GNN的对比学习。 本文工作： 作者提出了一种subgraph-level图对比学习方法MICRO-Graph。首先通过motif learning从大型数据集中提取motifs，然后利用这些学习到的motifs指导子图生成，再将这些子图用于GNN对比学习，达到对GNN进行预训练的目的。在ogbg-molhiv数据集上，利用MICRO-Graph框架对GNN进行预训练后，pre-trained GNN在各种标准数据集上的性能得到了很大提升。 2. 方法 目标： 以自监督方式（无需标签）预训练一个GNN编码器ENCθ(⋅)\\mathbf{\\text{ENC}}_\\theta(·)ENCθ​(⋅)，只需要少量有标签数据进行微调，即可泛化到同领域新数据集上。 作者提出的对比模型是subgraph-level的，因此最关键的问题就是如何生成用于对比的子图。为了解决这个问题，作者的大概思路如下：作者将motif learning问题看做一个可微EM聚类问题，然后用学习到的motifs来指导子图采样。MICRO-Graph框架如下图所示： 其大致执行步骤如下： 首先将一个batch的graph传入模型，通过GNN编码器ENCθ(⋅)\\mathbf{\\text{ENC}}_\\theta(·)ENCθ​(⋅)计算节点嵌入； 然后利用EM算法将节点聚类成motif-like子图，再利用池化函数得到子图嵌入； 然后再将得到的子图嵌入分别传入两个模块： Motif-Learner：利用子图嵌入更新motif嵌入 Contrastive Learning：施行GNN的对比学习 整个框架最复杂的就是中间那块motif-learner相关部分，下面作一个详细介绍。 2.1 motif-learner 这一部分其实包含两个小环节： 给定motif嵌入M\\mathbf MM，如何将所有节点划分成若干个motif-like子图集合； 得到子图集合后，如何反过来更新M\\mathbf MM，得到更好的motif原型。 给定有NNN个节点的图G\\mathcal GG，我们用{h1,...,hN}\\mathbf{\\{h_1,...,h_N\\}}{h1​,...,hN​}表示节点嵌入，Par\\mathbf ParPar表示对所有节点的某种划分方式，{s1,...,sJ}=G[Par]\\mathbf{\\{s_1,...,s_J\\}}=\\mathbf{\\mathcal G[Par]}{s1​,...,sJ​}=G[Par]表示该划分方式下得到的所有子图的嵌入。 为了对问题进行建模，我们为每个子图定义一个K-way类别随机变量zj∈{1,⋯ ,K}z_{j} \\in\\{1, \\cdots, K\\}zj​∈{1,⋯,K}，P(sj∣zj=k)P\\left(s_{j} \\mid z_{j}=k\\right)P(sj​∣zj​=k)表示sjs_jsj​是在k-th motif指导下生成的概率。这样关于单个子图的似然函数可以定义成： P(sj∣M,θ)=∑k=1KP(sj∣zj=k,M,θ)P(zj=k)(1)P\\left(s_{j} \\mid M, \\theta\\right)=\\sum_{k=1}^{K} P\\left(s_{j} \\mid z_{j}=k, M, \\theta\\right) P\\left(z_{j}=k\\right)\\tag 1 P(sj​∣M,θ)=k=1∑K​P(sj​∣zj​=k,M,θ)P(zj​=k)(1) 这里对”似然函数“相关概念做一个补充说明：p(x∣θ)p(x|\\theta)p(x∣θ) 对于函数p(x∣θ)p(x|\\theta)p(x∣θ)，有两个输入：x表示一个具体的数据；θ\\thetaθ表示模型参数。 如果θ\\thetaθ确定，x是变量，那么这个函数称作概率函数。即在给定θ\\thetaθ条件下，变量x出现的概率。 如果x是确定的，θ\\thetaθ为变量，那么这个函数就叫做似然函数。即在不同模型参数下，x出现的概率是多少。 对于建模问题，我们通常都是有一组观测数据，需要估计模型的参数，也就是上述第二种情况。非常常用的一种参数估计办法就是极大似然估计，即将似然函数p(x∣θ)p(x|\\theta)p(x∣θ)取最大值时的θ\\thetaθ作为模型参数（其背后思想是：已经发生的就是最可能发生的）。 因为假设所有子图都是独立同分布的，整图G\\mathcal GG的条件似然就是： P(G∣ Par ,M,θ)=∏sj∈G[Par]∑k=1KP(sj∣zj=k,M,θ)P(zj=k)(2)\\begin{array}{l} P(\\mathcal{G} \\mid \\text { Par }, M, \\theta) \\\\ =\\prod_{s_{j} \\in \\mathcal{G}[P a r]} \\sum_{k=1}^{K} P\\left(s_{j} \\mid z_{j}=k, M, \\theta\\right) P\\left(z_{j}=k\\right) \\end{array}\\tag 2 P(G∣ Par ,M,θ)=∏sj​∈G[Par]​∑k=1K​P(sj​∣zj​=k,M,θ)P(zj​=k)​(2) 此时，前文提到的两个问题都可以通过最大化该似然函数来解决： 给定M的情况下，利用EM最大化公式2，得到最优划分方式Par∗Par^*Par∗。 给定划分方式ParParPar情况下，同样利用EM最大化公式2，更新motif table M\\mathbf MM。 但是对于第1个问题的解决方式：“给定M，最大化上述似然函数来找到最优节点划分方式Par∗\\mathbf {Par^*}Par∗”难以实现。因为Par\\mathbf{Par}Par的搜索空间巨大，且随节点数量增加而指数增大，计算量太大。为了解决这一问题，作者将P(sj∣zj=k)P\\left(s_{j} \\mid z_{j}=k\\right)P(sj​∣zj​=k)进一步拆分到节点级。 具体来说，为每个节点定义一个K-way类型变量P(hl∣cl=k)P\\left(\\boldsymbol{h}_{l} \\mid c_{l}=k\\right)P(hl​∣cl​=k)，这样公式2可以转化成： P^(G∣Par,M,θ)=∏sj∈G[Par]∑k=1K∏l=1hl∈sjNP(hl∣cl=k,M,θ)P(zj=k)(3)\\begin{array}{l} \\hat{P}(\\mathcal{G} \\mid P a r, M, \\theta)= \\\\ \\prod_{s_{j} \\in G[P a r]} \\sum_{k=1}^{K} \\prod_{l=1 \\atop h_{l} \\in s_{j}}^{N} P\\left(h_{l} \\mid c_{l}=k, M, \\theta\\right) P\\left(z_{j}=k\\right) \\end{array}\\tag 3 P^(G∣Par,M,θ)=∏sj​∈G[Par]​∑k=1K​∏hl​∈sj​l=1​N​P(hl​∣cl​=k,M,θ)P(zj​=k)​(3) 总结一下就是上述两个优化问题可以分别分别定义成： Par∗,θ∗=arg⁡max⁡Par,θP^(G∣Par,M,θ)(4)\\begin{aligned} P a r^{*}, \\theta^{*} &amp;=\\arg \\max _{P a r, \\theta} \\hat{P}(\\mathcal{G} \\mid P a r, M, \\theta) \\end{aligned}\\tag 4 Par∗,θ∗​=argPar,θmax​P^(G∣Par,M,θ)​(4) M∗=arg⁡max⁡MP(G∣Par∗,M,θ∗)(5)\\begin{aligned} M^{*} &amp;=\\arg \\max _{\\boldsymbol{M}} P\\left(\\mathcal{G} \\mid P a r^{*}, M, \\theta^{*}\\right) \\end{aligned}\\tag 5 M∗​=argMmax​P(G∣Par∗,M,θ∗)​(5) 到这里就建模完毕，下面对这两个优化问题的具体解决方案进行详细介绍。 2.1.1 Modeling and Learning for The Graph Partition 注：这里作者说的所有EM相关算法，因为不存在什么联合分布、隐数据，其实就是极大似然法，和我们常用的softmax分类差不多。所谓E步就是求后验概率，M步就是根据后验概率计算似然损失，再利用损失函数进行梯度下降优化模型参数。 EM算法分为E和M两步，在E-step计算后验概率ql,k=P(cl=k∣hl)q_{l, k}=P\\left(c_{l}=k \\mid h_{l}\\right)ql,k​=P(cl​=k∣hl​)，在M-step对目标进行优化得到最优解。 这里作者首先将节点嵌入映射到motif嵌入空间，然后计算节点嵌入和motif嵌入之间的相似度作为后验概率ql,kq_{l,k}ql,k​： ql,k=exp⁡(ϕ(Whhl)Tϕ(mk)/τ)∑k′exp⁡(ϕ(Whhl)Tϕ(mk′)/τ)(6)q_{l, k}=\\frac{\\exp \\left(\\phi\\left(W_{h} \\boldsymbol{h}_{l}\\right)^{T} \\phi\\left(m_{k}\\right) / \\tau\\right)}{\\sum_{k^{\\prime}} \\exp \\left(\\phi\\left(W_{h} \\boldsymbol{h}_{l}\\right)^{T} \\phi\\left(m_{k^{\\prime}}\\right) / \\tau\\right)}\\tag 6 ql,k​=∑k′​exp(ϕ(Wh​hl​)Tϕ(mk′​)/τ)exp(ϕ(Wh​hl​)Tϕ(mk​)/τ)​(6) 其中ϕ(x)=x/∥x∥2\\phi(x)=x /\\|x\\|_{2}ϕ(x)=x/∥x∥2​为L−2L-2L−2范式，τ\\tauτ为温度参数。对于1个batch的图G={G1,⋯ ,GB}\\mathbb G=\\left\\{\\mathcal{G}_{1}, \\cdots, \\mathcal{G}_{B}\\right\\}G={G1​,⋯,GB​}，用Q=[q(1),⋯ ,q(B)]TQ=\\left[q^{(1)}, \\cdots, q^{(B)}\\right]^{T}Q=[q(1),⋯,q(B)]T表示所有node-to-motif概率。 在E-step，利用公式6可以计算后验概率P(cl=k∣hl)P\\left(c_{l}=k \\mid h_{l}\\right)P(cl​=k∣hl​)。这里和前人的研究类似，将该后验概率直接用于M-step存在问题，因为会出现坍塌解（即所有节点都分配给同一个motif）。 为了避免这个问题，作者采用了另一篇文章中的做法： max⁡Q^∈QTr⁡(Q^QT)+1λH(Q^), where Q={Q^∈R+NB,K∣Q^1K=1BNB,Q^T1NB=1KK}\\begin{array}{c} \\max _{\\hat{Q} \\in Q} \\operatorname{Tr}\\left(\\hat{Q} Q^{T}\\right)+\\frac{1}{\\lambda} H(\\hat{Q}), \\text { where } \\\\ Q=\\left\\{\\hat{Q} \\in \\mathbb{R}_{+}^{N_{B}, K} \\mid \\hat{Q} 1_{K}=\\frac{1_{B}}{N_{B}}, \\hat{Q}^{T} 1_{N_{B}}=\\frac{1_{K}}{K}\\right\\} \\end{array} maxQ^​∈Q​Tr(Q^​QT)+λ1​H(Q^​), where Q={Q^​∈R+NB​,K​∣Q^​1K​=NB​1B​​,Q^​T1NB​​=K1K​​}​ 这块没有细看，大概的原理是：通过某种正则化手段，强迫motif assignment平衡，防止所有节点坍塌到同一个motif，并且在将Q离散化。 然后这里和softmax多分类损失类似，定义node-mot损失函数如下： Lnode-mot =−∑l=1N∑k=1Kql,k∗log⁡ql,k(10)\\mathcal{L}_{\\text {node-mot }}=-\\sum_{l=1}^{N} \\sum_{k=1}^{K} q_{l, k}^{*} \\log q_{l, k}\\tag{10} Lnode-mot ​=−l=1∑N​k=1∑K​ql,k∗​logql,k​(10) 这里作者考虑到：使用这种子图采样方法忽略了图的结构信息，因为没有限制分到同一个子图中的节点之间存在边，因此得到的子图可能是稀疏的。 为了解决这个问题，作者参考前人研究，定义了一个spectral clustering-based正则化损失： Lreg=−Tr⁡(qTAq)Tr⁡(qTDq)+∥q~Tq~∥q~Tq~∥F−IJJ∥F(11)\\mathcal{L}_{r e g}=-\\frac{\\operatorname{Tr}\\left(q^{T} A q\\right)}{\\operatorname{Tr}\\left(q^{T} D q\\right)}+\\left\\|\\frac{\\tilde{q}^{T} \\tilde{q}}{\\left\\|\\tilde{q}^{T} \\tilde{q}\\right\\|_{F}}-\\frac{I_{J}}{\\sqrt{J}}\\right\\|_{F}\\tag{11} Lreg​=−Tr(qTDq)Tr(qTAq)​+∥∥∥∥∥​∥q~​Tq~​∥F​q~​Tq~​​−J​IJ​​∥∥∥∥∥​F​(11) 这个损失函数可以让我们得到的Q^\\hat QQ^​和spectral clustering结果更近一点。 2.1.2 Modeling and Learning for Motif Embeddings 和前面差不多，首先计算子图和motif之间的相似度，作为后验概率： pj,k=exp⁡(ϕ(Wssj)Tϕ(mk)/τ)∑j′exp⁡(ϕ(Wssj′)Tϕ(mk)/τ)(12)p_{j, k}=\\frac{\\exp \\left(\\phi\\left(W_{s} s_{j}\\right)^{T} \\phi\\left(m_{k}\\right) / \\tau\\right)}{\\sum_{j^{\\prime}} \\exp \\left(\\phi\\left(W_{s} s_{j^{\\prime}}\\right)^{T} \\phi\\left(m_{k}\\right) / \\tau\\right)}\\tag{12} pj,k​=∑j′​exp(ϕ(Ws​sj′​)Tϕ(mk​)/τ)exp(ϕ(Ws​sj​)Tϕ(mk​)/τ)​(12) 然后和上面一样，计算分类损失： Lmot-sub =−∑j=1J∑k=1Kπj,klog⁡pj,k(13)\\mathcal{L}_{\\text {mot-sub }}=-\\sum_{j=1}^{J} \\sum_{k=1}^{K} \\pi_{j, k} \\log p_{j, k}\\tag{13} Lmot-sub ​=−j=1∑J​k=1∑K​πj,k​logpj,k​(13) 这里公式格式和前面基本一样，只不过这里是利用损失函数进行梯度下降，更新MMM矩阵，而前面则利用公式10进行梯度下降，更新参数θ\\thetaθ，从而更好的对节点进行分组。 至此，我们就得到了所有motif学习相关的损失函数： Lmotif =λnLnode-mot +λsLmot-sub +λrLreg (14)\\mathcal{L}_{\\text {motif }}=\\lambda_{n} \\mathcal{L}_{\\text {node-mot }}+\\lambda_{s} \\mathcal{L}_{\\text {mot-sub }}+\\lambda_{r} \\mathcal{L}_{\\text {reg }}\\tag{14} Lmotif ​=λn​Lnode-mot ​+λs​Lmot-sub ​+λr​Lreg ​(14) 2.2 对比学习 如前文图2所示，这里将整图嵌入作为锚点，将从该锚点采样得到的子图作为正例，将从其他图采样得到的子图作为负例，对比损失如下： Lcontra =−1B∑i=1B∑sj∈Gilog⁡exp⁡(Yi,j/τ)∑j′exp⁡(Yi,j′/τ)(15)\\mathcal{L}_{\\text {contra }}=-\\frac{1}{B} \\sum_{i=1}^{B} \\sum_{s_{j} \\in G_{i}} \\log \\frac{\\exp \\left(Y_{i, j} / \\tau\\right)}{\\sum_{j^{\\prime}} \\exp \\left(Y_{i, j^{\\prime}} / \\tau\\right)}\\tag {15} Lcontra ​=−B1​i=1∑B​sj​∈Gi​∑​log∑j′​exp(Yi,j′​/τ)exp(Yi,j​/τ)​(15) 这样整个框架的损失定义为： L=αLmotif +(1−α)Lcontra (16)\\mathcal{L}=\\alpha \\mathcal{L}_{\\text {motif }}+(1-\\alpha) \\mathcal{L}_{\\text {contra }}\\tag{16} L=αLmotif ​+(1−α)Lcontra ​(16) 框架代码大致如下： 在初始状态下motif embedding和motif-like子图都是随机的。 3. 实验 3.1 基础实验 作者进行了下列两种实验： Transfer Fine-tune Setting： 在只有少量有标签数据的下游任务中对预训练好的GNN模型进行微调。 Feature Extraction Setting： 和前一种设置差不多，只不过将GNN看做特征提取器，在其基础上重新训练一个线性分类器。 实验结果如下表1和表2所示： 3.2 消融实验 主要针对：子图采样方法、对比视角、子图编码、motif数量、GNN原型5个方面进行消融实验，结果如下表3和图3所示： 作者对其中一些结果做了分析和假设，感兴趣的可以看原文。 3.3 可视化实验 作者通过closest subgraphs展示了模型学习到的子图： 其中包含生物化学分子里面常见的苯环、 醋酸酯 等。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"预训练","slug":"预训练","permalink":"http://rookieyin.github.io/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/"},{"name":"子图学习","slug":"子图学习","permalink":"http://rookieyin.github.io/tags/%E5%AD%90%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}]},{"title":"Deep Graph Contrastive Representation Learning","slug":"3 论文笔记/图学习/对比学习/7.Deep Graph Contrastive Representation Learning","date":"2021-09-25T09:39:01.000Z","updated":"2021-09-28T02:36:39.433Z","comments":true,"path":"02bcad3b2d8c/","link":"","permalink":"http://rookieyin.github.io/02bcad3b2d8c/","excerpt":"https://arxiv.org/pdf/2006.04131 https://github.com/CRIPAC-DIG/GRACE Deep Graph Contrastive Representation Learning，2020，arxiv preprint 总结：20年的一篇早期图对比学习的文章，作者主要针对19年发表的DGI模型的两个弊端进行改进，提出了一种比较简单的GCL框架GRACE（现在大部分GCL方法都沿用了这一种框架）。由于现在大部分GCL方法都是采用这种node-level对比框架，数据增强策略也更丰富，因此这篇文章和现有其他GCL方法相比并没有什么亮眼的创新之处。","text":"https://arxiv.org/pdf/2006.04131 https://github.com/CRIPAC-DIG/GRACE Deep Graph Contrastive Representation Learning，2020，arxiv preprint 总结：20年的一篇早期图对比学习的文章，作者主要针对19年发表的DGI模型的两个弊端进行改进，提出了一种比较简单的GCL框架GRACE（现在大部分GCL方法都沿用了这一种框架）。由于现在大部分GCL方法都是采用这种node-level对比框架，数据增强策略也更丰富，因此这篇文章和现有其他GCL方法相比并没有什么亮眼的创新之处。 1. 简介 1.1 摘要 Graph representation learning nowadays becomes fundamental in analyzing graph-structured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications. 现如今图表示学习对于分析图结构数据越来越重要。受进来对比方法的成功应用，本文作者通过利用节点级别的对比目标，提出了一种新的框架用于无监督图表示学习。具体来说，作者通过干扰生成两个图视角，然后最大化同一节点在不同视角下节点表示的一致性。为了给对比目标提供不同类型节点上下文信息，作者提出了一种在结构和属性层级生成图视图的混合方案。另外，作者提供了互信息和三元损失两个方面理论上的证明。作者同时在转导和非转导两种设定下，利用真实数据集进行了大量实验。实验结果表明，虽然作者的模型比较简单，但是和其他SOTA方法相比，性能得到了大幅度替身。在transductive任务中，作者的方法甚至不输于同类有监督方法，更证明了其在实际应用中的潜能。 1.2 本文工作 背景： （1）传统的无监督图表示学习方法，比如DeepWalk、node2vec等，它们都是对NLP中skip-gram模型的延伸。这些基于游走的方法过度依赖于网络结构中的邻近信息，通过对比迫使同一条游走路径中的节点具有相似的节点嵌入。（2）对于近年来得到广泛关注的GNNs，虽然在图学习邻域取得了很大的成功，但是大部分GNNs都是有监督的，依赖于大量有标签数据，这在实际应用中有时是不可行的。一些无监督GNNs，比如GraphSAGE，也和DeepWalk等类似，通过矩阵重构来学习节点嵌入，依然过度依赖于图邻接矩阵。（3）对于图对比学习，受CV中基于InfoMax方法的成功，DGI模型将CV中DIM模型延伸到图表示学习中，通过最大化节点间互信息，来学习节点嵌入。 动机： 作者认为DGI模型中的local-global MI maximization框架存在弊端： 虽然已经证明了在一定条件下其目标函数等价于最大化输入节点特征和高层级节点嵌入之间的互信息。但是DGI中是把节点和全局图进行对比，为了实现InfoMax目标，需要一个单射函数生成全局图嵌入，而单射属性非常受限，无法实现。在DGI中使用mean-pooling作为readout函数，不能保证图嵌入能从节点中提取有用信息。 DGI中使用feature shuffling生成新的图视图，在特征矩阵稀疏的时候，不能保证为节点生成不同的上下文信息，导致难以学习对比目标。 作者希望提出一种新的图对比学习框架，解决DGI模型中存在的这些弊端。 本文工作： 作者提出了一种新的图对比学习框架GRACE，解决了DGI模型中存在的两个弊端。 2. 方法 2.1 对比框架 这篇论文属于早期图对比学习研究，和目前各种GCL方法相比，框架没有什么亮眼之处，属于最通用、最基础的GCL框架。文章主要对DGI模型进行改进，后续很多方法都是基于这种框架改进得到。 如上图1所示，GRACE执行步骤大致如下： 生成两个图视角，用G~1\\widetilde G_1G1​，G~2\\widetilde G_2G2​表示。 利用GNNs，分别计算两个视角下的图嵌入U=f(X~1,A~1)U=f\\left(\\tilde{\\boldsymbol{X}}_{1}, \\widetilde{A}_{1}\\right)U=f(X~1​,A1​)，V=f(X~2,A~2)V=f\\left(\\tilde{\\boldsymbol{X}}_{2}, \\widetilde{A}_{2}\\right)V=f(X~2​,A2​)。 计算对比目标。具体来说，以G~1\\widetilde G_1G1​作为锚点，每个正样本对(ui,vi)(u_i,v_i)(ui​,vi​)的目标定义为： ℓ(ui,vi)=log⁡eθ(ui,vi)/τeθ(ui,vi)/τ⏟the positive pair +∑k=1N1[k≠i]eθ(ui,vk)/τ⏟inter-view negative pairs +∑k=1N1[k≠i]eθ(ui,uk)/τ⏟intra-view negative pairs \\ell\\left(\\boldsymbol{u}_{i}, \\boldsymbol{v}_{i}\\right)=\\log \\frac{e^{\\theta\\left(\\boldsymbol{u}_{i}, \\boldsymbol{v}_{i}\\right) / \\tau}}{\\underbrace{e^{\\theta\\left(\\boldsymbol{u}_{i}, \\boldsymbol{v}_{i}\\right) / \\tau}}_{\\text {the positive pair }}+\\underbrace{\\sum_{k=1}^{N} \\mathbb{1}_{[k \\neq i]} e^{\\theta\\left(\\boldsymbol{u}_{i}, \\boldsymbol{v}_{k}\\right) / \\tau}}_{\\text {inter-view negative pairs }}+\\underbrace{\\sum_{k=1}^{N} \\mathbb{1}_{[k \\neq i]} e^{\\theta\\left(\\boldsymbol{u}_{i}, \\boldsymbol{u}_{k}\\right) / \\tau}}_{\\text {intra-view negative pairs }}} ℓ(ui​,vi​)=logthe positive pair eθ(ui​,vi​)/τ​​+inter-view negative pairs k=1∑N​1[k​=i]​eθ(ui​,vk​)/τ​​+intra-view negative pairs k=1∑N​1[k​=i]​eθ(ui​,uk​)/τ​​eθ(ui​,vi​)/τ​ 其中θ(u,v)=s(g(u),g(v))\\theta(\\boldsymbol{u}, \\boldsymbol{v})=s(g(\\boldsymbol{u}), g(\\boldsymbol{v}))θ(u,v)=s(g(u),g(v))为判别器，sss为余弦相似度，ggg为非线性映射器（2层MLP）。同理，可以计算以G~2\\widetilde G_2G2​为锚点时的对比损失。这样整个模型的目标定义为： J=12N∑i=1N[ℓ(ui,vi)+ℓ(vi,ui)]\\mathcal{J}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left[\\ell\\left(u_{i}, v_{i}\\right)+\\ell\\left(v_{i}, u_{i}\\right)\\right] J=2N1​i=1∑N​[ℓ(ui​,vi​)+ℓ(vi​,ui​)] GRACE伪代码如下图所示： 2.2 视角生成 在对比学习中，数据增强策略是非常重要的一个组件，不同的增强策略会为节点提供不同的上下文信息。本文作者主要使用 Removing edges (RE) 和 Masking node features (MF) 两种增强策略。 RE 即随机去掉原始图的部分边。具体来说，首先随机采样一个mask矩阵R~∈{0,1}N×N\\widetilde{R} \\in\\{0,1\\}^{N \\times N}R∈{0,1}N×N，服从伯努利分布，即如果Aij=1A_{ij}=1Aij​=1，R~ij∼B(1−pr)\\widetilde{\\boldsymbol{R}}_{i j} \\sim \\mathcal{B}\\left(1-p_{r}\\right)Rij​∼B(1−pr​)，否则R~ij=0\\widetilde R_{ij}=0Rij​=0。其中prp_rpr​表示删除该边的概率。这样干扰后的邻接矩阵可以表示为： A~=A∘R~\\widetilde{\\boldsymbol{A}}=\\boldsymbol{A} \\circ \\widetilde{\\boldsymbol{R}} A=A∘R MF 即用0随机mask特征向量的部分维度。具体来说，按照1−pm1-p_m1−pm​的伯努利分布m~i∼B(1−pm),∀i\\widetilde{m}_{i} \\sim \\mathcal{B}\\left(1-p_{m}\\right), \\forall imi​∼B(1−pm​),∀i随机采样一个mask向量m~∈{0,1}F\\widetilde{m} \\in\\{0,1\\}^{F}m∈{0,1}F。干扰后的节点特征X~\\widetilde XX表示为： X~=[x1∘m~;x2∘m~;⋯ ;xN∘m~]⊤\\widetilde{\\boldsymbol{X}}=\\left[x_{1} \\circ \\tilde{m} ; x_{2} \\circ \\tilde{m} ; \\cdots ; x_{N} \\circ \\tilde{m}\\right]^{\\top} X=[x1​∘m~;x2​∘m~;⋯;xN​∘m~]⊤ 在GRACE中，作者同时使用这两种增强策略来生成新视图。生成的新视图G~1\\mathcal{\\widetilde G_1}G​1​，G~1\\mathcal{\\widetilde G_1}G​1​通过超参数pr，1,pm,1p_{r，1},p_{m,1}pr，1​,pm,1​和pr，2,pm,2p_{r，2},p_{m,2}pr，2​,pm,2​控制。作者通过实验发现，GRACE对这一超参的选择并不敏感，只要不过度破坏原始图信息即可，比如pr≤0.8p_r\\leq0.8pr​≤0.8，pm≤0.8p_m\\leq0.8pm​≤0.8。 2.3 理论分析 2.3.1 互信息 互信息Mutual Information（MI）是一种量化方式，计算的是一个随机变量包含另一个随机变量的信息量。 这一部分作者证明了对比目标JJJ是模型输入X和两个视角下节点嵌入之间互信息的下界，即J≤I(X,U,V)J\\leq I(X,U,V)J≤I(X,U,V)。 具体推导过程这里不做描述，感兴趣可以看原文。 2.3.2 三元损失 所谓三元损失，即通过三元组定义的一种损失函数：L=∑iN[∥f(xia)−f(xip)∥22−∥f(xia)−f(xin)∥22+α]+L=\\sum_{i}^{N}\\left[\\left\\|f\\left(x_{i}^{a}\\right)-f\\left(x_{i}^{p}\\right)\\right\\|_{2}^{2}-\\left\\|f\\left(x_{i}^{a}\\right)-f\\left(x_{i}^{n}\\right)\\right\\|_{2}^{2}+\\alpha\\right]_{+}L=∑iN​[∥f(xia​)−f(xip​)∥22​−∥f(xia​)−f(xin​)∥22​+α]+​。其目标如下图所示，即拉近锚点和正例样本间的距离，拉远锚点和负例样本间的距离： 这一部分作者证明了最小化对比目标和最大化三元损失一致： −ℓ(ui,vi)∝4Nτ+∑j=1N1[j≠i][(∥ui−vi∥2−∥ui−vj∥2)+(∥ui−vi∥2−∥ui−uj∥2)]-\\ell\\left(u_{i}, v_{i}\\right) \\propto 4 N \\tau+\\sum_{j=1}^{N} \\mathbb{1}_{[j \\neq i]}\\left[\\left(\\left\\|u_{i}-v_{i}\\right\\|^{2}-\\left\\|u_{i}-v_{j}\\right\\|^{2}\\right)+\\left(\\left\\|u_{i}-v_{i}\\right\\|^{2}-\\left\\|u_{i}-u_{j}\\right\\|^{2}\\right)\\right] −ℓ(ui​,vi​)∝4Nτ+j=1∑N​1[j​=i]​[(∥ui​−vi​∥2−∥ui​−vj​∥2)+(∥ui​−vi​∥2−∥ui​−uj​∥2)] 3. 实验 作者进行了三种类型实验：transductive 节点分类、大规模图上的inductive节点分类、多个图上的inductive节点分类。 3.1 实验设置 所有实验都采用DGI中的评估模式，首先按照无监督方式训练模型，然后将得到的嵌入用来训练一个逻辑回归分类器。 Transductive learning 使用两层GCN作为encoder： GCi(X,A)=σ(D^−12A^D^−12XWi)f(X,A)=GC2(GC1(X,A),A)\\begin{aligned} \\mathrm{GC}_{i}(\\boldsymbol{X}, \\boldsymbol{A}) &amp;=\\sigma\\left(\\hat{\\boldsymbol{D}}^{-\\frac{1}{2}} \\hat{\\boldsymbol{A}} \\hat{\\boldsymbol{D}}^{-\\frac{1}{2}} \\boldsymbol{X} \\boldsymbol{W}_{i}\\right) \\\\ f(\\boldsymbol{X}, \\boldsymbol{A}) &amp;=\\mathrm{GC}_{2}\\left(\\mathrm{GC}_{1}(\\boldsymbol{X}, \\boldsymbol{A}), \\boldsymbol{A}\\right) \\end{aligned} GCi​(X,A)f(X,A)​=σ(D^−21​A^D^−21​XWi​)=GC2​(GC1​(X,A),A)​ Inductive learning on large graph 对于大规模数据集，作者也基本参照DGI，使用带有残差连接的三层GraphSAGE-GCN： MP^i(X,A)=σ([D^−1A^X;X]Wi)f(X,A)=MP^3(MP^2(MP^1(X,A),A),A)\\begin{aligned} \\widehat{\\mathrm{MP}}_{i}(\\boldsymbol{X}, \\boldsymbol{A}) &amp;=\\sigma\\left(\\left[\\hat{\\boldsymbol{D}}^{-1} \\hat{\\boldsymbol{A}} \\boldsymbol{X} ; \\boldsymbol{X}\\right] \\boldsymbol{W}_{i}\\right) \\\\ f(\\boldsymbol{X}, \\boldsymbol{A}) &amp;=\\widehat{\\mathrm{MP}}_{3}\\left(\\widehat{\\mathrm{MP}}_{2}\\left(\\widehat{\\mathrm{MP}}_{1}(\\boldsymbol{X}, \\boldsymbol{A}), \\boldsymbol{A}\\right), \\boldsymbol{A}\\right) \\end{aligned} MPi​(X,A)f(X,A)​=σ([D^−1A^X;X]Wi​)=MP3​(MP2​(MP1​(X,A),A),A)​ 由于在大规模图上，GPU内存有限无法直接计算所有节点，所以这里采用GraphSAGE中subsampling方式进行计算。即首先采样一个minibatch节点，然后分别以每个节点为中心，1/2/3跳分别采样30/25/20个邻居节点。 Inductive learning on multiple graphs 还是和DGI中类似，堆叠三个mean-pooling层： H1=MP^1(X,A)H2=MP^2(XWskip +H1,A)f(X,A)=H3=MP^3(XWskip ′+H1+H2,A)\\begin{aligned} H_{1} &amp;=\\widehat{\\mathrm{MP}}_{1}(\\boldsymbol{X}, \\boldsymbol{A}) \\\\ \\boldsymbol{H}_{2} &amp;=\\widehat{\\mathrm{MP}}_{2}\\left(\\boldsymbol{X} \\boldsymbol{W}_{\\text {skip }}+\\boldsymbol{H}_{1}, \\boldsymbol{A}\\right) \\\\ f(\\boldsymbol{X}, \\boldsymbol{A})=\\boldsymbol{H}_{3} &amp;=\\widehat{\\mathrm{MP}}_{3}\\left(\\boldsymbol{X} \\boldsymbol{W}_{\\text {skip }}^{\\prime}+\\boldsymbol{H}_{1}+\\boldsymbol{H}_{2}, \\boldsymbol{A}\\right) \\end{aligned} H1​H2​f(X,A)=H3​​=MP1​(X,A)=MP2​(XWskip ​+H1​,A)=MP3​(XWskip ′​+H1​+H2​,A)​ 虽然在PPI数据集中包含多个图，但是出于计算效率考虑，作者只选取同一张图其他节点作为当前锚点的负样本。 3.2 实验结果 3.2.1 基础实验 从上表1可以看出，在所有实验设定下，和无监督方法相比，作者提出的GRACE模型都取得了最优表现。和有监督方法相比，在transductive设定下，GRACE也取得了最优表现。 3.2.2 敏感性实验 作者主要分析了模型对增强策略中pm,1,pr,1,pm,2,pr,2p_{m, 1}, p_{r, 1}, p_{m, 2}, p_{r, 2}pm,1​,pr,1​,pm,2​,pr,2​这些超参的敏感性，为了方便起见，作者设定p1=pr,1=pm,1p_{1}=p_{r, 1}=p_{m, 1}p1​=pr,1​=pm,1​，p2=pr,2=pm,2p_{2}=p_{r, 2}=p_{m, 2}p2​=pr,2​=pm,2​，结果如下图2所示： 可以看到只要不过度破坏原始数据结构和属性信息，模型对这些超参并不敏感。 3.2.3 消融实验 作者针对模型中两种增强策略RE和MF进行消融实验，结果如下表5所示：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning","slug":"3 论文笔记/图学习/对比学习/6.Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning","date":"2021-09-24T12:42:53.000Z","updated":"2021-09-28T02:37:06.804Z","comments":true,"path":"46cab6498bfc/","link":"","permalink":"http://rookieyin.github.io/46cab6498bfc/","excerpt":"https://arxiv.org/pdf/2105.05682 https://github.com/GRAND-Lab/MERIT Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning，2021，arxiv preprint 总结：作者将孪生网络和图对比学习结合到一起，提出了一种新的图对比学习方法MERIT。希望利用BYOL模型中自举机制解决现有图对比学习方法中负样本需要刻意选择的问题（但是我理解的这篇文章并没有用到BYOL中的思想，也没有解决这一问题）。具体来说，一方面通过孪生GNNs，设计了一种跨网络对比来从历史表示中提取知识；另一方面，为了进一步丰富自监督信号，引入了另一种不同尺度下的跨视角对比。总的来说，本文的创新点可以看做是两种工作的合并，实验结果还不错。","text":"https://arxiv.org/pdf/2105.05682 https://github.com/GRAND-Lab/MERIT Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning，2021，arxiv preprint 总结：作者将孪生网络和图对比学习结合到一起，提出了一种新的图对比学习方法MERIT。希望利用BYOL模型中自举机制解决现有图对比学习方法中负样本需要刻意选择的问题（但是我理解的这篇文章并没有用到BYOL中的思想，也没有解决这一问题）。具体来说，一方面通过孪生GNNs，设计了一种跨网络对比来从历史表示中提取知识；另一方面，为了进一步丰富自监督信号，引入了另一种不同尺度下的跨视角对比。总的来说，本文的创新点可以看做是两种工作的合并，实验结果还不错。 1. 简介 1.1 摘要 Graph representation learning plays a vital role in processing graph-structured data. However, prior arts on graph representation learning heavily rely on labeling information. To overcome this problem, inspired by the recent success of graph contrastive learning and Siamese networks in visual representation learning, we propose a novel self-supervised approach in this paper to learn node representations by enhancing Siamese self-distillation with multi-scale contrastive learning. Specifically, we first generate two augmented views from the input graph based on local and global perspectives. Then, we employ two objectives called cross-view and cross-network contrastiveness to maximize the agreement between node representations across different views and networks. To demonstrate the effectiveness of our approach, we perform empirical experiments on five real-world datasets. Our method not only achieves new state-of-the-art results but also surpasses some semi-supervised counterparts by large margins. Code is made available at https://github.com/GRAND-Lab/MERIT. 图表示学习在图结构数据任务中占有十分重要的地位，但是现有的图表示学习方法过度依赖于标签信息。为了克服这个问题，受图对比学习和孪生神经网络（CV）成功经验的启发，本文作者提出了一种新的自监督方法，通过使用多尺度对比学习增强Siamese自我蒸馏来学习节点表示。具体来说，我们首先分别基于输入图的局部和全局信息生成两个增强视角。然后我们使用两个目标函数，称为跨视图和跨网络对比，来最大化不同视角和网络下节点表示的一致性。为了证明我们提出的方法的有效性，我们在真实数据集上进行了多组实验。我们的方法不仅取得了最优效果，甚至大大超过了一些同类半监督模型。 1.2 本文工作 背景： 由于数据标注代价过大，有监督图表示学习方法的应用存在很大限制，而一些传统的无监督方法存在一些弊端。比如，DeepWalk、Node2Vec这些基于随机游走和skip-gram的模型强调相邻节点必须要有相似的表示；GraphSAGE这些基于矩阵重构的方法过度强调了图的邻近性，没有考虑更global的子图之间的关系。为了解决这些问题，近年来人们基于MI和contrastive learning，提出了多种图对比学习方法，比如MVGRL、GMI，GRACE等等。 动机： 现有的图对比学习方法存在一些弊端：一是这些基于MI的方法比如DGI、GMI、MVGRL等通常需要选择MI计算器，其计算代价比较大，另外会让模型对评判器的选择比较敏感；二是现有的GCL过度依赖于大量负样本来避免模型学习到的知识过于简单。也就是说，在对比学习中，负节点和负图是必不可少的，需要刻意选择。为了避免上述问题，在CV领域有人提出了BYOL模型，无需负样本，可以利用自举机制实现图像上的无监督表示学习。在视觉领域，对于自监督表示学习方法，有人采用了孪生网络。但是这一方法还没有被应用于图学习中。 本文工作： 本文作者为了克服前文提到的现有GCL方法存在的弊端，利用孪生网络中的自举机制，提出了一种简单有效的图对比学习框架来学习节点表示，称之为Multi-scale Contrastive Siamese Network（MERIT）。 3. 方法 如上图所示，作者提出的MERIT模型包含三个组件：图增强、跨网络对比、跨视角对比。模型训练流程为： 通过数据增强策略生成两种不同视角的图； 分别利用孪生网络中的在线网络和目标网络处理两个视角下的图（这里作者没作什么改变，和传统孪生网络类似）； 在不同尺度下对比两个视图下节点表示，如上图1最右边所示。 下面详细介绍下模型中这三个组件。 3.1 图增强 这块比较常规，作者从Graph Diffusion、Edge Modification、Subsampling和Node Feature Masking四种增强策略中随机选取两种不同策略。 对于这些增强策略的详细介绍可以参照之前的论文笔记，这里不做赘述。 3.2 跨网络对比学习 如上图1所示，在作者提出的框架中包含一个孪生结构，该结构包含两个单独的encoders（gθg_\\thetagθ​，pθp_\\thetapθ​，ggg，ppp），其中online encoder包含一个额外的预测器qθq_\\thetaqθ​。首先利用孪生网络中的在线网络和目标网络分别计算两个视角下的图表示，得到H1H^1H1，H2H^2H2，Z1Z^1Z1和Z2Z^2Z2。 得到四种图表示后，跨网络对比学习操作如下图a所示： 其中H1=qθ(Z1)H^1=q_\\theta(Z^1)H1=qθ​(Z1)，Z1=p0(g0(X~1,A1~))Z^{1}=p_{0}\\left(g_{0}\\left(\\tilde{X}_{1}, \\tilde{A_{1}}\\right)\\right)Z1=p0​(g0​(X~1​,A1​~​))表示视角1通过online网络得到的节点嵌入；Z^2=pζ(gζ(X~2,A2~))\\hat{Z}^{2}=p_{\\zeta}\\left(g_{\\zeta}\\left(\\tilde{X}_{2}, \\tilde{A_{2}}\\right)\\right)Z^2=pζ​(gζ​(X~2​,A2​~​))表示视角2通过target网络得到的节点嵌入。 具体来说，图中红色虚线表示正例对，其背后直觉是拉近不同网络、不同视角下相同节点的嵌入，这有利于从历史观察中获取知识，并提高在线编码器的稳定性。为了方便起见，作者不直接利用梯度下降更新目标网络的参数，而是通过动量更新机制来优化其参数： ζt=m⋅ζt−1+(1−m)⋅θt\\zeta^{t}=m \\cdot \\zeta^{t-1}+(1-m) \\cdot \\theta^{t} ζt=m⋅ζt−1+(1−m)⋅θt 其中mmm，ζ\\zetaζ，θ\\thetaθ分别表示动量、目标网络参数、在线网络参数。 为了进一步探究H1H^1H1和Z^2\\hat Z^2Z^2之间的对比关系，作者通过构建额外的负样本来正则化基本的正则损失，即： Lcn1(vi)=−log⁡exp⁡(sim⁡(hvi1,z^vi2))∑j=1Nexp⁡(sim⁡(hvi1,z^vj2))\\mathcal{L}_{c n}^{1}\\left(v_{i}\\right)=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, \\hat{z}_{v_{i}}^{2}\\right)\\right)}{\\sum_{j=1}^{N} \\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, \\hat{z}_{v_{j}}^{2}\\right)\\right)} Lcn1​(vi​)=−log∑j=1N​exp(sim(hvi​1​,z^vj​2​))exp(sim(hvi​1​,z^vi​2​))​ Lcn2(vi)=−log⁡exp⁡(sim⁡(hvi2,z^vi1))∑j=1Nexp⁡(sim⁡(hvi2,z^vj1))\\mathcal{L}_{c n}^{2}\\left(v_{i}\\right)=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{2}, \\hat{z}_{v_{i}}^{1}\\right)\\right)}{\\sum_{j=1}^{N} \\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{2}, \\hat{z}_{v_{j}}^{1}\\right)\\right)} Lcn2​(vi​)=−log∑j=1N​exp(sim(hvi​2​,z^vj​1​))exp(sim(hvi​2​,z^vi​1​))​ Lcn1(vi)\\mathcal{L}_{c n}^{1}\\left(v_{i}\\right)Lcn1​(vi​)表示对比H1H^1H1和Z^2\\hat Z^2Z^2，Lcn2(vi)\\mathcal{L}_{c n}^{2}\\left(v_{i}\\right)Lcn2​(vi​)表示对比H2H^2H2和Z^1\\hat Z^1Z^1。这样整个模型的cross-network损失定义为： Lcn=12N∑i=1N(Lcn1(vi)+Lcn2(vi))\\mathcal{L}_{c n}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left(\\mathcal{L}_{c n}^{1}\\left(v_{i}\\right)+\\mathcal{L}_{c n}^{2}\\left(v_{i}\\right)\\right) Lcn​=2N1​i=1∑N​(Lcn1​(vi​)+Lcn2​(vi​)) 3.3 跨视角对比学习 由于目标网络不直接进行梯度更新，因此跨视角对比学习只在在线网络中进行，如下图2b所示： 跨视角对比包含intra-和inter-view两个部分，这和GRACE一文中的方法类似但又有所不同。对于增强策略，作者这里不仅考虑采用局部结构和属性增强，还考虑通过图扩散注入全局拓扑信息。 inter-view contrasitive Linter 1(vi)=−log⁡exp⁡(sim⁡(hvi1,hvi2))∑j=1Nexp⁡(sim⁡(hvi1,hvj2))\\mathcal{L}_{\\text {inter }}^{1}\\left(v_{i}\\right)=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, h_{v_{i}}^{2}\\right)\\right)}{\\sum_{j=1}^{N} \\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, h_{v_{j}}^{2}\\right)\\right)} Linter 1​(vi​)=−log∑j=1N​exp(sim(hvi​1​,hvj​2​))exp(sim(hvi​1​,hvi​2​))​ 这里和前文中跨网络对比损失类似，分母负样本对只包含跨网络负样本对（首尾节点嵌入上标分别是1和2）。 intra-view contrasitive Linlra1(vi)=−log⁡exp⁡(sim⁡(hvi1,hvi2))exp⁡(sim⁡(hvi1,hvi2))+ΦΦ=∑j=1N1i≠jexp⁡(sim⁡(hvi1,hvj1))\\begin{aligned}\\mathcal{L}_{i n l r a}^{1}\\left(v_{i}\\right) &amp;=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, h_{v_{i}}^{2}\\right)\\right)}{\\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, h_{v_{i}}^{2}\\right)\\right)+\\Phi} \\\\\\Phi &amp;=\\sum_{j=1}^{N} \\mathbb{1}_{i \\neq j} \\exp \\left(\\operatorname{sim}\\left(h_{v_{i}}^{1}, h_{v_{j}}^{1}\\right)\\right)\\end{aligned} Linlra1​(vi​)Φ​=−logexp(sim(hvi​1​,hvi​2​))+Φexp(sim(hvi​1​,hvi​2​))​=j=1∑N​1i​=j​exp(sim(hvi​1​,hvj​1​))​ 公式分母中负样本对只包含同一视角网络中的负样本对（首尾节点嵌入上标都是1）。 这样整个模型的跨视角对比损失可以定义为： Lcv=12N∑i=1N(Lcv1(vi)+Lcv2(vi))\\mathcal{L}_{c v}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left(\\mathcal{L}_{c v}^{1}\\left(v_{i}\\right)+\\mathcal{L}_{c v}^{2}\\left(v_{i}\\right)\\right) Lcv​=2N1​i=1∑N​(Lcv1​(vi​)+Lcv2​(vi​)) 其中Lcvk(vi)=Lintra k(vi)+Linter k(vi),k∈{1,2}\\mathcal{L}_{c v}^{k}\\left(v_{i}\\right)=\\mathcal{L}_{\\text {intra }}^{k}\\left(v_{i}\\right)+\\mathcal{L}_{\\text {inter }}^{k}\\left(v_{i}\\right), \\quad k \\in\\{1,2\\}Lcvk​(vi​)=Lintra k​(vi​)+Linter k​(vi​),k∈{1,2}。至此，整个模型的损失函数定义为： L=βLcv+(1−β)Lcn\\mathcal{L}=\\beta \\mathcal{L}_{c v}+(1-\\beta) \\mathcal{L}_{c n} L=βLcv​+(1−β)Lcn​ 其中β\\betaβ为平衡因子。在推理阶段使用在线网络得到的两个嵌入用于下游任务，即H~=H1+H2∈RN×D′\\tilde{H}=H^{1}+H^{2} \\in \\mathbb{R}^{N \\times D^{\\prime}}H~=H1+H2∈RN×D′作为推理器的输入。 3. 实验 3.1 实验设置 采用1层GCN作为graph encoders（gθg_\\thetagθ​和gζg_\\zetagζ​）的骨架 超参数β\\betaβ从{0.2,0.4,0.6,0.8}\\{0.2,0.4,0.6,0.8\\}{0.2,0.4,0.6,0.8}中选取 数据集使用：Cora、CiteSeer、PubMed、Amazon Photo、Coauthor CS 3.2 节点分类实验 作者将MERIT和5种有监督方法和4中SOTA图对比学习方法进行对比，实验结果如下表所示： 可以看到作者提出的方法在所有数据集中都取得了最优结果。 3.3 参数敏感性 3.3.1 平衡因子β\\betaβ和动量mmm 观察上图，作者有如下发现： 给定一个固定的动量值m，β\\betaβ通常取0.4~0.6，模型性能最好。这证明了同时使用两种尺度的对比学习，比单独使用一种，效果更好。 给定一个固定的β\\betaβ值，mmm取1时模型性能很差。作者猜测这可能是因为将动量值设为1会阻碍模型提取知识，从而影响模型的优化。 mmm取0时模型亦然取得不错的效果，作者猜测这可能是因为bootstrapping机制中真正起作用的时stop gradient和predictor。 3.3.2 改变比例 除了mmm和β\\betaβ，数据增强在对比学习中也扮演着十分重要的角色。 上图4a展示了不同调整比例下模型性能的变化。 红线表示edge modification，蓝线表示edge modification+node feature modification。 在只使用EM策略时，调整比例越高，模型性能越好。这可能是对比学习的本质导致的，需要更具有挑战性的对比任务来获取更好的性能。 在同时使用EM和NFM时，调整比例过高会降低模型性能，因为这会过度破坏图的结构和属性信息。 上图4b展示了在使用EM、NFM的基础上添加Graph Diffusion时，模型性能的变化。 当α=0.5\\alpha=0.5α=0.5时模型性能最好。 当α=0\\alpha=0α=0时，即去掉Diffusion时，模型性能大幅下降。这证明了作者前文的猜想：即注入全局信息可以进一步提高模型的表达能力。 3.4 消融实验 为了验证MERIT中两种对比组件的有效性，作者提出了两种变体：MERIT w/o cross-network和MERIT w/o cross-view，分别表示只使用跨网络损失和只使用跨视角损失。实验结果如下表3所示： 另外作者为了验证MERIT的优越性，使用t-SNE对节点嵌入进行了可视化： 其中不同颜色代表不同节点类型。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Learning Graph Representation by Aggregating Subgraphs via Mutual Information Maximization","slug":"3 论文笔记/图学习/对比学习/5.Learning Graph Representation by Aggregating Subgraphs via Mutual Information Maximization","date":"2021-08-31T04:28:29.000Z","updated":"2021-11-27T05:54:24.496Z","comments":true,"path":"e4d61b74d6d1/","link":"","permalink":"http://rookieyin.github.io/e4d61b74d6d1/","excerpt":"https://arxiv.org/pdf/2103.13125 Learning Graph Representation by Aggregating Subgraphs via Mutual Information Maximization，2021，arxiv preprint 总结： 前面文章提到过，图对比学习中常用的数据增强策略可以归纳为4种，mask属性、增删节点、增删边和子图。本文作者从子图入手提出了一种图对比学习模型。具体来说，作者提出了一种自回归子图生成模型，然后将生成的子图聚合到一起作为新图，再和原图进行对比，用于无监督/半监督图分类任务。另外作者还添加了一些小trick，进一步提高了模型性能。","text":"https://arxiv.org/pdf/2103.13125 Learning Graph Representation by Aggregating Subgraphs via Mutual Information Maximization，2021，arxiv preprint 总结： 前面文章提到过，图对比学习中常用的数据增强策略可以归纳为4种，mask属性、增删节点、增删边和子图。本文作者从子图入手提出了一种图对比学习模型。具体来说，作者提出了一种自回归子图生成模型，然后将生成的子图聚合到一起作为新图，再和原图进行对比，用于无监督/半监督图分类任务。另外作者还添加了一些小trick，进一步提高了模型性能。 1. 简介 1.1 摘要 In this paper, we introduce a self-supervised learning method to enhance the graph-level representations with the help of a set of subgraphs. For this purpose, we propose a universal framework to generate subgraphs in an auto-regressive way and then using these subgraphs to guide the learning of graph representation by Graph Neural Networks. Under this framework, we can get a comprehensive understanding of the graph structure in a learnable way. And to fully capture enough information of original graphs, we design three information aggregators: attribute-conv, layer-conv and subgraph-conv to gather information from different aspects. And to achieve efficient and effective contrastive learning, a Head-Tail contrastive construction is proposed to provide abundant negative samples. Under all proposed components which can be generalized to any Graph Neural Networks, in the unsupervised case, we achieve new state-of-the-art results in several benchmarks. We also evaluate our model on semi-supervised learning tasks and make a fair comparison to state-of-the-art semi-supervised methods. 本文，我们提出了一种自监督图学习方法，通过子图集合提高图层级表示质量。为此，作者提出了一种通用的框架，以自回归的方式生成子图，然后用这些子图来指导GNN学习图表示。通过该框架，我们能够以一种可学习的方式深入理解图结构。另外，为了充分捕捉原始图信息，我们设计了三种类型信息聚合器：attribute-conv，layer-conv和subgraph-conv，从不同方面收集信息。为了实现高效的对比学习，作者提出了一种head-tail对比结构，可以提供丰富的负样本。通过将这些组件应用到GNNs中，作者在一些标准数据集上实现了sota效果。作者也进行了一些半监督实验来评估该模型。 1.2 本文工作 背景： GNNs虽然被广泛用于图表示学习，但是大多数都用于有标签数据集。在很多领域数据标记成本过高，因此无监督或者半监督学习方法是一种非常重要的技术。现有的方法主要有两类：一种是通过重构图结构比如VGAE，另一种是对比学习。 动机： 作者关注于如何从原始图中聚合信息，以及如何定义一个更好的、合理的约束来保留图的基本信息，提出一种新的无监督图对比学习方法。（说白了就是从子图这种增强策略入手，搞图对比学习） 作者贡献： 从子图入手，提出了一种图对比学习模型用于图分类任务。作者在一些现有工作的基础上添加了一些小trick，使模型性能有一点提升。具体来说： 设计了三种类型信息聚合器：attribute-conv，layer-conv和subgraph-conv，从不同方面收集信息。attribute-conv用于融合不同种类的原始信息；layer-conv用于聚合不同尺度的节点表示；subgraph-conv用于得到reconstructed graph的图表示。 提出了一种通用的可学习的自回归子图生成框架。利用生成的子图和subgraph-conv，可以对图进行重构，然后将重构图和原始图进行对比可以得到一个合理的目标函数。 提出了一种新的负样本采集方法Head-Tail对比采样，可以为学习到的表示提供有意义的约束。 注：上述提到的所有组件都是可插拔的，可以灵活迁移到任意图模型中。 2. 方法 整个框架可以划分成Node-Agg，Layer-Agg和Subgraph-Agg三个阶段。 首先在Node-Agg阶段，通过attribute-conv对各种属性进行聚合，得到基本的节点表示。 然后在Layer-Agg阶段，通过layer-conv对GNNs中不同尺度节点表示进行聚合，得到最终节点表示。 在Subgraph-Agg阶段，通过自回归进行子图采样，得到子图后，再利用subgraph-conv对所有子图信息进行聚合得到重构图的图表示。这一过程可以看做：数据增强（得到一个新的graph view）+图表示学习。 最后对比原始图表示h(G)h(G)h(G)和重构图表示h~(G)\\tilde h(G)h~(G)，优化模型。 2.1 Node-Agg阶段 图数据中往往包含丰富的信息，比如节点和边的属性信息，甚至是局部结构信息。我们可以通过将这些不同类型信息聚合到一起，提高学习到的节点表示的质量，进而学习到更好的图表示。 具体来说，假设有N中类型节点属性：X1,X2,...,XN Xi∈R∣V∣×NiX_1,X_2,...,X_N\\ X_i\\in\\mathbf R^{|V|\\times N_i}X1​,X2​,...,XN​ Xi​∈R∣V∣×Ni​。为了简化分析过程，我们考虑只有节点属性XV∈R∣V∣×DVX_V\\in\\mathbf R^{|V|\\times D_V}XV​∈R∣V∣×DV​和边属性XV∈R∣E∣×DEX_V\\in\\mathbf R^{|E|\\times D_E}XV​∈R∣E∣×DE​的情况： 首先将两者的转化成相同维度： XV(0)=MLP⁡v(XV)∈R∣V∣×d(2)X_{V}^{(0)}=\\operatorname{MLP}_{\\mathbf{v}}\\left(X_{V}\\right) \\in \\mathbf{R}^{|V| \\times d}\\tag 2 XV(0)​=MLPv​(XV​)∈R∣V∣×d(2) XE(0)=AGG(MLP⁡E(XE))∈R∣V∣×d(3)X_{E}^{(0)}=\\mathbf{A G G}\\left(\\operatorname{MLP}_{\\mathbf{E}}\\left(X_{E}\\right)\\right) \\in \\mathbf{R}^{|V| \\times d}\\tag 3 XE(0)​=AGG(MLPE​(XE​))∈R∣V∣×d(3) 其中AGGAGGAGG表示将边嵌入整合到相关节点中。 得到初始节点、边嵌入XV(0),XE(0)∈R∣V∣×dX_{V}^{(0)}, X_{E}^{(0)} \\in \\mathbf{R}^{|V| \\times d}XV(0)​,XE(0)​∈R∣V∣×d后，利用一个卷积核将两者合并到一起： X(0)=attribute-conv⁡([XV(0);XE(0)])∈R∣V∣×d(4)X^{(0)}=\\operatorname{attribute-conv}\\left(\\left[X_{V}^{(0)} ; X_{E}^{(0)}\\right]\\right) \\in \\mathbf{R}^{|V| \\times d}\\tag 4 X(0)=attribute-conv([XV(0)​;XE(0)​])∈R∣V∣×d(4) 这样我们就得到了GNNs的输入X(0)X^{(0)}X(0)。 2.2 Layer-Agg阶段 GNNs每一层都会得到一个节点表示：(X(1),X(2),…,X(L))\\left(X^{(1)}, X^{(2)}, \\ldots, X^{(L)}\\right)(X(1),X(2),…,X(L))，虽然X(L)X^{(L)}X(L)通常是有用的，但是不可避免的会丢失一些有用的节点信息。因此，作者使用一个layer-conv将GNNs每一层输出都聚合到一起作为最终节点嵌入： XG=layer-conv⁡([X(1);X(2);…;X(L)])∈R∣V∣×d(5)X_{\\mathcal{G}}=\\operatorname{layer-conv}\\left(\\left[X^{(1)} ; X^{(2)} ; \\ldots ; X^{(L)}\\right]\\right) \\in \\mathbf{R}^{|V| \\times d}\\tag 5 XG​=layer-conv([X(1);X(2);…;X(L)])∈R∣V∣×d(5) 得到所有节点的嵌入后，再通过一个readout函数计算整图表示： h(G)=READOUT(XG)∈Rd(6)h(\\mathcal{G})=\\mathbf{R E A D O U T}\\left(X_{\\mathcal{G}}\\right) \\in \\mathbf{R}^{d}\\tag 6 h(G)=READOUT(XG​)∈Rd(6) 2.3 Subgraph-Agg阶段 作者认为多视角图对比学习那篇文章中对比节点和图表示无法学习到高质量的图表示，因为节点表示和图表示蕴含的信息不在同一个层级。 本文作者提出了一种类似集成学习的子图方法，通过一系列原始图的子图构建一张新图和原始图进行对比，即： max⁡I(h(G);h~(G))(7)\\max \\mathcal{I}(h(\\mathcal{G}) ; \\tilde{h}(\\mathcal{G}))\\tag 7 maxI(h(G);h~(G))(7) 其中h~(G)\\tilde h(\\mathcal G)h~(G)表示重新构建的新图GrecG^{rec}Grec的表示向量。具体来说，GGG表示原始图，Grec={Gi,i=1,2,...,S}G^{rec}=\\{\\mathcal G_i,i=1,2,...,S\\}Grec={Gi​,i=1,2,...,S}表示子图集合，公式7可以写成： max⁡I(G;Grec)=EG[KL(p(Grec∣G)∥p(Grec))]\\max \\mathcal{I}\\left(\\mathbf{G} ; \\mathbf{G}^{\\mathbf{r e c}}\\right)=\\mathbb{E}_{\\mathbf{G}}\\left[\\mathbf{K L}\\left(p\\left(\\mathbf{G}^{\\mathrm{rec}} \\mid \\mathbf{G}\\right) \\| p\\left(\\mathbf{G}^{\\mathbf{r e c}}\\right)\\right)\\right] maxI(G;Grec)=EG​[KL(p(Grec∣G)∥p(Grec))] 其中KL(⋅∣∣⋅)\\mathbf{KL}(·||·)KL(⋅∣∣⋅)表示KL散度。下面详细介绍下该阶段的细节。 2.3.1 子图生成 对于子图生成方法，作者采用自回归模型： p(Grec ∣G)=p({Gi,i=1,2,…,S}∣G)=∏i=2Sp(Gi∣G,G1,…,Gi−1).(8)\\begin{aligned}p\\left(\\mathbf{G}^{\\text {rec }} \\mid \\mathbf{G}\\right) &amp;=p\\left(\\left\\{\\mathcal{G}_{i}, i=1,2, \\ldots, S\\right\\} \\mid \\mathbf{G}\\right) \\\\&amp;=\\prod_{i=2}^{S} p\\left(\\mathcal{G}_{i} \\mid \\mathbf{G}, \\mathcal{G}_{1}, \\ldots, \\mathcal{G}_{i-1}\\right) .\\end{aligned}\\tag 8 p(Grec ∣G)​=p({Gi​,i=1,2,…,S}∣G)=i=2∏S​p(Gi​∣G,G1​,…,Gi−1​).​(8) 作者提出了两种生成方法：Tree-split和Multi-head。 一、Basic Operator 先看一种基本操作，作者提出的两种子图生成方法都是在这一基本操作基础上衍化而来。 首先通过公式5得到每个节点嵌入XG∈R∣V∣×dX_\\mathcal G\\in\\mathbf R^{|V|\\times d}XG​∈R∣V∣×d后，再做一个线性转换后计算一个概率矩阵： P=Softmax⁡(XG⋅W)∈R∣V∣×2(11)P=\\operatorname{Softmax}\\left(X_{\\mathcal{G}} \\cdot W\\right) \\in \\mathbf{R}^{|V| \\times 2}\\tag {11} P=Softmax(XG​⋅W)∈R∣V∣×2(11) P中的元素pijp_{ij}pij​表示节点iii出现在子图jjj中的概率。公式11表示将原始图划分成两个子图。 二、Tree-split 如下图所示，Tree-split方法就是不断迭代执行basic operator，在前一轮生成的子图上执行basic operator，就想一棵二叉树一样。经过T论basic operator后，可以得到S=2TS=2^TS=2T个子图{XG1T,…,XG2TT}\\left\\{X_{\\mathcal{G}_{1}^{T}}, \\ldots, X_{\\mathcal{G}_{2 T}^{T}}\\right\\}{XG1T​​,…,XG2TT​​}。 三、Multi-head 和多头注意力机制一样，使用S个可学习矩阵{W1,…,WS}\\left\\{W^{1}, \\ldots, W^{S}\\right\\}{W1,…,WS}，并行执行basic operator，得到S个概率矩阵{P1,…,PS}\\left\\{P^{1}, \\ldots, P^{S}\\right\\}{P1,…,PS}。如果Pj,1i≥12P_{j, 1}^{i} \\geq \\frac{1}{2}Pj,1i​≥21​，则表示子图iii中保留节点jjj。 2.3.2 子图聚合 通过上述方法生成子图后，每个子图Gi\\mathcal G_iGi​执行一个readout函数，得到子图表示h(Gi)h(\\mathcal G_i)h(Gi​)： h(Gi)=READOUT(XGi)∈Rd,i=1,2,…,S(9)h\\left(\\mathcal{G}_{i}\\right)=\\mathbf{R E A D O U T}\\left(X_{\\mathcal{G}_{i}}\\right) \\in \\mathbf{R}^{d}, i=1,2, \\ldots, S\\tag 9 h(Gi​)=READOUT(XGi​​)∈Rd,i=1,2,…,S(9) 得到子图表示后，像集成学习一样，再利用subgraph-conv卷积操作将所有子图表示聚合到一起： h~(G)=subgraph⁡−conv⁡([h(G1);h(G2);…;h(GS)])∈Rd(10)\\tilde{h}(\\mathcal{G})=\\operatorname{subgraph}-\\operatorname{conv}\\left(\\left[h\\left(\\mathcal{G}_{1}\\right) ; h\\left(\\mathcal{G}_{2}\\right) ; \\ldots ; h\\left(\\mathcal{G}_{S}\\right)\\right]\\right) \\in \\mathbf{R}^{d}\\tag {10} h~(G)=subgraph−conv([h(G1​);h(G2​);…;h(GS​)])∈Rd(10) 2.4 模型训练 ϕ\\phiϕ表示模型所有参数，模型的目标函数定义为： max⁡Lϕ,ωuns≜∑G∈G1∣G∣Lϕ,ωuns(G)=∑G∈G1∣G∣Iϕ,ω(hϕ(G);h~ϕ(G))(13)\\begin{aligned}\\max \\mathcal{L}_{\\phi, \\omega}^{u n s} &amp; \\triangleq \\sum_{\\mathcal{G} \\in \\mathbf{G}} \\frac{1}{|\\mathbf{G}|} \\mathcal{L}_{\\phi, \\omega}^{u n s}(\\mathcal{G}) \\\\&amp;=\\sum_{\\mathcal{G} \\in \\mathbf{G}} \\frac{1}{|\\mathbf{G}|} I_{\\phi, \\omega}\\left(h_{\\phi}(\\mathcal{G}) ; \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\end{aligned}\\tag{13} maxLϕ,ωuns​​≜G∈G∑​∣G∣1​Lϕ,ωuns​(G)=G∈G∑​∣G∣1​Iϕ,ω​(hϕ​(G);h~ϕ​(G))​(13) Iϕ,ω(hϕ(G);h~ϕ(G))I_{\\phi, \\omega}\\left(h_{\\phi}(\\mathcal{G}) ; \\tilde{h}_{\\phi}(\\mathcal{G})\\right)Iϕ,ω​(hϕ​(G);h~ϕ​(G))表示互信息，本文采用 Jensen-Shannon散度： Iϕ,ωJSD(hϕ(G);h~ϕ(G))=EP(−sp(−Tω(hϕ(G),h~ϕ(G)))−EQ(sp(Tω(hϕ(G),h~ϕ(G))))(14)\\begin{aligned}I_{\\phi, \\omega}^{J S D}\\left(h_{\\phi}\\right.&amp;\\left.(\\mathcal{G}) ; \\tilde{h}_{\\phi}(\\mathcal{G})\\right) \\\\=&amp; \\mathbf{E}_{P}\\left(-s p\\left(-T_{\\omega}\\left(h_{\\phi}(\\mathcal{G}), \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\right)\\right.\\\\&amp;-\\mathbf{E}_{Q}\\left(s p\\left(T_{\\omega}\\left(h_{\\phi}(\\mathcal{G}), \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\right)\\right)\\end{aligned}\\tag{14} Iϕ,ωJSD​(hϕ​=​(G);h~ϕ​(G))EP​(−sp(−Tω​(hϕ​(G),h~ϕ​(G)))−EQ​(sp(Tω​(hϕ​(G),h~ϕ​(G))))​(14) 前面提到的目标函数只包括正样本，对于负样本的获取方式有两种：一是使用batch中的其他图，二是使用corruption函数污染原始图作为负样本。本文作者采用一种Head-Tail负样本采集方法，具体来说，对于图Gi\\mathcal G^iGi： head negative pair：通过shuffling节点嵌入X^(0)=\\hat{X}^{(0)}=X^(0)= Permute (X(0))∈R∣V∣×d\\left(X^{(0)}\\right) \\in \\mathbf{R}^{|V| \\times d}(X(0))∈R∣V∣×d得到图G^i\\hat{\\mathcal G}^iG^​i，(hϕ(G^i),h~ϕ(Gi))\\left(h_{\\phi}\\left(\\hat{\\mathcal{G}}^{i}\\right), \\tilde{h}_{\\phi}\\left(\\mathcal{G}^{i}\\right)\\right)(hϕ​(G^​i),h~ϕ​(Gi))称之为头负样本对。 tail negative pair：利用数据集中其他图hϕ(Gj),j≠ih_{\\phi}\\left(\\mathcal{G}^{j}\\right), j \\neq ihϕ​(Gj),j​=i生成尾负样本对(hϕ(Gj),h~ϕ(Gi))\\left(h_{\\phi}\\left(\\mathcal{G}^{j}\\right), \\tilde{h}_{\\phi}\\left(\\mathcal{G}^{i}\\right)\\right)(hϕ​(Gj),h~ϕ​(Gi))。 得到这两种类型负样本对后，公式14可以改写成： Lϕ,ωuns(G)=Ep(hϕ(G),hˉϕ(G))(−sp(−Tω(hϕ(G),h~ϕ(G)))−Ep(hϕ(G))p(hˉϕ(G))(sp(Tω(hϕ(G),h~ϕ(G)))−Ep(hϕ(G^),hˉϕ(G))(sp(Tω(hϕ(G^),h~ϕ(G)))(17)\\begin{aligned}\\mathcal{L}_{\\phi, \\omega}^{u n s}(\\mathcal{G})=&amp; \\mathbf{E}_{p\\left(h_{\\phi}(\\mathcal{G}), \\bar{h}_{\\phi}(\\mathcal{G})\\right)}\\left(-s p\\left(-T_{\\omega}\\left(h_{\\phi}(\\mathcal{G}), \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\right)\\right.\\\\&amp;-\\mathbf{E}_{p\\left(h_{\\phi}(\\mathcal{G})\\right) p\\left(\\bar{h}_{\\phi}(\\mathcal{G})\\right)}\\left(s p\\left(T_{\\omega}\\left(h_{\\phi}(\\mathcal{G}), \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\right)\\right.\\\\&amp;-\\mathbf{E}_{p\\left(h_{\\phi}(\\hat{\\mathcal{G}}), \\bar{h}_{\\phi}(\\mathcal{G})\\right)}\\left(s p\\left(T_{\\omega}\\left(h_{\\phi}(\\hat{\\mathcal{G}}), \\tilde{h}_{\\phi}(\\mathcal{G})\\right)\\right)\\right.\\end{aligned}\\tag {17} Lϕ,ωuns​(G)=​Ep(hϕ​(G),hˉϕ​(G))​(−sp(−Tω​(hϕ​(G),h~ϕ​(G)))−Ep(hϕ​(G))p(hˉϕ​(G))​(sp(Tω​(hϕ​(G),h~ϕ​(G)))−Ep(hϕ​(G^​),hˉϕ​(G))​(sp(Tω​(hϕ​(G^​),h~ϕ​(G)))​(17) 在半监督学习中，我们还利用数据标签计算交叉熵损失：Lϕ,θsup(yϕ(Gi);yi)=Epϕ(Gi;h(Gi))log⁡pθ(y∣h(Gi))\\mathcal{L}_{\\phi, \\theta}^{s u p}\\left(y_{\\phi}\\left(\\mathcal{G}^{i}\\right) ; y^{i}\\right)=\\mathbb{E}_{p_{\\phi}\\left(\\mathcal{G}^{i} ; h\\left(\\mathcal{G}^{i}\\right)\\right)} \\log p_{\\theta}\\left(y \\mid h\\left(\\mathcal{G}^{i}\\right)\\right)Lϕ,θsup​(yϕ​(Gi);yi)=Epϕ​(Gi;h(Gi))​logpθ​(y∣h(Gi))。此时整个半监督模型的损失函数定义为： max⁡Lϕ,ω,θsemi=∑i=1∣GL∣Lϕ,θsup(yϕ(Gi);yi)+λ∑j=1∣GL∣+∣GU∣Lϕ,ωuns(Gj)(18)\\max \\mathcal{L}_{\\phi, \\omega, \\theta}^{s e m i}=\\sum_{i=1}^{\\left|G^{L}\\right|} \\mathcal{L}_{\\phi, \\theta}^{s u p}\\left(y_{\\phi}\\left(\\mathcal{G}^{i}\\right) ; y^{i}\\right)+\\lambda \\sum_{j=1}^{\\left|\\mathbf{G}^{L}\\right|+\\left|\\mathbf{G}^{U}\\right|} \\mathcal{L}_{\\phi, \\omega}^{u n s}\\left(\\mathcal{G}^{j}\\right)\\tag{18} maxLϕ,ω,θsemi​=i=1∑∣GL∣​Lϕ,θsup​(yϕ​(Gi);yi)+λj=1∑∣GL∣+∣GU∣​Lϕ,ωuns​(Gj)(18) 下图展示了模型的伪代码： 3. 实验 3.1 实验设置 一、数据集 无监督： TUDataset，MUTAG，PTC-MR，IMDB-BINARY和IMDB-MULTI，REDDIT-BINARY和REDDIT-MULTI-5K 半监督： QM9 二、实验配置 无监督： 采用图分类任务评估模型，具体流程和InfoGraph一致，采用10-fold交叉验证作为模型分类表现。实验重复7次，去除最大最小值后，取平均值作为最终结果。 半监督： 采用QM9数据集，随机每次随机选取5000个样本作为有标签样本，10000个样本作为验证样本，另外10000个样本作为测试样本，其余的作为无标签训练样本。 三、模型配置 无监督： 采用GIN作为base model，节点度作为初始节点属性，当没有边属性时不需要attribute-conv。所有hidden层维度都是128，batch大小128，GNN层数4，子图数量S∈{2,4,8}S\\in\\{2,4,8\\}S∈{2,4,8}，初始学习率10−310^{-3}10−3，epoch数量100。 半监督： 和无监督实验类似。 3.2 实验结果 3.2.1 对比实验 3.2.2 消融实验 这一部分主要对模型各个组件进行消融实验。 BASE ：TS或者MH子图生成+layer-conv； BASE+NEG：表示在BASE基础上添加head negative samples； OURS：在BASE+NEG的基础上添加subgraph-conv。 可以看到，从第一行到最后一行，性能都是有所提升的，说明作者提出的模型中各个组件都是有效的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"子图学习","slug":"子图学习","permalink":"http://rookieyin.github.io/tags/%E5%AD%90%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}]},{"title":"Graph Contrastive Learning Automated","slug":"3 论文笔记/图学习/对比学习/4.Graph Contrastive Learning Automated","date":"2021-08-28T03:10:58.000Z","updated":"2021-09-28T02:36:59.351Z","comments":true,"path":"acd2c96a31cf/","link":"","permalink":"http://rookieyin.github.io/acd2c96a31cf/","excerpt":"https://arxiv.org/pdf/2106.07594 https://github.com/Shen-Lab/GraphCL_Automated Graph Contrastive Learning Automated ，2021，ICML 总结：可以看做“Graph Contrastive Learning with Augmentations”这篇文章的优化工作。本文作者提出了一种自动图对比学习策略JOAO，并基于此提出了一种变体JOAOv2。具体来说，由于图数据集的异质性，现有的图对比学习方法需要根据不同数据集采用试错法手动选取增强策略，这限制了GraphCL的通用性。作者受对抗学习的启发，提出了一种双层优化机制，将增强策略的采样分布整合到模型目标损失中，通过梯度下降进行优化，自动选取最适合当前数据集的增强策略。大量实验证明作者提出的JOAO策略是有效的，自动选取的增强策略和人工试错法得到的增强策略基本一致。","text":"https://arxiv.org/pdf/2106.07594 https://github.com/Shen-Lab/GraphCL_Automated Graph Contrastive Learning Automated ，2021，ICML 总结：可以看做“Graph Contrastive Learning with Augmentations”这篇文章的优化工作。本文作者提出了一种自动图对比学习策略JOAO，并基于此提出了一种变体JOAOv2。具体来说，由于图数据集的异质性，现有的图对比学习方法需要根据不同数据集采用试错法手动选取增强策略，这限制了GraphCL的通用性。作者受对抗学习的启发，提出了一种双层优化机制，将增强策略的采样分布整合到模型目标损失中，通过梯度下降进行优化，自动选取最适合当前数据集的增强策略。大量实验证明作者提出的JOAO策略是有效的，自动选取的增强策略和人工试错法得到的增强策略基本一致。 1. 简介 1.1 摘要 Self-supervised learning on graph-structured data has drawn recent interest for learning generalizable, transferable and robust representations from unlabeled graphs. Among many, graph contrastive learning (GraphCL) has emerged with promising representation learning performance. Unfortunately, unlike its counterpart on image data, the effectiveness of GraphCL hinges on adhoc data augmentations, which have to be manually picked per dataset, by either rules of thumb or trial-and-errors, owing to the diverse nature of graph data. That significantly limits the more general applicability of GraphCL. Aiming to fill in this crucial gap, this paper proposes a unified bi-level optimization framework to automatically, adaptively and dynamically select data augmentations when performing GraphCL on specific graph data. The general framework, dubbed JOint Augmentation Optimization (JOAO), is instantiated as min-max optimization. The selections of augmentations made by JOAO are shown to be in general aligned with previous “best practices” observed from handcrafted tuning: yet now being automated, more flexible and versatile. Moreover, we propose a new augmentation-aware projection head mechanism, which will route output features through different projection heads corresponding to different augmentations chosen at each training step. Extensive experiments demonstrate that JOAO performs on par with or sometimes better than the state-of-the-art competitors including GraphCL, on multiple graph datasets of various scales and types, yet without resorting to any laborious dataset-specific tuning on augmentation selection. We release the code at https://github.com/Shen-Lab/GraphCL_Automated. 近年来用于图结构数据的自监督学习得到了广泛研究，可以从无标签图中学习通用的、可迁移的、稳定的表示。很多图表示学习模型在表示学习任务中都取得了很不错的性能。不幸的是，和图像中对比学习不同，图对比学习的有效性依赖于特定的增强策略。但是由于图数据集的多样性，需要采用是错法为当前数据集手动选取合适的增强策略。这极大的限制了GraphCL模型的通用性。为了解决这个问题，本文我们提出了一种统一的双层优化框架，可以针对具体数据集自动地、自适应地、动态地选取数据增强策略。该框架称之为联合增强优化JOAO，可以看做是一种min-max优化的实例。通过JOAO 选出来的增强策略基本和人工选取的最优增强策略一致。另外，我们提出了一种新的增强感知映射头机制，可以通过每个训练步骤选择的不同增强策略对应的投影头对输出特征进行路由。大量实验证明，在各种类型数据集上，不需要手动选取增强策略，JOAO都取得了相当甚至优于SOTA方法的性能。 1.2 本文工作 背景： 近些年来用于图结构数据的自监督模型，尤其是图对比学习模型得到了广泛研究。但是和图像数据不同，图数据集十分多样，比如社交网络、引用网络、生物网络等。现有的图自监督模型无法解决这种多样性带来的挑战。比如，当前SOTA图对比学习模型GraphCL需要手动选取合适的增强策略，生成对比视角。 动机： 通过试错方式为GraphCL模型选取合适的数据增强策略，极大地限制了GraphCL模型的通用性，并且这在实际应用中有时是不可行的。从这一点出发，作者在本文中研究如何让模型自动地、自适应地、动态地选取合适的增强策略。 作者贡献： 简而言之，作者提出了一种即插即用的联合增强优化方法JOAO。作为一种bi-level优化框架，作者首次使用它来自动地、自适应地、动态地选取数据增强策略，并取得了比较好的实验结果。 2. 方法 先来看一下目前通用的一种图对比学习框架，作者在此基础上添加了一个可插拔的联合增强优化方法，让模型自动地、自适应地选取最合适的增强策略。 2.1 通用图对比学习框架 上图展示了通用GrapahCL的计算步骤： G∼PGG\\sim\\mathbb P_GG∼PG​表示服从分布PG\\mathbb P_GPG​的图G，A1A_1A1​和A2A_2A2​表示两种随机增强策略，增强策略集合表示为A={NodeDrop,Subgraph,EdgePert,AttrMask,Identical}\\mathcal A=\\{NodeDrop,Subgraph,EdgePert,AttrMask,Identical\\}A={NodeDrop,Subgraph,EdgePert,AttrMask,Identical}，并且A∈A:G→GA\\in\\mathcal A:\\mathcal G\\rightarrow\\mathcal GA∈A:G→G。 通过增强策略得到两个不同视图后，使用GNN计算节点嵌入，在通过转换函数将特征映射到对比空间计算对比损失： min⁡θL(G,A1, A2,θ)=min⁡θ{(−EPG×P(A1, A2)sim⁡(Tθ,1(G),Tθ,2(G)⏞Positive pairs )+EPG×PA1log⁡(EPG,×PA2exp⁡(sim⁡(Tθ,1(G),Tθ,2(G′)⏟Negative pairs )))}(1)\\begin{aligned} &amp; \\min _{\\theta} \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right) \\\\ =&amp; \\min _{\\theta}\\left\\{\\left(-\\mathbb{E}_{\\mathbb{P}_{\\mathrm{G}} \\times \\mathbb{P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)}} \\operatorname{sim}(\\overbrace{\\mathrm{T}_{\\theta, 1}(\\mathrm{G}), \\mathrm{T}_{\\theta, 2}(\\mathrm{G})}^{\\text {Positive pairs }})\\right.\\right.\\\\ &amp;\\left.+\\mathbb{E}_{\\mathbb{P}_{\\mathbf{G}} \\times \\mathbb{P}_{\\mathbf{A}_{1}}} \\log \\left(\\mathbb{E}_{\\mathbb{P}_{G}, \\times \\mathbb{P}_{\\mathbf{A}_{2}}} \\exp \\left(\\operatorname{sim}(\\underbrace{\\mathrm{T}_{\\theta, 1}(\\mathrm{G}), \\mathrm{T}_{\\theta, 2}\\left(\\mathrm{G}^{\\prime}\\right)}_{\\text {Negative pairs }})\\right)\\right)\\right\\} \\end{aligned}\\tag 1 =​θmin​L(G,A1​, A2​,θ)θmin​⎩⎪⎨⎪⎧​⎝⎜⎛​−EPG​×P(A1​, A2​)​​sim(Tθ,1​(G),Tθ,2​(G)​Positive pairs ​)+EPG​×PA1​​​log⎝⎜⎜⎛​EPG​,×PA2​​​exp⎝⎜⎜⎛​sim(Negative pairs Tθ,1​(G),Tθ,2​(G′)​​)⎠⎟⎟⎞​⎠⎟⎟⎞​⎭⎪⎪⎬⎪⎪⎫​​(1) 其中simsimsim表示余弦相似度函数。现有的GraphCL框架中，增强策略还需要人工手动选择。 2.2 JOAO框架 2.2.1 优化框架 2.1节公式1定义的损失存在两个弊端：一是需要基于先验知识预定义增强策略分布PA1,A2\\mathbb P_{A_1,A_2}PA1​,A2​​，二是只使用了Dirac分布（即每个数据集只采用了一对增强策略）。 作者提出了一种新方法，通过下列双层优化框架，来动态地、自动地学习PA1,A2\\mathbb P_{A_1,A_2}PA1​,A2​​： min⁡θL(G,A1, A2,θ) s.t. P(A1, A2)∈arg⁡min⁡P(A1′,A2′)D(G,A1′,A2′,θ)(2)\\begin{array}{l} \\min _{\\theta} \\quad \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right)\\\\ \\text { s.t. } \\quad \\mathbb{P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)} \\in \\arg \\min _{\\mathbb{P}_{\\left(A_{1}^{\\prime}, \\mathrm{A}_{2}^{\\prime}\\right)}} \\mathcal{D}\\left(\\mathrm{G}, \\mathrm{A}_{1}^{\\prime}, \\mathrm{A}_{2}^{\\prime}, \\theta\\right) \\end{array}\\tag 2 minθ​L(G,A1​, A2​,θ) s.t. P(A1​, A2​)​∈argminP(A1′​,A2′​)​​D(G,A1′​,A2′​,θ)​(2) 作者称上述公式为联合增强优化（JOAO），即将增强策略分布添加到优化函数中。公式2第一层目标L\\mathcal LL和通用GraphCL框架目标一致，第二层目标D\\mathcal DD联合优化采样分布PA1,A2\\mathbb P_{A_1,A_2}PA1​,A2​​用于增强策略选择。 2.2.2 实例化框架 作者受对抗训练的启发，将上述优化框架实例化为Min-Max Optimization形式： min⁡θL(G,A1, A2,θ) s.t. P(A1, A2)∈arg⁡max⁡P(A1′,A2′){L(G,A1′,A2′,θ)−γ2dist⁡(P(A1′,A2′),Pprior )}(3)\\begin{array}{l} \\min _{\\theta} \\quad \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right) \\\\ \\text { s.t. } \\quad \\mathbb{P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)} \\in \\arg \\max _{\\mathbb{P}_{\\left(\\mathrm{A}_{1}^{\\prime}, \\mathrm{A}_{2}^{\\prime}\\right)}}\\left\\{\\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}^{\\prime}, \\mathrm{A}_{2}^{\\prime}, \\theta\\right)\\right. \\\\ \\left.\\quad-\\frac{\\gamma}{2} \\operatorname{dist}\\left(\\mathbb{P}_{\\left(\\mathrm{A}_{1}^{\\prime}, \\mathrm{A}_{2}^{\\prime}\\right)}, \\mathbb{P}_{\\text {prior }}\\right)\\right\\} \\end{array}\\tag 3 minθ​L(G,A1​, A2​,θ) s.t. P(A1​, A2​)​∈argmaxP(A1′​,A2′​)​​{L(G,A1′​,A2′​,θ)−2γ​dist(P(A1′​,A2′​)​,Pprior ​)}​(3) 其中γ∈R≥0\\gamma \\in \\mathcal{R}_{\\geq 0}γ∈R≥0​， Pprior\\mathbb P_{prior}Pprior​表示增强策略先验分布，dist:P×P→R≥0dist:\\mathcal{P} \\times \\mathcal{P} \\rightarrow \\mathcal{R}_{\\geq 0}dist:P×P→R≥0​ 表示两个分布之间的距离函数。本文作者设定Pprior\\mathbb P_{prior}Pprior​为均匀分布，dist(⋅,⋅)dist(·,·)dist(⋅,⋅)选用平方欧氏距离。这样有 dist⁡(P(A1, A2),Pprior )=∑i=1∣A∣∑j=1∣A∣(pij−1∣A∣2)2\\operatorname{dist}\\left(\\mathbb{P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)}, \\mathbb{P}_{\\text {prior }}\\right)=\\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}|}\\left(p_{i j}-\\frac{1}{|\\mathcal{A}|^{2}}\\right)^{2}dist(P(A1​, A2​)​,Pprior ​)=∑i=1∣A∣​∑j=1∣A∣​(pij​−∣A∣21​)2。 2.2.3 目标优化方法 (这块关于下层优化涉及到的数学知识比较多，看的不是很懂。感兴趣的同学可以阅读原文，自行验证下作者的推理过程。) 模型损失优化伪代码如下图所示： 上层最小化对比损失 采用上一层增强策略分布，优化GNNs参数： θ(n)=θ(n−1)−α′∇θL(G,A1, A2,θ)(4)\\theta^{(n)}=\\theta^{(n-1)}-\\alpha^{\\prime} \\nabla_{\\theta} \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right)\\tag 4 θ(n)=θ(n−1)−α′∇θ​L(G,A1​, A2​,θ)(4) 下层最大化增强策略采样 （这块公式转换、推导看的不是很懂，感兴趣可以看原文） 直接对下层采样分布进行优化不太好操作，作者将公式1重新转换成： L(G,A1, A2,θ)=∑i=1∣A∣∑j=1∣A∣ Targeted pij⏞{−EP6sim⁡(Tθi(G),Tθj(G))+EP6log⁡(∑j′=1∣A∣pj′⏟Undesired EPG,exp⁡(sim⁡(Tθi(G),Tθj′(G′))))}(5)\\begin{array}{l} \\begin{array}{c} \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right)=\\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}| \\text { Targeted }} \\overbrace{p_{i j}}\\left\\{-\\mathbb{E}_{\\mathbb{P}_{6}} \\operatorname{sim}\\left(T_{\\theta}^{i}(\\mathrm{G}), T_{\\theta}^{j}(\\mathrm{G})\\right)\\right. \\\\ \\left.+\\mathbb{E}_{\\mathbb{P}_{6}} \\log (\\sum_{j^{\\prime}=1}^{|\\mathcal{A}|} \\underbrace{p_{j^{\\prime}}}_{\\text {Undesired }} \\mathbb{E}_{\\mathbb{P}_{G}}, \\exp \\left(\\operatorname{sim}\\left(T_{\\theta}^{i}(\\mathrm{G}), T_{\\theta}^{j^{\\prime}}\\left(G^{\\prime}\\right)\\right)\\right))\\right\\} \\end{array}\\\\ \\end{array}\\tag 5 L(G,A1​, A2​,θ)=∑i=1∣A∣​∑j=1∣A∣ Targeted ​pij​​{−EP6​​sim(Tθi​(G),Tθj​(G))+EP6​​log(∑j′=1∣A∣​Undesired pj′​​​EPG​​,exp(sim(Tθi​(G),Tθj′​(G′))))⎭⎪⎬⎪⎫​​​(5) 其中Tθi=Ai∘fθ′∘gθ′′,(i=1,…,5)T_{\\theta}^{i}=A^{i} \\circ f_{\\theta^{\\prime}} \\circ g_{\\theta^{\\prime \\prime}},(i=1, \\ldots, 5)Tθi​=Ai∘fθ′​∘gθ′′​,(i=1,…,5)表示特征提取器， pj′=pj=Prob⁡(A2=Aj)p_{j^{\\prime}}=p_{j}=\\operatorname{Prob}\\left(A_{2}=A^j\\right)pj′​=pj​=Prob(A2​=Aj) 。 然后作者再通过Jensen不等式对目标函数进行数值近似： L(G,A1, A2,θ)≈∑i=1∣A∣∑j=1∣A∣pij⏞Targeted ℓ(G,Ai,Aj,θ)=∑i=1∣A∣∑j=1∣A∣pij{−EPGsim⁡(Tθi(G),Tθj(G))+EPGlog⁡(EPG′cxp⁡(sim⁡(Tθi(G),Tθj(G′))))}(7)\\begin{aligned} &amp; \\mathcal{L}\\left(\\mathrm{G}, \\mathrm{A}_{1}, \\mathrm{~A}_{2}, \\theta\\right) \\approx \\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}|} \\overbrace{p_{i j}}^{\\text {Targeted }} \\ell\\left(\\mathrm{G}, A^{i}, A^{j}, \\theta\\right) \\\\ =&amp; \\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}|} p_{i j}\\left\\{-\\mathbb{E}_{\\mathrm{P}_{G}} \\operatorname{sim}\\left(T_{\\theta}^{i}(\\mathrm{G}), T_{\\theta}^{j}(\\mathrm{G})\\right)\\right.\\\\ &amp;\\left.+\\mathbb{E}_{\\mathbb{P}_{\\mathrm{G}}} \\log \\left(\\mathbb{E}_{\\mathrm{P}_{G^{\\prime}}} \\operatorname{cxp}\\left(\\operatorname{sim}\\left(T_{\\theta}^{i}(\\mathrm{G}), T_{\\theta}^{j}\\left(\\mathrm{G}^{\\prime}\\right)\\right)\\right)\\right)\\right\\} \\end{aligned}\\tag 7 =​L(G,A1​, A2​,θ)≈i=1∑∣A∣​j=1∑∣A∣​pij​​Targeted ​ℓ(G,Ai,Aj,θ)i=1∑∣A∣​j=1∑∣A∣​pij​{−EPG​​sim(Tθi​(G),Tθj​(G))+EPG​​log(EPG′​​cxp(sim(Tθi​(G),Tθj​(G′))))}​(7) 这样公式3中下层优化公式可以重写成： P(A1, A2)∈arg⁡max⁡p∈P,p=[pij],i,j=1,…,∣A∣{ψ(p)}ψ(p)=∑i=1∣A∣∑j=1∣A∣pijℓ(G,Ai,Aj,θ)−γ2∑i=1∣A∣∑j=1∣A∣(pij−1∣A∣2)2,(8)\\begin{array}{l} \\mathbb{P}_{\\left(\\mathrm{A}_{1}, \\mathrm{~A}_{2}\\right)} \\in \\arg \\max _{p \\in \\mathcal{P}, p=\\left[p_{i j}\\right], i, j=1, \\ldots,|\\mathcal{A}|}\\{\\psi(\\boldsymbol{p})\\}\\\\ \\psi(\\boldsymbol{p})=\\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}|} p_{i j} \\ell\\left(\\mathrm{G}, A^{i}, A^{j}, \\theta\\right)-\\frac{\\gamma}{2} \\sum_{i=1}^{|\\mathcal{A}|} \\sum_{j=1}^{|\\mathcal{A}|}\\left(p_{i j}-\\frac{1}{|\\mathcal{A}|^{2}}\\right)^{2},\\\\ \\end{array}\\tag 8 P(A1​, A2​)​∈argmaxp∈P,p=[pij​],i,j=1,…,∣A∣​{ψ(p)}ψ(p)=∑i=1∣A∣​∑j=1∣A∣​pij​ℓ(G,Ai,Aj,θ)−2γ​∑i=1∣A∣​∑j=1∣A∣​(pij​−∣A∣21​)2,​(8) 2.3 增强感知多映射头——JOAOv2 JOAO虽然可以动态选取最优的增强策略但是也存在一个弊端：即和使用单重类型增强策略相比，JOAO中不停变换增强策略会导致生成的图过度偏离原始分布。具体提出了一种新的策略： 具体来说，构建∣A∣|\\mathcal A|∣A∣个映射头，分别对应于某种增强策略。在训练过程中，选中某种增强策略后，映射头也改成该增强策略相对应的映射头。如下表2所示，在不进行各种显示调参情况下向，JOAOv2的性能要优于JOAO。 3. 实验 3.1 Sanity Check 这一部分算是可解释性试验。作者希望通过实验验证：针对每个数据集，JOAO自动选取的增强策略对是否合理。具体来说，作者将JOAO训练过程中选取各种增强策略所占比例可视化，和试错法选取增强策略的结果进行对比。实验结果如下图3所示： 第一行：表示JOAO训练过程中各种augmentation pair所占百分比，值越大说明该种增强组合和数据集越匹配。 第二行：手动设置各种类型增强策略组合，模型性能变化情况。同样地，值越大，说明该种组合越适合该数据集。值为负数，说明这种组合完全不适合该数据集，会降低模型性能。 对比两行数据，可以发现第二行中蓝色方块在第一行中对应位置基本都是0，说明JOAO模型基本不会选取不适合当前数据集的增强策略组合。另外，第二行中数值较高的方块，在第一行对应位置的数值也会更高。因此，可以看出JOAO自动选取的增强策略组合是合理的。 3.2 对比实验 该部分实验发现可以总结为： 在各类数据集上，JOAO的表现和手动调整的GraphCL方法表现相当。 带有增强感知映射头的JOAOv2可以进一步提升模型性能，有时甚至优于GraphCL方法比如生物邻域数据集。 和GraphCL一样，JOAOv2也可以扩展到大规模数据集上，与较小数据集相比，有时性能更好。 3.2.1 TUDataset 下表4、表5分别展示了半监督、无监督学习结果。 JOAO和人工试错确定增强策略的GraphCL性能具有可比性 JOAOv2性能优于JOAO，说明增强感知多映射头可以提高模型性能 JOAOv2性能优于GraphCL，平均排名1.8低于GraphCL的2.4 3.2.2 生物数据集 对于特定邻域，由于JOAOv2是一种通用框架，没有编码该领域特定知识，因此性能会低于一些专门用于该领域的启发式自监督方法。因此，为了提高JOAOv2竞争力，将邻域知识引入该框架是未来可能的一个研究方向。 由于泛化性能更好，对于unseen数据集，JOAOv2的性能要优于GraphCL 3.2.3 大规模OGB数据集","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"自适应","slug":"自适应","permalink":"http://rookieyin.github.io/tags/%E8%87%AA%E9%80%82%E5%BA%94/"}]},{"title":"Contrastive Multi-View Representation Learning on Graphs","slug":"3 论文笔记/图学习/对比学习/3.Contrastive Multi-View Representation Learning on Graphs","date":"2021-08-22T14:06:38.000Z","updated":"2021-09-28T02:36:55.775Z","comments":true,"path":"5ae71cf10c2f/","link":"","permalink":"http://rookieyin.github.io/5ae71cf10c2f/","excerpt":"http://proceedings.mlr.press/v119/hassani20a/hassani20a.pdf https://github.com/kavehhassani/mvgrl Contrastive Multi-View Representation Learning on Graphs ，2020，ICML 总结：这篇文章应该算是图对比学习中非常值得一看的文章，个人感觉创新性比较强。作者从多视角入手，提出了一种新的多视角图对比学习模型，通过跨视角对比来训练模型，学习更好的节点/图表示，用于下游任务。文章的实验比较丰富，探讨了多种对比策略和视角组合，实验结果也非常棒，无论在节点分类还是图分类任务中，和无监督方法相比性能都取得了较大提升，和无监督方法也具有可比性。","text":"http://proceedings.mlr.press/v119/hassani20a/hassani20a.pdf https://github.com/kavehhassani/mvgrl Contrastive Multi-View Representation Learning on Graphs ，2020，ICML 总结：这篇文章应该算是图对比学习中非常值得一看的文章，个人感觉创新性比较强。作者从多视角入手，提出了一种新的多视角图对比学习模型，通过跨视角对比来训练模型，学习更好的节点/图表示，用于下游任务。文章的实验比较丰富，探讨了多种对比策略和视角组合，实验结果也非常棒，无论在节点分类还是图分类任务中，和无监督方法相比性能都取得了较大提升，和无监督方法也具有可比性。 1. 简介 1.1 摘要 We introduce a self-supervised approach for learning node and graph level representations by contrasting structural views of graphs. We show that unlike visual representation learning, increasing the number of views to more than two or contrasting multi-scale encodings do not improve performance, and the best performance is achieved by contrasting encodings from first-order neighbors and a graph diffusion. We achieve new state-of-the-art results in self supervised learning on 8 out of 8 node and graph classification benchmarks under the linear evaluation protocol. For example, on Cora (node) and Reddit-Binary (graph) classification benchmarks, we achieve 86.8% and 84.5% accuracy, which are 5.5% and 2.4% relative improvements over previous state-of-the-art. When compared to supervised baselines, our approach outperforms them in 4 out of 8 benchmarks. 本文我们介绍了一种自监督节点/图表示学习方法，通过对比图的不同views来学习节点/图表示。我们发现，和视觉领域表示学习不同，增加views数量（超过2个）或者对比多个尺度encoding不能提高模型性能。模型最好的性能是在对比一阶邻域和单个图diffusion时得到的。在8个节点/图分类标准数据集上，我们的方法都取得了最优表现。例如在Cora和Reddit-Binary数据及上，我们分别获得了86.8%和84.55准确度，比当前最好方法分别搞5.5%和2.4%。和有监督方法相比，我们的方法在4个数据集上表现更优。 1.2 本文工作 （这块作者背景、动机什么的感觉写的不太行。准确来说大概的背景和动机应该是：GNNs大多都是有监督模型，对于无监督图学习模型比较少，其中图对比学习比较火性能也比较好。但是，现有图对比学习大多都是单一视角下的对比，多视角下的无监督图学习没有采用对比学习比如deep graph infomax，这些模型存在一些弊端。这些弊端也就是作者文中所说的。） 背景： 近年来GNNs被广泛应用于图学习各个邻域，但是大多数GNNs都需要task-dependent labels来学习好的表示。但是和视频、文本、图像相比，图数据的标签标注代价更大，需要更多的领域知识，比如分子图。为了解决这一问题，人们提出了一些不需要依赖标签数据的无监督GNNs，比如变分自编码器、对比模型等。 动机： 现有的图对比学习模型通过对比学习最大化节点和图表示之间的互信息（MI），在节点/图分类任务上取得了最优效果，但是这些方法需要具体的编码器来学习图或者节点表示。（没有看过这些方法原文，可能这些方法只能使用特定的encoders，这个就是作者本文中需要解决的问题） 本文工作： 作者参考CV中的multi-view对比学习，提出了图上的多视角对比学习框架。作者在研究该框架过程中得到了一些有趣的结果：（1）增加对比学习中views的数量不会提升模型性能；（2）跨views对比节点和图表示效果更好；（3）相比于复杂的graph pool方法，比如DiffPool，简单的graph-readout函数效果更好；（4）添加正则化或者归一化会降低模型性能。基于这些发现，作者提出的多视角对比学习框架在8个数据集上都取得了最优表现，并且和有监督学习方法也具有可比性。 2. 方法 作者受计算机视觉中多视角对比学习的启发，通过最大化当前view的节点表示和另一个view的图表示之间的MI值来训练模型。如上图1所示，作者的模型包含四个组件： 数据增强机制： 基于某种数据增强策略得到两个graph view，然后进行图采样得到子图。 GNNs encoder： 两个GNNs分别用于两个view，不过两个GNNs的最后一层MLP层共享参数。（这样确保将特征向量映射到同一个对比空间） 图池化层： 根据节点特征计算整图表示向量，本文作者采用简单的MLP计算图特征向量。（这里没有采用复杂的图池化技术，比如DiffPool，因为作者实验中发现使用简单的MLP性能更好） 判别器： 交叉对比两个view中节点表示和图表示，最大化两者之间的MI值。 下面详细介绍下模型详细细节。 2.1 数据增强策略 针对图数据，作者考虑两种增强策略： 特征增强，比如mask特征向量部分维度或者添加一些高斯噪声。 结构增强，通过增删图中部分边，子图采样或者使用最短距离或扩散矩阵生成全局视图等方法，对图结构进行破话和增强。 第一种增强策略在节点没有初始特征的情况下无法使用，并且作者发现给节点特征增加噪声或者mask部分维度会导致模型性能降低。因此，作者在本文中选取sub-sampling方式生成global view。 作者在实验中发现：将邻接矩阵转换成diffusion矩阵，并把这两个矩阵看做congruent views效果最好。作者猜测可能是邻接矩阵和扩散矩阵分别提供了图结构的局部和全局视图，最大化从这两个视图中学习到的表示的一致性可以让模型同时编码丰富的局部和全局信息。 具体来说，本文作者首先的是“ Diffusion improves graph learning ”一文中的Diffusion 策略： S=∑k=0∞ΘkTk∈Rn×n\\mathbf{S}=\\sum_{k=0}^{\\infty} \\Theta_{k} \\mathbf{T}^{k} \\in \\mathbb{R}^{n \\times n} S=k=0∑∞​Θk​Tk∈Rn×n 其中T∈Rn×n\\mathbf T\\in\\mathbb R^{n\\times n}T∈Rn×n表示转换矩阵，Θ\\ThetaΘ表示权重系数（它决定了global-local信息比例），T=AD−1\\mathbf{T=AD^{-1}}T=AD−1，θk=α(1−α)k\\theta_{k}=\\alpha(1-\\alpha)^{k}θk​=α(1−α)k，θk=e−ttk/k!\\theta_{k}=e^{-t} t^{k} / k !θk​=e−ttk/k!。更详细的Diffusion策略可以查看原文。类似的，与heat、PPR相对应的diffusion计算方法如下： Sheat =exp⁡(tAD−1−t)SPPR=α(In−(1−α)D−1/2AD−1/2)−1\\begin{array}{c} \\mathbf{S}^{\\text {heat }}=\\exp \\left(t \\mathbf{A} \\mathbf{D}^{-1}-t\\right) \\\\ \\mathbf{S}^{\\mathrm{PPR}}=\\alpha\\left(\\mathbf{I}_{n}-(1-\\alpha) \\mathbf{D}^{-1 / 2} \\mathbf{A D}^{-1 / 2}\\right)^{-1} \\end{array} Sheat =exp(tAD−1−t)SPPR=α(In​−(1−α)D−1/2AD−1/2)−1​ 作者在后面消融实验中探讨了不同类型diffusion策略对模型性能的影响。 2.2 GNNs编码器 作者采用通用的GCN作为基本图编码器，如前文图1所示，其计算步骤如下： gθ(.),gω(.):Rn×dx×Rn×n⟼Rn×dhg_{\\theta}(.), g_{\\omega}(.): \\mathbb{R}^{n \\times d_{x}} \\times \\mathbb{R}^{n \\times n} \\longmapsto\\mathbb{R}^{n \\times d_h}gθ​(.),gω​(.):Rn×dx​×Rn×n⟼Rn×dh​，两套GCN分别计算两个视角下节点表示。 fψ(.):Rn×dh⟼Rn×dhf_{\\psi}(.): \\mathbb{R}^{n \\times d_{h}} \\longmapsto \\mathbb{R}^{n \\times d_{h}}fψ​(.):Rn×dh​⟼Rn×dh​，由两层MLP+PReLU组成的映射头，将节点特征映射到对比空间。需要注意的是，两个视角共享同一个映射头。 Pool+MLP计算图表示，P(.):Rn×dh⟼Rdh\\mathcal{P}(.): \\mathbb{R}^{n \\times d_{h}} \\longmapsto \\mathbb{R}^{d_{h}}P(.):Rn×dh​⟼Rdh​为graph readout函数，得到图表示后传给MLP fϕ(.):Rdh⟼Rdhf_{\\phi}(.): \\mathbb{R}^{d_{h}} \\longmapsto\\mathbb{R}^{d_{h}}fϕ​(.):Rdh​⟼Rdh​。同样，两个视角下的MLP共享参数。 在预测时，作者将两个view下的嵌入相加用于下游任务，即h⃗=h⃗gα+h⃗gβ∈Rn\\vec{h}=\\vec{h}_{g}^{\\alpha}+\\vec{h}_{g}^{\\beta} \\in \\mathbb{R}^{n}h=hgα​+hgβ​∈Rn 和H=Hα+Hβ∈Rn×dh\\mathbf{H}=\\mathbf{H}^{\\alpha}+\\mathbf{H}^{\\beta} \\in \\mathbb{R}^{n \\times d_{h}}H=Hα+Hβ∈Rn×dh​分别作为最终节点嵌入和图嵌入用于下游任务。 2.3 模型训练 作者还是利用deep InfoMax中的方法，最大化两个视图间的MI： max⁡θ,ω,ϕ,ψ1∣G∣∑g∈G[1∣g∣∑i=1∣g∣[MI⁡(h⃗iα,h⃗gβ)+MI⁡(h⃗iβ,h⃗gα)]]\\max _{\\theta, \\omega, \\phi, \\psi} \\frac{1}{|\\mathcal{G}|} \\sum_{g \\in \\mathcal{G}}\\left[\\frac{1}{|g|} \\sum_{i=1}^{|g|}\\left[\\operatorname{MI}\\left(\\vec{h}_{i}^{\\alpha}, \\vec{h}_{g}^{\\beta}\\right)+\\operatorname{MI}\\left(\\vec{h}_{i}^{\\beta}, \\vec{h}_{g}^{\\alpha}\\right)\\right]\\right] θ,ω,ϕ,ψmax​∣G∣1​g∈G∑​⎣⎢⎡​∣g∣1​i=1∑∣g∣​[MI(hiα​,hgβ​)+MI(hiβ​,hgα​)]⎦⎥⎤​ 作者直接计算两个向量间的点乘作为MI值，整个模型伪代码如下： 3. 实验 数据集： Citesser、Cora、Pubmed用于节点分类，MUTAG、PTC、Reddit-Binary、IMDB-Binary和IMDB-Multi用于图分类。 评价指标： 采用SOTA模型中的方法，具体来说，节点分类任务中采用DGI模型中使用的方法，图分类任务中采用InfoGrapp模型中使用的方法。 3.1 基础对比实验 上表2展示了三个数据集上节点分类任务中各个模型的表现，可以发现无论和有监督还是无监督方法相比，作者提出的模型都取得了最优表现。 从上表3可以发现，在节点聚类任务中，作者提出的模型依旧取得了最优表现。 从上表4可以发现，在图分类任务中，和Kernel、无监督方法相比，作者提出的方法取得了最优表现。和有监督方法相比，作者提出的模型在这五个数据集上也具有一定可比性。 3.2 消融实验 作者进行了三类消融实验：MI计算方法，对比模式和views组合。实验结果如下表5所示： MI计算方法 作者对比了NCE、JSD、NT-XENT和DV四种方法，可以看到在节点分类任务上四者性能差不多，但是在图分类任务上JSD在5个数据集上的表现都是最好的。 对比模式 local-global： 对deep InfoMax的扩展，对比node encodings和另外一个视图中的graph encodings。 global-global： 对比两个view下的graph encodings。 multi-scale： 所谓多尺度，即将一个视图下的图编码和另一个视图下的中间编码进行对比，反之亦然。对于节点编码也同样如此。 hybrid： 混合型，即同时使用local-global和global-global。 ensemble： 两个视图下，节点和图编码都和本视图下的编码作对比 从上表5的实验结果可以看到，local-global对比模式性能最好。 views组合 作者对比了多种views组合，从实验结果看ADJ-PPR两个views下进行对比效果最好。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"多视角","slug":"多视角","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E8%A7%86%E8%A7%92/"}]},{"title":"Graph Contrastive Learning with Augmentations","slug":"3 论文笔记/图学习/对比学习/2.Graph Contrastive Learning with Augmentations","date":"2021-08-17T12:11:54.000Z","updated":"2021-09-28T02:36:52.586Z","comments":true,"path":"9d9b31282eff/","link":"","permalink":"http://rookieyin.github.io/9d9b31282eff/","excerpt":"https://arxiv.org/pdf/2010.13902 https://github.com/Shen-Lab/GraphCL Graph Contrastive Learning with Augmentations ，2020，NIPS 总结：作者认为图学习领域，由于数据集巨大，并且GNNs由于过拟合问题往往层数很浅，因此研究GNNs下的预训练技术十分有必要。针对图分类下的预训练技术，作者的贡献主要有两个：一是仿照CV中的数据增强，提出了四种图数据增强策略；二是提出了一个新的图对比学习框架GraphCL。另外值得一提的是，作者通过实验对四种图数据增强策略进行了很多更细致的研究，得出了一些有趣的结论。","text":"https://arxiv.org/pdf/2010.13902 https://github.com/Shen-Lab/GraphCL Graph Contrastive Learning with Augmentations ，2020，NIPS 总结：作者认为图学习领域，由于数据集巨大，并且GNNs由于过拟合问题往往层数很浅，因此研究GNNs下的预训练技术十分有必要。针对图分类下的预训练技术，作者的贡献主要有两个：一是仿照CV中的数据增强，提出了四种图数据增强策略；二是提出了一个新的图对比学习框架GraphCL。另外值得一提的是，作者通过实验对四种图数据增强策略进行了很多更细致的研究，得出了一些有趣的结论。 1. 简介 1.1 摘要 Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We first design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in preliminary experiments. Our codes are available at: https://github.com/Shen-Lab/GraphCL. 对于现有的GNNs，获取图结构数据通用的、可迁移的、稳定的特征表示仍然具有很大挑战。和用于图像数据的CNNs不同，很少有工作探索在GNNs中使用自监督学习和预训练。本文作者提出了一种用于无监督图表示学习的图对比学习框架GraphCL。我们首先设计了四种图增强类型，可以整合不同类型先验知识。然后在四种不同设定下（半监督、无监督、迁移学习和对抗攻击），我们在多个数据集上系统研究了这些增强方式间各种组合，对模型性能的影响。实验结果表明，即使不微调数据增强范围，也不实用复杂GNN架构，和当前最优方法相比，我们的GraphCL框架也能得到相当或者更好的泛化能力、可迁移能力以及稳定性。我们还研究了图增强的范围、形式对模型的影响，并在初步试验中得到了更好的实验结果。 1.2 本文工作 背景： GNNs在图学习领域应用十分广泛，研究人员提出了各种变体用于链路预测、图分类、链路分类等任务，取得了SOTA性能。但是在graph-level任务场景下，GNNs大多采用端到端的有监督方式训练，很少有工作探索GNNs下的自监督预训练技术。这背后的原因可能是人们研究的图数据集经常受限于size，并且GNNs为了避免过平滑问题，通常层数比较浅。 动机： 作者认为探索GNN下的pre-training shemes十分有必要。一方面，对于图数据集来说Task-specific标签通常比较稀疏（比如在生物、化学领域，标签获取代价比较大），而pre-training就像在CV中一样，刚好可以缓解这一问题带来的影响。另一方面，预训练对于GNNs必要性的两个可能原因是：1. 现实世界中图数据集通常非常庞大；2. 预训练可以让模型有一个更好的初始化参数，提高模型泛化能力。基于上面的分析，作者认为在GNN中使用pre-training技术十分有必要。 挑战： 和CV这种规则的序列化数据不同，图数据含有和各种不同上下文相关的结构信息，因此很难设计一个对下游任务普遍有益的GNN预训练方案。一种用于图层级任务的原生GNN预训练方案就是重构图的邻接矩阵（比如GAE和GraphSAGE）。但是这种方法限制很多，因为它过度强调的proximity并不总是有益的，可能会损害结构信息。因此一种设计有效的预训练框架应该能够捕获图结构数据中高度异构信息。 本文工作： 本文作者提出了一种用于GNN预训练的对比学习方法，解决图中数据异构带来的挑战。具体来说，本文贡献如下：（1）设计了四种数据增强模式，每一种模式都整合了特定的先验知识；（2）利用数据增强得到不同的graph views，基于这些提出了一种新的图对比学习框架GraphCL用于GNN预训练。 2. 方法 2.1 数据增强 数据增强，即通过在原始数据上施加某种变换得到新的数据，但是不改变数据的语义标签。比如在CV中将图像数据进行剪切、旋转等操作得到新的图像，这样可以在模型中强制编码一些图像相关的先验知识（从旋转图像、局部图像中获取到的）。借鉴图像中的增强模式，本文作者针对graph-level数据增强提出了四种数据增强策略： Node dropping: 随机删除图中部分节点，每个节点被删除的概率遵循i.i.d分布。 Edge perturbation： 随机删除、增加图中的边，增加/删除概率同样遵循i.i.d分布。 Attribute masking： 用0 mask掉节点特征向量部分维度属性。 Subgraph： 利用随机游走从图G\\mathcal GG中采样子图。 2.2 GraphCL框架 作者提出的GraphCL框架如下图1所示： GraphCL主要包含四个组件： 图数据增强： 利用前文提到的数据增强策略得到两个graph views G^i\\hat{\\mathcal G}_iG^​i​和G^j\\hat{\\mathcal G}_jG^​j​，其中G^i∼qi(⋅∣G),G^j∼qj(⋅∣G)\\hat{\\mathcal{G}}_{i} \\sim q_{i}(\\cdot \\mid \\mathcal{G}), \\hat{\\mathcal{G}}_{j} \\sim q_{j}(\\cdot \\mid \\mathcal{G})G^​i​∼qi​(⋅∣G),G^​j​∼qj​(⋅∣G)。 GNN-based编码器： 用于计算两个graph view下graph-level特征嵌入，hi\\mathbb h_ihi​和hj\\mathbb h_jhj​分别的应用图 G^i\\hat{\\mathcal G}_iG^​i​和G^j\\hat{\\mathcal G}_jG^​j​。 映射头： 即非线性变换g(⋅)g(·)g(⋅)，将特征向量映射到对比损失空间，在图对比学习中通常使用一个两层MLP，得到zi\\mathbb z_izi​和zj\\mathbb z_jzj​。 对比损失函数： 对比目标就是最大化两个graph view对应的zi\\mathbb z_izi​和zj\\mathbb z_jzj​之间的一致性。预训练期间，每个minibatch采用N个图，数据增强后可以得到2N个图，用zn,iz_{n,i}zn,i​和zn,jz_{n,j}zn,j​表示该batch下的第n张图。第n张图下的损失定义为： ℓn=−log⁡exp⁡(sim⁡(zn,i,zn,j)/τ)∑n′=1,n′≠nNexp⁡(sim⁡(zn,i,zn′,j)/τ)\\ell_{n}=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(\\boldsymbol{z}_{n, i}, \\boldsymbol{z}_{n, j}\\right) / \\tau\\right)}{\\sum_{n^{\\prime}=1, n^{\\prime} \\neq n}^{N} \\exp \\left(\\operatorname{sim}\\left(\\boldsymbol{z}_{n, i}, \\boldsymbol{z}_{n^{\\prime}, j}\\right) / \\tau\\right)} ℓn​=−log∑n′=1,n′​=nN​exp(sim(zn,i​,zn′,j​)/τ)exp(sim(zn,i​,zn,j​)/τ)​ 其中sim⁡(zn,i,zn,j)=zn,i∣zn,j/∥zn,i∥∥zn,j∥\\operatorname{sim}\\left(\\boldsymbol{z}_{n, i}, \\boldsymbol{z}_{n, j}\\right)=\\boldsymbol{z}_{n, i}^{\\mid} \\boldsymbol{z}_{n, j} /\\left\\|\\boldsymbol{z}_{n, i}\\right\\|\\left\\|\\boldsymbol{z}_{n, j}\\right\\|sim(zn,i​,zn,j​)=zn,i∣​zn,j​/∥zn,i​∥∥zn,j​∥表示余弦距离函数，τ\\tauτ为温度参数。最终整体损失应该类似n张图损失之和（原文说间附录A，但是没找到带附录版本论文原文）。 另外，GraphCL的整体损失可以重写成下面形式： ℓ=EPGi{−EP(Gj∣Gi)T(f1(G^i),f2(G^j))+log⁡(EPGjeT(f1(G^i),f2(G^j)))}\\ell=\\mathbb{E}_{\\mathbb{P}_{\\mathcal{G}_{i}}}\\left\\{-\\mathbb{E}_{\\mathbb{P}_{\\left(\\mathcal{G}_{j} \\mid \\mathcal{G}_{i}\\right)}} T\\left(f_{1}\\left(\\hat{\\mathcal{G}}_{i}\\right), f_{2}\\left(\\hat{\\mathcal{G}}_{j}\\right)\\right)+\\log \\left(\\mathbb{E}_{\\mathbb{P}_{\\mathcal{G}_{j}}} e^{T\\left(f_{1}\\left(\\hat{\\mathcal{G}}_{i}\\right), f_{2}\\left(\\hat{\\mathcal{G}}_{j}\\right)\\right)}\\right)\\right\\} ℓ=EPGi​​​{−EP(Gj​∣Gi​)​​T(f1​(G^​i​),f2​(G^​j​))+log(EPGj​​​eT(f1​(G^​i​),f2​(G^​j​)))} 上面的损失其实是最大化了hi\\mathcal h_ihi​和hj\\mathbb h_jhj​之间mutual information的下界。（原文说在附录里面有详细解释，同上，没找到带附录版本原文） 2.3 数据增强在GCL中扮演的角色 这一部分主要通过实验探讨数据增强在图对比学习中究竟起多大作用？ 2.3.1 数据增强/组合数据增强 通过分析上述实验结果，可以分析得到下列结论： 数据增强在图对比学习中至关重要 观察上图2最右上角数据可以看出，不适用任何数据增强策略，模型性能受到很大影响。这是符合我们直觉的，因为不做数据增强，对比的两个图完全一样，损失中positive pair损失为0，只有negative pair 损失，这导致学习到的所有图都互相远离。 组合不同类型增强策略，收益更高 观察上图2对角线实验结果，可以看到起性能往往不是最优的，这和计算机视觉中对比学习结果是一致的。在CV中，一种猜想是组合不同的增强策略可以避免学习到的特征简单地过度拟合低级“捷径”，使学习到的特征更加泛化。 作者这里提出了一个类似的猜想，认为相比较而言，组合不同类型增强策略会让模型学习变得更加困难。为了验证这个猜想，作者对不同设定下的模型学习过程进行了可视化： 可以看到不同类型增强策略的组合收敛速度更慢，更加难以学习。 2.3.2 数据增强：类型、范围、模式 Edge perturbation对社交网络有利，但是对于生化分子数据有弊 从前文图2中可以看出，NCI数据集中使用Edge perturbation增强策略会使得模型性能大幅降低。上图4左边两幅图的实验结果和这一推断也是相吻合的。 Attribute mask对于denser graph更有益 观察上图右边两幅实验结果，可以看到对于更dense的COLLAB，属性mask收益更高。作者基于此进一步猜想mask pattern也很重要，多mask一些度高的hub节点有利于denser graphs，因为对于孤立节点，GNN难以补全其丢失信息。 为了验证这个假设，作者利用节点度计算attribute被mask的概率，实验结果如下图5右边两幅图所示： Node drop和Subgraph对各种数据集都有利 观察图2实验结果可以发现，Node drop和Subgraph对所有数据集都有利，尤其是Subgraph。 作者也测试了节点度对node drop策略的影响，实验结果如上图5左边两幅图所示，可以看到和mask attribute类似的结果。 3. 实验 这部分主要对比在半监督、无监督、迁移学习设定下，GraphCL和SOTA算法在图分类任务上的性能。 一、半监督学习 二、无监督表示学习 三、迁移学习 四、对抗鲁棒性","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"数据增强","slug":"数据增强","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Graph Contrastive Learning with Adaptive Augmentation","slug":"3 论文笔记/图学习/对比学习/1.Graph Contrastive Learning with Adaptive Augmentation","date":"2021-08-15T12:58:30.000Z","updated":"2021-09-28T02:36:48.027Z","comments":true,"path":"3ace053d12ac/","link":"","permalink":"http://rookieyin.github.io/3ace053d12ac/","excerpt":"https://arxiv.org/pdf/2010.14945 https://github.com/CRIPAC-DIG/GCA Graph Contrastive Learning with Adaptive Augmentation ，2021，WWW 总结：现有的图对比学习方法大多采用统一的数据增强策略，忽略了对数据增强策略方面的研究。作者认为现有的数据增强方式存在两个弊端：一是对于节点属性，简单的数据增强数据增强没什么效果；二是对于拓扑结构数据增强忽略了不同节点在图中影响力不同。因此作者提出了一种新的基于自适应数据增强策略的图对比学习框架GCA。实验结果虽然在大多数设定下都是最优的，但是没提高多少，给人一种调参调出来的感觉。从消融实验的结果来看，模型核心创新点带来的性能提升并不多。","text":"https://arxiv.org/pdf/2010.14945 https://github.com/CRIPAC-DIG/GCA Graph Contrastive Learning with Adaptive Augmentation ，2021，WWW 总结：现有的图对比学习方法大多采用统一的数据增强策略，忽略了对数据增强策略方面的研究。作者认为现有的数据增强方式存在两个弊端：一是对于节点属性，简单的数据增强数据增强没什么效果；二是对于拓扑结构数据增强忽略了不同节点在图中影响力不同。因此作者提出了一种新的基于自适应数据增强策略的图对比学习框架GCA。实验结果虽然在大多数设定下都是最优的，但是没提高多少，给人一种调参调出来的感觉。从消融实验的结果来看，模型核心创新点带来的性能提升并不多。 1. 简介 1.1 摘要 Recently, contrastive learning (CL) has emerged as a successful method for unsupervised graph representation learning. Most graph CL methods first perform stochastic augmentation on the input graph to obtain two graph views and maximize the agreement of representations in the two views. Despite the prosperous development of graph CL methods, the design of graph augmentation schemes—a crucial component in CL—remains rarely explored. We argue that the data augmentation schemes should preserve intrin-sic structures and attributes of graphs, which will force the model to learn representations that are insensitive to perturbation on unimportant nodes and edges. However, most existing methods adopt uniform data augmentation schemes, like uniformly dropping edges and uniformly shuffling features, leading to suboptimal performance. In this paper, we propose a novel graph contrastive representation learning method with adaptive augmentation that incorporates various priors for topological and semantic aspects of the graph. Specifically, on the topology level, we design augmentation schemes based on node centrality measures to highlight important connective structures. On the node attribute level, we corrupt node features by adding more noise to unimportant node features, to enforce the model to recognize underlying semantic information. We perform extensive experiments of node classification on a variety of real-world datasets. Experimental results demonstrate that our proposed method consistently outperforms existing state-of-the-art baselines and even surpasses some supervised counterparts, which validates the effectiveness of the proposed contrastive framework with adaptive augmentation. 近年来，对比学习成为了一种成功的用于无监督图表示学习方法。大多数图对比学习方法首先对输入图执行随机增强，得到两个graph views，然后最大化这两个views下图表示的一致性。虽然图表示学习方法发展火热，但是对于作为CL方法中的重要组件图增强模式，很少被探索。我们认为图增强模式应该保留图中固有的结构、属性信息，这样模型学习到的表示能够对抗噪声节点的扰动。但是，大多数现有方法都采用统一的数据增强模式，比如统一去掉部分边或者统一对特征进行shuffle，这导致得到的模型是次优的。本文，我们提出了一种新的图对比表示学习方法，通过结合从图拓扑结构、语义上得到的先验知识，实现自适应数据增强。具体来说，在拓扑结构维度，我们设计的增强策略是基于node centrality来寻找相对更重要的结构信息。在节点属性维度，我们通过向不重要的特征维度加入更多噪声，强制模型识别潜在的意义信息。我们在大量真实数据集上进行了节点分类实验，实验结果表明我们提出的方法优于当前最优方法，甚至超过了部分有监督学习方法，这证明了我们提出的“自适应增强对比框架”的有效性。 1.2 本文工作 背景： 过去几年，图表示学习发展火热，GNN作为最重要的图表示学习方法之一，得到了广泛关注。但是，现有的大多数GNNs都是有监督学习方法，依赖大量有标签数据。对比学习作为一种重要的无监督学习方法，最近被广泛用于图表示学习。 动机： 在CV领域，数据增强模式已经被证明了是CL方法中一个非常重要的组件，但是在图领域对于图数据增强方法探索甚少。 本文工作： 作者认为现有的图对比学习方法中数据增强模式存在两个弊端： 简单的数据增强方法比如DGI中使用的feature shifting，不足以生成diverse邻居，尤其是当节点特征很稀疏时会导致难以优化对比目标函数。 现有方法在数据增强时，忽略了不同节点影响力的差异性。比如通过均匀丢掉一些边来构造graph view，可能会删除一些影响力很大的边，导致得到的嵌入质量降低。 基于上面的分析，作者认为CL方法中的增强策略应该要和输入图动态适应，让增强后的图能够保持其固有结构。本文，作者提出了一种新的对比学习框架用于无监督图表示学习，如下图所示： 首先通过数据增强方法生成两个不同的graph view，利用对比损失训练模型，即最大化同一个节点在两个view下嵌入一致性。 2. 方法 2.1 对比学习框架 如前图1所示，作者提出的GCA框架依旧遵循通用的图对比模式，即生成两个graph view，最大化同一个节点在两个view下节点嵌入的一致性。作者提出的的GCA框架执行步骤如下： 每一轮随机采用两个增强函数t∼Tt\\sim\\mathcal Tt∼T，t′∼Tt&#x27;\\sim\\mathcal Tt′∼T，其中T\\mathcal TT表示所有可能的增强函数集合。 生成两个不同的graph views，G~1=t(G~)\\widetilde{G}_{1}=t(\\widetilde{G})G1​=t(G)，G~2=t′(G~)\\widetilde{G}_{2}=t^{\\prime}(\\widetilde{G})G2​=t′(G)。两个视图下的节点嵌入分别表示为U=f(X~1,A~1)U=f\\left(\\widetilde{X}_{1}, \\widetilde{A}_{1}\\right)U=f(X1​,A1​)，V=f(X~2,A~2)V=f\\left(\\widetilde{X}_{2}, \\widetilde{A}_{2}\\right)V=f(X2​,A2​)，其中X~∗\\widetilde{X}_{*}X∗​和A~∗\\widetilde{A}_{*}A∗​分别表示特征矩阵和邻接矩阵。 对于视图G~1\\widetilde G_1G1​下的任意一节点viv_ivi​，将其嵌入表示ui\\mathbb u_iui​视作锚点，将该节点在另一个视图下的嵌入表示vi\\mathbb v_ivi​看作正例，两个视图下的所有其他节点嵌入看作负例。最后，对于每个正例对(ui,vi)(\\mathbb{u_i,v_i})(ui​,vi​)定义如下pairwise objective： ℓ(ui,vi)=log⁡eθ(ui,vi)/τ⏟positive pair +∑k≠ieθ(ui,vk)/τ⏟inter-view negative pairs +∑k≠ieθ(ui,vi)/τ⏟intra-view negative pairs ⏟,\\begin{array}{l} \\ell\\left(u_{i}, v_{i}\\right)= \\\\ \\log \\underbrace{e \\underbrace{\\theta\\left(u_{i}, v_{i}\\right) / \\tau}_{\\text {positive pair }}+\\underbrace{\\sum_{k \\neq i} e^{\\theta\\left(u_{i}, v_{k}\\right) / \\tau}}_{\\text {inter-view negative pairs }}+\\underbrace{\\sum_{k \\neq i} e^{\\theta\\left(u_{i}, v_{i}\\right) / \\tau}}_{\\text {intra-view negative pairs }}}, \\end{array} ℓ(ui​,vi​)=logepositive pair θ(ui​,vi​)/τ​​+inter-view negative pairs k​=i∑​eθ(ui​,vk​)/τ​​+intra-view negative pairs k​=i∑​eθ(ui​,vi​)/τ​​​,​ 其中τ\\tauτ为温度参数。定义θ(u,v)=s(g(u),g(v))\\theta(\\mathbb{u,v})=s(g(\\mathbb u),g(\\mathbb v))θ(u,v)=s(g(u),g(v))，其中s(⋅,⋅)s(·,·)s(⋅,⋅)表示余弦距离，g(⋅)g(·)g(⋅)表示非线性转换。 基于paire wise损失，整个模型的木变函数可以定义为： J=12N∑i=1N[ℓ(ui,vi)+ℓ(vi,ui)]\\mathcal{J}=\\frac{1}{2 N} \\sum_{i=1}^{N}\\left[\\ell\\left(u_{i}, v_{i}\\right)+\\ell\\left(v_{i}, u_{i}\\right)\\right] J=2N1​i=1∑N​[ℓ(ui​,vi​)+ℓ(vi​,ui​)] 2.2 自适应增强策略 和常规图对比学习中的数据增强策略不同，作者提出了一种自适应数据增强策略，尝试保留重要的结构、属性信息不变，丢掉或改变那些不重要的边和属性。 2.2.1 Topology-level增强 对于拓扑结构数据增强，一种直接的方法就是从原始边集合E\\mathcal EE中采用调整后的子集E~\\widetilde {\\mathcal E}E： P{(u,v)∈E~}=1−puveP\\{(u, v) \\in \\widetilde{\\mathcal{E}}\\}=1-p_{u v}^{e} P{(u,v)∈E}=1−puve​ 其中(u,v)∈E(u,v)\\in\\mathcal E(u,v)∈E，puvep_{uv}^epuve​表示丢掉边(u,v)(u,v)(u,v)的概率。作者认为puvep_{uv}^epuve​应该和边重要性挂钩，即越重要的边，被丢掉的概率越小。 在图学习领域，衡量节点重要性的一种通用方法就是node centrality。这里，作者定义edge centrality wuvew_{uv}^ewuve​来衡量边重要性。 具体来说，给定node centrality度量方法φc(⋅):V→R+\\varphi_{c}(\\cdot): \\mathcal{V} \\rightarrow \\mathbb{R}^{+}φc​(⋅):V→R+，有wuve=(φc(u)+φc(v))/2w_{u v}^{e}=\\left(\\varphi_{c}(u)+\\varphi_{c}(v)\\right) / 2wuve​=(φc​(u)+φc​(v))/2。对于有向图，则直接使用尾结点centrality作为边centrality wuve=φc(v)w_{u v}^{e}=\\varphi_{c}(v)wuve​=φc​(v)。 得到edge centrality后，令suve=log wuves_{uv}^e=log\\ w_{uv}^esuve​=log wuve​前文中概率puvep_{uv}^epuve​计算方式如下： puve=min⁡(smax⁡e−suvesmax⁡e−μse⋅pe,pτ)(4)p_{u v}^{e}=\\min \\left(\\frac{s_{\\max }^{e}-s_{u v}^{e}}{s_{\\max }^{e}-\\mu_{s}^{e}} \\cdot p_{e}, p_{\\tau}\\right)\\tag 4 puve​=min(smaxe​−μse​smaxe​−suve​​⋅pe​,pτ​)(4) 其中pep_epe​为超参数，表示整体丢边概率，smaxes_{max}^esmaxe​和μse\\mu_s^eμse​分别表示suves_{uv}^esuve​的最大值和平均值，pτ&lt;1p_\\tau&lt;1pτ​&lt;1表示cut-off概率，防止丢边概率过大，导致图结构过度损失。 对于node centrality计算方法，作者使用下面三种： Degree centrality 即将节点度作为centrality，在有向图中将入度作为centrality。 Eigenvector centrality 将节点邻接矩阵最大特征值对应的特征向量作为centrality。和degree centrality不同，eigenvector centrality还考虑了相邻节点的重要性。在有向图中使用右特征向量作为centrality。 PageRank centrality 将pagerank算法计算得到的权重作为centrality，具体定义如下： σ=αAD−1σ+1\\sigma=\\alpha A D^{-1} \\sigma+1 σ=αAD−1σ+1 为了直观的展示作者提出的自适应数据增强方法，作者对Karate club数据集上部分数据进行了可视化实验： 上图中展示的是由两个教练分别领导的两个不同学生小组，可以看到三种数据增强策略都更加强调教练和本组学员之间的边。 2.2.2 Node-attribute-level增强 和图像领域数据增强类似，作者通过用0随机mask特征向量部分维度，实现增加节点属性噪声的效果。 具体来说，首先采样一个随机向量m~∈{0,1}F\\tilde{\\boldsymbol{m}} \\in\\{0,1\\}^{F}m~∈{0,1}F，其满足分布m~i∼Bern⁡(1−pif),∀i\\tilde{m}_{i} \\sim \\operatorname{Bern}\\left(1-p_{i}^{f}\\right), \\forall im~i​∼Bern(1−pif​),∀i。强化后的节点特征表示为： X~=[x1∘m~;x2∘m~;⋯ ;xN∘m~]⊤\\widetilde{X}=\\left[x_{1} \\circ \\tilde{m} ; x_{2} \\circ \\tilde{m} ; \\cdots ; x_{N} \\circ \\tilde{m}\\right]^{\\top} X=[x1​∘m~;x2​∘m~;⋯;xN​∘m~]⊤ 和topology-level强化类似，概率值pifp_i^fpif​应该反映节点特征i−thi-thi−th维度的重要性。 作者假设对于频繁出现的特征维度，其重要程度更高。 对于one-hot节点特征xui∈{0,1}x_{ui}\\in\\{0,1\\}xui​∈{0,1}，每个维度重要程度计算方法如下： wif=∑u∈Vxui⋅φc(u)w_{i}^{f}=\\sum_{u \\in \\mathcal{V}} x_{u i} \\cdot \\varphi_{c}(u) wif​=u∈V∑​xui​⋅φc​(u) 其中φc(⋅)\\varphi_c(·)φc​(⋅)表示node centrality度量方法。 对于连续节点特征xux_uxu​，xuix_{ui}xui​表示第i维度的数值，作者这里直接使用该值的绝对值计算维度重要性： wif=∑u∈V∣xui∣⋅φc(u)w_{i}^{f}=\\sum_{u \\in \\mathcal{V}}\\left|x_{u i}\\right| \\cdot \\varphi_{c}(u) wif​=u∈V∑​∣xui​∣⋅φc​(u) 和topology-level一样，最终的概率值计算方法如下： pif=min⁡(smax⁡f−sifsmax⁡f−μsf⋅pf,pτ)p_{i}^{f}=\\min \\left(\\frac{s_{\\max }^{f}-s_{i}^{f}}{s_{\\max }^{f}-\\mu_{s}^{f}} \\cdot p_{f}, p_{\\tau}\\right) pif​=min(smaxf​−μsf​smaxf​−sif​​⋅pf​,pτ​) 其中sif=log wifs_i^f=log\\ w_i^fsif​=log wif​，smaxfs_{max}^fsmaxf​和μsf\\mu_s^fμsf​分别表示最大值和平均值，pτp_\\taupτ​为超参数。 2.3 理论证明 这一部分作者从MI maximization和triplet loss两方面证明了模型的有效性。 一、MI maximization MI即Mutual Information互信息（概率论和信息论中的概念），表示一个随机变量中包含另一个随机变量的信息量，也可以理解成两个随机变量之间的相关程度。 这块具体证明看的不是很懂，感兴趣的可以看原文。最后证明了作者前文中提出的目标函数J\\mathcal JJ是输入特征X和学习到的特征表示之间MI值的下界： J≤I(X;U,V)\\mathcal{J} \\leq I(X ; U, V) J≤I(X;U,V) 大概的证明过程为：首先证明J\\mathcal JJ是InfoNCE（一种图对比学习方法）的下界，而InfoNCE目标函数是MI的下界，即I(U;V)≤I(X;U,V)I(U ; V) \\leq I(X ; U, V)I(U;V)≤I(X;U,V)。本文提出的数据增强策略，在对比两个view 时，可以强制模型将重要的信息编码到节点嵌入中。 二、Triplet loss 本文定义的目标函数J\\mathcal JJ也可以看做深度度量学习中常用的三元损失。详细证明和分析过程可以看原文。 最后作者得出两个结论，一是本文提出的数据增强策略是有效的，二是GCA中的对比目标优化代价低。 3. 实验 作者通过实验回答下列三个问题： 在节点分类任务上，作者提出的GCA模型是否优于baseline方法？ 作者提出的数据增强策略是否有用？不同增强策略性能如何？ GCA模型对超参是否敏感？关键超参对模型性能有何影响？ 3.1 实验设置 一、数据集 二、Baselines 传统方法：DeepWalk，node2vec 深度学习方法：GAE，VGAE，DGI，GMI，MVGL 有监督学习方法：GCN，GAT 三、实现细节 所有模型都采用两层GCN作为编码器： GCi(X,A)=σ(D^−12A^D^−12XWi)f(X,A)=GC2(GC1(X,A),A)\\begin{aligned} \\mathrm{GC}_{i}(\\boldsymbol{X}, \\boldsymbol{A}) &amp;=\\sigma\\left(\\hat{D}^{-\\frac{1}{2}} \\hat{A} \\hat{D}^{-\\frac{1}{2}} X W_{i}\\right) \\\\ f(X, A) &amp;=\\mathrm{GC}_{2}\\left(\\mathrm{GC}_{1}(X, A), A\\right) \\end{aligned} GCi​(X,A)f(X,A)​=σ(D^−21​A^D^−21​XWi​)=GC2​(GC1​(X,A),A)​ 3.2 实验结果 一、RQ1：在节点分类任务上，作者提出的GCA模型是否优于baseline方法？ 二、RQ2：作者提出的数据增强策略是否有用？不同增强策略性能如何？ 三、RQ3：GCA模型对超参是否敏感？关键超参对模型性能有何影响？ 为了简化问题，作者这里设置pe=pe,1=pe,2p_e=p_{e,1}=p_{e,2}pe​=pe,1​=pe,2​，pf=pf,1=pf2p_f=p_{f,1}=p_{f_2}pf​=pf,1​=pf2​​。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"数据增强","slug":"数据增强","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"}]},{"title":"Attentional Constellation Nets for Few-Shot Learning","slug":"3 论文笔记/小样本学习/9.Attentional Constellation Nets for Few-Shot Learning","date":"2021-07-12T06:17:34.000Z","updated":"2021-07-12T06:21:57.734Z","comments":true,"path":"ad4e2c7525d5/","link":"","permalink":"http://rookieyin.github.io/ad4e2c7525d5/","excerpt":"https://openreview.net/pdf?id=vujTf_I8Kmc https://github.com/wuwenshan/ConstellationNet Attentional Constellation Nets for Few-Shot Learning，2021，ICLR 总结：本文将传统part-based模型中的constellation模型用于小样本学习中，解决小样本场景下样本稀少问题。文章的创新点在于如何将传统constellation模型融合到CNN中用于小样本学习。给我的启发：感觉和ICLR 2021另外一篇concept learner论文异曲同工，都是从更高层级的part of object入手，而非传统像素级别，让模型学习一些高层级的显性知识（这样模型泛化能力可能更强，有利于测试集上分类）。感觉这种part-based方向值得深入研究下。","text":"https://openreview.net/pdf?id=vujTf_I8Kmc https://github.com/wuwenshan/ConstellationNet Attentional Constellation Nets for Few-Shot Learning，2021，ICLR 总结：本文将传统part-based模型中的constellation模型用于小样本学习中，解决小样本场景下样本稀少问题。文章的创新点在于如何将传统constellation模型融合到CNN中用于小样本学习。给我的启发：感觉和ICLR 2021另外一篇concept learner论文异曲同工，都是从更高层级的part of object入手，而非传统像素级别，让模型学习一些高层级的显性知识（这样模型泛化能力可能更强，有利于测试集上分类）。感觉这种part-based方向值得深入研究下。 1. 简介 1.1 摘要 The success of deep convolutional neural networks builds on top of the learningof effective convolution operations, capturing a hierarchy of structured featuresvia filtering, activation, and pooling. However, the explicit structured features, e.g. object parts, are not expressive in the existing CNN frameworks. In this paper,we tackle the few-shot learning problem and make an effort to enhance structured features by expanding CNNs with a constellation model, which performs cell feature clustering and encoding with a dense part representation; the relationships among the cell features are further modeled by an attention mechanism. With the additional constellation branch to increase the awareness of object parts, our method is able to attain the advantages of the CNNs while making the overall internal representations more robust in the few-shot learning setting. Our approach attains a significant improvement over the existing methods in few-shot learning on the CIFAR-FS, FC100, and mini-ImageNet benchmarks. 深度CNN的成功建立在有效卷积操作的学习上，通过过滤、激活、池化可以捕捉不同层次的结构特征。但是现有的CNN框架无法表达显示结构特征，比如object parts。本文，我们解决了小样本学习问题，并努力尝试通过将CNNs和constellation模型（用dense part表示对cell特征进行聚类和编码）相结合来强化结构特征，再进一步用注意力机制对不同cell feature之间的关系进行建模。在小样本设定下，通过额外的constellation分支来增加object parts的感知能力，我们的方法可以在保证CNNs优势的同时让整体内部表示更robust。和现有小样本学习方法相比，我们的方法在CIFAR-FS、FC100和mini-Imagenet三个数据集上性能有显著提升。 1.2本文工作 背景： 深度CNNs在计算机视觉的各种应用中取得了很大进展，通过可视化CNN内部结构，我们可以揭示学习到的卷积核对于物体类别的语义信息。在前几层显示bar/edge这类形状，中间层显示object parts，后面几层显示face/object这类形状。 In general, we consider the learned convolution kernels being somewhat implicit about the underlying objects since they represent projections/mappings for the input but without the explicit knowledge about the parts in terms of their numbers, distributions, and spatial configurations.这段英文大概就是说，传统CNNs是个黑盒模型，没有显性知识，单纯将一个样本通过一些列卷积操作映射成一个表示向量。 在CV领域，对于explict object representation也有很多相关研究比如deformable templates，pictorial structure、constellation model等等，这些模型可以称之为part-based 模型。这类模型有三个特点：（1）unsupervised learning；（2）explicit clustering；（3）对spatial configuration of the parts特征进行建模。和CNNs相比，这些方法都是带有显式的part-based representation。 动机： 在小样本学习场景下，CNNs的implicit 和part-based模型的explict feature representation能不能结合到一起呢？小样本场景下，CNNs可能由于没有足够训练样本导致无法学习到通用的表示，但是clustering and dictionary learning可以提供一种直接的数据抽象方法。 注：这里的“clustering and dictionary learning”应该就是part-based 模型里面的一些操作，感兴趣可自行了解。 本文工作： 作者提出了一个端到端的框架，通过无缝结合constellation模型和卷积操作，将implicit 和 explicit part-based 表示结合到一起，用于小样本分类任务。首先利用cell feature 聚类模型对潜在的object parts进行编码，生成一个dense distance map。然后利用自注意力机制对这些cell间关系进行建模。作者将它们的方法命名为ConstellationNet，通过大量实验证明了该方法的有效性。 2. 方法 constellation是2006年“ One-shot learning of object categories ”中提出来的概念，在一个混合模型中单独学习appearance和shape。本文作者以端到端的方式对constellation模型进行改进。模型框架如下图1所示： 在常规Conv层后面加了一个Constell层，其中包含cell feature clustering和cell relation modeling两个步骤。 2.1 Cell Feature Clustering 基于前人的一些工作，假设cell features表示为U={u1,u2,...,Un}\\mathcal U={\\mathbf {\\{u_1,u_2,...,U_n\\}}}U={u1​,u2​,...,Un​}，其中n=BHWn=BHWn=BHW，B表示batch size，H和W分别表示高和宽。k-means聚类的目标函数可以定义为： min⁡∑i∑kmik∥ui−vk∥22 s.t. mik∈{0,1},∑kmik=1(3)\\min \\sum_{i} \\sum_{k} m_{i k}\\left\\|\\mathbf{u}_{i}-\\mathbf{v}_{k}\\right\\|_{2}^{2} \\quad \\text { s.t. } \\quad m_{i k} \\in\\{0,1\\}, \\quad \\sum_{k} m_{i k}=1\\tag 3 mini∑​k∑​mik​∥ui​−vk​∥22​ s.t. mik​∈{0,1},k∑​mik​=1(3) 其中V={v1,v2,...,vK}\\mathcal V=\\{\\mathbf{v_1,v_2,...,v_K}\\}V={v1​,v2​,...,vK​}为聚类中心，mikm_{ik}mik​表示ui\\mathbf u_iui​是否被分配到vk\\mathbf v_kvk​着一簇。对于每一个cell ui\\mathbf u_iui​，聚类后得到的assignment map mi=(mi1,mi2,...,mik)\\mathbf m_i=(m_{i1},m_{i2},...,m_{ik})mi​=(mi1​,mi2​,...,mik​)，可以作为part-based representation，为下一层卷积操作提供额外信息。 上面这种聚类方式存在两个弊端： CNNs通常采用SGD方式进行优化，前向传播过程中只有一个mini-batch样本参与进来，导致聚类中心无法囊括整个数据集的特征分布。 对于每个cell ui\\mathbf u_iui​最终得到的map mi\\mathbf m_imi​是离散的，能提供的信息有限。 因此，作者受其他工作的启发设计了一种mini-batch soft k-means聚类算法： Initialization：随机初始化一个全局聚类中心V={v1,v2,...,vK}\\mathcal V=\\{\\mathbf{v_1,v_2,...,v_K}\\}V={v1​,v2​,...,vK​}，定义counter s=(s1,s2,…,sK)=0\\mathbf{s}=\\left(s_{1}, s_{2}, \\ldots, s_{K}\\right)=\\mathbf{0}s=(s1​,s2​,…,sK​)=0。 Cluster Assignment：给定cell features U={u1,u2,…,un}\\mathcal{U}=\\left\\{\\mathbf{u}_{1}, \\mathbf{u}_{2}, \\ldots, \\mathbf{u}_{n}\\right\\}U={u1​,u2​,…,un​}，计算距离向量di=(di1,di2,…diK)\\mathbf{d}_{i}=\\left(d_{i 1}, d_{i 2}, \\ldots d_{i K}\\right)di​=(di1​,di2​,…diK​)表示ui\\mathbf u_iui​和所有聚类中心之间的距离然后分别计算mik∈Rm_{ik}\\in\\mathbb Rmik​∈R和当前这一mini-batch下的聚类中心： dik=∥ui−vk∥22,mik=e−βdik∑je−βdij,vk′=∑imikui∑imik(4)d_{i k}=\\left\\|\\mathbf{u}_{i}-\\mathbf{v}_{k}\\right\\|_{2}^{2}, \\quad m_{i k}=\\frac{e^{-\\beta d_{i k}}}{\\sum_{j} e^{-\\beta d_{i j}}}, \\quad \\mathbf{v}_{k}^{\\prime}=\\frac{\\sum_{i} m_{i k} \\mathbf{u}_{i}}{\\sum_{i} m_{i k}}\\tag 4 dik​=∥ui​−vk​∥22​,mik​=∑j​e−βdij​e−βdik​​,vk′​=∑i​mik​∑i​mik​ui​​(4) Centroid Movement：执行一次count update δs=∑imi\\delta\\mathbf s=\\sum_i\\mathbf m_iδs=∑i​mi​，然后利用当前mini-batch下的聚类中心更新全局聚类中心： vk←(1−η)vk+ηvk′,η=λsk+Δsk(5)\\mathbf{v}_{k} \\leftarrow(1-\\eta) \\mathbf{v}_{k}+\\eta \\mathbf{v}_{k}^{\\prime}, \\quad \\eta=\\frac{\\lambda}{s_{k}+\\Delta s_{k}}\\tag 5 vk​←(1−η)vk​+ηvk′​,η=sk​+Δsk​λ​(5) Counter Update：更新counter s\\mathbf ss，并reshaped distance向量{di}\\{\\mathbf d_i\\}{di​} s←s+Δs(6)\\mathrm{s} \\leftarrow \\mathrm{s}+\\Delta \\mathrm{s}\\tag 6 s←s+Δs(6) 通过不断更新全局聚类中心，上述算法可以解决mini-batch下数据量有限的问题。需要注意的是，每个batch中的距离向量{di}\\mathbf \\{d_i\\}{di​}会被reshape到一个distance map D∈RB×H×H×W×K\\mathbf D\\in\\mathbb R^{B\\times H\\times H\\times W\\times K}D∈RB×H×H×W×K。每个距离向量di\\mathbf d_idi​可以被看做codebook学习中的一个learned cell code，反映了part representation。 2.2 Cell Relation And Spatial Configuration Modeling 本文作者采用自注意力机制，构建不同part-based表示之间的空间关系。首先按照“ End-to-end object detection with transformers”中的方式，给距离map D\\mathbf DD加上positional encoding P∈RB×H×W×C\\mathbf P\\in\\mathbb R^{B\\times H\\times W\\times C}P∈RB×H×W×C，然后直接展开得到FI\\mathbf {F_I}FI​。同时直接将D\\mathbf DD展开得到FI′\\mathbf {F_I&#x27;}FI′​： FI=SpatialFlatten(D+P)∈RB×HW×K,FI′=SpatialFlatten(D)∈RB×HW×K(7)\\mathbf {F_I}=\\text{SpatialFlatten}(\\mathbf D+\\mathbf P)\\in\\mathbb R^{B\\times HW\\times K},\\mathbf{F_I&#x27;}=\\text{SpatialFlatten}(\\mathbf D)\\in\\mathbb R^{B\\times HW\\times K}\\tag 7 FI​=SpatialFlatten(D+P)∈RB×HW×K,FI′​=SpatialFlatten(D)∈RB×HW×K(7) 然后将FI\\mathbf{F_I}FI​和FI′\\mathbf{F_I&#x27;}FI′​作为{Fq,Fk,Fv}⊂RB×HW×K\\left\\{\\mathbf{F}^{q}, \\mathbf{F}^{k}, \\mathbf{F}^{v}\\right\\} \\subset \\mathbb{R}^{B \\times H W \\times K}{Fq,Fk,Fv}⊂RB×HW×K，对应权重分别为{Wq,Wk,Wv}⊂RK×K\\left\\{\\mathbf{W}^{q}, \\mathbf{W}^{k}, \\mathbf{W}^{v}\\right\\} \\subset \\mathbb{R}^{K \\times K}{Wq,Wk,Wv}⊂RK×K，最终计输出FA\\mathbf{F_A}FA​： [Fq,Fk,Fv]=[FIWq,FIWk,FI′Wv](8){\\left[\\mathbf{F}^{q}, \\mathbf{F}^{k}, \\mathbf{F}^{v}\\right]=\\left[\\mathbf{F}_{\\mathbf{I}} \\mathbf{W}^{q}, \\mathbf{F}_{\\mathbf{I}} \\mathbf{W}^{k}, \\mathbf{F}_{\\mathrm{I}}^{\\prime} \\mathbf{W}^{v}\\right]} \\tag 8 [Fq,Fk,Fv]=[FI​Wq,FI​Wk,FI′​Wv](8) FA=Att⁡(Fq,Fk,Fv)=softmax⁡(Fq(Fk)⊤K)Fv(9)\\mathbf{F}_{\\mathrm{A}}=\\operatorname{Att}\\left(\\mathbf{F}^{q}, \\mathbf{F}^{k}, \\mathbf{F}^{v}\\right)=\\operatorname{softmax}\\left(\\frac{\\mathbf{F}^{q}\\left(\\mathbf{F}^{k}\\right)^{\\top}}{\\sqrt{K}}\\right) \\mathbf{F}^{v}\\tag 9 FA​=Att(Fq,Fk,Fv)=softmax(K​Fq(Fk)⊤​)Fv(9) 在实际应用中采用多头注意力机制，然后通过权重参数W\\mathbf WW整合所有头的输出： FMHA = MultiHeadAtt (Fq,Fk,Fv)=[F1,…,FJ]W,Fj=Att⁡(Fjq,Fjk,Fjv)0(1)\\mathbf{F}_{\\text {MHA }}=\\text { MultiHeadAtt }\\left(\\mathbf{F}^{q}, \\mathbf{F}^{k}, \\mathbf{F}^{v}\\right)=\\left[\\mathbf{F}_{1}, \\ldots, \\mathbf{F}_{J}\\right] \\mathbf{W}, \\quad \\mathbf{F}_{j}=\\operatorname{Att}\\left(\\mathbf{F}_{j}^{q}, \\mathbf{F}_{j}^{k}, \\mathbf{F}_{j}^{v}\\right)\\tag 10 FMHA ​= MultiHeadAtt (Fq,Fk,Fv)=[F1​,…,FJ​]W,Fj​=Att(Fjq​,Fjk​,Fjv​)0(1) 3. 实验 一、对比 二、各个模块间消融 三、超参消融 四、可视化 可以看到，在early layers中的聚类反映的是简单的low-level形状，而在high layers中反映的更多的是复杂结构。上图第二行，为第四层学习到的两个聚类中心。 上图左边反映的是图片不同cell feature被分配的聚类中心，可以看到对于相同类别的一组照片，不同照片的相同不为分配的聚类中心是相似的。 上图右边是cell relation模型中注意力矩阵热图，可以看到采用多头注意力机制可以提取整个目标的特征，这对最终分类是很有帮助的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图像分类","slug":"图像分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}]},{"title":"Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML","slug":"3 论文笔记/小样本学习/8.Rapid Learning or Feature Reuse Towards Understanding the Effectiveness of MAML","date":"2021-07-08T02:26:54.000Z","updated":"2021-07-08T02:30:38.457Z","comments":true,"path":"e0231deb83dc/","link":"","permalink":"http://rookieyin.github.io/e0231deb83dc/","excerpt":"https://arxiv.org/pdf/1909.09157 https://github.com/learnables/learn2learn Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML，2020，ICLR 总结：文章提出的ANIL算法是2021ICLR另一篇BOIL文章的前传，强烈推荐将MAML、ANIL和BOIL三篇文章放到一起看，感觉还是很奇妙的，值得深入研究。文章从“ Is MAML’s efficacy predominantly due to rapid learning or feature reuse?”问题出发，通过实验证明了feature reuse是MAML成功的主要因素，并据此提出了ANIL（Almost No Inner Loop）和NIL（No Inner Loop）两种新算法。文章实验很丰富，结果也很漂亮。","text":"https://arxiv.org/pdf/1909.09157 https://github.com/learnables/learn2learn Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML，2020，ICLR 总结：文章提出的ANIL算法是2021ICLR另一篇BOIL文章的前传，强烈推荐将MAML、ANIL和BOIL三篇文章放到一起看，感觉还是很奇妙的，值得深入研究。文章从“ Is MAML’s efficacy predominantly due to rapid learning or feature reuse?”问题出发，通过实验证明了feature reuse是MAML成功的主要因素，并据此提出了ANIL（Almost No Inner Loop）和NIL（No Inner Loop）两种新算法。文章实验很丰富，结果也很漂亮。 1. 简介 1.1 摘要 An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that con-sists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML’s popularity, a fundamental open question remains —— is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changesin the representations) or due to feature reuse, with the meta-initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where were move the inner loop for all but the (task-specific) head of the underlying neural network. ANIL matches MAML’s performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network(the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly. 用于解决小样本问题的元学习算法是机器学习的一个重要研究方向之一，其中一种非常成功的算法就是MAML。它通过两个优化循环：外循环学习一个有效的meta-initialization，内循环可以快速适应新任务。尽管MAML得到了广泛应用，但是还存在一个开放性问题待解决：MAML的成功取决于meta-initialization带来的rapid learning还是feature reuse（远处是参数已经能够学习到高质量特征）。为了调查这个问题，我们进行了消融实验，并分析了样本潜在表示，发现feature reuse是MAML成功的主要因素。基于此，我们提出了ANIL（Almost No Inner Loop）算法，它是MAML的一种简化版本。ANIL移除了内循环中对所有参数的更新，只保留了神经网络的head（即分类器）部分。在标准数据集的小样本图像分类任务上，ANIL取得了和MAML相当的表现，但是计算代价更低。我们进一步研究了head和body部分对模型整体性能更精细的贡献，发现在模型在测试任务上的表现完全取决于学习到的特征的质量，我们甚至还可以去掉网络的head部分（即NIL算法）。最后，我们更广泛地讨论了元学习算法中rapid learning和feature reuse的作用。 1.2 本文工作 背景： 用于小样本场景的元学习方法得到了很多关注，MAML就是一种非常成功的元学习算法。MAML通过外循环学习一个优良的meta-initialization参数，内循环可以快速学习适应新任务。 动机： MAML虽然得到了广泛研究并且人们提出了很多变体，但是大多都是针对如何提高MAML性能的。**存在一个开放问题：MAML的成功来自于内循环的rapid learning还是外循环的feature reuse？**如上图1所示。 本文工作： 作者通过大量实验证明了MAML的成功主要来自于feature reuse，即执行内循环前模型的初始参数已经可以学习到高质量的样本特征。即使内循环不对模型body部分（即特征提取器）参数进行更新，模型在新任务上也能有较好的性能。在此基础上作者提出了ANIL和NIL模型。 2. 方法&amp;实验 2.1 MAML 这部分可以参考我另一篇论文笔记：BOIL: Towards Representation Change for Few-shot 中对于MAML的介绍。BOIL是对本文工作的延伸，是一种和ANIL刚好相反的算法。 2.2 Rapid Learning VS Feature Reuse 这部分主要探讨：“ Is MAML’s efficacy predominantly due to rapid learning or feature reuse? ”。先定义两个概念： head： 模型的最后一层，即分类层，比如softmax层，根据样本表示计算分类得分 body： 模型最后一层前面所有层，可以理解成特征提取器，用来计算样本表示 为了验证rapid learning和feature reuse究竟谁占据主导地位，作者设计了两组实验： 元测试阶段冻结模型参数，去掉内循环中的adaptation操作，观察模型表现 利用表示向量相似度工具，直接分析内循环中样本表示向量有多大变化 一、冻结参数 为了研究内循环adaptation的影响，元测试阶段，我们逐层冻结特征提取器的参数，然后对比模型的表现。实验结果如下表1： 可以发现，冻结特征提取器参数对模型性能并没有产生影响。这表明：meta-initialization下的特征提取器已经能够从样本中提取足够多信息用于分类，在测试任务中不需要进行额外优化。 二、表示间相似度 这部分，作者分析了内循环的adaptation期间样本特征究竟有没有发生很大的变化。 上图展示了卷积操作前后样本表示之间的相似度，可以发现在CCA和CKA这两种度量标准下，模型的卷积操作并没有给节点表示带来很大改变，相似度没有低于0.9。 上述两个实验都指向同一个结论：即feature reuse在MAML中占据主导地位，而rapid learning可有可无。 三、早期学习过程 上面的实验是在完整完成meta-train后，在元测试阶段进行的。下面分别在MAML迭代训练10000,20000,30000次后，检测内循环中adaptation对模型性能的影响。实验结果如下图所示： 可以看到，在早期学习过程中，内循环的adaptation操作对模型性能的影响也不明显。 2.3 ANIL 2.3.1 算法 前面一系列实验证明MAML中，内循环的adaptation操作对模型性能的影响很小，因此作者提出了一种新的算法ANIL（Almost No Inner Loop）。MAML和ANIL之间的对比如下图4所示： 对比MAML算法，ANIL算法在训练和测试阶段的内循环中，不更新模型body部分参数，只更新head部分分类器参数。假设模型参数为θ=(θ1,...,θl)\\theta=(\\theta_1,...,\\theta_l)θ=(θ1​,...,θl​)，在ANIL算法中梯度更新方式如下： θm(b)=(θ1,…,(θl)m−1(b)−α∇(θl)m−1(b)LSb(fθm−1(b)))\\theta_{m}^{(b)}=\\left(\\theta_{1}, \\ldots,\\left(\\theta_{l}\\right)_{m-1}^{(b)}-\\alpha \\nabla_{\\left(\\theta_{l}\\right)_{m-1}^{(b)}} \\mathcal{L}_{S_{b}}\\left(f_{\\theta_{m-1}^{(b)}}\\right)\\right) θm(b)​=(θ1​,…,(θl​)m−1(b)​−α∇(θl​)m−1(b)​​LSb​​(fθm−1(b)​​)) 2.3.2 实验 一、模型时间复杂度 由于ANIL更新参数更少，因此训练和预测速度更快。实验表明，和MAML相比，ANIL训练阶段速度平均提升1.7倍，预测阶段速度平均提升4.1倍。 二、模型性能 下表对比了ANIL和MAML的准确度，可以发现两者相差无几，进一步证明了内循环body部分adaptation操作没有必要。 三、MAML和ANIL 为了进一步研究两个模型学习过程中行为相似度，下图展示了两个模型训练过程中损失和准确度的变化曲线： 可以看到两条曲线趋势基本完全一致。下表展示了不同模型之间学习到的表示之间的相似度： 三组数据基本一致。通过上面两个实验可以看出，两个算法的性能、学习过程、学习结果都高度相似，进一步证明了内循环的adaptation操作没有作用。 2.4 Head VS Body 这部分主要探讨模型head和body两部分的贡献。这部分的动机来源于问题：“ Howimportant is the head at test time, when good features have already been learned? ”。既然前面说内循环中对body的优化没有用，那么head是否有必要存在？能不能直接将模型head部分去掉？为此作者提出了一个新的算法NIL（No Inner Loop）。 2.4.1 元测试阶段的Head 通过元训练得到ANIL模型后，在测试阶段去掉模型的head，直接用模型学习到的表示进行分类，实验结果如下表4： 可以看到对比MAML和ANIL，NIL的性能并没有发生明显变化。 2.4.2 不同训练策略下的NIL 这部分的实验，元训练阶段采用不同训练策略，元测试阶段使用NIL方法，它们的性能对比如下表5： 可以看到，用MAML和ANIL训练模型时性能最好。Multitask训练时由于没有task specific head导致模型性能最差，甚至低于随机特征。最后一行，用NIL训练模型时性能低于第一、二行用MAML训练模型，因此可以得出结论：训练时的head对模型能否学习有效的特征是很重要的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"name":"MAML","slug":"MAML","permalink":"http://rookieyin.github.io/tags/MAML/"}]},{"title":"Modeling Relational Data with Graph Convolutional Networks","slug":"3 论文笔记/图学习/异构网络/5.Modeling Relational Data with Graph Convolutional Networks","date":"2021-07-07T03:00:01.000Z","updated":"2021-07-07T03:03:20.265Z","comments":true,"path":"f57d828e8582/","link":"","permalink":"http://rookieyin.github.io/f57d828e8582/","excerpt":"https://arxiv.org/pdf/1703.06103 https://github.com/tkipf/relational-gcn Modeling Relational Data with Graph Convolutional Networks，2018，ESWC 总结：比较早的一篇用于知识图谱上信息补全的模型，具体来说用来解决实体分类和链路预测两个任务。针对知识图谱中三元组数据，对传统GCNs的转换函数做了改进提出了R-GCN模型。在实体分类任务中采用encoder架构，在链路预测任务中采用encoder-decoder即自编码器架构。最后的实验效果不是很理想，不过文章影响力挺大，被引量比较高。","text":"https://arxiv.org/pdf/1703.06103 https://github.com/tkipf/relational-gcn Modeling Relational Data with Graph Convolutional Networks，2018，ESWC 总结：比较早的一篇用于知识图谱上信息补全的模型，具体来说用来解决实体分类和链路预测两个任务。针对知识图谱中三元组数据，对传统GCNs的转换函数做了改进提出了R-GCN模型。在实体分类任务中采用encoder架构，在链路预测任务中采用encoder-decoder即自编码器架构。最后的实验效果不是很理想，不过文章影响力挺大，被引量比较高。 1. 简介 1.1 摘要 Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata)remain incomplete. We introduce Relational Graph Convo-lutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operat-ing on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline. 知识图谱衍生了很多应用，比如问答、信息检索。尽管人们在创造和维护知识图谱上投入了很大的努力，但是大型知识图谱比如Yago、DBPedia或者Wikidata都存在不完整问题。本文我们介绍关系型图卷积神经网络R-GCNs，并将其应用于两个知识图谱补全任务：链路预测和实体分类。RGCNs基于现有的很多图上神经网络模型，专门设计用来处理真实知识库中普遍存在的multi-relational特征。我们证明了RGCNs作为一个独立模型在实体分类任务上的有效性。我们进一步展示了通过编码器模型，在关系图的多个推理步骤中基类证据，可以显著改进项DistMult这样的factorization链路预测模型的性能。实验证明在FB15k-237上，和纯编码器模型相比性能提升29.8%。 1.2 本文工作 背景： 知识图谱衍生了很多应用，比如问答和信息检索。虽然人们在创建和维护知识图谱方面投入了很大精力，但是大型知识图谱中还是存在不完整问题，影响了下游应用的性能。预测知识库中的缺失信息是统计关系学习（SRL）的主要研究方向。 动机： 本文作者考虑两个任务：（1）链路预测，即寻找丢失的三元组；（2）实体分类，即对齐实体的类别属性。在这两种情况下，许多丢失的信息其实被编码在了图的结构信息中。例如上图1所示，知道Mikhail在Vaganova Academy读书，那么他应该有个person标签，并且知识库中很可能应该存在三元组（Mikhail， lived_in， Russia）。基于这个直觉，作者为图中的实体设计了一个编码器，同时用于上面两个任务。 本文工作： 作者提出了RGCN模型用于上文提到的两个任务。对于实体分类任务，和GCN类似，以RGCN得到的节点表示作为输入，用一个softmax分类器预测实体标签。对于链路预测任务，可以将整个模型看做一个自编码器，编码器即为RGCN，生成实体的潜在特征表示，解码器可以是任何一个tensor factorization模型，本文采用一种简单高效的解码器DistMult。 2. 方法 2.1 消息传播 作者提出的RGCN模型可以看做GCN在大规模关系型数据中的一种拓展。基于现有的GNN架构，作者在关系图上定义的信息传播模型如下： hi(l+1)=σ(∑r∈R∑j∈Nir1ci,rWr(l)hj(l)+W0(l)hi(l))(2)h_{i}^{(l+1)}=\\sigma\\left(\\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_{i}^{r}} \\frac{1}{c_{i, r}} W_{r}^{(l)} h_{j}^{(l)}+W_{0}^{(l)} h_{i}^{(l)}\\right) \\tag 2 hi(l+1)​=σ⎝⎜⎛​r∈R∑​j∈Nir​∑​ci,r​1​Wr(l)​hj(l)​+W0(l)​hi(l)​⎠⎟⎞​(2) 其中Nir\\mathcal{N_i^r}Nir​表示节点viv_ivi​的邻居集合，R\\mathcal RR表示所有关系集合，ci,rc_{i,r}ci,r​表示一个problem-specific正则化常量（可以学习得到，也可以预先设定好比如ci,r=∣Nir∣c_{i,r}=|\\mathcal {N_i^r}|ci,r​=∣Nir​∣）。需要注意的是，和普通GCNs不同，这里聚合邻居信息的方式是relation-specific，即按不同类型的边进行聚合。 对于图中每个节点，公式2可以并行计算。不过在实际应用中，公式2可以通过稀疏矩阵乘法来避免对邻域信息的显示相加，提高运算效率。R-GCN中对于单个节点，其嵌入转换过程如下图2所示： 2.2 正则化 将上述公式2应用到大规模高度multi-relational存在的主要问题就是：模型参数量随着关系种类增加而增加，在实际应用中对于某些稀有关系还会导致过拟合。为了解决这个问题，作者提出了两种不同的正则化技术：basis-decomposition和block-diagonal-decomposition。 basis-decomposition Wr(l)=∑b=1Barb(l)Vb(l)(3)W_{r}^{(l)}=\\sum_{b=1}^{B} a_{r b}^{(l)} V_{b}^{(l)}\\tag 3 Wr(l)​=b=1∑B​arb(l)​Vb(l)​(3) 将权重参数Wr(l)W_r^{(l)}Wr(l)​分解成若干个基本转换Vb(l)V_b^{(l)}Vb(l)​的线性组合， 其中系数arb(l)a_{rb}^{(l)}arb(l)​只取决于关系rrr。 block-diagonal-decomposition Wr(l)=⨁b=1BQbr(l)(4)W_{r}^{(l)}=\\bigoplus_{b=1}^{B} Q_{b r}^{(l)}\\tag 4 Wr(l)​=b=1⨁B​Qbr(l)​(4) 将Wr(l)W_r^{(l)}Wr(l)​分解成块对角矩阵diag(Q1r(l),...,QBr(l))diag(Q_{1r}^{(l)},...,Q_{Br}^{(l)})diag(Q1r(l)​,...,QBr(l)​)。 其中公式3可以看做是在不同类型关系之间共享权重，而公式4可以看做对每种类型关系的权重矩阵进行系数约束。 2.3 损失函数 实体分类 堆叠公式2定义的RGCN层，输出层采用softmax函数，损失函数采用交叉熵损失 L=−∑i∈Y∑k=1Ktikln⁡hik(L)(5)\\mathcal{L}=-\\sum_{i \\in \\mathcal{Y}} \\sum_{k=1}^{K} t_{i k} \\ln h_{i k}^{(L)}\\tag 5 L=−i∈Y∑​k=1∑K​tik​lnhik(L)​(5) 链路预测 如上图3b所示，链路预测模型多了一个解码器。编码器为每个节点计算一个嵌入向量，解码器根据节点嵌入计算两个节点之间存在边的概率。本文采用DistMult作为解码器，两个实体之间存在关系r的得分计算方式如下： f(s,r,o)=esTRreo(6)f(s, r, o)=e_{s}^{T} R_{r} e_{o}\\tag 6 f(s,r,o)=esT​Rr​eo​(6) 通过负采样技术和交叉熵损失优化模型，让真实三元组得分高于虚假三元组： L=−1(1+ω)∣E^∣∑(s,r,o,y)∈Tylog⁡l(f(s,r,o))+(1−y)log⁡(1−l(f(s,r,o))),(7)\\begin{array}{r} \\mathcal{L}=-\\frac{1}{(1+\\omega)|\\hat{\\mathcal{E}}|} \\sum_{(s, r, o, y) \\in \\mathcal{T}} y \\log l(f(s, r, o))+ \\\\ (1-y) \\log (1-l(f(s, r, o))), \\end{array}\\tag 7 L=−(1+ω)∣E^∣1​∑(s,r,o,y)∈T​ylogl(f(s,r,o))+(1−y)log(1−l(f(s,r,o))),​(7) 3. 实验 3.1 实体分类 RGCN在AIFB和AM数据集上取得了最好表现，但是MUTAG和BGS两个数据集上效果欠佳。作者猜测可能是聚合邻域信息时采用固定的标准化系数导致的。作者认为一种可能的解决方式是：用注意力机制代替1/ci,r1/c_{i,r}1/ci,r​。 3.2 链路预测 详细信息可以看原文，这里不做过多叙述。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"知识图谱","slug":"知识图谱","permalink":"http://rookieyin.github.io/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"}]},{"title":"BOIL Towards Representation Change for Few-shot Learning","slug":"3 论文笔记/小样本学习/7.BOIL Towards Representation Change for Few-shot Learning","date":"2021-07-05T12:15:25.000Z","updated":"2021-07-05T12:22:31.987Z","comments":true,"path":"98bd19685759/","link":"","permalink":"http://rookieyin.github.io/98bd19685759/","excerpt":"https://arxiv.org/pdf/2008.08882 BOIL: Towards Representation Change for Few-shot Learning，2021，ICLR 总结：本文作者针对MAML方法提出了一种新的变体——BOIL，Body Only undate in Inner Loop，在内循环中只更新特征提取器，不更新分类器。将MAML、ANIL和BOIL三个模型结合起来看还挺有趣的。在前人的研究中，针对MAML有两种假设，分别是representation reuse和representation change。作者通过大量实验证明了MAML和ANIL的内在学习机制是representation reuse，而BOIL的内在学习机制是representation change，并且BOIL的这种机制下的模型性能要优于MAML/ANIL，尤其在跨域任务中。文章实验做得很漂亮，个人觉得是一篇很有阅读价值的论文。","text":"https://arxiv.org/pdf/2008.08882 BOIL: Towards Representation Change for Few-shot Learning，2021，ICLR 总结：本文作者针对MAML方法提出了一种新的变体——BOIL，Body Only undate in Inner Loop，在内循环中只更新特征提取器，不更新分类器。将MAML、ANIL和BOIL三个模型结合起来看还挺有趣的。在前人的研究中，针对MAML有两种假设，分别是representation reuse和representation change。作者通过大量实验证明了MAML和ANIL的内在学习机制是representation reuse，而BOIL的内在学习机制是representation change，并且BOIL的这种机制下的模型性能要优于MAML/ANIL，尤其在跨域任务中。文章实验做得很漂亮，个人觉得是一篇很有阅读价值的论文。 1. 简介 1.1 摘要 Model Agnostic Meta-Learning (MAML) is one of the most representative of gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples using inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. It has recently been hypothesized that representation reuse, which makes little change in efficient representations, is the dominant factor in the performance of the meta-initialized model through MAML in contrast to representation change, which causes a significant change in representations. In this study, we investigate the necessity of representation change for the ultimate goal of few-shot learning, which is solving domain-agnostic tasks. To this aim, we propose a novel meta-learning algorithm, called BOIL(Body Onlyupdate in Inner Loop), which updates only the body (extractor) of the model and freezes the head (classifier) during inner loop updates. BOIL leverages representation change rather than representation reuse. This is because feature vectors(representations) have to move quickly to their corresponding frozen head vectors. We visualize this property using cosine similarity, CKA, and empirical results with-out the head. BOIL empirically shows significant performance improvement over MAML, particularly on cross-domain tasks. The results imply that representation change in gradient-based meta-learning approaches is a critical component . MAML是基于梯度元学习方法中最具代表性的一种，基于外循环学习到的元初始参数，在新任务上只需要少量内循环即可有较好的表现。最近有一种假设，representation reuse（它对有效表示产生的变化很小）是MAML模型优秀性能的主导因素，而representation change会导致representation发生显著变化。在这项研究中，我们调查了representation change对于domain-agnostic小样本学习任务最终目标的必要性。为此，我们提出了一种新的元学习算法BOIL（Body Only update in Inner Loop），在内循环中值更新模型body（即特征提取器）部分参数，冻结分类器参数。BOIL利用representation change而不是representation reuse，因为特征向量必须快速的移动到相对应的冻结头向量。我们使用余弦相似度、CKA和经验结果对这一性质进行了可视化。BOIL和MAML相比取得了很大提升，尤其在跨域任务上。这一结果表明representation change在基于梯度的元学习方法上是非常重要的一部分。 1.2 本文工作 背景： MAML作为最具代表性的基于梯度的元学习方法包含两个优化步骤：一是内循环学习task specific知识，而是外循环学习general元初始参数。前人的一些研究中将外循环称之为feature reuse，内循环称之为rapid learning。 动机： 本文将“feature reuse”和“rapid learning”重新定义为“representation reuse”和“representation change”。现有的一些假设认为，MAML的核心在于representation reuse，即外循环学习到的元初始参数。本文作者提出了一个新的问题：“Is representation reuse sufficient for meta-learning?”，作者认为元学习的成功更多的来自于representation change，而不是representation reuse，尤其在跨域任务中。 本文工作： 作者为了验证自己的想法，提出了BOIL模型，在内循环中只学习模型的body部分，即特征提取器。标准数据集上的大量实验表明，和MAML相比，作者提出的BOIL模型性能有显著提升，尤其在跨域任务上。 2. 方法 2.1 MAML MAML算法包含两个优化循环：内循环和外循环，希望为task-learner学习一个最好的初始参数，以便模型能快速适应新任务。具体来说： 任务采样： 首先采样一个batch的任务，每个任务τi\\tau_iτi​包含一个支持集Sτi\\mathcal{S_{\\tau_i}}Sτi​​和一个查询集Qτi\\mathcal{Q_{\\tau_i}}Qτi​​。然后为每个任务采样n中标签，每种标签采样k个样本，这样每个支持集包含n×kn\\times kn×k个样本，每个查询集同样从相同类别标签中采样。 元训练 （1）内循环： 假设该meta-batch包含B个任务，内循环中，将θ\\thetaθ作为该任务下模型初始参数，然后使用task-specific损失LSτi(fθ)L_{S_{\\tau_i}}(f_\\theta)LSτi​​​(fθ​)反向传播，优化参数： θτi=θ−α∇θLSτi(fθ)(1)\\theta_{\\tau_{i}}=\\theta-\\alpha \\nabla_{\\theta} L_{S_{\\tau_{i}}}\\left(f_{\\theta}\\right)\\tag 1 θτi​​=θ−α∇θ​LSτi​​​(fθ​)(1) （2）外循环： 将内循环中所有任务的损失求和，重新进行反向传播，更新元初始化参数θ\\thetaθ： θ′=θ−β∇θLmeta (θ), where Lmeta (θ)=∑i=1BLQτi(fθτi)(2)\\theta^{\\prime}=\\theta-\\beta \\nabla_{\\theta} L_{\\text {meta }}(\\theta), \\text { where } L_{\\text {meta }}(\\theta)=\\sum_{i=1}^{B} L_{Q_{\\tau_{i}}}\\left(f_{\\theta_{\\tau_{i}}}\\right)\\tag 2 θ′=θ−β∇θ​Lmeta ​(θ), where Lmeta ​(θ)=i=1∑B​LQτi​​​(fθτi​​​)(2) 元测试： 内循环操作和元训练阶段一致（微调模型），但是外循环只计算模型在查询集上的精度，不执行梯度下降步骤。 2.2 ANIL “Rapid learning or feature reuse? ”这篇论文中提出了两个对立的假设，并证明了representation reuse在MAML中占主导地位： representation reuse： 认为在内循环之前模型已经足够泛化了，因此内循环中更不更新特征提取器已经无所谓了 representation change： 将MAML的归功于内循环中对特征提取器的优化操作，因此内循环中对特征提取器的优化必不可少 为了证明MAML中的representation reuse假说，作者提出了ANIL模型，它在训练和测试阶段的内循环中只更新分类器参数。实验结果表明和MAML先比，ANIL取得了有竞争力的表现。这表明通过MAML/ANIL训练得到的特征提取器在用于新任务时，得到的样本表示已经足够用于分类了，不需要对特征提取器参数进行更新。 更进一步，他们提出了NIL-testing（No Inner Loop）算法：在测试阶段直接把分类器去掉，直接利用用特征提取器得到的样本表示计算查询集样本和支持集样本间的距离进行分类。NIL-testing同样取得了和MAML差不多的性能。基于这些实验结果，研究人员把MAML的成功归因于representation reuse。 2.3 BOIL 作者对representation change的必要性进行调查后，提出了和“repid learning of feature reuse?”一文相对立的观点。作者认为元训练模型应该具有比较好的domain-agnostic adaptation能力，但是representation reuse显然不满足这一点。因为source和target domain之间相似度越高，representation reuse效果越好。当source和target domain之间相似度比较低的时候，representation reuse的很难取得令人满意的效果。 具体来说，对于元初始参数θ\\thetaθ可以划分成body（即特征提取器）参数θb\\theta_bθb​和head（即分类器）参数θh\\theta_hθh​，即θ={θb,θh}\\theta=\\{\\theta_b, \\theta_h\\}θ={θb​,θh​}。对于某个输入样本，其类别预测方式为：y^=fθ(x)=fθh(fθb(x))∈Rn, where fθb(x)∈Rd\\hat{y}=f_{\\theta}(x)=f_{\\theta_{h}}\\left(f_{\\theta_{b}}(x)\\right) \\in \\mathbb{R}^{n}, \\text { where } f_{\\theta_{b}}(x) \\in \\mathbb{R}^{d}y^​=fθ​(x)=fθh​​(fθb​​(x))∈Rn, where fθb​​(x)∈Rd。 对于某个具体任务τi\\tau_iτi​来说，其body参数和head参数分别表示为θb,τi\\theta_{b,\\tau_i}θb,τi​​和θh,τi\\theta_{h,\\tau_i}θh,τi​​，则内循环中参数优化方式如下： θb,τi=θb−αb∇θbLSτi(fθ)&amp;θh,τi=θh−αh∇θhLSτi(fθ)(3)\\theta_{b, \\tau_{i}}=\\theta_{b}-\\alpha_{b} \\nabla_{\\theta_{b}} L_{S_{\\tau_{i}}}\\left(f_{\\theta}\\right) \\&amp; \\theta_{h, \\tau_{i}}=\\theta_{h}-\\alpha_{h} \\nabla_{\\theta_{h}} L_{S_{\\tau_{i}}}\\left(f_{\\theta}\\right)\\tag 3 θb,τi​​=θb​−αb​∇θb​​LSτi​​​(fθ​)&amp;θh,τi​​=θh​−αh​∇θh​​LSτi​​​(fθ​)(3) MAML，ANIL，BOIL三种算法的不同之处就在于公式3中学习率的设定： MAML： 通常设置α=αb=αh(≠0)\\alpha=\\alpha_b=\\alpha_h(\\neq 0)α=αb​=αh​(​=0) ANIL： 设置αb=0\\alpha_b=0αb​=0，αh≠0\\alpha_h\\neq0αh​​=0 BOIL： 设置αb≠0\\alpha_b\\neq0αb​​=0，αh=0\\alpha_h=0αh​=0 下图1展示了三种不同更新方式下，内循环之后，模型发生的变化： 图a中，MAML在内循环中只对特征提取器进行了微调，分类器参数更新比较多，所以内循环后，特征分布基本不变，但是分类边界有比较大的变化。ANIL压根没有更新特征提取器，所以结果和MAML类似。 图b中，BOIL在内循环没有更新分类器，但是对特征提取器进行了更新，所以内循环后，分类边界没有变化，而样本分布发生了很大变化。 3. 实验 3.1 标准数据集及跨域任务上的表现 表1展示了标准数据集，1-shot和5-shot下MAML、ANIL和BOIL的性能。可以看到除了1-shot设定下的tieredImageNet数据集上ANIL取得最优表现，其他设定下BOIL都取得了最优表现。在Cars和CUB这种细粒度数据集上，BOIL取得了更明显的性能提升，这证明representation change即使在source和target domain之间相似度较高的场景下也是非常必要的。 表2实验结果表明跨域任务的所有设定下，BOIL均取得了最优性能。这表明BOIL中的representation change能够帮助模型更好的适应和source domain完全不同的unseen target domain。 3.2 学习率消融 可以看到学习率为0的时候，性能最好。 3.3 BOIL和Preconditioning Gradients 对Preconditionning Gradients不是很了解，这部分实验不做详细介绍，感兴趣的可以阅读原文。 3.4 BOIL中的representation change 一、Representation Change before/after Adaptation 为了分析BOIL算法种的学习机制究竟是representation reuse还是representation change，作者展示了adaptation前后的余弦相似度和CKA值。 上图展示了miniImageNet中一个查询集的余弦相似度，该查询集包含5个类别，每个类别有15个样本。上图橙色线代表同一个类别样本间的平均相似度，蓝色线代表不同类别样本之间的凭据相似度。上图中左边的为adaptation前，即未执行内循环操作前，右边表示执行完adaptation后。分析上图结果可以得出以下三个结论： 从上图2(a)(b)形状类似，adaptation操作对结果没有产生影响，ANIL/MAML支持representation reuse这一假说。 从上图2©可以看出，adaptation前后实验结果并不相同，执行完adaptation后，第四个卷积层执行完后类间相似度得到了降低，BOIL支持representation change这一假说。 从上图2©中可以看到，adaptation操作对前三个卷积层并没有产生显著影响，知道第四个卷积层才对模型产生影响。关于这一点前人有关于此的研究，具体可以查看原文。 总结： 从上面实验结果可以返现，MAML/ANIL遵循的时representation reuse训练机制，而BOIL遵循representation change训练机制，具体来说在最后一个卷积层之前是representation reuse，在最后一个卷积层是representation change。 为了进一步证明BOIL在low- and mid-level层时representation reuse，而high-level层是representation change，作者计算了模型在不同层的CKA值。两个表示向量的CKA值接近1，说明这两个表示几乎相同。结果如下图3所示： 可以看到MAML/ANIL算法中，经过特征提取器后，特征向量几乎没有发生改变。但是在BOIL中最后一层特征向量发生了显著变化，这一结果进一步佐证了上述余弦相似度实验得到的结论。 二、实验下BOIL中Representation Change w/head和w/0 head分别表示内循环中保留和去掉head（即分类器）。分析上表5，可以得出以下结论： with head情况下的所有算法： before adaptation之前所有算法性能都在20%左右，等于瞎猜。after adaptation之后所有模型性能都得到显著提高，并且BOIL在四种设定下都取得了最好的表现。这说明BOIL的representation change比MAML/ANIL的representation reuse更有效。 without head情况下的MAML/ANIL： 可以看到adaptation前模型已经学习到了一个质量较高的representation，因此adaptation对于模型性能的提升并没有什么帮助。（实验结果和理论假设是相呼应的：即MAML/ANIL的学习机制是representation reuse）。 without head情况下的BOIL： 这种情况下执行完adaptation操作后，BOIL的性能会得到显著提升。（实验结果也和理论假设相呼应：即BOIL的学习机制是representation change）。 3.5 大型网络下的BOIL 下表6展示了以残差网络作为BOIL骨架时的模型性能，其中LSC表示Last Skip Connection。 可以看到训练阶段和测试阶段的数据无论来自同一个domain和还是不同domain，BOIL都取得了最好性能。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"name":"MAML","slug":"MAML","permalink":"http://rookieyin.github.io/tags/MAML/"}]},{"title":"MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning","slug":"3 论文笔记/小样本学习/6.MELR Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning","date":"2021-07-02T01:50:11.000Z","updated":"2021-07-02T02:07:46.574Z","comments":true,"path":"37c8c413dda8/","link":"","permalink":"http://rookieyin.github.io/37c8c413dda8/","excerpt":"https://openreview.net/pdf?id=D3PcGLdMx0 MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning，2021，ICLR 总结：这是一篇针对小样本学习模型稳定性的文章。作者从小样本元学习模型抗干扰能力比较弱，在poor sampling情况下稳定性比较差这一点入手，提出了一种新的元学习框架MELR。具体来说基于CEAM和CECR这两个技术，提升了元学习模型在poor sampling下的稳定性。前者是一种跨episode的自注意力方法，后者是一种跨episode的正则化方法。个人觉得模型的实际意义不是很大，实际应用中，尤其标准数据集中这种poor sampling并不常见，对模型的性能应该没太多影响。作者提出的MELR模型和传统模型相比增加了一定复杂度，但是从标准数据集上的实验来看，性能并没有提高太多。不过，个人认为小样本模型抗干扰能力或者说稳定性确实是一个比较有研究价值的方向。","text":"https://openreview.net/pdf?id=D3PcGLdMx0 MELR: Meta-Learning via Modeling Episode-Level Relationships for Few-Shot Learning，2021，ICLR 总结：这是一篇针对小样本学习模型稳定性的文章。作者从小样本元学习模型抗干扰能力比较弱，在poor sampling情况下稳定性比较差这一点入手，提出了一种新的元学习框架MELR。具体来说基于CEAM和CECR这两个技术，提升了元学习模型在poor sampling下的稳定性。前者是一种跨episode的自注意力方法，后者是一种跨episode的正则化方法。个人觉得模型的实际意义不是很大，实际应用中，尤其标准数据集中这种poor sampling并不常见，对模型的性能应该没太多影响。作者提出的MELR模型和传统模型相比增加了一定复杂度，但是从标准数据集上的实验来看，性能并没有提高太多。不过，个人认为小样本模型抗干扰能力或者说稳定性确实是一个比较有研究价值的方向。 1. 简介 1.1 摘要 Most recent few-shot learning (FSL) approaches are based on episodic training whereby each episode samples few training instances (shots) per class to imitate the test condition. However, this strict adhering to test condition has a negative side effect, that is, the trained model is susceptible to the poor sampling of few shots. In this work, for the first time, this problem is addressed by exploiting inter-episode relationships. Specifically, a novel meta-learning via modeling episode-level relationships (MELR) framework is proposed. By sampling two episodes containing the same set of classes for meta-training, MELR is designed to ensure that the meta-learned model is robust against the presence of poorly-sampled shots in the meta-test stage. This is achieved through two key components: (1)a Cross-Episode Attention Module (CEAM) to improve the ability of alleviating the effects of poorly-sampled shots, and (2) a Cross-Episode Consistency Regularization (CECR) to enforce that the two classifiers learned from the two episodes are consistent even when there are unrepresentative instances. Extensive experiments for non-transductive standard FSL on two benchmarks show that our MELR achieves 1.0%–5.0% improvements over the baseline (i.e., ProtoNet) used for FSLin our model and outperforms the latest competitors under the same settings. 现有小样本学习方法大多数都是基于episodic训练，每个episode中每个类别只采样少量样本，来模拟测试环境。但是这种严格的遵循测试条件存在负面影响，即训练出的模型容易受到小样本poor sampling的影响。本文，我们首次通过挖掘不同episode之间的关系来解决这个问题。具体来说，我们通过对episode-level关系进行建模，提出了一种新的元学习方法MELR。通过每次采样两个类别相同的episode用于元训练，MELR能够保证模型在poorly-sampled的测试环境下也能保持稳定。这个功能是通过两个关键组件实现的：（1）Cross-Episode Attention Module（CEAM），帮助模型抵消pooly-sample shots的影响；（2）Cross-Episode Consistency Regularization（CECR），当存在unrepresentative样本时，让来自不同episode的两个分类器竟可能保持一致。两个标准FSL数据集下的大量非转导实验表明我们的MELR模型和baseline相比能取得1%~5%的性能提升，并且在相同设置下优于最新的竞争对手。 注：什么是poorly-sampled样本？就是品质比较差、噪声比较多的样本。比如，用一只背对着我们，同时身体被部分遮挡的猫来训练分类器，这时训练出的模型可能无法识别品质好的猫的图片。 1.2 本文工作 背景： 传统的深度神经网络，比如CNN，依赖于大量有标签数据，但是在很多实际应用场景中无法获取充足的有标签样本。因此，近些年来小样本学习得到了广泛研究，尤其是基于元学习的小样本学习方法。 动机： 现有的元学习方法基本都是采用episode 方式训练模型，即在训练时利用样本充足的基类构造episode。每个episode都模拟测试环境构建的，即一个N-way K-shot的任务。这种完全模拟测试环境的方式可以保证元学习模型能够快速适应新的小样本任务。但是这会给模型带来负面影响：模型容易受到poor sampling的影响，即模型稳定性不够。 原因： 上述所说的弊端，本质上还是因为小样本场景下，训练样本数量不够多，模型抗噪声能力比较弱，容易受到对抗攻击，导致模型稳定性较差，尤其在1-shot设定下。比如，在1-shot设定下的support集中，采用一张背对着我们同时身体被部分遮挡的猫来训练分类器，那么查询集中一张品质较高的猫可能就无法被识别。 本文工作： 作者提出了一种新的元学习框架MELR，通过CEAM和CECR两个功能组件提高模型在poor sampling下的稳定性 。前者是一个跨episode的自注意力方法，后者是一个跨episode的正则化方法。 2. 方法 在传统元学习方法中，生成N-way K-shot episode的方式如下： （1）从基类CbC_bCb​中选取N个类别，并re-index得到Ce={1,2,...,N}C_e=\\{1,2,...,N\\}Ce​={1,2,...,N}。 （2）CeC_eCe​中每个类别随机选取K个support样本和Q个query样本，得到Se={(xi,yi)∣yi∈Ce,i=1,2,...,N×K}S_e=\\{(x_i,y_i)|y_i\\in C_e,i=1,2,...,N\\times K\\}Se​={(xi​,yi​)∣yi​∈Ce​,i=1,2,...,N×K}和Qe={(xi,yi)∣yi∈Ce,i=1,2,...,N×Q}Q_e=\\{(x_i,y_i)|y_i\\in C_e,i=1,2,...,N\\times Q\\}Qe​={(xi​,yi​)∣yi​∈Ce​,i=1,2,...,N×Q}。 对于episode e，损失函数通常定义如下： Lfsc(e)=E(xi,yi)∈QeL(yi,f(ψ(xi);Se))(1)L_{f s c}(e)=\\mathbb{E}_{\\left(x_{i}, y_{i}\\right) \\in \\mathcal{Q}_{e}} L\\left(y_{i}, f\\left(\\psi\\left(x_{i}\\right) ; \\mathcal{S}_{e}\\right)\\right)\\tag 1 Lfsc​(e)=E(xi​,yi​)∈Qe​​L(yi​,f(ψ(xi​);Se​))(1) 其中ψ\\psiψ表示特征提取函数，f(⋅;Se):Rd→RNf\\left(\\cdot ; \\mathcal{S}_{e}\\right): \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{N}f(⋅;Se​):Rd→RN表示得分函数（比如softmax），L(⋅,⋅)L(·,·)L(⋅,⋅)表示损失函数（通常用交叉熵损失）。通过多个上面这样的episode不断训练模型后，在meta-test episode上测试模型。 上图展示了本文提出的MELR模型框架图。可以看到，和传统元学习相比，区别在于每一次训练都会构建两个类别相同的episode，然后经过CEAM对所有样本特征进行转换后，再计算查询集样本的类别得分，最后损失函数中会添加一项正则化损失。下面具体介绍下作者提出的CEAM和CECR方法。 2.1 CEAM 每一轮从同一个类别集合CeC_eCe​采样两个episode，e(1)=(Se(1),Qe(1))e^{(1)}=(S_e^{(1)},Q_e^{(1)})e(1)=(Se(1)​,Qe(1)​)和e(2)=(Se(2),Qe(2))e^{(2)}=(S_e^{(2)},Q_e^{(2)})e(2)=(Se(2)​,Qe(2)​)，e(1)∩e(2)=∅e^{(1)}\\cap e^{(2)}=\\emptysete(1)∩e(2)=∅。我了降低badly-sampled样本的影响，作者提出了CEAM——跨episode注意力模型。 具体来说，S(1)=[ψ(xi)T;xi∈Se(1)]∈RNK×d\\mathbf{S}^{(1)}=\\left[\\psi\\left(x_{i}\\right)^{T} ; x_{i} \\in \\mathcal{S}_{e}^{(1)}\\right] \\in \\mathbb{R}^{N K \\times d}S(1)=[ψ(xi​)T;xi​∈Se(1)​]∈RNK×d和Q(1)=[ψ(xi)T;xi∈Qe(1)]∈RNQ×d\\mathbf{Q}^{(1)}=\\left[\\psi\\left(x_{i}\\right)^{T} ; x_{i} \\in \\mathcal{Q}_{e}^{(1)}\\right] \\in\\mathbb R^{NQ\\times d}Q(1)=[ψ(xi​)T;xi​∈Qe(1)​]∈RNQ×d分别表示支持集和查询集样本的特征矩阵，S(2)\\mathbf S^{(2)}S(2)和Q(2)\\mathbf Q^{(2)}Q(2)同理。同时F(1)=[S(1);Q(1)]∈RN(K+Q)×d\\mathbf{F}^{(1)}=\\left[\\mathbf{S}^{(1)} ; \\mathbf{Q}^{(1)}\\right] \\in \\mathbb{R}^{N(K+Q) \\times d}F(1)=[S(1);Q(1)]∈RN(K+Q)×d，F(2)\\mathbf F^{(2)}F(2)同理。具体计算方法如下： F^(1)=CEAM⁡(F(1),S(2),S(2))=F(1)+softmax⁡(FQ(1)SK(2)Td)SV(2)(2)\\hat{\\mathbf{F}}^{(1)}=\\operatorname{CEAM}\\left(\\mathbf{F}^{(1)}, \\mathbf{S}^{(2)}, \\mathbf{S}^{(2)}\\right)=\\mathbf{F}^{(1)}+\\operatorname{softmax}\\left(\\frac{\\mathbf{F}_{Q}^{(1)} \\mathbf{S}_{K}^{(2) T}}{\\sqrt{d}}\\right) \\mathbf{S}_{V}^{(2)}\\tag 2 F^(1)=CEAM(F(1),S(2),S(2))=F(1)+softmax(d​FQ(1)​SK(2)T​​)SV(2)​(2) 其中输入的Q、K、V三元组是将原有特征矩阵映射到一个潜在空间中，计算方式如下： FQ(1)=F(1)WQ∈RN(K+Q)×d(3)\\begin{aligned}\\mathbf{F}_{Q}^{(1)}&amp;=\\mathbf{F}^{(1)} \\mathbf{W}_{Q} \\in \\mathbb{R}^{N(K+Q) \\times d} \\end{aligned}\\tag 3 FQ(1)​​=F(1)WQ​∈RN(K+Q)×d​(3) SK(2)=S(2)WK∈RNK×d(4)\\begin{aligned} \\mathbf{S}_{K}^{(2)}=\\mathbf{S}^{(2)} \\mathbf{W}_{K} \\in \\mathbb{R}^{N K \\times d} \\end{aligned}\\tag 4 SK(2)​=S(2)WK​∈RNK×d​(4) SV(2)=S(2)WV∈RNK×d(5)\\begin{aligned} \\mathbf{S}_{V}^{(2)}&amp;=\\mathbf{S}^{(2)} \\mathbf{W}_{V} \\in \\mathbb{R}^{N K \\times d} \\end{aligned}\\tag 5 SV(2)​​=S(2)WV​∈RNK×d​(5) 对于e(2)e^{(2)}e(2)，计算方式也是一样的： F^(2)=CEAM⁡(F(2),S(1),S(1))=F(2)+softmax⁡(FQ(2)SK(1)Td)SV(1)(6)\\hat{\\mathbf{F}}^{(2)}=\\operatorname{CEAM}\\left(\\mathbf{F}^{(2)}, \\mathbf{S}^{(1)}, \\mathbf{S}^{(1)}\\right)=\\mathbf{F}^{(2)}+\\operatorname{softmax}\\left(\\frac{\\mathbf{F}_{Q}^{(2)} \\mathbf{S}_{K}^{(1) T}}{\\sqrt{d}}\\right) \\mathbf{S}_{V}^{(1)}\\tag 6 F^(2)=CEAM(F(2),S(1),S(1))=F(2)+softmax(d​FQ(2)​SK(1)T​​)SV(1)​(6) 其中WQ,WK and WV\\mathbf{W}_{Q}, \\mathbf{W}_{K} \\text { and } \\mathbf{W}_{V}WQ​,WK​ and WV​都是可学习参数。 2.2 CECR 为了进一步提高模型对badly-sampled样本的抗干扰能力，作者提出了CECR方法，强迫两个分类器能够保持一致的预测。具体来说，CECR采用基于知识蒸馏的策略。f(⋅;S^(1)):Rd→RNf(\\cdot ; \\hat{\\mathbf{S}}^{(1)}): \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{N}f(⋅;S^(1)):Rd→RN和 f(⋅;S^(2)):Rd→RNf(\\cdot ; \\hat{\\mathbf{S}}^{(2)}): \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{N}f(⋅;S^(2)):Rd→RN分别表示基于S^(1)\\mathbf{\\hat S}^{(1)}S^(1)和S^(2)\\mathbf{\\hat S}^{(2)}S^(2)训练得到的分类器。为了评价哪个分类器性能更好，我们在Q^e(1,2)=Q^e(1)∪Q^e(2)={(q^i(1,2),yi(1,2)),i=1,2,⋯ ,2NQ})\\hat{\\mathcal{Q}}_{e}^{(1,2)}=\\hat{\\mathcal{Q}}_{e}^{(1)} \\cup \\hat{\\mathcal{Q}}_{e}^{(2)}=\\{(\\hat{\\mathbf{q}}_{i}^{(1,2)}, y_{i}^{(1,2)}), i=1,2, \\cdots, 2 N Q\\})Q^​e(1,2)​=Q^​e(1)​∪Q^​e(2)​={(q^​i(1,2)​,yi(1,2)​),i=1,2,⋯,2NQ})计算两个分类器的准确度。 我们将准确度高的分类器作为teacher分类器，另一个作为student分类器。下面假设f(⋅;S^(1))f(\\cdot ; \\hat{\\mathbf{S}}^{(1)})f(⋅;S^(1))准确度高于f(⋅;S^(2))f(\\cdot ; \\hat{\\mathbf{S}}^{(2)})f(⋅;S^(2))，知识蒸馏损失定义如下： Lcecr(e(1),e(2);T)=E(q^i(1,2),yi(1,2))∈Q^e(1,2)L′(f(q^i(1,2);S^(1)),f(q^i(1,2);S^(2));T)(7)L_{c e c r}\\left(e^{(1)}, e^{(2)} ; T\\right)=\\mathbb{E}_{\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)}, y_{i}^{(1,2)}\\right) \\in \\hat{\\mathcal{Q}}_{e}^{(1,2)} }L^{\\prime}\\left(f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(1)}\\right), f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(2)}\\right) ; T\\right)\\tag 7 Lcecr​(e(1),e(2);T)=E(q^​i(1,2)​,yi(1,2)​)∈Q^​e(1,2)​​L′(f(q^​i(1,2)​;S^(1)),f(q^​i(1,2)​;S^(2));T)(7) TTT温度参数，如果使用softmax函数作为分类器，则有： L′(f(q^i(1,2);S^(1)),f(q^i(1,2);S^(2));T)=−∑j=1Nσj(f(q^i(1,2);S^(1));T)log⁡(σj(f(q^i(1,2);S^(2));T))(8)\\begin{aligned}&amp; L^{\\prime}\\left(f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(1)}\\right), f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(2)}\\right) ; T\\right) \\\\=&amp;-\\sum_{j=1}^{N} \\sigma_{j}\\left(f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(1)}\\right) ; T\\right) \\log \\left(\\sigma_{j}\\left(f\\left(\\hat{\\mathbf{q}}_{i}^{(1,2)} ; \\hat{\\mathbf{S}}^{(2)}\\right) ; T\\right)\\right)\\end{aligned}\\tag 8 =​L′(f(q^​i(1,2)​;S^(1)),f(q^​i(1,2)​;S^(2));T)−j=1∑N​σj​(f(q^​i(1,2)​;S^(1));T)log(σj​(f(q^​i(1,2)​;S^(2));T))​(8) 需要注意的是反向传播时，f(⋅;S^(1))f(·;\\mathbf{\\hat S}^{(1)})f(⋅;S^(1))的梯度会被掐断，因为teacher分类器的输出用来指导学生分类器了。（这应该是知识蒸馏中的常规操作）。 2.3 模型训练 对于每个episode的分类损失函数定义如下： Lfsc(e)=E(q^i,yi)∈Q^eL(yi,fProtoNet (q^i;S^))=E(q^i,yi)∈Q^e−log⁡σyi(fProtoNet (q^i;S^))(9)\\begin{aligned}L_{f s c}(e) &amp;=\\mathbb{E}_{\\left(\\hat{\\mathbf{q}}_{i}, y_{i}\\right) \\in \\hat{\\mathcal{Q}}_{e}} L\\left(y_{i}, f_{\\text {ProtoNet }}\\left(\\hat{\\mathbf{q}}_{i} ; \\hat{\\mathbf{S}}\\right)\\right) \\\\&amp;=\\mathbb{E}_{\\left(\\hat{\\mathbf{q}}_{i}, y_{i}\\right) \\in \\hat{\\mathcal{Q}}_{e}}-\\log \\sigma_{y_{i}}\\left(f_{\\text {ProtoNet }}\\left(\\hat{\\mathbf{q}}_{i} ; \\hat{\\mathbf{S}}\\right)\\right)\\end{aligned}\\tag 9 Lfsc​(e)​=E(q^​i​,yi​)∈Q^​e​​L(yi​,fProtoNet ​(q^​i​;S^))=E(q^​i​,yi​)∈Q^​e​​−logσyi​​(fProtoNet ​(q^​i​;S^))​(9) 在结合CECR中的模型损失，我们定义模型的最终损失为： Ltotal =12(Lfsc(e(1))+Lfsc(e(2)))+λLcecr(e(t),e(s);T)(10)L_{\\text {total }}=\\frac{1}{2}\\left(L_{f s c}\\left(e^{(1)}\\right)+L_{f s c}\\left(e^{(2)}\\right)\\right)+\\lambda L_{c e c r}\\left(e^{(t)}, e^{(s)} ; T\\right)\\tag {10} Ltotal ​=21​(Lfsc​(e(1))+Lfsc​(e(2)))+λLcecr​(e(t),e(s);T)(10) 模型的伪代码如下图所示： 3. 实验 数据集： miniImageNet和tieredImageNet 实现细节： 分别使用Conv4-64，Conv4-512和ResNet作为特征提取器。为了加速训练过程，三个模型都在之前工作基础上先进行了预训练。 3.1 对比实验 注： ProtoNet †\\text { ProtoNet }^{\\dagger} ProtoNet †表示训练是也采样两个episode。 ResNet-12优于Conv4-512，Conv4-512优于Conv4-64。这个是符合我们的直觉的，更大的神经网络，学习到的图像特征质量更好。 MELR和其他所有方法相比，在所有设定下都取得了最优效果。 和baseline ProtoNet相比，MELR在1-shot下取得的性能提升大于5-shot，因为1-shot下模型poor sampling的可能性更大。这从侧面佐证了作者提出的MELR模型可以提高模型稳定性。 3.2 拓展实验 消融实验 （1）图(a)表示对MELR的各个组件进行消融，可以看到CECR和CEAM对模型性能的提升都有帮助。 （2）图(b)对CEAM的不同实现方式进行了对比，本文CEAM的实现方式是将support样本作为“keys”和“values”，另一个episode的所有样本作为“queries”，表示为Support→AllSupport\\rightarrow AllSupport→All。还可以将prototypes作为“keys”和“values”或者单独将query样本作为&quot;queries&quot;，分别表示为： Prototype → Query, Support → Query, and Prototype → All \\text { Prototype } \\rightarrow \\text { Query, Support } \\rightarrow \\text { Query, and Prototype } \\rightarrow \\text { All } Prototype → Query, Support → Query, and Prototype → All 。 （3）图©对比了CECR的不同实现方法。 可视化 （1）图(a)~©可视化了 ProtoNet †\\text { ProtoNet }^{\\dagger} ProtoNet † ，ProtoNet†+CEAMProtoNet^{\\dagger}+CEAMProtoNet†+CEAM 和 ProtoNet†+CEAM+CECRProtoNet^{\\dagger}+CEAM+CECRProtoNet†+CEAM+CECR 三个模型中的数据分布。 （2）图(d)~(e)可是花了查询集合支持集中的注意力权重热图。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}]},{"title":"Concept Learners for Few-Shot Learning","slug":"3 论文笔记/小样本学习/5.Concept Learners for Few-Shot Learning","date":"2021-06-29T10:06:25.000Z","updated":"2021-06-29T10:11:58.544Z","comments":true,"path":"60dfc66a65fd/","link":"","permalink":"http://rookieyin.github.io/60dfc66a65fd/","excerpt":"https://arxiv.org/pdf/2007.07375 https://github.com/snap-stanford/comet Concept Learners for Few-Shot Learning，2021，ICLR 总结：文章立足点比较好，从人类认知模式出发，即人类认知的核心在于结构化、可复用的concepts，比如鸟类生物的羽毛、翅膀、喙，通过组合这些concepts我们可以快速、准确的识别鸟类生物。但是现有的元学习方法都是学习一个joint、unstructured先验知识，这限制了模型的泛化能力。因此作者从concept这个维度，提出了COMET模型，通过聚合多个不同concept learner学到的信息进行小样本分类。但是从实验结果看，COMET的主要缺点是对concept的依赖过大。使用人工标注concept时，和baseline相比COMET性能有很大幅度提升，但是使用自动提取的concept时，性能提升有限，而且这种性能的提升可能更多的来自于模型的复杂度（因为N个concept learner相当于堆叠了N个原型网络，模型复杂度提高了N倍）。","text":"https://arxiv.org/pdf/2007.07375 https://github.com/snap-stanford/comet Concept Learners for Few-Shot Learning，2021，ICLR 总结：文章立足点比较好，从人类认知模式出发，即人类认知的核心在于结构化、可复用的concepts，比如鸟类生物的羽毛、翅膀、喙，通过组合这些concepts我们可以快速、准确的识别鸟类生物。但是现有的元学习方法都是学习一个joint、unstructured先验知识，这限制了模型的泛化能力。因此作者从concept这个维度，提出了COMET模型，通过聚合多个不同concept learner学到的信息进行小样本分类。但是从实验结果看，COMET的主要缺点是对concept的依赖过大。使用人工标注concept时，和baseline相比COMET性能有很大幅度提升，但是使用自动提取的concept时，性能提升有限，而且这种性能的提升可能更多的来自于模型的复杂度（因为N个concept learner相当于堆叠了N个原型网络，模型复杂度提高了N倍）。 1. 简介 1.1 摘要 Developing algorithms that are able to generalize to a novel task given only a few labeled examples represents a fundamental challenge in closing the gap between machine- and human-level performance. The core of human cognition lies in the structured, reusable concepts that help us to rapidly adapt to new tasks and provide reasoning behind our decisions. However, existing meta-learning methods learn complex representations across prior labeled tasks without imposing any structure on the learned representations. Here we propose COMET, a meta-learning method that improves generalization ability by learning to learn along human-interpretable concept dimensions. Instead of learning a joint unstructured metric space, COMET learns mappings of high-level concepts into semi-structured metricspaces, and effectively combines the outputs of independent concept learners. We evaluate our model on few-shot tasks from diverse domains, including fine-grained image classification, document categorization and cell type annotationon a novel dataset from a biological domain developed in our work. COMET significantly outperforms strong meta-learning baselines, achieving 6–15% relative improvement on the most challenging 1-shot learning tasks, while unlike existing methods providing interpretations behind the model’s predictions. 为了缩小机器和人类学习性能之间的差距，开发能够在之给定少量样本下就能适应新任务的算法是一个基本挑战。人类认知的核心在于结构化、可复用的concepts，它可以帮助我们快速适应新任务并提供决策背后的推理。但是现有的元学习方法在学习复杂表征的过程中，并不会添加任何结构。本文我们提出了COMET模型——一种元学习方法，从人类可解释的concept维度出发，通过learning to learn来提高模型泛化能力。和元学习不同，COMET不是学习一个联合的无结构的度量空间，而是学习将高层级的concept映射到半结构化度量空间，然后讲这些独立的concept learners有效结合到一起。我们在多个领域，包括图像分类、文本分类、生物，评估了我们的方法。在1-shot设定下，和其他元学习方法相比，COMET取得了6%-15%的性能提升，同时不像其他方法，我们的模型是可解释的。 1.2 本文工作 先验知识： 要理解本文，需要先理解“concept”这一概念。所谓“concept”，我觉得可以理解成物体具有代表性的局部组件，以鸟为例，它的羽毛、嘴巴、翅膀等都是非常重要的的concept，可以帮助人类进行识别。“ Intuitively, concepts can be seen as part-based representations of the input and reflect the way humans reason about the world. ”原文中这句话也说的比较形象。 动机： 人类的知识是结构化的，由各种可以重复使用的concepts组成。比如我们在识别新的鸟类物种时，我们早就知道了羽毛、翅膀、喙这些concept的大概样子，所以来了一张鸟类照片，我们只需要关注这些具体concepts，然后将它们组合到一起就能识别它的种类。但是现有的元学习方法，学习到的是一个joint and unstructured先验知识，这限制了模型的泛化能力。 本文工作： 从人类可解释的concept维度，提出了一种新的元学习模型COMET。COMET为每个concept学习一个单独的度量空间，这里作者借鉴原型网络思想，为每个concept学习一个concept prototype。然后将不同concept learners和concept prototype中的信息有效聚合在一起进行最终预测。和现有的元学习方法相比，比如原型网络、匹配网络等等，COMET模型是可解释的，这是十分重要的，尤其在小样本场景下。 2. 方法 假设： 假定输入数据的维度可以划分成若干相关维度的子集，分别对应人类可解释的高层级的concept。这些集合可能有重叠、噪声、不完整，但是在许多真实场景中这种划分是存在的。例如，CV中concept可以对应图像的segment，NLP中对应语义相关的单词，生物学中可以对应于外部的知识库和本体。其实在很多领域中，已经有现成的concepts，或者可以通过现有技术进行自动生成。 Concept符号表示：C={c(j)}j=1N\\mathcal C = \\{\\mathbf c^{(j)}\\}_{j=1}^NC={c(j)}j=1N​表示N个concepts集合，其中每个concept c(j)∈{0,1}D\\mathbb c^{(j)}\\in\\{0,1\\}^Dc(j)∈{0,1}D为一个D维binary向量，cij=1c_i^{j}=1cij​=1表示 i−thi-thi−th 维度可以用来描述该concept，DDD表示输入数据的维度。对于C\\mathcal CC，我们不做任何限制，这也就意味着里面可以有重复或者冗余的concept。 一、算法细节 COMET算法如上图1所示，它不是只学习一个映射函数fθ:RD→RMf_{\\boldsymbol{\\theta}}: \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{M}fθ​:RD→RM，而是为每一个concept都学习一个单独的embedding函数fθ(j):RD→RMf_{\\boldsymbol{\\theta}}^{(j)}: \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{M}fθ(j)​:RD→RM。如图1所示，concept嵌入函数被称之为concept learners，是一个深度神经网络下的非线性函数。每个concept learner j都会计算一个concept prototypes pk(j)p_k^{(j)}pk(j)​，表示 kkk 类别下该concept的原型。具体计算方式如下： pk(j)=1∣Sk∣∑(xi,yi)∈Skfθ(j)(xi∘c(j))(3)\\mathbf{p}_{k}^{(j)}=\\frac{1}{\\left|\\mathcal{S}_{k}\\right|} \\sum_{\\left(\\mathbf{x}_{i}, y_{i}\\right) \\in \\mathcal{S}_{k}} f_{\\boldsymbol{\\theta}}^{(j)}\\left(\\mathbf{x}_{i} \\circ \\mathbf{c}^{(j)}\\right)\\tag 3 pk(j)​=∣Sk​∣1​(xi​,yi​)∈Sk​∑​fθ(j)​(xi​∘c(j))(3) 其中∘\\circ∘表示Hadamard product。最终每个类别 kkk 都会得到N个concept原型 {pk(j)}j=1K\\{p_k^{(j)}\\}_{j=1}^K{pk(j)​}j=1K​。 二、类别判定 给定一个查询数据 xq\\mathbf x_qxq​，先得到它的所有concept embeddings后，然后通过计算这些embedding到对应concept原型之间的距离来判定其类别。具体计算公式如下： pθ(y=k∣xq)=exp⁡(−∑jd(fθ(j)(xq∘c(j)),pk(j)))∑k′exp⁡(−∑jd(fθ(j)(xq∘c(j)),pk′(j)))(4)p_{\\boldsymbol{\\theta}}\\left(y=k \\mid \\mathbf{x}_{q}\\right)=\\frac{\\exp \\left(-\\sum_{j} d\\left(f_{\\boldsymbol{\\theta}}^{(j)}\\left(\\mathbf{x}_{q} \\circ \\mathbf{c}^{(j)}\\right), \\mathbf{p}_{k}^{(j)}\\right)\\right)}{\\sum_{k^{\\prime}} \\exp \\left(-\\sum_{j} d\\left(f_{\\boldsymbol{\\theta}}^{(j)}\\left(\\mathrm{x}_{q} \\circ \\mathbf{c}^{(j)}\\right), \\mathbf{p}_{k^{\\prime}}^{(j)}\\right)\\right)}\\tag 4 pθ​(y=k∣xq​)=∑k′​exp(−∑j​d(fθ(j)​(xq​∘c(j)),pk′(j)​))exp(−∑j​d(fθ(j)​(xq​∘c(j)),pk(j)​))​(4) 其中d(⋅)d(·)d(⋅)表示距离函数，作者这里采用欧式距离，因为实验中作者发现欧式距离效果比余弦距离好。 三、可解释性 除了算法本身外，COMET还可以通过下面两个功能，对算法背后的预测结果提供强有力的解释。 Local and global concept importance score COMET模型中，每个类别不在是由一个原型表示，而是由N个concept原型表示。 local score：对于某个查询样本xq\\mathbf x_qxq​，d(fθ(j)(xq∘c(j)),pk(j))d\\left(f_{\\boldsymbol{\\theta}}^{(j)}\\left(\\mathbf{x}_{q} \\circ \\mathbf{c}^{(j)}\\right), \\mathbf{p}_{k}^{(j)}\\right)d(fθ(j)​(xq​∘c(j)),pk(j)​)的倒数可以表示local得分，得分越高表示该部分concept对于该样本类型判别来说越重要。这也直观的解释了模型在预测xq\\mathbb x_qxq​类型时，背后的推理过程。 global score：同样地，对于一组查询样本或者整个类别样本，我们可以从global score角度对模型的行为进行解释。通过计算每种concept embedding和concept prototype之间距离的平均值，可以得到对于这一组样本，哪中concept最重要。 寻找局部相似样本 给定一个concept jjj，COMET可以通过计算concept embedding和concept prototype之间的距离并进行排序，找到局部相似或者差异很大的样本。 3. 实验 数据集： 分别在CV、NLP、生物三个领域对COMET的性能进行了测试，使用的数据集分别为CUB、Reuters和Tabula Muris。 Baselines： FineTune(ICLR 2019)、匹配网络、MAML、关系网络、MetaOptNet、DeepEMD（只能用于图像分类）和原型网络。 实验设置： 所有实验都是5-way设置，测试阶段随机采样600个episode计算平均精度。CUB数据集上采用4层CNN为骨架，输入大小为84×8484\\times 8484×84。更具体信息可以参看原文附件A。 3.1 基础实验 一、对比实验 下表1展示了COMET和其他baseline的实验结果，可以看到COMET模型在性能上取得了大幅度提升，平均接近10%。 为了证明COMET性能的提升不是额外的权重带来的（因为COMET中N个concept learner相当于N个原型网络），作者对比了COMET和强化原型网络，结果如下表2所示： 其中第一行表示训练多个原型网络投票表决，第二行表示concept learner之间共享权重，第三行为完整的COMET。可以看到和ProtoNetEns相比，COMET的性能仍然有较大幅度提升尤其在后两个数据集上。不过ProtoNetEns和ProtoNet相比性能也得到了较多提升，因此说明COMET的性能提升也有部分来源于额外的权重（堆复杂度）。 二、concept数量消融 可以看到，随着concept数量增加，模型性能会提升，但concept躲到一定程度后，性能提升并不明显，存在性能上限。另外从上图右边可以看出，concept数量即使在1500时模型性能并没有受到影响，这证明了COMET的稳定性很好，不会受冗余的concept的影响。 3.2 无监督concept标注 前面的数据集都是基于人工标注的concept进行的，下面的实验利用自动提取的concept测试COMET的性能。下图5展示了CUB数据集上自动提取的landmarks，concepts数量设定为30： 虽然提取出的坐标比较粗糙，但是如下表3所示，和最好方法相比，COMET方法依旧有性能提升： 这里可以看到和人工标记concept相比，COMET带来的性能提升大幅度下降。虽然基于自动提取concept的COMET性能也得到了部分提升，但是我觉得这种性能的提升可能来源于模型复杂度，即额外参数。作者这里没有和ProtoNetEns进行对比，我觉得如果对比两者性能的话，差别应该不大。因此，可以看出COMET对concept的依赖是很大的，如果使用模糊的concept，很难带来令人满意的性能提升。 3.3 可解释性 回答下列4个问题： 对于某个查询样本，哪个concept对于类型判别最重要 对于某个类别，哪个concept最重要 哪些样本具有局部相似性 global concept指的是将整张图片看做一个concept，这时往往反映的时背景相似度。 哪些样本能够最好的代表concept原型","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}]},{"title":"A Meta-Learning Approach for Graph Representation Learning in Multi-Task Settings","slug":"3 论文笔记/图学习/9.A Meta-Learning Approach for Graph Representation Learning in Multi-Task Settings","date":"2021-06-28T06:34:30.000Z","updated":"2021-08-15T13:01:12.975Z","comments":true,"path":"55b6b5aeb67b/","link":"","permalink":"http://rookieyin.github.io/55b6b5aeb67b/","excerpt":"https://arxiv.org/pdf/2012.06755 https://github.com/DavideBuffelli/SAME A Meta-Learning Approach for Graph Representation Learning in Multi-Task Settings，2020，NIPS workshop 总结：本文是2020年NIPS workshop上分享的一篇文章，角度很新颖，跳出了用元学习解决小样本问题这个圈子，利用元学习跨任务学习这一特性，来解决多任务图学习问题。文章算法很简单，基本和MAML模型完全一致，但是切入角度值得借鉴。","text":"https://arxiv.org/pdf/2012.06755 https://github.com/DavideBuffelli/SAME A Meta-Learning Approach for Graph Representation Learning in Multi-Task Settings，2020，NIPS workshop 总结：本文是2020年NIPS workshop上分享的一篇文章，角度很新颖，跳出了用元学习解决小样本问题这个圈子，利用元学习跨任务学习这一特性，来解决多任务图学习问题。文章算法很简单，基本和MAML模型完全一致，但是切入角度值得借鉴。 1.简介 1.1 摘要 Graph Neural Networks (GNNs) are a framework for graph representation learning, where a model learns to generate low dimensional node embeddings that encapsulate structural and feature-related information. GNNs are usually trained in an end-to-end fashion, leading to highly specialized node embeddings. However, generating node embeddings that can be used to perform multiple tasks (with performance comparable to single-task models) is an open problem. We propose a novel meta-learning strategy capable of producing multi-task node embeddings. Our method avoids the difficulties a rising when learning to perform multiple tasks concurrently by, instead, learning to quickly (i.e. with a few steps of gradient descent) adapt to multiple tasks singularly. We show that the embeddings produced by our method can be used to perform multiple tasks with comparable or higher performance than classically trained models. Our method is model-agnostic and task-agnostic, thus applicable to a wide variety of multi-task domains. GNNs是图表示学习中非常重要的框架之一，图表示学习通过同时捕捉结构和特征信息，为节点生成低维节点嵌入。GNNs通常采用端到端的训练方式，导致生成的节点嵌入过于specialized（即不够泛化，比如只能用于节点分类或者链路预测，不能两者兼顾）。但是，生成可用于多种任务（与单任务模型具有可比性）的节点嵌入任然是一个开放的问题。我们提出了一种新的元学习策略，可以生成用于多任务的节点嵌入。我们的方法避免了同时学习多个任务时产生的困难，通过学习可以快速（即只需少量梯度步骤）适应多个任务。和传统方法相比，我们的方法生成的嵌入可以用于多个任务中，并取得相当的或者更好的性能。我们的方法是模型无关以及任务无关的，因此可以广泛用于各种多任务领域。 1.2 本文工作 背景： GNNs作为图学习中非常重要的深度模型之一，得到了很多研究。图学习中研究最多的三个任务是：节点分类、链路预测和图分类。现有的GNNs大多都是围绕节点表示学习，并且遵循同样地架构模式：encoder-decoder结构。encoder部分学习低维的节点嵌入，decoder部分利用节点嵌入执行下游任务。 动机： 大多数GNNs模型都采用端到端方式训练，得到的节点嵌入都是高度specialized，无法同时用于多个不同的任务。 如图1所示，如果将某个任务中学习到的节点嵌入迁移到其他任务中，会导致模型性能下降。但是在实际应用中，许多机器学模型都是在资源受限的环境中使用，这种环境下不同任务之间参数是十分重要的。 本文工作： 本文作者基于元学习，具体来说基于MAML，提出了一种新的 model−agnosticmodel-agnosticmodel−agnostic and task−agnostictask-agnostictask−agnostic 多任务学习模型，只需要少量的梯度下降就能将模型迁移到新的任务中，并取得比较好的效果。 2. 方法 下面主要从三个部分介绍作者提出的方法：（1）Episode Design（Episode，元学习里面的一个概念，可以理解成和batch类似的一个东西）；（2）Model Architecture Design；（3）Meta-Training Design。 一、Episode设计 如图2a所示，作者定义multi-task episode Ei(m)∼p(E(m))\\mathcal E_i^{(m)}\\sim p(\\mathcal E^{(m)})Ei(m)​∼p(E(m))为一个三元组：Ei(m)=(LEi(m),SEi(m),TEi(m))\\mathcal{E}_{i}^{(m)}=\\left(\\mathcal{L}_{\\mathcal{E}_{i}}^{(m)}, \\mathcal{S}_{\\mathcal{E}_{i}}^{(m)}, \\mathcal{T}_{\\mathcal{E}_{i}}^{(m)}\\right)Ei(m)​=(LEi​(m)​,SEi​(m)​,TEi​(m)​)，并且有： LEi(m)=λ(GC)LEi(GC)+λ(NC)LEi(NC)+λ(LP)LEi(LP)SEi(m)={SEi(GC),SEi(NC),SEi(LP)},TEi(m)={TEi(GC),TEi(NC),TEi(LP)}\\begin{array}{l} \\mathcal{L}_{\\mathcal{E}_{i}}^{(m)}=\\lambda^{(G C)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{GC})}+\\lambda^{(N C)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{NC})}+\\lambda^{(L P)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{LP})} \\\\ \\mathcal{S}_{\\mathcal{E}_{i}}^{(m)}=\\left\\{\\mathcal{S}_{\\mathcal{E}_{i}}^{(\\mathrm{GC})}, \\mathcal{S}_{\\mathcal{E}_{i}}^{(\\mathrm{NC})}, \\mathcal{S}_{\\mathcal{E}_{i}}^{(\\mathrm{LP})}\\right\\}, \\quad \\mathcal{T}_{\\mathcal{E}_{i}}^{(m)}=\\left\\{\\mathcal{T}_{\\mathcal{E}_{i}}^{(\\mathrm{GC})}, \\mathcal{T}_{\\mathcal{E}_{i}}^{(\\mathrm{NC})}, \\mathcal{T}_{\\mathcal{E}_{i}}^{(\\mathrm{LP})}\\right\\} \\end{array} LEi​(m)​=λ(GC)LEi​(GC)​+λ(NC)LEi​(NC)​+λ(LP)LEi​(LP)​SEi​(m)​={SEi​(GC)​,SEi​(NC)​,SEi​(LP)​},TEi​(m)​={TEi​(GC)​,TEi​(NC)​,TEi​(LP)​}​ 其中λ(⋅)\\lambda^(·)λ(⋅)为平衡系数，LEi(m)\\mathcal L^{(m)}_{\\mathcal E_i}LEi​(m)​表示内循环中损失函数，SEi(m)\\mathcal S_{\\mathcal E_i}^{(m)}SEi​(m)​和TEi(m)\\mathcal T_{\\mathcal E_i}^{(m)}TEi​(m)​表示支持集和查询集。这样模型的meta-objective定义为： Lmeta (m)=∑Ei(m)∼p(E(m))λ(GC)LEi(GC)+λ(NC)LEi(NC)+λ(LP)LEi(LP)\\mathcal{L}_{\\text {meta }}^{(m)}=\\sum_{\\mathcal{E}_{i}^{(m)} \\sim p\\left(\\mathcal{E}^{(m)}\\right)} \\lambda^{(G C)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{GC})}+\\lambda^{(N C)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{NC})}+\\lambda^{(L P)} \\mathcal{L}_{\\mathcal{E}_{i}}^{(\\mathrm{LP})} Lmeta (m)​=Ei(m)​∼p(E(m))∑​λ(GC)LEi​(GC)​+λ(NC)LEi​(NC)​+λ(LP)LEi​(LP)​ 注：这里和MAML中episode的设计基本没变，只不过MAML的S\\mathcal SS和T\\mathcal TT中包含的是同一类型任务。 二、模型架构设计 采用一个多头架构的encoder-decoder模型，骨架采用3层GCN，decoder由3个头组成（分别对应三个任务）： 节点分类头：一个带Softmax的单层神经网络。 图分类头：首先有一个单层神经网络对捡点钱如作线性转换，然后跟一个ReLU激活操作，再将所有节点嵌入做平均后传入最终带有softmax的单层神经网络。 链路预测头：一个带ReLu的单层神经网络对节点嵌入做转换，然后用另一个单层神经网络以两个节点嵌入为输入，输出这两个节点之间存在边的概率。 三、元训练设计 和MAML的训练方式基本一样，下图展示了本文模型的伪代码： 对比下图MAML算法伪代码，作者基本没有做改动，采用二次梯度更新来学习，内循环称之为Adaptation，外循环称之为Updation： 整个模型参数θ\\thetaθ可以分成四部分：θGCN\\theta_{GCN}θGCN​，θNC\\theta_{NC}θNC​，θGC\\theta_{GC}θGC​，θLP\\theta_{LP}θLP​。作者将模型命名成SAME（Single-Task Adaptation for Multi-Task Embeddings），如图2b、c两部分所示，SAME有两种变体： implicit SAME（iSAME）：adaptation阶段（内循环），所有参数θ\\thetaθ都参与更新。 explicit SAME（eSAME）：adaptation阶段只更新θNC\\theta_{NC}θNC​，θGC\\theta_{GC}θGC​，θLP\\theta_{LP}θLP​三个参数，θGCN\\theta_{GCN}θGCN​不更新。 3. 实验 主要回答下列4个问题： iSAME和eSAME在单任务设定下能不能有好的表现？ Cl表示用传统模型监督模型，iSAME和eSAME表示用作者的方法生成的embedding训练线性分类器。可以看到三者在不同任务、不同数据集上的表现基本一致。 iSAME和eSAME在多任务设定下表现如何？ 第一行表示用于单个任务的传统有监督模型；第二行表示在三个任务上训练好模型后，两个任务上微调；第三、四行分别表示iSAME和eSAME策略。 可以看到直接采用微调的方式实现多任务学习是不可行的（其他很多论文中的实验也反映了这一点），效果比传统方法和SAME方法都差。作者提出的SAME方法在大部分设定下取得的性能都和传统方法具有可比性，50%场景下还取得了由于传统方法的性能。 iSAME和eSASME是否真的提取到了传统多任务模型无法捕获的信息？ 从上图可以看出，将模型从任意两种任务迁移到第三种训练时没见过的任务上，作者提出SAME策略都取得了更好的表现。 和传统多任务模型相比，iSAME和eSAME能否取得有竞争力或者更好的表现？ Cl表示传统多任务模型，FT表示微调，Δm\\Delta_mΔm​表示和单任务相比，多任务模型性能的变化情况。可以看到作者提出的SAME策略大部分场景下都是优于传统多任务模型的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"}]},{"title":"Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph","slug":"3 论文笔记/小样本图学习/16.Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph","date":"2021-06-27T08:01:28.000Z","updated":"2021-06-27T08:08:32.838Z","comments":true,"path":"19e45d945e3d/","link":"","permalink":"http://rookieyin.github.io/19e45d945e3d/","excerpt":"https://ojs.aaai.org/index.php/AAAI/article/view/16551/16358 Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph，2021，AAAI 总结：本文的出发点是：单个元任务中不同节点间的相互依赖关系应该被编码到prior knowledge中，但是两个节点在整个图中的距离可能较远，GNNs无法捕获这种long range dependencies。作者的解决方案就是，在两个节点u和v之间采样路径，使用path encoder计算路径编码，同时考虑不同任务之间学习到的先验知识应该被对齐到整个图上，所以从task和graph两个level上分别计算location embedding。另外考虑到远距离节点之间的路径采样效率很低，提出了一种新的基于hub节点的路径采样策略。总的来说，文章写得挺好的，实验结果也挺好的，学习价值较高，可惜作者暂时没有提供源码。","text":"https://ojs.aaai.org/index.php/AAAI/article/view/16551/16358 Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph，2021，AAAI 总结：本文的出发点是：单个元任务中不同节点间的相互依赖关系应该被编码到prior knowledge中，但是两个节点在整个图中的距离可能较远，GNNs无法捕获这种long range dependencies。作者的解决方案就是，在两个节点u和v之间采样路径，使用path encoder计算路径编码，同时考虑不同任务之间学习到的先验知识应该被对齐到整个图上，所以从task和graph两个level上分别计算location embedding。另外考虑到远距离节点之间的路径采样效率很低，提出了一种新的基于hub节点的路径采样策略。总的来说，文章写得挺好的，实验结果也挺好的，学习价值较高，可惜作者暂时没有提供源码。 1. 简介 1.1 摘要 Node classification is an important problem on graphs. While recent advances in graph neural networks achieve promising performance, they require abundant labeled nodes for training. However, in many practical scenarios, there often exist novel classes in which only one or a few labeled nodes are available as supervision, known as few-shot node classification. Although meta-learning has been widely used in vision and language domains to address few-shot learning, its adoption on graphs has been limited. In particular, graph nodes in a few-shot task are not independent and relate to each other. To deal with this, we propose a novel model called Relative and Absolute Location Embedding (RALE) hinged on the concept of hub nodes. Specifically, RALE captures the task-level dependency by assigning each node a relative location within a task, as well as the graph-level dependency by assigning each node an absolute location on the graph to further align different tasks toward learning a transferable prior. Finally,extensive experiments on three public datasets demonstratethe state-of-the-art performance of RALE. 节点分类作为图学习中非常重要的任务之一，尽管最近GNNs取得了不错的表现，但是这些模型需要大量有标签节点用于训练。在许多实际应用中，经常存在一些新类别只要少量有标签节点用来训练模型，称之为小样本节点分类。尽管元学习已经被广泛用于解决CV和NLP领域的小样本学习，但将其应用到图结构数据上存在很大限制。特别是在小样本任务中图节点并不是独立的，而是相互关联的。为了解决这个问题，我们基于hub nodes理念提出了一个新的模型，称之为Relative and Absolute Location Embedding（RALE）。具体来说，RALE通过节点在单个任务中的相对位置捕捉task-level依赖，同时根据节点在图上的绝对位置来捕捉graph-level依赖，来对其不同任务，学习一个可迁移的先验知识。 1.2 本文工作 动机： GNNs虽然在图分类任务中取得了不错的效果，但是通常需要大量有标签数据。节点分类任务的一种典型设置是：给定类别集合，每个节点属于一个类别，模型目标就是基于有标签节点预测没有标签节点的类别标签。但是在很多场景下，我们需要处理训练时未见到的新类。一方面，存在一些类别，称之为基类，具有充足样本，但另一方面新类只有少量有标签节点。例如图1(a)所示的toy citation网络，“SVM”、“Neural network”这类主题的节点很多，但是“Explainable AI”和“Fair ML”这类主题节点很少。本文作者研究的就是针对这些novel calss的分类问题，称之为小样本节点分类。 现有工作弊端： 现有的几篇利用元学习做小样本节点分类的文章都是遵循通用的meta-learning paradigm。具体来说它们将小样本节点分类定义为一系列分类任务（即元任务），每个任务的目的是：经过少量support nodes微调先验知识后，预测query node的类别，如图1(b)所示。在现有的这些方法中，单个任务中节点的相互依赖并没有被显示建模，也没有被整合到可迁移的先验知识中。 作者方案： 为了捕获GNNs无法捕获到的单个任务内节点间的long-range dependencies，作者先采样节点之间的路径，然后使用path encoder计算节点的location embedding，从task和graph两个level捕获节点间的依赖，用于小样本节点分类。 2. 方法 整个模型大致可以分成图3所示三个部分： 图3(a)，给定一张图，利用Graph encoder为每个节点计算一个embedding，同时采样得到meta task； 图3(b)，针对每个task中的节点，首先根据hub节点采样一个路径集合（分两部分，task level和graph level），再结合node embedding和path encoder学习path embedding； 根据node embedding，RL embedding和AL embedding三个向量进行节点分类。 2.1 计算位置嵌入 单纯利用GNNs作为graph encoder存在一些弊端，因为GNNs为了防止过平滑问题，层数通常较浅，这导致难以对距离较远的两个节点之间的关系进行建模。因此作者在graph encoder基础上提出了一个path encoder，对距离较远的两个节点之间的依赖进行建模。具体来说，假设Pu,v\\mathcal P_{u,v}Pu,v​表示节点u和v之间的路径集合（路径长度在最大长度之内），位置嵌入计算公式如下： evR=ϕ({Pu,v:u∈R};θg,θp)(1)\\mathbf{e}_{v}^{\\mathcal{R}}=\\phi\\left(\\left\\{\\mathcal{P}_{u, v}: u \\in \\mathcal{R}\\right\\} ; \\theta_{g}, \\theta_{p}\\right)\\tag 1 evR​=ϕ({Pu,v​:u∈R};θg​,θp​)(1) 其中ϕ\\phiϕ表示嵌入函数，Pu,v\\mathcal P_{u,v}Pu,v​表示路径集合，R\\mathcal RR表示reference节点集合，θg\\theta_gθg​表示graph encoder参数，θp\\theta_pθp​表示path encoder参数。 一、Graph encoder 用ϕg(⋅;θg)\\phi_g(·;\\theta_g)ϕg​(⋅;θg​)表示GNN encoder，参数为θg\\theta_gθg​，其每一层计算方式如下： hvi=M(hvi−1,{hui−1,∀u∈Nv};θg)(2)\\mathbf{h}_{v}^{i}=\\mathcal{M}\\left(\\mathbf{h}_{v}^{i-1},\\left\\{\\mathbf{h}_{u}^{i-1}, \\forall u \\in \\mathcal{N}_{v}\\right\\} ; \\theta_{g}\\right)\\tag 2 hvi​=M(hvi−1​,{hui−1​,∀u∈Nv​};θg​)(2) 其中hvi∈Rdih_v^i\\in\\mathbb R^{d_i}hvi​∈Rdi​表示第i层节点v的d嵌入向量，Nv\\mathcal N_vNv​表示v的邻居节点集合，M\\mathcal MM表示消息传播函数，hv0=xvh_v^0=x_vhv0​=xv​。用ϕg(v;θg)=hv∈Rdg\\phi_g(v;\\theta_g)=h_v\\in\\mathbb R^{d_g}ϕg​(v;θg​)=hv​∈Rdg​表示节点v最终嵌入向量。 二、Path encoder 给定一条路径p=(v1,v2,...,vs)p=(v_1,v_2,...,v_s)p=(v1​,v2​,...,vs​)，根据graph encoder的输出可以得到一组嵌入向量P=ϕg(p;θg)=(hv1,hv2,...,hvs)P=\\phi_g(p;\\theta_g)=(\\mathbf{h_{v1},h_{v2},...,h_{vs}})P=ϕg​(p;θg​)=(hv1​,hv2​,...,hvs​)。Path encoder模型可表示如下： p=ϕp(P;θp)(3)\\mathbf{p}=\\phi_{p}\\left(P ; \\theta_{p}\\right)\\tag 3 p=ϕp​(P;θp​)(3) 其中ϕ(⋅;θp)\\phi(·;\\theta_p)ϕ(⋅;θp​)表示一个序列模型比如RNN或者Transformer，参数为θp\\theta_pθp​。 三、Location embedding 利用前面两个encoder，给定起始点u，我们可以计算节点v的location embedding： ev{u}=AGGR⁡({ϕp(ϕg(p;θg);θp):∀p∈Pu,v})(4)\\mathbf{e}_{v}^{\\{u\\}}=\\operatorname{AGGR}\\left(\\left\\{\\phi_{p}\\left(\\phi_{g}\\left(p ; \\theta_{g}\\right) ; \\theta_{p}\\right): \\forall p \\in \\mathcal{P}_{u, v}\\right\\}\\right)\\tag 4 ev{u}​=AGGR({ϕp​(ϕg​(p;θg​);θp​):∀p∈Pu,v​})(4) 其中AGGR(⋅)AGGR(·)AGGR(⋅)表示聚合函数，比如平均池化，Puv\\mathcal P_{uv}Puv​表示从u起始终到v的路径集合。如果给定起始点集合R\\mathcal RR，节点v的location计算方法如下： evR=ϕ({Pu,v:u∈R};θg,θp)=AGGR⁡({ev{u}:∀u∈R})(5)\\begin{aligned} \\mathbf{e}_{v}^{\\mathcal{R}} &amp;=\\phi\\left(\\left\\{\\mathcal{P}_{u, v}: u \\in \\mathcal{R}\\right\\} ; \\theta_{g}, \\theta_{p}\\right) \\\\ &amp;=\\operatorname{AGGR}\\left(\\left\\{\\mathbf{e}_{v}^{\\{u\\}}: \\forall u \\in \\mathcal{R}\\right\\}\\right) \\end{aligned}\\tag 5 evR​​=ϕ({Pu,v​:u∈R};θg​,θp​)=AGGR({ev{u}​:∀u∈R})​(5) 2.2 路径采样 2.1部分介绍了图3中各种encoder和aggregator的详细计算方法，下面主要介绍图3中(b1)和(b2)部分的详细过程。 如前文所述，在小样本任务中support节点和query节点在图中的距离可能很远，为了捕捉远距离节点间的long-range dependencies，作者利用hubs节点概念，从两个维度计算location embedding来解决这个问题。 所谓Hub节点，指的是PageRank算法种得分最高的若干个节点，它们对于整个图来说非常重要。用H⊂V\\mathcal{H\\subset V}H⊂V表示通过某种centrality方法计算得到的hub节点集合。hub节点在task level和graph level分别扮演者两个重要的角色。 一、Task level 给定任务t=(St,Qt)t=(S_t,Q_t)t=(St​,Qt​)，为了捕捉该任务下所有节点之间的依赖，我们为每个节点v分配一个relative location，称之为RL。具体来说，对于∀v∈St∪Qt\\forall v\\in S_t\\cup Q_t∀v∈St​∪Qt​，它的RL embedding计算方式如下： evSt=ϕ({Ps,v:s∈St};θg,θp)(6)\\mathbf{e}_{v}^{S_{t}}=\\phi\\left(\\left\\{\\mathcal{P}_{s, v}: s \\in S_{t}\\right\\} ; \\theta_{g}, \\theta_{p}\\right)\\tag 6 evSt​​=ϕ({Ps,v​:s∈St​};θg​,θp​)(6) 其中Ps,v\\mathcal P_{s,v}Ps,v​表示路径集合，可以通过起始节点为s，终点节点为v，最大路径长度为lpl_plp​的随机游走得到。但是在图中节点s和v之间的距离可能很远，导致原生的随机游走方法效率会很低，而且很大可能在lpl_plp​步内找不到一条合适路径。 为了解决这个问题，作者通过hub节点来采样路径。具体来说，首先分别从s节点和v节点开始，终点为hub节点，路径长度为lp/2l_p/2lp​/2，利用随机游走采样路径得到segment sampling。然后对这些segments进行重组得到path，比如图3(b)的(b1)部分存在v6→v9v_6\\rightarrow v_9v6​→v9​和v8→v9v_8\\rightarrow v_9v8​→v9​两个segments可以重组成路径v8→v9→v6v_8\\rightarrow v_9\\rightarrow v_6v8​→v9​→v6​。 二、Graph level RL embedding是对单个任务内所有节点之间的依赖进行建模，为了学习一个通用的可迁移先验知识，需要将这种task level依赖关系对其到graph level。作者将hub节点H\\mathcal HH看做globel reference节点集合，给每个节点分配一个absolute location，称之为AL，并计算对应的AL embedding： evH=ϕ({Ph,v:h∈H};θg,θp)(7)\\mathbf{e}_{v}^{\\mathcal{H}}=\\phi\\left(\\left\\{\\mathcal{P}_{h, v}: h \\in \\mathcal{H}\\right\\} ; \\theta_{g}, \\theta_{p}\\right)\\tag 7 evH​=ϕ({Ph,v​:h∈H};θg​,θp​)(7) 具体来说需要采样起始节点为hub节点，终点节点为v的路径（其实就是前面提到的segment，无需重复计算），然后使用path encoder计算对应embedding。 2.3 其他 一、分类层 给定任务t中的某个节点v，它的分类得分计算方式如下： ψ(v;Θ)=SoFTMAX⁡(σ(W[hv∥evSt∥evH]))(8)\\psi(v ; \\Theta)=\\operatorname{SoFTMAX}\\left(\\sigma\\left(\\mathbf{W}\\left[\\mathbf{h}_{v}\\left\\|\\mathbf{e}_{v}^{S_{t}}\\right\\| \\mathbf{e}_{v}^{\\mathcal{H}}\\right]\\right)\\right)\\tag 8 ψ(v;Θ)=SoFTMAX(σ(W[hv​∥∥∥​evSt​​∥∥∥​evH​]))(8) 二、目标函数 交叉熵损失最为目标函数： L(St;Θ)=−∑v∈St∑i=1mIℓ(v)=iln⁡(ψ(v;Θ)[i])(9)L\\left(S_{t} ; \\Theta\\right)=-\\sum_{v \\in S_{t}} \\sum_{i=1}^{m} \\mathbb{I}_{\\ell(v)=i} \\ln (\\psi(v ; \\Theta)[i])\\tag 9 L(St​;Θ)=−v∈St​∑​i=1∑m​Iℓ(v)=i​ln(ψ(v;Θ)[i])(9) 三、复杂度 整个算法包含两部分：一是segment采样和path重构（这部分只需要执行一次），二是基于元任务优化模型目标。作者文中说伪代码和复杂度分析在附件中提供，但是我这个版本的论文中并没有supplementary。 3. 实验 3.1 实验设置 数据集划分： Baselines： GNNs：GCN，GraphSAGE，GAT，训练阶段利用base class上的分类任务训练GNN模型，测试阶段冻结GNN部分参数，用support集微调分类层参数。 GNN+‘s：还是上面三种GNNs架构，不过每种模型都在base calsses上进行预训练，测试阶段利用support set对模型参数微调，在query set上测试。 元学习模型：Meta-GNN，Proto-GNN 对于所有元学习模型，都采用GraphSAGE作为GNN架构，对于RALE，采用自监督模型作为path encoder。 3.2 实验结果 对比GNNs和GNN+’s，可以发现没有绝对的优劣之分，用测试任务对GNNs的聚合函数进行微调可能导致过拟合，因此直接使用微调方式无法解决小样本问题。 Meta-GNN、Proto-GNN和GNNs、GNN+'s相比，性能只取得了很小的提升，表明如果不对节点间的依赖进行建模，元学习对于小样本图学习的帮助有限。 RALE相比之下，在大部分实验设置下都取得了优异的表现。但是在Amazon数据集，5-shot设定下，RALE表现较差。作者分析可能的原因是： The possible reason is that the co-purchasing ties between diverse items on a large e-commerce platform like Amazon are weaker than email ex-changes between users or topical relatedness between posts participated in by the same user on social networks. Thus, it becomes less important to capture the dependencies, and the attention mechanism in GAT/GAT+ is more suited to weighing diverse neighbors especially when given more shots。大概意思是亚马逊这种大型电子商务平台上不同物体间co-purchasing比较弱，因此对dependency的捕捉不太依赖，而GAT中的注意力机制更适合对各种邻居进行加权，尤其在more shots情况下。（感觉也没解释太清楚） 3.3 模型分析 一、消融实验 RALE\\r表示去掉RL embedding，RALE\\a表示去掉AL embedding，RALE\\ar表示都去掉。 二、hubs和随机游走 hub节点比例越小，两个节点之间可能存在的路径就越少，图5a展示了不同hub ratio下模型准确率，可以看到随着hub ratio增加，模型准确度会增加，但是hub ratio达到5%后，模型性能基本不变。 图5b-d分别展示了不同lpl_plp​、d和w下模型性能，lpl_plp​表示最大路径长度，www表示每个节点的number of walks，lll表示walk length。这三个量的增大，都会导致模型性能和coverage ratio的增加。但是在相同设置下，使用hub节点（图中的红线）采样路径模型准确度更高，表示作者的hub-based采样策略是有效的。 三、参数敏感性 针对embedding的维度和学习率进行了敏感性实验。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Data Augmentation for Graph Neural Networks","slug":"3 论文笔记/图学习/8.Data Augmentation for Graph Neural Networks","date":"2021-06-20T06:17:16.000Z","updated":"2021-07-31T05:01:14.162Z","comments":true,"path":"58a2384fa86a/","link":"","permalink":"http://rookieyin.github.io/58a2384fa86a/","excerpt":"https://arxiv.org/pdf/2006.06830 https://github.com/zhao-tong/GAug Data Augmentation for Graph Neural Networks ，2021，AAAI 总结：和CV、NLP中的数据增强不同，通过Edge Manipulation进行图数据增强，提出了GAUG框架。具体来说删去图中可能是噪声的边，增加图中可能丢失的边（对模型有益），其实可以看做是一个降噪和补全的过程（不知道其他图数据增强技术是不是有其他增强方法）。另外GAUG的动机和本质是：增加同类别节点之间的边，去掉不同类别节点之间的边，这在异构图中是不成立的，因此无法用于异构图学习。不过可以考虑是否可以将数据增强方法用于小样本图学习中。","text":"https://arxiv.org/pdf/2006.06830 https://github.com/zhao-tong/GAug Data Augmentation for Graph Neural Networks ，2021，AAAI 总结：和CV、NLP中的数据增强不同，通过Edge Manipulation进行图数据增强，提出了GAUG框架。具体来说删去图中可能是噪声的边，增加图中可能丢失的边（对模型有益），其实可以看做是一个降噪和补全的过程（不知道其他图数据增强技术是不是有其他增强方法）。另外GAUG的动机和本质是：增加同类别节点之间的边，去掉不同类别节点之间的边，这在异构图中是不成立的，因此无法用于异构图学习。不过可以考虑是否可以将数据增强方法用于小样本图学习中。 1. 简介 1.1 摘要 Data augmentation has been widely used to improve gener-alizability of machine learning models. However, compara-tively little work studies data augmentation for graphs. Thisis largely due to the complex, non-Euclidean structure ofgraphs, which limits possible manipulation operations. Aug-mentation operations commonly used in vision and languagehave no analogs for graphs. Our work studies graph dataaugmentation for graph neural networks (GNNs) in the con-text of improving semi-supervised node-classification. Wediscuss practical and theoretical motivations, considerationsand strategies for graph data augmentation. Our work showsthat neural edge predictors can effectively encode class-homophilic structure to promote intra-class edges and de-mote inter-class edges in given graph structure, and our maincontribution introduces the GAUGgraph data augmentationframework, which leverages these insights to improve per-formance in GNN-based node classification via edge predic-tion. Extensive experiments on multiple benchmarks showthat augmentation via GAUGimproves performance acrossGNN architectures and datasets. 数据增强已经被广泛用于给中机器学习模型，但是在图学习领域很少有关于数据增强的研究。因为在图这种非欧式结构数据十分复杂，不能直接将CV和NLP中的数据增强技术迁移到图中。本文我们研究图数据增强技术，用于GNNs中来提高半监督节点分类的性能。我们从理论和实际两个方面分析了我们的动机和策略。我们的工作表明神经边预测器能够有效编码class-homophilic结构，增加intra-class边，减少inter-class边。本文我们主要的贡献是提出了GAUG图数据增强框架，通过预测边，提高GNN-based模型的节点分类性能。多个数据集上的大量实验表明，通过GAUG进行数据增强可以提高GNN的性能。 1.2 本文工作 数据增强技术被广泛用于CV和NLP领域，可以增加模型泛化能力，更加关注信号本身而非噪声。但是在图学习领域，很少有工作将GNNs和数据增强结合到一起，因为图的结构很复杂，难以将CV和NLP中的数据增强技术迁移过来。 在图中作数据增强，显然只能添加或删除节点或者边，但是在节点分类任务中添加或删除节点显然是不现实的，因此只能增删一些边。 本文作者采取的数据增强策略为：利用消息传播（GNNs），删除“noisy”边，增加“missing”边。 上图展示了使用作者提出的数据增强方法后，模型分类性能得到了显著提高。其中a图为未使用数据增强，b图为随机增减边，c图为使用作者提出的GAUG方法，d表示上帝视角。图中的M和O分别表示GAUG的两种模式，下文中会介绍。 1.3 动机 实际： 现实世界中的图很容易受到noise影响，这回导致我们得到的图和ideal graph存在gap。上面图1展示了，通过增加同类别节点之间的边（intra-class），删减不同类别节点之间的边(inter-class)可以有效提高模型性能。直觉上来说，这种操作鼓励同类别节点之间的嵌入更加平滑（趋同），并区别与其他类节点嵌入，提高区别性（因为GNNs本质是消息传播，同类别节点之间边增多，不同类别节点之间边减少，会导致同类别节点之间学习到的嵌入更加平滑，可以参考热传播模型）。 理论： 考虑理想状态下，图中只有同类别节点之间存在边，假设有节点类型有k个，那么图天然的就被分成了k份，GNNs准确完成节点分类。因为，此时对于相同类型节点，GNNs学到的节点嵌入是完全相同的，不同类型节点GNNs学习到的嵌入一定是不同的（文章中有关于该定理的证明）。 2. 方法 CV中的数据增强方法通常分成两个步骤：（1）transformation，f:S→T\\mathcal{f:S\\rightarrow T}f:S→T，生成输入图像S\\mathcal{S}S的变体T\\mathcal TT；（2）用S∪T\\mathcal {S\\cup T}S∪T训练模型。但是图数据的增强有所不同，因为CV中图像数量∣S∣&gt;&gt;1|S|&gt;&gt;1∣S∣&gt;&gt;1，而图数据中∣S∣=1|S|=1∣S∣=1。 本文作者提出两种策略GAUG-M和GAUG-O： GAUG-M：通过图转换操作f:G→Gm\\mathcal {f:\\mathcal G\\rightarrow G_m}f:G→Gm​生成新图Gm\\mathcal G_mGm​，G\\mathcal GG在training和inference阶段都用Gm\\mathcal G_mGm​替代。 GAUG-O：执行多个transformation fi:G→Gmi,i=1...Nf_i:\\mathcal{G\\rightarrow G_m^i}, i=1...Nfi​:G→Gmi​,i=1...N，G∪{Gmi}i=1N\\mathcal{G\\cup\\{G_m^i\\}_{i=1}^N}G∪{Gmi​}i=1N​用于训练，G\\mathcal GG用于inference。 在训练和测试阶段图不改变的情况下可以采用GAUG-M策略，但是在测试阶段图会发生改变的情况下只能用GAUG-O策略。在实际应用中，这两种策略其实是和transductive、inductive相对应的。 2.1 GAUG-M GAUG-M包含两个步骤： 使用edge predictor，计算所有节点之间存在边的概率 利用第一步得到的概率，对原有图中的边进行增加和删减，生成修改后的图Gm\\mathcal G_mGm​ 所以，整个方法的关键其实就是edge predictor fep:A,X→Mf_ep:A,X\\rightarrow Mfe​p:A,X→M的定义。以原始图为输入，输出概率矩阵MMM，MuvM_{uv}Muv​表示节点u和v之间存在边的概率。 本文作者采用GAE作为edge predictor，它包含两个GCN层（encoder）和一个内积层（decoder）： M=σ(ZZT), where Z=fGCL(1)(A,fGCL(0)(A,X))(2)\\mathbf{M}=\\sigma\\left(\\mathbf{Z} \\mathbf{Z}^{T}\\right), \\text { where } \\mathbf{Z}=f_{G C L}^{(1)}\\left(\\mathbf{A}, f_{G C L}^{(0)}(\\mathbf{A}, \\mathbf{X})\\right)\\tag 2 M=σ(ZZT), where Z=fGCL(1)​(A,fGCL(0)​(A,X))(2) 其中Z\\mathbf ZZ表示编码后的hidden embedding，M\\mathbf MM表示输出的概率矩阵，σ(⋅)\\sigma(·)σ(⋅)表示element-wise激活函数。 上图展示了使用GAUG-M进行数据增强后，图中inter-class和intra-class边数量的变化情况。可以看到使用GAUG-M后，intra-class边的数量增加的快，减少的慢，而inter-class边的数量增加的慢，减少的快。对比图右边随机增减边，模型性能有显著提高。 2.2 GAUG-O GAUG-O不需要单独训练edge predictor，可以end-to-end训练。下图展示了GAUG-O的运行过程： 这里作者同样采用GAE作为edge predictor。 （1） 首先利用GAE对原始图G\\mathcal GG进行调整得到Gm\\mathcal G_mGm​； （2） 然后将调整后的邻接矩阵和原始邻接矩阵采用加权的方式合并到一起； （3） 再进行伯努利边稀疏化得到最终的邻接矩阵A′A&#x27;A′； （4） 最后通过GNN节点分类器进行节点分类。 具体计算公式如下： Aij′=⌊11+e−(log⁡Pij+G)/τ+12⌋ where Pij=αMij+(1−α)Aij(3)\\begin{array}{l} \\mathbf{A}_{i j}^{\\prime}=\\left\\lfloor\\frac{1}{1+e^{-\\left(\\log \\mathbf{P}_{i j}+G\\right) / \\tau}}+\\frac{1}{2}\\right\\rfloor \\\\ \\text { where } \\mathbf{P}_{i j}=\\alpha \\mathbf{M}_{i j}+(1-\\alpha) \\mathbf{A}_{i j} \\end{array}\\tag 3 Aij′​=⌊1+e−(logPij​+G)/τ1​+21​⌋ where Pij​=αMij​+(1−α)Aij​​(3) 其中A′A&#x27;A′为最终采样后的邻接矩阵，τ\\tauτ为Gumbel-softmax分布的temperature，G∼Gumbel(0,1)G\\sim Gumbel(0,1)G∼Gumbel(0,1)为Gumbel随机变量，α\\alphaα为超参。得到A′A&#x27;A′后，再结合节点特征XXX，利用节点分类器进行分类，分类损失为： L=Lnc+βLcp, where Lnc=CE(y^,y) and Lep=BCE(σ(fep(A,X)),A)\\begin{aligned} &amp; \\mathcal{L}=\\mathcal{L}_{n c}+\\beta \\mathcal{L}_{c p}, \\\\ \\text { where } &amp; \\mathcal{L}_{n c}=C E(\\hat{\\mathbf{y}}, \\mathbf{y}) \\\\ \\text { and } &amp; \\mathcal{L}_{e p}=B C E\\left(\\sigma\\left(f_{e p}(\\mathbf{A}, \\mathbf{X})\\right), \\mathbf{A}\\right) \\end{aligned} where and ​L=Lnc​+βLcp​,Lnc​=CE(y^​,y)Lep​=BCE(σ(fep​(A,X)),A)​ 前者LncL_{nc}Lnc​为分类损失，后者LcpL_{cp}Lcp​为边预测损失，σ(⋅)\\sigma(·)σ(⋅)为element-wise sigmoid，CECECE和BCEBCEBCE为交叉熵损失。 3. 实验 采用的六个数据集如下表所示： baseline采用：ADAEDGE，BGCN，DROPEDGE 一、对比实验 经过GAUG-M和GAUG-O数据增强后，四种GNN模型性能得到显著提高。 二、增删比例 上图展示了不同增删比率下模型性能，横轴表示增加比例，纵轴表示删除比例，red-white-blue点分别表示outperformance，at-par和underperformance。 三、训练过程 图5a中展示了GAUG-O让增加了图中intra-class边的比例，降低了inter-class边的比例。图5b中展示了训练过程中两种损失的变化情况，可以发现在刚开始几个epoch，Lnc\\mathcal L_{nc}Lnc​逐渐降低，F1F1F1逐渐增大，但是Lep\\mathcal L_{ep}Lep​逐渐增大，调和了Lnc\\mathcal L_{nc}Lnc​的监督效果。之后LncL_{nc}Lnc​继续减小，intra-class边比率还在增加，出现过拟合。 四、监督程度敏感性 上图展示了不同数目节点用于训练情况下各个模型性能。可以看到在弱监督情况下，GAUG可以显著提高GNNs模型性能。 原文附录中还提供了了非常多的补充实验，感兴趣可以参见原文附录。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"数据增强","slug":"数据增强","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"}]},{"title":"A Universal Representation Transformer Layer for Few-Shot Image Classification","slug":"3 论文笔记/小样本学习/3.A Universal Representation Transformer Layer for Few-Shot Image Classification","date":"2021-06-17T12:43:08.000Z","updated":"2022-06-01T06:42:48.135Z","comments":true,"path":"04719895d5f9/","link":"","permalink":"http://rookieyin.github.io/04719895d5f9/","excerpt":"https://arxiv.org/pdf/2006.11702 https://github.com/liulu112601/URT A Universal Representation Transformer Layer for Few-Shot Image Classification，2021，ICLR 总结：文章提出的URT方法基于SUR方法改进而来，用于multi-domain下的小样本学习。现有的小样本学习方法基本都是从单个dataset/domain（样本充足）中采样元任务，但是这在实际应用中是不现实的。本文作者提出的URT方法，作者将Transformer中的自注意力机制整合到小样本学习中，从多个预训练好的backbone中自动选取合适的backbone学习样本表示。和SUR方法相比通用性更高，并且在大多数数据集上都取得了更好的分类性能。文章中图画的挺好看，实验比较丰富，可以借鉴到其他领域论文中。","text":"https://arxiv.org/pdf/2006.11702 https://github.com/liulu112601/URT A Universal Representation Transformer Layer for Few-Shot Image Classification，2021，ICLR 总结：文章提出的URT方法基于SUR方法改进而来，用于multi-domain下的小样本学习。现有的小样本学习方法基本都是从单个dataset/domain（样本充足）中采样元任务，但是这在实际应用中是不现实的。本文作者提出的URT方法，作者将Transformer中的自注意力机制整合到小样本学习中，从多个预训练好的backbone中自动选取合适的backbone学习样本表示。和SUR方法相比通用性更高，并且在大多数数据集上都取得了更好的分类性能。文章中图画的挺好看，实验比较丰富，可以借鉴到其他领域论文中。 1. 简介 1.1 摘要 Few-shot classification aims to recognize unseen classes when presented with only a small number of samples. We consider the problem of multi-domain few-shot image classification, where unseen classes and examples come from diverse data sources. This problem has seen growing interest and has inspired the development of benchmarks such as Meta-Dataset. A key challenge in this multi-domain setting is to effectively integrate the feature representations from the diverse set of training domains. Here, we propose a Universal Representation Transformer (URT) layer, that meta-learns to leverage universal features for few-shot classification by dynamically re-weighting and composing the most appropriate domain-specific representations. In experiments, we show that URT sets a new state-of-the-art result on Meta-Dataset. Specifically, it achieves top-performance on the highest number of data sources compared to competing methods. We analyze variants of URT and present a visualization of the attention score heatmaps that sheds light on how the model performs cross-domain generalization. Our code is available at https://github.com/liulu112601/URT. 小样本分类旨在只有少量样本的情况下能够区分unseen类别。本文作者考虑multi-domain小样本图像分类问题，unseen类别和样本来自不同的domain。该问题吸引了很多研究人员的关注，并刺激了相关标准数据集的发展比如Meta-Dataset。multi-domain设定下的一个关键挑战是如何有效地整合来自不同domain的特征信息。本文作者提出了一个Universal Representation Transformer（URT）层，通过动态加权，组合最合适的domain-specific表示来学习universal特征用于小样本分类。在实验部分，我们展示了URT在Meta-Dataset上取得了最优结果。具体来说，和competing方法相比，URT在大部分数据集上都取得了top-performance。我们分析了URT的各种变体，并且展示了模型学到的注意力权重来解释模型如何实现cross-domain generalization。我们的代码可以通过 https://github.com/liulu112601/URT 获取。 1.2 本文工作 应用场景： multi-domain few-shot classification，不仅仅每个task中训练样本少，而且训练集和测试集样本来自多个不同的域。这种场景下，模型不仅要解决常规的小样本分类存在的挑战（即每个类别只有少量样本），还要实现跨域学习。 现有方法： Triantafillou等人构造了一个用于跨域小样本分类的标准数据集Meta-Dataset，基于此人们也提出了一些该场景下的方法，其中最为突出的就是SUR（Selecting Universal Representation），本文提出URT就是在该方法基础上改进而来。 URT： SUR方法设计了一个流程手动为每个backbone加权，为新任务中样本学习一个通用表示，没有迁移（跨任务/跨域）学习。本文作者提出的URT方法，利用Transformer中的注意力机制自动学习pre-trained backbones的权重，学习task-adapted表示。 1.3 Problem Setting 小样本分类： 在每个类别只有少量样本的情况下实现分类，每个任务中包含一个支持集S和查询集Q。S中有N个类别，每个类别有K个样本，在S上训练模型，在Q上测试模型分类性能，这就是一个N-way-K-shot小样本分类任务。 元学习： 小样本场景下的一种学习技术。一种常用的训练元学习模型的方式是episodic training，在大型数据集中采样多个小样本任务T=(Q,S)T=(Q,S)T=(Q,S)，用这些任务迭代训练模型，元学习模型优化目标通常如下： min⁡ΘE(S,Q)∼p(T)[L(S,Q,Θ)],L(S,Q,Θ)=1∣Q∣∑(x,y)∼Q−log⁡p(y∣x,S;Θ)+λΩ(Θ)(1)\\min _{\\Theta} \\mathbb{E}_{(S, Q) \\sim p(T)}[\\mathcal{L}(S, Q, \\Theta)], \\mathcal{L}(S, Q, \\Theta)=\\frac{1}{|Q|} \\sum_{(\\boldsymbol{x}, y) \\sim Q}-\\log p(y \\mid \\boldsymbol{x}, S ; \\Theta)+\\lambda \\Omega(\\Theta)\\tag 1 Θmin​E(S,Q)∼p(T)​[L(S,Q,Θ)],L(S,Q,Θ)=∣Q∣1​(x,y)∼Q∑​−logp(y∣x,S;Θ)+λΩ(Θ)(1) Meta-Dataset： 传统小样本分类任务的设定是N-way-K-shot，每个任务支持集中包含N个类别，每个类别有K个样本，而meta-task采样自同一个domain或者dataset（比如Omniglot和miniImageNet），但是这在实际应用中是不现实的。因此，Triantafillou等人提出了Meta-Dataset，它由10个不同数据集（domain）组成，其中8个用于训练。并且从benchmark中提取的每个任务中N和K的值时不同的。 2. URT 图片解释：（1）假设某个task中S集中两个类别“Waxcap”和“Fly aganic”，每个类别各有两张图片；Q集合有一张图片（上图第一张）。（2）模型有四个预训练好的backbones，分别计算上图5个样本representation{ri}\\{r_i\\}{ri​}（上图中四种颜色矩形方块表示四个backbones学习到的特征向量concat在一起）。（3）每个类别所有样本的representation求平均值得到该类别的特征表示（类似类别原型）r(Si)r(S_i)r(Si​)。（4）对r(Si)r(S_i)r(Si​)进行自注意力操作得到该类别下的注意力权重。（5）该任务下所有类别注意力权重求平均值得到该任务下的注意力权重。（5）将该任务下的注意力权重和查询集样本的特征表示相乘得到查询集样本的最终表示用于分类。 2.1 Single-Head URT层 图1中展示的就是单头URT层，ri(x)r_i(x)ri​(x)表示第i个domain下backbone学习到的表示，该样本的universal表示定义为： r(x)=concat⁡(r1(x),…,rm(x))(2)r(\\mathbf{x})=\\operatorname{concat}\\left(r_{1}(\\mathbf{x}), \\ldots, r_{m}(\\mathbf{x})\\right)\\tag 2 r(x)=concat(r1​(x),…,rm​(x))(2) 支持集中每个类别的表示（类似类别原型）定义为： r(Sc)=1∣Sc∣∑x∈Scr(x)(3)r\\left(S_{c}\\right)=\\frac{1}{\\left|S_{c}\\right|} \\sum_{\\boldsymbol{x} \\in S_{c}} r(\\boldsymbol{x})\\tag 3 r(Sc​)=∣Sc​∣1​x∈Sc​∑​r(x)(3) 然后为每个类别单独执行自注意力操作，计算权重得分，具体操作图1右边所示： （1）计算Queries qcq_cqc​，qc=Wqr(Sc)+bq\\mathbf{q}_{c}=\\mathbf{W}^{q} r\\left(S_{c}\\right)+\\mathbf{b}^{q}qc​=Wqr(Sc​)+bq，其中WqW^qWq和bqb^qbq为可学习参数。 （2）计算Keys ki,ck_{i,c}ki,c​，ki,c=Wkri(Sc)+bk\\mathbf{k}_{i, c}=\\mathbf{W}^{k} r_{i}\\left(S_{c}\\right)+\\mathbf{b}^{k}ki,c​=Wkri​(Sc​)+bk，其中WkW^kWk和bkb^kbk为可学习参数，ri(Sc)=1/∣Sc∣∑x∈Scri(x)r_{i}\\left(S_{c}\\right)=1 /\\left|S_{c}\\right| \\sum_{\\boldsymbol{x} \\in S_{c}} r_{i}(\\boldsymbol{x})ri​(Sc​)=1/∣Sc​∣∑x∈Sc​​ri​(x)。 （3）计算Attention scores αi\\alpha_iαi​，下式中l表示queries和keys的维度： αi,c=exp⁡(βi,c)∑i′exp⁡(βi′,c),βi,c=qc⊤ki,cl(4)\\alpha_{i, c}=\\frac{\\exp \\left(\\beta_{i, c}\\right)}{\\sum_{i^{\\prime}} \\exp \\left(\\beta_{i^{\\prime}, c}\\right)}, \\beta_{i, c}=\\frac{\\mathbf{q}_{c}^{\\top} \\mathbf{k}_{i, c}}{\\sqrt{l}}\\tag 4 αi,c​=∑i′​exp(βi′,c​)exp(βi,c​)​,βi,c​=l​qc⊤​ki,c​​(4) αi=∑cαi,cN(5)\\alpha_{i}=\\frac{\\sum_{c} \\alpha_{i, c}}{N}\\tag 5 αi​=N∑c​αi,c​​(5) 得到该任务下每个backbone的注意力得分αi\\alpha_iαi​后，重新计算查询集样本的表示： ϕ(x)=∑iαiri(x)(6)\\phi(\\mathrm{x})=\\sum_{i} \\alpha_{i} r_{i}(\\mathrm{x})\\tag 6 ϕ(x)=i∑​αi​ri​(x)(6) 2.2 Multi-Head URT Layer H头URT层即将单头URT层的注意力计算部分重复执行H次，然后将公式6替换成公式7： ϕ(x)=concat⁡(ϕ1(x),…,ϕII(x))(7)\\phi(\\mathrm{x})=\\operatorname{concat}\\left(\\phi_{1}(\\mathrm{x}), \\ldots, \\phi_{\\mathrm{II}}(\\mathrm{x})\\right)\\tag 7 ϕ(x)=concat(ϕ1​(x),…,ϕII​(x))(7) 这里根据经验，作者发现随机初始化每个头的注意力权重不能实现各个头之间的互补性和唯一性，因此作者参照其他人的做法添加了一个正则化损失，避免注意力得分的重复： Ω(Θ)=∥(AA⊤−I)∥F2(8)\\Omega(\\Theta)=\\left\\|\\left(\\mathbf{A} \\mathbf{A}^{\\top}-\\mathbf{I}\\right)\\right\\|_{F}^{2}\\tag 8 Ω(Θ)=∥∥∥​(AA⊤−I)∥∥∥​F2​(8) 其中AAA表示注意力得分矩阵。 2.3 模型训练 采用原型网络中的分类方法，根据样本特征表示和类别原型之间的距离计算样本属于该类别的概率： p(y=c∣x,S;Θ)=exp⁡(−d(ϕ(x)−pc))∑c′=1Nexp⁡(−d(ϕ(x)−pc′))(9)p(y=c \\mid x, S ; \\Theta)=\\frac{\\exp \\left(-d\\left(\\phi(x)-p_{c}\\right)\\right)}{\\sum_{c^{\\prime}=1}^{N} \\exp \\left(-d\\left(\\phi(x)-p_{c^{\\prime}}\\right)\\right)}\\tag 9 p(y=c∣x,S;Θ)=∑c′=1N​exp(−d(ϕ(x)−pc′​))exp(−d(ϕ(x)−pc​))​(9) 其中pc=1/∣Sc∣∑x∈Scϕ(x)\\boldsymbol{p}_{c}=1 /\\left|S_{c}\\right| \\sum_{\\boldsymbol{x} \\in S_{c}} \\phi(\\boldsymbol{x})pc​=1/∣Sc​∣∑x∈Sc​​ϕ(x)表示类别c的原型。本文作者采用余弦相似度作为度量，具体算法如下图所示： 3. 实验 主要回答下面3个问题： URT和Meta-Dataset数据集上的state-of-art方法相比性能如何？ URT中的自注意力是否具有可解释性？学习到的注意力得分是否有效？ URT即使在backbone采用不同方式训练的情况下是否持续有效？ 实验设置：采用Meta-Dataset数据集，预训练的backbone在训练URT时冻结参数，URT层训练10000个episodes，初始学习率为0.01，采用余弦学习率scheduler，训练episode有50%概率来自ImageNet数据源等等。 3.1 对比实验 作者对比了URT和SUR、一些基于微调迁移学习的baselines以及元学习方法，实验结果如下： 下图展示了不同方法在MNIST，CIFAR-10，CIFAR-100上的实验结果： 3.2 可解释性 下图展示了two heads URT在测试任务中生成的注意力权重： 左边蓝色表示first head学习到的注意力权重热图，右边橙色表示second head学习到的注意力权重热图。 3.3 通用性 为了进一步证明URT在学习universal representation上的优越性能，作者基于一组不同的backbone架构进行了实验。Following SUR，作者先在ILSVRC上训练一个backbone，然后在其他每个数据集上分别学习单独的FiLM层，学习domain-specific backbone。实验结果如下表所示： 3.4 消融实验 下表中w/o Wqw/o\\ W^qw/o Wq表示计算queries时Wq=0W^q = 0Wq=0，保留偏置bqb^qbq；w/o Wkw/o\\ W^kw/o Wk表示计算keys时Wk=0W^k=0Wk=0，保留偏置bkb^kbk。其他行同理，实验结果如下表所示： 作者还对head数目做了消融实验，结果如下表所示：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图像分类","slug":"图像分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}]},{"title":"常用CSS居中方法集锦","slug":"1 前端/CSS/常用CSS居中方法集锦","date":"2021-06-07T08:48:29.000Z","updated":"2021-06-21T00:31:24.791Z","comments":true,"path":"520aaf09ab1b/","link":"","permalink":"http://rookieyin.github.io/520aaf09ab1b/","excerpt":"总结 对于行内元素，可以使用center/margin:auto/text-align:center等实现水平居中。块级元素常用的居中方法有absolute，flex，padding，tabel-ceil，伪元素等技术实现。下文中各个方法实现效果为： 水平居中 垂直居中 行内元素 1,2,3,4 2,3,4 块级元素 1,2,3,5,6,7,8,9,10 2,3,5,6,7,8,9,10","text":"总结 对于行内元素，可以使用center/margin:auto/text-align:center等实现水平居中。块级元素常用的居中方法有absolute，flex，padding，tabel-ceil，伪元素等技术实现。下文中各个方法实现效果为： 水平居中 垂直居中 行内元素 1,2,3,4 2,3,4 块级元素 1,2,3,5,6,7,8,9,10 2,3,5,6,7,8,9,10 1.水平居中，外层套上center标签，但是html5已经不支持该标签，使用margin:0 auto可以实现同样效果。 12345678&lt;div class=&quot;parent&quot;&gt; &lt;center&gt; &lt;div class=&quot;child1&quot;&gt; &lt;/div&gt; &lt;/center&gt; &lt;div style=&quot;margin:0 auto;&quot;&gt; &lt;/div&gt;&lt;/div&gt; 2.水平垂直居中，absolute+top/left/right/bottom，其中top/bottom/right/left的值相同则垂直水平居中，不同则相对中心位置偏移。 1234567891011.parent&#123; position:relative;&#125;.child&#123; position:absolute; margin:auto; top:0; bottom:0; right:0; left:0;&#125; 3.absolute+transform，先利用left+top使child元素距离父组件左上角50%，再利用transform向左上偏移child元素宽高的一半，使child中心和parent中心重合。使用时需要注意兼容性。 123456789.parent&#123; position:relative;&#125;.child&#123; position:absolute; left:50%; top:50%; transform:translate(-50%,-50%);&#125; 4.文字居中：设置行高设置为元素高度，但是这种只能针对单行文字，若有换行样式会混乱。 123&lt;div style=&quot;width:800px;height:500px;background-color: #ff5f47;line-height: 500px;text-align: center;&quot;&gt; 水平垂直居中&lt;/div&gt; 5.多行文字可以用tabel-cell实现。 123456789101112.parent&#123; width:800px; height:500px; background-color: #ff5f47; display: table-cell; text-align:center; vertical-align: middle;&#125;.child&#123; background-color: green; margin: auto&#125; 6.已知宽高，可利用padding+background-clip实现居中，设置padding为parent宽高减去child宽高的一半，同时设置background-clip:content-box。 123456789101112.parent&#123; width:800px; height:500px; background-color: #ff5f47;&#125;.child&#123; width:200px; height: 100px; background-color: green; padding: 200px 300px; background-clip:content-box;&#125; 7.flex布局实现居中，使用需要注意兼容性。 12345678910111213.parent&#123; width:800px; height:500px; background-color: #ff5f47; display: flex; align-items: center; justify-content: center;&#125;.child&#123; width:200px; height: 100px; background-color: green;&#125; 8.display:table-cell实现居中，利用vertical-align让子元素垂直居中，再在子元素中利用margin:auto实现水平居中。 12345678910111213.parent&#123; width:800px; height:500px; background-color: #ff5f47; display: table-cell; vertical-align: middle;&#125;.child&#123; width:200px; height: 100px; background-color: green; margin:auto;&#125; 9.伪元素实现居中，利用伪元素占位。 12345678910111213141516171819.parent&#123; width:800px; height:500px; background-color: #ff5f47; text-align: center;&#125;.child&#123; width:200px; height:100px; background-color: green; display: inline-block; vertical-align: middle;&#125;.parent::before&#123; content: &#x27;&#x27;; height: 100%; display:inline-block; vertical-align: middle;&#125; 10.使用calc计算padding的距离，如果只知道child的尺寸，可以通过padding: calc((100% - child_width)/2)实现居中。使用时需要注意兼容性。","categories":[{"name":"前端","slug":"前端","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"CSS","slug":"前端/CSS","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/CSS/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://rookieyin.github.io/tags/CSS/"}]},{"title":"Git安装与配置","slug":"7 其他/Git安装与配置","date":"2021-06-07T06:10:35.000Z","updated":"2021-06-21T00:31:24.788Z","comments":true,"path":"7ab1d4dfb868/","link":"","permalink":"http://rookieyin.github.io/7ab1d4dfb868/","excerpt":"","text":"一、Git的安装、版本库创建 1.安装 下载安装程序（https://git-scm.com/downloads）；配置环境变量 在GitBash中执行以下命令： git config --global user.name “GitHub账户名” git config --global user.email &quot;GitHub绑定的邮箱“ 2.创建版本库 切换到任意一个目录；执行git init命令，在当前目录创建版本库完成。 二、Git常用命令 1. 文件提交到本地版本库 git add filename git commit -m &quot;描述信息“ 2.版本切换 git status：查看当前仓库的状态，比如是否有更改为提交 git diff filename：查看文件filename上次的修改记录 git log：显示从最近到最远的提交日志 git reset --hard HEAD^：head^，head^^分别表示上一个和上两个版本，head~100表示上100个版本，也可以用commit id 替代head git reflog：查看命令提交记录，获取commit id，再使用git reset 可以进行版本切换 git checkout --file：撤销修改，回到最近一次git commit或者add时的状态 git reset HEAD ：将暂存区中的修改撤销掉 注：丢弃工作区的修改使用git chekout，丢弃暂存区的修改使用git reset head git rm ：删除文件file，注意需要执行 git commit才能生效，如果误删除可以使用git checkout --file命令 3.远程库连接 (1)ssh-keygen -t rsa -C&quot;邮箱地址&quot; (2)用户主目录中找到.ssh目录，目录中id_rsa时私钥，id_rsa.pub是公钥 (3)登录GtiHub，打开“Account setting&quot;，将公钥粘贴，点击”add key&quot; 4.本地库与远程库同步 git remote add origin git@github.com:RookieYin/GitLearn.git 执行上述命令后，成功连接远程库，远程库名字为“origin” git push -u origin master，将本地库内容推送到远程库 git push发生冲突时，解决方案如下： （1）git branch --set-upstream-to=origin/dev dev，远程分支和本地分支建立连接 （2）git pull，将远程分支抓取到本地 （3）git merge，合并两个分支，发生冲突，解决后再提交，然后push 5.远程库克隆 git clone git@github.com:RookieYin/GitLearn.git 6.Git的分支 master分支是版本库中的主分支，每次提交master都会向前移动一步。 当新创建一个dev分之后，Head只想dev，表示当前分支在dev上。 此时新提交一次，dev分支向前移动一步。 dev分支上工作完成后，可以执行merge指令合并master和dev分支。 如果我们切换到master分支后也进行了一次提交，merge时就会存在冲突。 我们需要解决冲突后再进行合并。 实际生产中，Git中的分支大概如上图。master很稳定，用来发布新版本；dev开发环境，一定时候将dev合并到master；每个团队成员有自己单独的分支，完成后合并到dev分支。 git checkout -b dev：创建并切换dev分支，-b参数表示创建并切换（相当于git branch dev;git checkout dev) git branch：查看当前版本库存在的所有分支 git merge dev：将dev分支和当前分支合并 git log --graph --pretty=online --abbrev-commit：可以图形化展示分支合并情况 git branch -d dev：删除dev分支 git switch -c dev：创建并切换到dev分支 git switch dev：切换到dev分支 git stash：可以将当前工作现场储存起来，完成临时工作任务后继续工作 git stash apply：恢复工作现场，stash内容不删除，使用git stash drop 来删除，如果有多次stash，可以使用git stash list查看所有stash的id，然后在apply后面指定某个stash git stash pop：恢复工作现场的同时，把stash内容删除了 git push origin dev：可以向远程库推送dev分支 git tag v1.0：给最新一次提交打上标签v1.0 git tag v1.0 commit_id：给指定的commit打上标签v1.0 git tag：查看所有标签 git show v1.0：可以查看标签v1.0的提交的内容 git tag -a v1.0 -m&quot;xxxxxx&quot; commit_id：通过-m参数可以创建带有说明的标签 git tag -d v1.0：可以删除标签v1.0 git push origin v1.0：可以将本地标签推送到远程 git push origin --tags：将本地所有标签推送到远程 git push origin :refs/tags/v1.0：可以将远程的标签删除","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://rookieyin.github.io/tags/Git/"}]},{"title":"浅谈CSS中的定位","slug":"1 前端/CSS/浅谈CSS中的定位","date":"2021-06-07T05:43:46.000Z","updated":"2021-06-21T00:31:24.793Z","comments":true,"path":"63744a63d594/","link":"","permalink":"http://rookieyin.github.io/63744a63d594/","excerpt":"说在最前面 一切皆为框。div、h1或p元素被称为块级元素，这些元素显示为一块内容，即为“块框”。span和strong等元素称为行内元素，他们的内容显示在同一行中，即为“行内框”。 在没设置任何style的情况下，这些框，按照正常的顺序在文档流中排列：即块框独占一行，行内框显示在同一行。 注意：width属性、垂直内边距、外边距都无法作用于行内框；行内框宽度发生溢出会自动换行","text":"说在最前面 一切皆为框。div、h1或p元素被称为块级元素，这些元素显示为一块内容，即为“块框”。span和strong等元素称为行内元素，他们的内容显示在同一行中，即为“行内框”。 在没设置任何style的情况下，这些框，按照正常的顺序在文档流中排列：即块框独占一行，行内框显示在同一行。 注意：width属性、垂直内边距、外边距都无法作用于行内框；行内框宽度发生溢出会自动换行 CSS定位机制 CSS有三种基本的定位机制：普通流、浮动和绝对定位。可以通过display属性设置定位类型： 一、相对定位 相对定位：相对于元素在普通流中的位置。通过设置元素的垂直或者水平位置，让元素相对于它的起点进行移动。 #box_relative{ position: relative; left: 30px; right: 20px; } 注意：相对定位，无论是否移动，元素任然占据原来的空间，移动的元素会覆盖其他框。 二、绝对定位 绝对定位：元素脱离文档流，不占据空间，位置相对于最近的已定位祖先。 #box_absolute { position: absolute; left: 30px; right: 20px } 注意：绝对定位元素位置对于正常文档流中其他元素相当于不存在，可用z-index属性设置元素堆放次序。 三、浮动 1、浮动的框向左或者向右移动，直到它的外边缘碰到包含框或者另一个浮动框的边框为止。 2、浮动框脱离普通文档流，普通文档流中的框不知道浮动框的存在。 CSS中的display属性 display属性可以用来设置元素生成的显示框的类型。 CSS中的position属性 可参考https://developer.mozilla.org/zh-CN/docs/Web/CSS/position这篇文章，讲的很详细。","categories":[{"name":"前端","slug":"前端","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"CSS","slug":"前端/CSS","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/CSS/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://rookieyin.github.io/tags/CSS/"},{"name":"前端","slug":"前端","permalink":"http://rookieyin.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"定位","slug":"定位","permalink":"http://rookieyin.github.io/tags/%E5%AE%9A%E4%BD%8D/"}]},{"title":"深度学习小知识","slug":"2.深度学习小知识","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.784Z","comments":true,"path":"84e5e0d70fc8/","link":"","permalink":"http://rookieyin.github.io/84e5e0d70fc8/","excerpt":"1. 池化层 池化层是卷积神经网络的常用组件之一，最早见于LeNet一文中，现在也被扩展到很多其他神经网络中。池化层模仿人的视觉系统对数据进行降维，用更高层次的特征表示图像。 池化层的目的有： 对数据降维，降低信息冗余 提升模型的不变性，包括平移不变性、旋转不变性、尺度不变性等等 防止过拟合 常见的池化技术有：最大池化、平均池化、重叠池化、随机池化、组合池化等等。","text":"1. 池化层 池化层是卷积神经网络的常用组件之一，最早见于LeNet一文中，现在也被扩展到很多其他神经网络中。池化层模仿人的视觉系统对数据进行降维，用更高层次的特征表示图像。 池化层的目的有： 对数据降维，降低信息冗余 提升模型的不变性，包括平移不变性、旋转不变性、尺度不变性等等 防止过拟合 常见的池化技术有：最大池化、平均池化、重叠池化、随机池化、组合池化等等。 2. Batch，Iteration，Epoch Batch：在数据集很大的时候，我们无法直接把所有数据全部喂给神经网络（内存不够），此时需要将数据划分成多个小块，一块一块的传递给神经网络。每一小块数据就称为1个batch，模型每收到一个batch就进行一次前向传播和反向传播进行参数优化。因此，根据不同batch size，会使用不同类型的梯度下降。 Epoch：当整个数据集中数据都完成了一次前向传播和反向传播称之为一个epoch。在神经网络模型中，只传递一次完整数据集是不够的，我们需要将完成数据集在网络中传递多次直到模型收敛。但随着epoch数目的增加，模型会逐渐由过拟合变成欠拟合。 Iteration：完成1个epoch需要执行的batch的数目，比如训练集有2000个样本，1个batch有500个样本，那么完成1个epoch需要4个iteration。 梯度下降种类 transductive和inductive 降采样 层级Softmax 在线算法 正则化","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://rookieyin.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"http://rookieyin.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"WL和GNN","slug":"1.WL和GNN","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:44:22.711Z","comments":true,"path":"fba7fdb413dc/","link":"","permalink":"http://rookieyin.github.io/fba7fdb413dc/","excerpt":"1. Weisfeiler-Leman算法 图同构： 通俗点就是两个图的特征及结构信息完全相同。具体来说就是：如果图G和图H同构，那么在G和H的顶点集间存在一个“edge-preserving&quot;的双射函数fff，使得“如果节点u和v在图G中相连，那么f(u)f(u)f(u)和f(v)f(v)f(v)在图H中也相连”。下图展示了两个同构图G和H： Jaccard相似度： Jaccard index，又称为Jaccard相似系数或者叫雅可比相似度系数，用来比较有限样本集之间的相似性与差异性。Jaccard系数值越大，样本相似度越高。狭义的Jaccard系数计算公式如下： J(A,B)=∣A∩B∣∣A∪B∣=∣A∩B∣∣A∣+∣B∣−∣A∩B∣J(A,B)=\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{|A\\cap B|}{|A|+|B|-|A\\cap B|} J(A,B)=∣A∪B∣∣A∩B∣​=∣A∣+∣B∣−∣A∩B∣∣A∩B∣​ 当A和B都为空集时，J(A,B)=1J(A,B)=1J(A,B)=1；当A=BA=BA=B时，J(A,B)=1J(A,B)=1J(A,B)=1。 Weisfeiler-Leman(WL，威斯费勒-莱曼)是用来测试图同构的一种经典算法，可以在准多项式复杂度内判别两个图是否同构。所谓的图同构就是两个图中对应节点的特征信息和结构信息都相同，则称两个图同构。因此就需要一种高效地计算方法能将特征信息及结构位置信息映射成一个数值，我们称其为这个节点的ID。最后，两个图的相似度问题就可以转化成两个图节点集合ID的Jaccard相似度问题。 思路： 计算节点ID需要用到节点的特征信息和结构信息。特征信息即节点自带的Embedding，而结构信息可以通过节点的邻居来刻画，比如，如果两个节点的Embedding相同，并且他们连接了Embedding完全相同的邻居，此时我们是无法区分这两个节点的，因此这两个节点的ID相同。我们可以通过对节点ID的Hash来高效判断两个节点ID是否一致。 Input： 一对图G=(V,E,X)G=(V,E,X)G=(V,E,X)和H=(U,F,Y)H=(U,F,Y)H=(U,F,Y) Output： 是否存在双射函数f:V→Uf:V\\rightarrow Uf:V→U，使得Xv=Yf(v) ∀v∈VX_v=Y_{f(v)}\\ \\forall v\\in VXv​=Yf(v)​ ∀v∈V，并且当且仅当{f(u),f(v)∈F}\\{f(u),f(v)\\in F\\}{f(u),f(v)∈F}时，{u,v}∈E\\{u,v\\}\\in E{u,v}∈E。","text":"1. Weisfeiler-Leman算法 图同构： 通俗点就是两个图的特征及结构信息完全相同。具体来说就是：如果图G和图H同构，那么在G和H的顶点集间存在一个“edge-preserving&quot;的双射函数fff，使得“如果节点u和v在图G中相连，那么f(u)f(u)f(u)和f(v)f(v)f(v)在图H中也相连”。下图展示了两个同构图G和H： Jaccard相似度： Jaccard index，又称为Jaccard相似系数或者叫雅可比相似度系数，用来比较有限样本集之间的相似性与差异性。Jaccard系数值越大，样本相似度越高。狭义的Jaccard系数计算公式如下： J(A,B)=∣A∩B∣∣A∪B∣=∣A∩B∣∣A∣+∣B∣−∣A∩B∣J(A,B)=\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{|A\\cap B|}{|A|+|B|-|A\\cap B|} J(A,B)=∣A∪B∣∣A∩B∣​=∣A∣+∣B∣−∣A∩B∣∣A∩B∣​ 当A和B都为空集时，J(A,B)=1J(A,B)=1J(A,B)=1；当A=BA=BA=B时，J(A,B)=1J(A,B)=1J(A,B)=1。 Weisfeiler-Leman(WL，威斯费勒-莱曼)是用来测试图同构的一种经典算法，可以在准多项式复杂度内判别两个图是否同构。所谓的图同构就是两个图中对应节点的特征信息和结构信息都相同，则称两个图同构。因此就需要一种高效地计算方法能将特征信息及结构位置信息映射成一个数值，我们称其为这个节点的ID。最后，两个图的相似度问题就可以转化成两个图节点集合ID的Jaccard相似度问题。 思路： 计算节点ID需要用到节点的特征信息和结构信息。特征信息即节点自带的Embedding，而结构信息可以通过节点的邻居来刻画，比如，如果两个节点的Embedding相同，并且他们连接了Embedding完全相同的邻居，此时我们是无法区分这两个节点的，因此这两个节点的ID相同。我们可以通过对节点ID的Hash来高效判断两个节点ID是否一致。 Input： 一对图G=(V,E,X)G=(V,E,X)G=(V,E,X)和H=(U,F,Y)H=(U,F,Y)H=(U,F,Y) Output： 是否存在双射函数f:V→Uf:V\\rightarrow Uf:V→U，使得Xv=Yf(v) ∀v∈VX_v=Y_{f(v)}\\ \\forall v\\in VXv​=Yf(v)​ ∀v∈V，并且当且仅当{f(u),f(v)∈F}\\{f(u),f(v)\\in F\\}{f(u),f(v)∈F}时，{u,v}∈E\\{u,v\\}\\in E{u,v}∈E。 1.1 1-WL hl(t)(v)=HASH(hl(t−1)(v),F{hlt−1(u)∣u∈N(v)})h_l^{(t)}(v)=HASH\\Big(h_l^{(t-1)}(v),\\mathcal F\\Big\\{h_l^{t-1}(u)|u\\in N(v)\\Big\\}\\Big) hl(t)​(v)=HASH(hl(t−1)​(v),F{hlt−1​(u)∣u∈N(v)}) 其中vvv表示单个节点，F\\mathcal FF表示邻居EmbeddingEmbeddingEmbedding的聚合函数，可以是简单的拼接。hl(t−1)(v)h_l^{(t-1)}(v)hl(t−1)​(v)表示上一轮迭代中节点vvv的Embedding。HASHHASHHASH是哈希函数，也可以是其他单射函数（输入x不同，得到的f(x)一定不同）。 多重集 多重集是集合概念的推广，它允许集合中元素重复出现。一个多重集可以看做是一个二元组X=(S,m)X=(S,m)X=(S,m)，其中S为在X中出现的所有元素构成的集合，m:S→N≥1m:S\\rightarrow\\mathbb N_{\\geq1}m:S→N≥1​表示S中每个元素出现的次数。 流程 Input： 一对图G=(V,E,X)G=(V,E,X)G=(V,E,X)和H=(U,F,Y)H=(U,F,Y)H=(U,F,Y) cv(0)←Hash(Xv) (∀v∈V)c_v^{(0)}\\leftarrow Hash(X_v)\\ (\\forall v\\in V)cv(0)​←Hash(Xv​) (∀v∈V) du(0)←Hash(Yu) (∀u∈U)d_u^{(0)}\\leftarrow Hash(Y_u)\\ (\\forall u\\in U)du(0)​←Hash(Yu​) (∀u∈U) for l=1,2,...(untill convergence)l=1,2,...(untill\\ convergence)l=1,2,...(untill convergence) (1) if {{cv(l−1) ∣ v∈V}}≠{{du(l−1) ∣ u∈U}}\\{\\{c_v^{(l-1)}\\ |\\ v\\in V\\}\\}\\neq \\{\\{d_u^{(l-1)}\\ |\\ u\\in U\\}\\}{{cv(l−1)​ ∣ v∈V}}​={{du(l−1)​ ∣ u∈U}} then return “non-isomorphic” (2) cv(l)←Hash(cv(l−1),{{cw(l−1) ∣ w∈NG(v)}}) (∀v∈V)c_v^{(l)}\\leftarrow Hash(c_v^{(l-1)},\\{\\{c_w^{(l-1)}\\ |\\ w\\in\\mathcal N_G(v)\\}\\})\\ (\\forall v\\in V)cv(l)​←Hash(cv(l−1)​,{{cw(l−1)​ ∣ w∈NG​(v)}}) (∀v∈V) (3) du(l)←Hash(du(l−1),{{dw(l−1) ∣ w∈NH(u)}}) (∀u∈U)d_u^{(l)}\\leftarrow Hash(d_u^{(l-1)},\\{\\{d_w^{(l-1)}\\ |\\ w\\in\\mathcal N_H(u)\\}\\})\\ (\\forall u\\in U)du(l)​←Hash(du(l−1)​,{{dw(l−1)​ ∣ w∈NH​(u)}}) (∀u∈U) return “possibly isomorphic” 1-WL一定会在O(∣V∣+∣U∣)O(|V|+|U|)O(∣V∣+∣U∣)迭代内终止。如果1-WL算法输出&quot;non-isomorphic&quot;，那么G和H一定是非同构的。但是如果1-WL输出&quot;possibly isomorphic&quot;，那么G和H也可能是非同构的，如下图所示： 实例 问题1：为什么1-WL返回possibly isomorphicpossibly\\ isomorphicpossibly isomorphic时，两个图可能非同构的？ 因为WL用邻居来刻画图的结构信息，如果非同构图G和H中存在这样一个节点对组合：任意一个节点对中两个节点的特征相同，且邻居数量、特征都相同，那么此时1-WL算法无法区分这两个非同构图。 问题2：为什么1-WL最多迭代O(∣V∣+∣U∣)O(|V|+|U|)O(∣V∣+∣U∣)？ 考虑回答这个问题：为什么k-WL最多迭代O(∣V∣k+∣U∣k)O(|V|^k+|U|^k)O(∣V∣k+∣U∣k)次？ 因为k-WL算法中，对于有n个顶点的图最多有nkn^knk种颜色类别，所以最多在nkn^knk次迭代后颜色状态达到稳定，算法终止。 1.2 k-WL 1-WL算法计算过程中只考虑1个顶点，k-WL算法计算时考虑的是K个顶点组成的k-tuple。 流程 Input： 一对图G=(V,E,X)G=(V,E,X)G=(V,E,X)和H=(U,F,Y)H=(U,F,Y)H=(U,F,Y) cv(0)←Hash(G[v]) (∀v∈Vk)c_\\mathbf v^{(0)}\\leftarrow Hash(G[\\mathbf v])\\ (\\forall\\mathbf v\\in V^k)cv(0)​←Hash(G[v]) (∀v∈Vk) du(0)←Hash(H[u]) (∀u∈Uk)d_\\mathbf u^{(0)}\\leftarrow Hash(H[\\mathbf u])\\ (\\forall\\mathbf u\\in U^k)du(0)​←Hash(H[u]) (∀u∈Uk) for l=1,2,...(untill convergence)l=1,2,...(untill\\ convergence)l=1,2,...(untill convergence) (1) if {{cv(l−1) ∣ v∈V}}≠{{du(l−1) ∣ u∈U}}\\{\\{c_\\mathbf v^{(l-1)}\\ |\\ \\mathbf v\\in V\\}\\}\\neq \\{\\{d_\\mathbf u^{(l-1)}\\ |\\ \\mathbf u\\in U\\}\\}{{cv(l−1)​ ∣ v∈V}}​={{du(l−1)​ ∣ u∈U}} then return “non-isomorphic” (2) cv,i(l)←{{cw(l−1) ∣ w∈NG,ik−WL(v)}} (∀v∈Vk,i∈[k])c_{\\mathbf v,i}^{(l)}\\leftarrow \\{\\{c_\\mathbf w^{(l-1)}\\ |\\ \\mathbf w\\in\\mathcal N_{G,i}^{k-WL}(\\mathbf v)\\}\\}\\ (\\forall\\mathbf v\\in V^k, i\\in[k])cv,i(l)​←{{cw(l−1)​ ∣ w∈NG,ik−WL​(v)}} (∀v∈Vk,i∈[k]) (3) cv(l)←Hash(cv(l−1),cv,1(l),...,cv,k(l)}}) (∀v∈Vk)c_\\mathbf v^{(l)}\\leftarrow Hash(c_\\mathbf v^{(l-1)},c_{\\mathbf v,1}^{(l)},...,c_{\\mathbf v,k}^{(l)}\\}\\})\\ (\\forall\\mathbf v\\in V^k)cv(l)​←Hash(cv(l−1)​,cv,1(l)​,...,cv,k(l)​}}) (∀v∈Vk) (4) du,i(l)←{{dw(l−1) ∣ w∈NH,ik−WL(u)}} (∀u∈Uk,i∈[k])d_{\\mathbf u,i}^{(l)}\\leftarrow \\{\\{d_\\mathbf w^{(l-1)}\\ |\\ \\mathbf w\\in\\mathcal N_{H,i}^{k-WL}(\\mathbf u)\\}\\}\\ (\\forall\\mathbf u\\in U^k, i\\in[k])du,i(l)​←{{dw(l−1)​ ∣ w∈NH,ik−WL​(u)}} (∀u∈Uk,i∈[k]) (5) du(l)←Hash(du(l−1),du,1(l),...,du,k(l)}}) (∀u∈Uk)d_\\mathbf u^{(l)}\\leftarrow Hash(d_\\mathbf u^{(l-1)},d_{\\mathbf u,1}^{(l)},...,d_{\\mathbf u,k}^{(l)}\\}\\})\\ (\\forall\\mathbf u\\in U^k)du(l)​←Hash(du(l−1)​,du,1(l)​,...,du,k(l)​}}) (∀u∈Uk) return “possibly isomorphic” 其中NG,ik−WL(v)={(v1,...,vi−1,w,vi+1,...,vk) ∣ w∈V}\\mathcal N_{G,i}^{k-WL}(\\mathbf v)=\\{(v_1,...,v_{i-1},w,v_{i+1},...,v_k)\\ |\\ w\\in V\\}NG,ik−WL​(v)={(v1​,...,vi−1​,w,vi+1​,...,vk​) ∣ w∈V}表示k元组v\\mathbf vv的i-th邻居，即用G中的其他顶点任意顶点www替换v\\mathbf vv中的第i个顶点。对于连个k-tuple，当且仅当下面两个条件都满足时，Hash(G[v1])=Hash(G[v2])Hash(G[\\mathbf v^1])=Hash(G[\\mathbf v^2])Hash(G[v1])=Hash(G[v2])： Xvi1=Xvi2,∀i∈[k]\\mathbf {X_{v_i^1}=X_{v_i^2}}, \\forall i\\in[k]Xvi1​​=Xvi2​​,∀i∈[k] 当且仅当{vi2 vj2}∈E, ∀i,j∈[k]\\{\\mathbf v_i^2\\,\\mathbf v_j^2\\}\\in E,\\ \\forall i,j\\in[k]{vi2​vj2​}∈E, ∀i,j∈[k]时，vi1,vj1∈E{\\mathbf v_i^1,\\mathbf v_j^1}\\in Evi1​,vj1​∈E 1.2 k-FWL WL算法有很多变体形式，主要通过改变邻居信息的聚合方式来进行优化，k-FWL就是其中一种。 流程 Input： 一对图G=(V,E,X)G=(V,E,X)G=(V,E,X)和H=(U,F,Y)H=(U,F,Y)H=(U,F,Y) cv(0)←Hash(G[v]) (∀v∈Vk)c_\\mathbf v^{(0)}\\leftarrow Hash(G[\\mathbf v])\\ (\\forall\\mathbf v\\in V^k)cv(0)​←Hash(G[v]) (∀v∈Vk) du(0)←Hash(H[u]) (∀u∈Uk)d_\\mathbf u^{(0)}\\leftarrow Hash(H[\\mathbf u])\\ (\\forall\\mathbf u\\in U^k)du(0)​←Hash(H[u]) (∀u∈Uk) for l=1,2,...(untill convergence)l=1,2,...(untill\\ convergence)l=1,2,...(untill convergence) (1) if {{cv(l−1) ∣ v∈V}}≠{{du(l−1) ∣ u∈U}}\\{\\{c_\\mathbf v^{(l-1)}\\ |\\ \\mathbf v\\in V\\}\\}\\neq \\{\\{d_\\mathbf u^{(l-1)}\\ |\\ \\mathbf u\\in U\\}\\}{{cv(l−1)​ ∣ v∈V}}​={{du(l−1)​ ∣ u∈U}} then return “non-isomorphic” (2) cv,w(l)←(cv[0]←w(l−1),...,cv[k]←w(l−1)) (∀v∈Vk,w∈V)c_{\\mathbf v,w}^{(l)}\\leftarrow (c_{\\mathbf v[0]\\leftarrow w}^{(l-1)},...,c_{\\mathbf v[k]\\leftarrow w}^{(l-1)})\\ (\\forall\\mathbf v\\in V^k, w\\in V)cv,w(l)​←(cv[0]←w(l−1)​,...,cv[k]←w(l−1)​) (∀v∈Vk,w∈V) (3) cv(l)←Hash(cv(l−1),{{cv,w(l) ∣ w∈V}}) (∀v∈Vk)c_\\mathbf v^{(l)}\\leftarrow Hash(c_\\mathbf v^{(l-1)},\\{\\{c_{\\mathbf v,w}^{(l)}\\ |\\ w\\in V\\}\\})\\ (\\forall\\mathbf v\\in V^k)cv(l)​←Hash(cv(l−1)​,{{cv,w(l)​ ∣ w∈V}}) (∀v∈Vk) (4) du,w(l)←(du[0]←w(l−1),...,du[k]←w(l−1)) (∀u∈Uk,w∈U)d_{\\mathbf u,w}^{(l)}\\leftarrow (d_{\\mathbf u[0]\\leftarrow w}^{(l-1)},...,d_{\\mathbf u[k]\\leftarrow w}^{(l-1)})\\ (\\forall\\mathbf u\\in U^k, w\\in U)du,w(l)​←(du[0]←w(l−1)​,...,du[k]←w(l−1)​) (∀u∈Uk,w∈U) (5) du(l)←Hash(du(l−1),{{du,w(l) ∣ w∈U}}) (∀u∈Uk)d_\\mathbf u^{(l)}\\leftarrow Hash(d_\\mathbf u^{(l-1)},\\{\\{d_{\\mathbf u,w}^{(l)}\\ |\\ w\\in U\\}\\})\\ (\\forall\\mathbf u\\in U^k)du(l)​←Hash(du(l−1)​,{{du,w(l)​ ∣ w∈U}}) (∀u∈Uk) return “possibly isomorphic” 其中cv[i]←w=c(v1,...,vi−1,w,vi+1,...,vk)c_{\\mathbf v[i]\\leftarrow w}=c(v_1,...,v_{i-1},w,v_{i+1},...,v_k)cv[i]←w​=c(v1​,...,vi−1​,w,vi+1​,...,vk​)。FWL和WL的区别在于：FWL先concate节点w替换的所有邻居，在将其与k元组v\\mathbf vv进行Hash操作。k−FWLk-FWLk−FWL算法可以区分k−WLk-WLk−WL算法不能区分的非同构图，但是也存在k−FWLk-FWLk−FWL无法区分的非同构图。 问题：为什么k−FWLk-FWLk−FWL比k−WLk-WLk−WL要强？ 证明待定。 1.3 不同WL间的性能比较 1-WL和2-WL性能一样 证明待定。 当k≥2k\\geq2k≥2时，k−FWLk-FWLk−FWL和(k+1)−WL(k+1)-WL(k+1)−WL性能一样 证明待定。 当k≥2k\\geq2k≥2时，(k+1)−WL(k+1)-WL(k+1)−WL一定比k−WLk-WLk−WL要强 比如，1-WL不能区分下图，但是3-WL能区分。 证明待定。 上述结论主要根据参考文献“ Pebble games and linear equations ”中下面两条定理得到的： 定理1：A≡CkBA\\equiv_C^k BA≡Ck​B当且仅当k-WL算法无法区分图A和图B。 定理2：A≡C2B⇔A≡C&lt;2BA\\equiv_C^2 B \\Leftrightarrow A\\equiv_C^{&lt;2}BA≡C2​B⇔A≡C&lt;2​B；对于k≥3k\\geq 3k≥3，A≡CkB⇒A≡C&lt;kB⇒A≡Ck−1BA\\equiv_C^k B\\Rightarrow A\\equiv_C^{&lt;k}B\\Rightarrow A\\equiv_C^{k-1}BA≡Ck​B⇒A≡C&lt;k​B⇒A≡Ck−1​B。 （上述第二条关于FWL的结论给的参考文献和第三条结论的相同，但是没找到相关结论） 对于WL算法能区分哪些图，不能区分哪些图，学术界也做了很多研究，有一下结论： 如果两个图是随机均匀获取到的，那么随着图越来越大，1-WL算法的失败率逐渐变为0。 证明待定。 当k≥2k\\geq2k≥2时，一定存在一个大小为O(k)O(k)O(k)的非同构图(G,H)(G,H)(G,H)，k-WL算法输出&quot;possibly isomorphic&quot;。 证明待定。 1-WL算法能区分任意一对非同构树S和T。 证明待定。 任意正整数k,n∈Z+k,n\\in\\mathbb Z^+k,n∈Z+，对于有n个顶点的k正则图，1-WL算法输出结果一定是&quot;possibly isomorphic&quot;。 证明待定。 1-WL算法可以在准线性时间内区分出它可以区分的非同构图。 证明待定。 2. GNNs和WL间的联系 定理： 对于任何基于消息传播的GNN模型，在图G和图H上，如果1-WL输出结果为”possibly isomorphic&quot;，那么GNN模型的到的图嵌入hGh_GhG​和hHh_HhH​一定相同。（1-WL算法性能是GNN的上限） 解释： GNNs中的聚合函数和更新函数可以看做对1-WL中Hansh函数的近似。所以，要想GNNs模型拥有和1-WL一样的性能，需要想办法将GNNs中的聚合函数和更新函数变成单射函数。 2.1 GIN模型——消息传播GNNs的天花板 2.1.1 定理证明 引理：G1G_1G1​和G2G_2G2​是非同构图。如果通过GNNA:G→RdA:\\mathcal G\\rightarrow\\mathbb R^dA:G→Rd得到的图embedding是不同的，那么1-WL算法作用于这两个图上的结果一定是non isomorphicnon\\ isomorphicnon isomorphic。 定理： 用A:G→Rd\\mathcal A:\\mathcal G\\rightarrow\\mathbb R^dA:G→Rd表示GNN。对于一个层数足够的GNN，如果满足下列两个条件，则对于所有1-WL算法输出为非同构的图，GNN模型得到的embedding一定不同： A\\mathcal AA聚合和更新函数hv(k)=ϕ(hv(k−1,f({hu(k−1):u∈N(v)}))h_v^{(k)}=\\phi\\Big(h_v^{(k-1},f\\Big(\\Big\\{h_u^{(k-1)}:u\\in\\mathcal N(v)\\Big\\}\\Big)\\Big)hv(k)​=ϕ(hv(k−1​,f({hu(k−1)​:u∈N(v)}))，其中fff作用于多重集的函数，ϕ\\phiϕ是单射函数。 A\\mathcal AA的graph-level readout函数，即作用于节点特征集合{hv(k)}\\{h_v^{(k)}\\}{hv(k)​}上的函数是单射的。 定理3： 假设集合X\\mathcal XX是可数的。存在一个函数f:X→Rnf:\\mathcal X\\rightarrow\\mathbb R^nf:X→Rn，对于每一个有限大小的集合X⊂XX\\subset\\mathcal XX⊂X，使得h(X)=∑x∈Xf(x)h(X)=\\sum_{x\\in X}f(x)h(X)=∑x∈X​f(x)是唯一的。另外存在一个多重集上的函数g，对于某种函数$ \\phi ，可以按照，可以按照，可以按照g(X)=$$\\phi(\\sum_{x\\in X}f(x))$方式分解。 推论6： 假设集合X\\mathcal XX是可数的。存在函数f:X→Rnf:\\mathcal X\\rightarrow\\mathbb R^nf:X→Rn，使得h(c,X)=(1+ϵ)⋅f(c)+∑x∈Xf(x)h(c,X)=(1+\\epsilon)·f(c)+\\sum_{x\\in X}f(x)h(c,X)=(1+ϵ)⋅f(c)+∑x∈X​f(x)对于所有(c,X)(c,X)(c,X)都成立，其中ϵ\\epsilonϵ有无数种选择（也可以是无理数），c∈Xc\\in\\mathcal Xc∈X，X⊂XX\\subset \\mathcal XX⊂X。同样地，也存在一个作用于(c,X)(c,X)(c,X)上的函数g，对于某种函数φ\\varphiφ，可以将g分解为：g(c,X)=φ((1+ϵ)⋅f(c)+g(c,X)=\\varphi((1+\\epsilon)·f(c)+g(c,X)=φ((1+ϵ)⋅f(c)+∑x∈Xf(x))\\sum_{x\\in X}f(x))∑x∈X​f(x))。 2.1.2 聚合和更新函数 根据通用近似定理（人工神经网络可以近似任意函数），在GIN中作者用MLP来对f(k+1)∘φ(k)f^{(k+1)}\\circ \\varphi^{(k)}f(k+1)∘φ(k)进行建模。在第一层中，如果节点特征是one-hot编码，我们不需要使用MLP，因为对他们求和本身就是单射的。GIN中的聚合和更新算法如下： hv(k)=MLP(k)((1+ϵ)⋅hv(k−1)+∑u∈N(v)hu(k−1))h_v^{(k)}=MLP^{(k)}\\Big(\\big(1+\\epsilon\\big)·h_v^{(k-1)}+\\sum_{u\\in\\mathcal N(v)}h_u^{(k-1)}\\Big) hv(k)​=MLP(k)((1+ϵ)⋅hv(k−1)​+u∈N(v)∑​hu(k−1)​) 2.1.3 graph-level readout函数 为了考虑所有的结构信息，在计算图特征时用到了所有迭代中的节点特征。作者参考Jumping Knowledge那篇论文的架构： hG=CONCAT(READOUT({hv(k)∣v∈G}) ∣ k=0,1,...,K)h_G=CONCAT(READOUT(\\{h_v^{(k)}|v\\in G\\})\\ |\\ k=0,1,...,K) hG​=CONCAT(READOUT({hv(k)​∣v∈G}) ∣ k=0,1,...,K) 根据定理3和推论6，如果用求和函数代替READOUT（和第一层不需要用MLP的理由一样)，这样GIN就可证明地推广了WL-test和WL subtree kernel。 2.2 比1-WL更强的GNNs Morris等人在2019年发表了一篇名为“ eisfeiler andlemango neural: Higher-order graph neural network ”的文章，里面基于set K-WL算法提出了一种更强大的模型k-GNNs（之所以不用k-WL是为了减少内存开销）。 2.2.1 Set k-WL算法 Set k-WL和k-WL算法不同的时：不在使用k-tuple作为基本研究对象，而是使用k-set。[V]k={S⊆V ∣ ∣S∣=k}[V]_k=\\{S\\subseteq V\\ |\\ |S|=k\\}[V]k​={S⊆V ∣ ∣S∣=k}表示V的一个真子集，大小为k。NV,kset(S)={W∈[V]k ∣ ∣W∪V∣=k−1}\\mathcal N_{V,k}^{set}(S)=\\{W\\in[V]_k\\ |\\ |W\\cup V|=k-1\\}NV,kset​(S)={W∈[V]k​ ∣ ∣W∪V∣=k−1}表示V的所有邻居构成的集合。set k-WL算法流程如下： cS(0)←Hash(G[S])(∀S∈[V]k)c_S^{(0)}\\leftarrow Hash(G[S])(\\forall S\\in [V]_k)cS(0)​←Hash(G[S])(∀S∈[V]k​) dT(0)←Hash(H[T])(∀T∈[U]k)d_T^{(0)}\\leftarrow Hash(H[T])(\\forall T\\in[U]_k)dT(0)​←Hash(H[T])(∀T∈[U]k​) for l=1,2,...(util convergence)l=1,2,...(util\\ convergence)l=1,2,...(util convergence) (a) if {{cS(l−1) ∣ S∈[V]k}}≠{{dT(l−1) ∣ T∈[U]k}}\\{\\{c_S^{(l-1)}\\ |\\ S\\in[V]_k\\}\\}\\neq\\{\\{d_T^{(l-1)}\\ |\\ T\\in[U]_k\\}\\}{{cS(l−1)​ ∣ S∈[V]k​}}​={{dT(l−1)​ ∣ T∈[U]k​}} return “non-isomorphic” (b) cS(l)←Hash(cS(l−1),{{cW(l−1) ∣ W∈NV,kset(S)}})(∀S∈[V]k)c_S^{(l)}\\leftarrow Hash(c_S^{(l-1)},\\{\\{c_W^{(l-1)}\\ |\\ W\\in\\mathcal N_{V,k}^{set}(S)\\}\\})(\\forall S\\in[V]_k)cS(l)​←Hash(cS(l−1)​,{{cW(l−1)​ ∣ W∈NV,kset​(S)}})(∀S∈[V]k​) © dT(l)←Hash(dT(l−1),{{dW(l−1) ∣ W∈NU,kset}})(∀G∈[U]k)d_T^{(l)}\\leftarrow Hash(d_T^{(l-1)},\\{\\{d_W^{(l-1)}\\ |\\ W\\in\\mathcal N_{U,k}^{set}\\}\\})(\\forall G\\in[U]_k)dT(l)​←Hash(dT(l−1)​,{{dW(l−1)​ ∣ W∈NU,kset​}})(∀G∈[U]k​) return “possibly isomorphic” set 3-WL可以检测出三角形的数量（1-WL不行），因此可以区分上面几对图，但是1-WL无法区分。需要注意的是set k-WL算法是严格弱于k-WL算法的。例如3-WL算法可以区分下面两个图，但是set 3-WL区分不了，因为3-WL可以检测出4-cycles的数量： 2.2.2 k-GNNs hS(0)=f(0)(G[S])hS(k)=W1(k)hS(k−1)+∑W∈NV,kset(S)W2(k)hW(k−1)\\begin{aligned} h_S^{(0)}&amp;=f^{(0)}(G[S])\\\\ h_S^{(k)}&amp;=W_1^{(k)}h_S^{(k-1)}+\\sum\\limits_{W\\in\\mathcal N_{V,k}^{set}(S)}W_2^{(k)}h_W^{(k-1)} \\end{aligned} hS(0)​hS(k)​​=f(0)(G[S])=W1(k)​hS(k−1)​+W∈NV,kset​(S)∑​W2(k)​hW(k−1)​​ 其中f(0)(G[S])f^{(0)}(G[S])f(0)(G[S])给每个S导出的子图赋予一个特征向量。k-GNN可以看作在G⨂kG^{\\bigotimes k}G⨂k上作消息传播，当且仅当T∈NV,kset(S)T\\in\\mathcal N_{V,k}^{set}(S)T∈NV,kset​(S)时，S∈[V]kS\\in[V]_kS∈[V]k​和T∈[V]kT\\in[V]_kT∈[V]k​之间存在一条边。 定理： 对于任意图G和H，k≥2k\\geq2k≥2，如果set k-WL输出图G和H是“non-isomorphic”，一定存在一个k-GNN计算出的图嵌入hGh_GhG​和hHh_HhH​是不一样的。 3. 高阶GNN k-GNNs的一个缺点就是需要保留O(nk)O(n^k)O(nk)个embedding，花费太多内存了。Maron等人在“ provably powerful graph networks ”一文中基于2−FWL2-FWL2−FWL算法提出了一种模型，该模型只需要保留O(n2)O(n^2)O(n2)个embedding，但是拥有和3-WL一样的表现性能。下面介绍一下高阶invariant和equivariant的GNNs。 3.1 Invariance 和 Equivariance 假设SnS_nSn​表示一个[n]上的对称群，张量X∈RnkX\\in\\mathbb R^{n^k}X∈Rnk，排列p∈Snp\\in S_np∈Sn​，定义(p⋅X)∈Rnk(p·X)\\in\\mathbb R^{n^k}(p⋅X)∈Rnk为(p⋅X)p(i1),p(i2),...,p(in)=Xi1,i2,...,in(p·X)_{p(i_1),p(i_2),...,p(i_n)}=X_{i_1,i_2,...,i_n}(p⋅X)p(i1​),p(i2​),...,p(in​)​=Xi1​,i2​,...,in​​。对于一个张量X∈Rnk×dX\\in\\mathbb R^{n^k\\times d}X∈Rnk×d和排列p∈Snp\\in S_np∈Sn​，我们定义(p⋅X)∈Rnk×d(p·X)\\in\\mathbb R^{n^k\\times d}(p⋅X)∈Rnk×d为(p⋅X)p(i1),p(i2),...,p(in),j=Xi1,i2,...,in,j(p·X)_{p(i_1),p(i_2),...,p(i_n),j}=X_{i_1,i_2,...,i_n,j}(p⋅X)p(i1​),p(i2​),...,p(in​),j​=Xi1​,i2​,...,in​,j​。 Invariance 如果对于任意X∈RnkX\\in\\mathbb R^{n^k}X∈Rnk以及p∈Snp\\in S_np∈Sn​，如果f(p⋅X)=f(X)f(p·X)=f(X)f(p⋅X)=f(X)成立，那么称f:Rnk→Rf:\\mathbb R^{n^k}\\rightarrow\\mathbb Rf:Rnk→R是invariant。 如果对于任意X∈Rnk×dX\\in\\mathbb R^{n^k\\times d}X∈Rnk×d以及p∈Snp\\in S_np∈Sn​，如果f(p⋅X)=f(X)f(p·X)=f(X)f(p⋅X)=f(X)成立，那么称f:Rnk×d→Rnl×d′f:\\mathbb R^{n^k\\times d}\\rightarrow\\mathbb R^{n^l\\times d&#x27;}f:Rnk×d→Rnl×d′是invariant。 Equivariance 如果对于任意X∈RnkX\\in\\mathbb R^{n^k}X∈Rnk以及p∈Snp\\in S_np∈Sn​，如果f(p⋅X)=p⋅f(X)f(p·X)=p·f(X)f(p⋅X)=p⋅f(X)成立，那么称f:Rnk→Rf:\\mathbb R^{n^k}\\rightarrow\\mathbb Rf:Rnk→R是equivariant。 如果对于任意X∈Rnk×dX\\in\\mathbb R^{n^k\\times d}X∈Rnk×d以及p∈Snp\\in S_np∈Sn​，如果f(p⋅X)=p⋅f(X)f(p·X)=p·f(X)f(p⋅X)=p⋅f(X)成立，那么称f:Rnk×d→Rnl×d′f:\\mathbb R^{n^k\\times d}\\rightarrow\\mathbb R^{n^l\\times d&#x27;}f:Rnk×d→Rnl×d′是equivariant。 4. Relational Pooling 未完待续。。。 5. 参考文献","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"WL测试","slug":"WL测试","permalink":"http://rookieyin.github.io/tags/WL%E6%B5%8B%E8%AF%95/"}]},{"title":"Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings","slug":"3 论文笔记/图学习/1.Weisfeiler and Leman go sparse Towards scalable higher-order graph embeddings","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.792Z","comments":true,"path":"a79338adc799/","link":"","permalink":"http://rookieyin.github.io/a79338adc799/","excerpt":"https://arxiv.org/abs/1904.01543 https://www.github.com/chrsmrrs/sparsewl Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings","text":"https://arxiv.org/abs/1904.01543 https://www.github.com/chrsmrrs/sparsewl Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings 1. 论文概述 1.1 论文摘要 Graph kernels based on the 1-dimensional Weisfeiler-Leman algorithm and corr-esponding neural architectures recently emerged as powerful tools for (supervised) learning with graphs. However, due to the purely local nature of the algorithms,they might miss essen-tial patterns in the given data and can only ha-ndle binary relations. The k-dimensional Weisfeiler-Leman algorithm address-es this by considering k-tuples, defined over the set of vertices, and defines a suitab-le notion of adjacency between these vertex tuples. Hence, it accounts for the higher-order interactions between vertices. However, it does not scale and may suffer from overfitting when used in a machine learning setting. Hence, it remains an important open problem to design WL-based graph learning methods that are simultan-eously expressive, scalable, and non-overfitting. Here, we propose local variants and corresponding neural architectures, which consid-er a subset of the original neighborhood, making them more scalable, and less prone to overfitting. The expressive power of (one of) our algorithms is strictly higher than the original algorithm, in terms of ability to distinguish non-isomorphic graphs. Our experimental study confirms that the local algorithms, both kernel and neural architectures,lead to vastly reduced computation times, and prevent overfitting. The kernel version establishes a new state-of-the-art for graph classi-fication on a wide range of benchmark datasets, while the neural version shows promising performance on large-scale molecular regression tasks. 基于1维WL算法及其对应的神经架构的图kernels已经成为了有监督图学习中非常强大的工具。但是，由于这些算法天然的纯局部性，它们可能会错过一些给定数据上的基本模式，并且只能处理二元关系。k维WL算法通过考虑顶点集上的k元组并且给这些顶点元组之间定义了一个合适的adjacency概念解决了这一问题，解释了顶点之间的高阶交互。但是它无法缩放，并且在及其学习的设置下可能会过拟合。因此，设计具有课表大型、可伸缩和non overfitting的基于WL的图学习方法任然是一个重要且开放的问题。本文中作者提出了局部变量和其对应的神经架构，它们使用原始邻域的一个子集，从而使模型更具伸缩性，并且不太容易过拟合。就区分非同构图而言，作者的算法的表现要优于原始算法。实验研究表明无论是基于kernel还是基于神经网络，作者的局部算法都能够大幅缩减计算时间，并防止过拟合。kernel版本的算法为许多基准数据集建立了新的state-of-the-art，而neural版本算法在大规模分子回归任务中也展现了promising性能。 1.2 内容简介 从化学生物到图片和社交网络，图结构的数据非常普遍存在的。为了在这些领域发展有效的机器学习模型，我们需要一些技术能够探索隐藏在图结构内部以及节点和边中的大量信息。近些年来，许多用于图学习的方法被提出，大部分都是基于graph kernel或者GNN。其中基于1维WL的graph kernel及其对应的GNNs取得了有监督图学习中最先进的结果。但是1维WL有两个缺点： 通过简单地聚合邻居信息，其纯局部性特点会使得模型忽略一些数据中的重要模式。 它只适用于二元结构，不能直接用于处理一般的t元结构，比如超图或者子图。 一个性能更强的算法是k−WLk-WLk−WL，通过给k元组分配颜色而不是单个节点，它能捕捉范围更广、更高阶的模式。但是它领域的基数是k⋅nk·nk⋅n，其中n表示整个图的节点数，因此其每次迭代的运行时间没有考虑图的稀疏性。另外，研究人员提出了和k−WLk-WLk−WL能力相当的神经网络架构，但是面临着同样地问题，必须使用densedensedense矩阵乘法。 本文为了解决这一问题提出了δ−k−LWL\\delta-k-LWLδ−k−LWL算法，它在每次迭代过程中只考虑局部邻居。因此，局部邻居的基数依赖于图的稀疏性。 之后作者从理论上分析了他们提出的这种WLWLWL变体在判别非同构图问题上比k−WLk-WLk−WL更强，并设计了一些δ−k−LWL\\delta-k-LWLδ−k−LWL可以区分但是k−WLk-WLk−WL无法区分的非同构图。 在神经网络方面，作者给出了对应的神经网络版本δ−k−LGNN\\delta-k-LGNNδ−k−LGNN，并证明了它和δ−k−LWL\\delta -k-LWLδ−k−LWL具有相同的能力。 2. 算法 2.1 先验知识 符号表示 （1） 1&lt;h1&gt;未完待续... ...&lt;&#x2F;h1&gt;","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"WL测试","slug":"WL测试","permalink":"http://rookieyin.github.io/tags/WL%E6%B5%8B%E8%AF%95/"},{"name":"图嵌入","slug":"图嵌入","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%B5%8C%E5%85%A5/"}]},{"title":"DeepWalk: Online Learning of Social Representation","slug":"3 论文笔记/图学习/3.DeepWalk Online Learning of Social Representations","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.795Z","comments":true,"path":"41e25e276db9/","link":"","permalink":"http://rookieyin.github.io/41e25e276db9/","excerpt":"DeepWalk: Online Learning of Social Representation","text":"DeepWalk: Online Learning of Social Representation 1. 简介 1.1 摘要 We presentDeepWalk, a novel approach for learning la-tent representations of vertices in a network. These latentrepresentations encode social relations in a continuous vectorspace, which is easily exploited by statistical models.Deep-Walkgeneralizes recent advancements in language mod-eling and unsupervised feature learning (ordeep learning)from sequences of words to graphs.DeepWalkuses local information obtained from trun-cated random walks tolearnlatent representations by treat-ing walks as the equivalent of sentences. We demonstrateDeepWalk’s latent representations on several multi-labelnetwork classification tasks for social networks such as Blog-Catalog, Flickr, and YouTube. Our results show thatDeep-Walkoutperforms challenging baselines which are alloweda global view of the network, especially in the presence ofmissing information.DeepWalk’s representations can pro-videF1scores up to 10% higher than competing methodswhen labeled data is sparse. In some experiments,Deep-Walk’s representations are able to outperform all baselinemethods while using 60% less training data.DeepWalkis also scalable. It is an online learning algo-rithm which builds useful incremental results, and is triviallyparallelizable. These qualities make it suitable for a broadclass of real world applications such as network classifica-tion, and anomaly detection. 我们展示了DEEPWALK——一种用于学习网络中节点的潜在表示的原生方法。这些潜在的表示在一个连续的向量空间中编码了社会关系，可以轻松应用到统计学习模型中去。DEEPWALK整合了从单词序列到图形的语言模型和无监督特征学习的最新进展。DEEPWALK把游走序列看做句子，利用从截断随机游走获得的局部信息来学习节点的潜在表示。我们在一些社交网络例如BlogCatlog、Flickr和Youtubu数据集上，通过多标签网络分类任务验证了DeepWalk学习到的潜在表示。我们的结果表明DeepWalk优于很多有挑战性的baseline，尤其在信息缺失的情况下。在有标签数据稀疏的情况下，DeepWalk的F1得分要比对比方法高10%。在一些实验中，尽管训练数据少60%，DeepWalk的效果仍然要优于所有的baseline。DeepWalk也是可扩展的，它是一种在线学习算法，可以建立有用的增量结果，并且可以并行化。这些性质使其适合很多现实世界中的应用，如网络分类，异常检测等。 1.2 简介 这篇文章中，作者将自然语言处理中的模型推广到网络表示学习中，将随机游走序列看做句子，将顶点看做单词，通过对游走序列进行建模来学习图中顶点的潜在特征。 DeepWalk的输入时一张图，输出的是潜在表示。算法在Karate网络中的效果如下图所示，我们发现除了输入和输出之间结构上的惊人相似外，算法输出的潜在表示还是线性可分的。 DeepWalk具有以下优点： DeppWalk效果比其他方法要好，尤其在有标签节点数量很少的时候。 DeepWalk得到的潜在表示泛化能力更好，适用于非常简单的线性分类器，并且可以和任何分类方法结合。 DeepWalk是一个在线算法，并行程度高 这篇文章作者的主要贡献有： 2. 方法 2.1 问题定义 图G=(V,E)G=(V,E)G=(V,E)，V表示网络中的节点，E⊆(V×V)E\\subseteq(V\\times V)E⊆(V×V)表示边。给定部分节点有标签的社交网络GL=(V,E,X,Y)G_L=(V,E,X,Y)GL​=(V,E,X,Y)，属性X∈R∣V∣×SX\\in\\mathbb R^{|V|\\times S}X∈R∣V∣×S，S表示特征空间的大小，Y∈R∣V∣×∣Y∣Y\\in\\mathbb R^{|V|\\times|\\mathcal Y|}Y∈R∣V∣×∣Y∣是标签集合。 2.2 算法 DeepWalk算法包含两部分：随机游走序列生成器和参数更新程序。 **Random Walk Generator：**输入图G，从viv_ivi​节点开始，生成指定长度t的游走序列WviW_{v_i}Wvi​​ **Update Procedure：**使用SkipGram算法更新节点表示（SkipGram模型可参考https://zhuanlan.zhihu.com/p/27234078） 层次Softmax：https://zhuanlan.zhihu.com/p/56139075 未完待续... ...","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"随机游走","slug":"随机游走","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/"}]},{"title":"COMBINING LABEL PROPAGATION AND SIMPLE MODELS OUT-PERFORMS GRAPH NEURAL NETWORKS","slug":"3 论文笔记/图学习/4.Combining Label Propagation and Simple ModelsOut-Performs Graph Neural Networks","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.800Z","comments":true,"path":"ffef744e791f/","link":"","permalink":"http://rookieyin.github.io/ffef744e791f/","excerpt":"https://arxiv.org/pdf/2010.13993v2.pdf https://github.com/CUAI/CorrectAndSmooth COMBINING LABEL PROPAGATION AND SIMPLE MODELS OUT-PERFORMS GRAPH NEURAL NETWORKS，ICLR，2021 总结：GNN作为图学习方面的主要技术，但是其模型越来越复杂，模型收益的可解释性很差。作者发现通过结合几个简单的方法（C&amp;S后处理步骤），在多个数据集上能超过或者媲美当前最优GNN的性能。具体来说先用简单的模型比如MLP或者线性模块预测节点类型分布，然后通过两个标签传播对预测结果进行修正（Correct）和平滑（Smooth）处理。文章的发现或者带给我们的启发有一下几点：（1）图学习模型不一定要很复杂，一些简单模型的组合往往也能取得很好地效果；（2）之间将标签用于模型中，在直推式节点分类中有很好地效果（这也是作者认为该模型的收益来源）。","text":"https://arxiv.org/pdf/2010.13993v2.pdf https://github.com/CUAI/CorrectAndSmooth COMBINING LABEL PROPAGATION AND SIMPLE MODELS OUT-PERFORMS GRAPH NEURAL NETWORKS，ICLR，2021 总结：GNN作为图学习方面的主要技术，但是其模型越来越复杂，模型收益的可解释性很差。作者发现通过结合几个简单的方法（C&amp;S后处理步骤），在多个数据集上能超过或者媲美当前最优GNN的性能。具体来说先用简单的模型比如MLP或者线性模块预测节点类型分布，然后通过两个标签传播对预测结果进行修正（Correct）和平滑（Smooth）处理。文章的发现或者带给我们的启发有一下几点：（1）图学习模型不一定要很复杂，一些简单模型的组合往往也能取得很好地效果；（2）之间将标签用于模型中，在直推式节点分类中有很好地效果（这也是作者认为该模型的收益来源）。 1. 简介 1.1 摘要 Graph Neural Networks (GNNs) are the predominant technique for learning over graphs. However, there is relatively little understanding of why GNNs are successful in practice and whether they are necessary for good performance. Here, we show that for many standard transductive node classification benchmarks, we can exceed or match the performance of state-of-the-art GNNs by combining shallow models that ignore the graph structure with two simple post-processing steps that exploit correlation in the label structure: (i) an “error correlation” that spreads residual errors in training data to correct errors in test data and (ii) a “prediction correlation” that smooths the predictions on the test data. We call this overall procedure Correct and Smooth (C&amp;S), and the post-processing steps are implemented via simple modifications to standard label propagation techniques fromearly graph-based semi-supervised learning methods. Our approach exceeds or nearly matches the performance of state-of-the-art GNNs on a wide variety of benchmarks, with just a small fraction of the parameters and orders of magnitude faster runtime. For instance, we exceed the best known GNN performance on the OGB-Products dataset with 137 times fewer parameters and greater than 100 timesless training time. The performance of our methods highlights how directly incorporating label information into the learning algorithm (as was done in traditionaltechniques) yields easy and substantial performance gains. We can also incorporate our techniques into big GNN models, providing modest gains. Our code forthe OGB results is at https://github.com/CUAI/CorrectAndSmooth. GNNs虽然是图学习上非常主流的方法，但是相比较其他方法，我们不知道GNN为什么在实际应用中能取得成功，以及它对于好的实验结果是否是必要的。本文，作者发现对于许多标准的transductive节点分类benchmarks，通过组合忽略图结构的浅层模型，利用两个简单关联的两个简单post-processing步骤：（1）“error correlation”，在训练数据中传递residual errors来修正测试数据中的错误；（2）“prediction correlation，平滑测试数据中的预测结果。作者称这个过程为Correct and Smooth（C&amp;S）。其中两个post-processing技术是通过对早期基于图的半监督学习方法地标签传播技术进行简单修改得到的。在许多标准数据集上，该方法的性能能够超过或者达到当前最优GNNs方法，并且参数量更少，训练时间更短。例如，在OGB-Products数据集上，我们的方法优于当前最好的GNN方法，并且参数量减少137倍，训练时间减少100倍。该方法的性能凸显了如何直接将标签信息整合到学习算法种产生简单而显著的性能增益。 我们还可以将我们的技术整合到大型GNN模型中，获得适度的收益 。 1.2 本文工作 动机： GNN的发展通常都是围绕“构建一个比基本变体（比如GCN，GraphSAGE）更具表征能力的架构”，比如GAT，GIN。许多新的GNN架构的思想都来源于语言或者视觉模型中，比如注意力和深层CNNs等等。但是随着这些模型越来越复杂，越来越难以理解他们为什么能获得性能的提升，并且难以将其拓展到大规模数据集上。 问题定义： 无向图G=(V,E)G=(V,E)G=(V,E)，其中n=∣V∣n=|V|n=∣V∣，X∈Rn×pX\\in\\mathbb R^{n\\times p}X∈Rn×p为特征矩阵，A为邻接矩阵，D为度矩阵，S表示正则化后的邻接矩阵D−1/2AD−1/2D^{-1/2}AD^{-1/2}D−1/2AD−1/2。对于预测问题，节点集合V划分成有标签节点集合L和无标签节点集合U。Y∈Rn×cY\\in\\mathbb R^{n\\times c}Y∈Rn×c表示one-hot标签向量，c为类型数量。将有标签节点进一步划分成训练集LtL_tLt​和验证集LvL_vLv​。transductive分类问题定义为：给定G，X，Y，预测节点j∈Uj\\in Uj∈U的类别。 本文工作： 作者提出了一个包含三部分的pipeline，（1）base prediction，用一个简单模型（比如MLP或者线性模型）忽略图结构，基于节点特征进行节点类型预测；（2）correction step，在图中传播uncertainties来修正base prediction；（3）对预测进行smooth操作。其中（2）（3）是post-processing步骤，不参与训练。 目标： 研究如何用更简单的方法来改善图学习中的预测性能，并更好地理解模型性能提高的原因。 “ However, our goal is not to say thatcurrent graph learning methods are poor or inappropriate. Instead, we aim to highlight easier waysin which to improve prediction performance in graph learning and to better understand the source of performance gains. Our main finding is that more direct incorporation of labels into the learning algorithms is key. ” 2. 方法 2.1 Simple Base Predictor 采用不依赖图结构的简单预测器预测节点类型。 具体来说，训练模型f，最小化∑i∈Ltl(f(xi),yi)\\sum_{i\\in L_t}l(f(x_i),y_i)∑i∈Lt​​l(f(xi​),yi​)，其中xix_ixi​表示X的第i行，yiy_iyi​表示Y的第i行，l表示损失函数。本文中f表示MLP或者一个线性模块，l表示交叉熵损失。 通过f，可以得到预测结果Z∈Rn×cZ\\in\\mathbb R^{n\\times c}Z∈Rn×c（经softmax得到的概率分布）。 注：这里的基预测器也可以选择基于GNN的方法。 2.2 Correcting for Error 通过整合labels来修正错误，提高base prediction Z的准确度。 基本思想： 我们期望base prediction中的errors和图中的边是正相关的，也就是说节点i中的error会增加其邻居节点出现相似error的概率。 作者受residual propagation的启发，定义一个error matrix E∈Rn×cE\\in\\mathbb R^{n\\times c}E∈Rn×c： ELt=ZLt−YLt,ELv=0,EU=0(1)E_{L_{t}}=Z_{L_{t}}-Y_{L_{t}}, \\quad E_{L_{v}}=0, \\quad E_{U}=0\\tag 1 ELt​​=ZLt​​−YLt​​,ELv​​=0,EU​=0(1) 采用标签传播技术来smooth error，优化目标如下： E^=arg⁡min⁡W∈Rn×ctrace⁡(WT(I−S)W)+μ∥W−E∥F2(2)\\hat{E}=\\underset{W \\in \\mathbb{R}^{n \\times c}}{\\arg \\min } \\operatorname{trace}\\left(W^{T}(I-S) W\\right)+\\mu\\|W-E\\|_{F}^{2}\\tag 2 E^=W∈Rn×cargmin​trace(WT(I−S)W)+μ∥W−E∥F2​(2) 上述优化目标可以通过不断迭代E(t+1)=(1−α)E+αSE(t)E^{(t+1)}=(1-\\alpha) E+\\alpha S E^{(t)}E(t+1)=(1−α)E+αSE(t)得到，其中α=1/(1+μ)\\alpha=1/(1+\\mu)α=1/(1+μ)，E(0)=EE^{(0)}=EE(0)=E。 考虑对于分类问题，smoothed error E^\\hat EE^范围可能不对： ∥E(t+1)∥2≤(1−α)∥E∥+α∥S∥2∥E(t)∥2=(1−α)∥E∥2+α∥E(t)∥2(3)\\left\\|E^{(t+1)}\\right\\|_{2} \\leq(1-\\alpha)\\|E\\|+\\alpha\\|S\\|_{2}\\left\\|E^{(t)}\\right\\|_{2}=(1-\\alpha)\\|E\\|_{2}+\\alpha\\left\\|E^{(t)}\\right\\|_{2}\\tag 3 ∥∥∥∥​E(t+1)∥∥∥∥​2​≤(1−α)∥E∥+α∥S∥2​∥∥∥∥​E(t)∥∥∥∥​2​=(1−α)∥E∥2​+α∥∥∥∥​E(t)∥∥∥∥​2​(3) 当E(0)=EE^{(0)}=EE(0)=E时，有∣∣E(t)∣∣2≤∣∣E∣∣2||E^{(t)}||_2\\leq||E||_2∣∣E(t)∣∣2​≤∣∣E∣∣2​，因此这种标签传播不能完全修正图中所有节点的error。为了解决这个问题，作者提出了两种scaling误差的变体： （1）Autoscale “Intuitively, we want to scale the size of errors in E^\\hat EE^ to be approximately the size of theerrors in E. ” 因为只知道训练集有标签节点的error，所以作者用这部分节点的error来近似获取scale值： （2）FDiff-scale 参考2003年一篇文章中的做法，固定训练集节点中的error。具体来说，迭代EU(t+1)=[D−1AE(t)]UE_U^{(t+1)}=[D^{-1}AE^{(t)}]_UEU(t+1)​=[D−1AE(t)]U​，同时保持EL(t)=ELE_L^{(t)}=E_LEL(t)​=EL​直到收敛得到E^\\hat EE^。 作者发现这种方式下也可以找到一个有效的超参s，得到Z(r)=Z+sE^Z^{(r)}=Z+s\\hat EZ(r)=Z+sE^。 σ=1∣Lt∣∑j∈Lt∥ej∥1\\sigma=\\frac{1}{\\left|L_{t}\\right|} \\sum_{j \\in L_{t}}\\left\\|e_{j}\\right\\|_{1} σ=∣Lt​∣1​j∈Lt​∑​∥ej​∥1​ Zi,:(r)=Zi,:+σE^:,i/∥E^:,iT∥1 for i∈UZ_{i,:}^{(r)}=Z_{i,:}+\\sigma \\hat{E}_{:, i} /\\left\\|\\hat{E}_{:, i}^{T}\\right\\|_{1} \\text { for } i \\in U Zi,:(r)​=Zi,:​+σE^:,i​/∥∥∥∥​E^:,iT​∥∥∥∥​1​ for i∈U 2.3 Smoothing Final Prediction 经过前面两步，可以得到修正后的预测结果Z(r)Z^{(r)}Z(r)。为了得到最终的预测结果，需要对corrected prediction进行smooth操作。 动机： 相邻节点之间很可能拥有相似的label（同构图中）。 作者这里采用另一个标签传播对标签分布进行平滑处理。首先从最优标签猜测开始，即： GLt=YLt,GLv,U=ZLv,U(r)G_{L_{t}}=Y_{L_{t}}, \\quad G_{L_{v}, U}=Z_{L_{v}, U}^{(r)} GLt​​=YLt​​,GLv​,U​=ZLv​,U(r)​ 然后重复执行G(t+1)=(1−α)G+αSG(t)G^{(t+1)}=(1-\\alpha) G+\\alpha S G^{(t)}G(t+1)=(1−α)G+αSG(t) with G(0)=GG^{(0)}=GG(0)=G直到收敛，得到最终预测Y^\\hat YY^。 2.4 Summary 采用图结构不相干的简单模型获取初始预测结果Z 利用error propagation修正基础预测得到Z(r)=Z+E^Z^{(r)}=Z+\\hat EZ(r)=Z+E^ 通过另一个LP对Z(r)Z^{(r)}Z(r)进行平滑处理得到最终预测 3. 实验 3.1 实验设置 数据集： 下表9个数据集 数据划分： training/validation/test比例不同数据集分别设置为40%/10%/50%和60%/20%/20%。 base predictors： 使用Linear和MLP作为基预测器（输入为节点特征和spectral embedding）。 对比方法： GCN，SGC，APPNP。Plain Linear（只使用raw features）和Label Propagation（只使用label）。 SOTA方法： Arxiv和Product数据集采用UniMp作为SOTA；Cora、Pubmed和Citeseer数据集采用GCNII作为SOTA；Rice31数据集采用GCN with spectral and node2vec embeddings作为SOTA；WikiCS选用APPNP作为SOTA。 3.2 实验结果 一、训练过程不使用验证集中的标签 作者提出的C&amp;S能显著提高模型性能； 带有C&amp;S的plain linear在很多情况下的性能都由于plain GCNs，LP也能取得和GCNs差不多的效果 注：这说明在图中直接结合correlation和简单实用特征通常是一个更好的想法 作者提出的模型的变体在多个数据集上由于SOTA方法 二、训练过程使用验证集中的标签 在C&amp;S过程中使用验证集标签，实验结果得到了进一步的提升。 在很多直推式节点分类任务中，想取得好的表现，GNN（代价比较大）不是必须的。 将传统的标签传播技术和简单的预测器组合到一起在这些任务上的表现优于GNN模型。 三、训练代价 下图展示了不同精度下模型的参数量： 四、可视化","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"标签传播","slug":"标签传播","permalink":"http://rookieyin.github.io/tags/%E6%A0%87%E7%AD%BE%E4%BC%A0%E6%92%AD/"}]},{"title":"Inductive Representation Learning on Large Graphs","slug":"3 论文笔记/图学习/5.Inductive Representation Learning on Large Graphs","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.797Z","comments":true,"path":"d813e783423d/","link":"","permalink":"http://rookieyin.github.io/d813e783423d/","excerpt":"https://arxiv.org/pdf/1706.02216 https://github.com/williamleif/GraphSAGE Inductive Representation Learning on Large Graphs，2017，NIPS 总结：现有的图表示学习方法都是transductive的，即测试用的节点在训练时是seen的。本文作者提出了一种inductive图表示学习方法GraphSAGE。inductive的具体实现方法就是学习一个聚合器，每一层采样固定大小的邻居，然后聚合这些邻居的信息用于生成当前层目标节点的嵌入向量，而不是为每一个节点学习一个嵌入向量。","text":"https://arxiv.org/pdf/1706.02216 https://github.com/williamleif/GraphSAGE Inductive Representation Learning on Large Graphs，2017，NIPS 总结：现有的图表示学习方法都是transductive的，即测试用的节点在训练时是seen的。本文作者提出了一种inductive图表示学习方法GraphSAGE。inductive的具体实现方法就是学习一个聚合器，每一层采样固定大小的邻居，然后聚合这些邻居的信息用于生成当前层目标节点的嵌入向量，而不是为每一个节点学习一个嵌入向量。 1. 简介 1.1 摘要 Low-dimensional embeddings of nodes in large graphs have proved extremelyuseful in a variety of prediction tasks, from content recommendation to identifyingprotein functions. However, most existing approaches require that all nodes in thegraph are present during training of the embeddings; these previous approaches areinherentlytransductiveand do not naturally generalize to unseen nodes. Here wepresent GraphSAGE, a generalinductiveframework that leverages node featureinformation (e.g., text attributes) to efficiently generate node embeddings forpreviously unseen data. Instead of training individual embeddings for each node,we learn a function that generates embeddings by sampling and aggregating featuresfrom a node’s local neighborhood. Our algorithm outperforms strong baselineson three inductive node-classification benchmarks: we classify the category ofunseen nodes in evolving information graphs based on citation and Reddit postdata, and we show that our algorithm generalizes to completely unseen graphsusing a multi-graph dataset of protein-protein interactions. 大规模图中节点的低维嵌入在各种预测任务中是非常有用的，比如内容推荐或者蛋白质功能确认。但是，现有的大多数方法都是transductive的，即训练的时候所有节点都要是可见的，不能将模型泛化到unseen节点。本文作者提出了GraphSAGE模型——一种通用的indective框架，通过利用节点特征信息，为unseen节点生成有效的embeddings。GraphSAGE不是为每个节点训练单独的嵌入，而是学习一个函数，通过从节点的局部领域采样和聚合特征俩生成嵌入的。我们的算法在三个inductive节点分类标准数据集上的性能都优于baseline方法。 1.2 本文工作 现有的大多数图嵌入算法都是matrix-factorization-based来优化节点嵌入，这些方法都是transductive的，无法直接用于unseen节点。虽然可以将这些方法调整成inductive，但是计算代价过大，每次做新预测前都要重新优化模型。 目前为止，GCNs仅仅被用于固定图下的transductive learning。本文作者将GCNs拓展到inductive无监督学习任务中，提出了一种通用的图嵌入框架GraphSAGE。 和那些利用矩阵分解的图嵌入方法不同，作者利用节点特征（比如文本属性，节点度等等）来学习可以generalize到unseen节点的嵌入函数。 具体来说，模型不是为每个节点训练一个单独的嵌入向量，而是训练一系列aggregator functions，通过聚合节点局部领域的特征信息，为每个节点生成嵌入向量，如下图所示： 2. 方法 整个框架最核心的问题就是：如何从节点的局部邻域聚合特征信息？即聚合函数如何定义。 2.1 嵌入生成算法 假设模型参数已经训练好了，本部分主要介绍框架的前向传播算法。 具体来说，假设模型学习到了K个aggregator函数，用AGGREGATEk,∀k∈{1,...,K}AGGREGATE_k,\\forall k\\in\\{1,...,K\\}AGGREGATEk​,∀k∈{1,...,K}表示。每个聚合函数都有权重参数Wk,∀k∈{1,...,K}W^k,\\forall k\\in\\{1,...,K\\}Wk,∀k∈{1,...,K}。K表示模型层数，即搜索深度。前向传播算法伪代码如下： 算法外层K个循环，表示模型有K层，即节点聚合了K阶邻域的信息。需要注意的时k=0时，hv0h^0_vhv0​表示节点的输入特征xvx_vxv​。 一、算法1拓展到minibatch setting 为了使用stochastic gradient descent优化模型，算法需要支持minibatches的前向传播和反向传播。下图展示了minibatch下的前项传播算法： 大概的思想是先为所有节点采样好每一层k中需要用的的邻居节点，然后再执行前向传播算法。算法2的2~7行即采样部分：BkB^kBk集合中存储着该batch下的所有输入节点（即需要计算embedding的节点），Bk−1B^{k-1}Bk−1存储着BkB^kBk集合中所有节点及这些节点的邻居，以此类推。最后B0B^0B0中存储着原始输入节点B及这些节点K阶邻域内的所有邻居节点。 节点采样完毕后，和算法1一样，执行前向传播过程，计算节点嵌入。 二、和WLtest之间的关联 如果我们对算法1作几点调整：（1）set K=∣V∣K=|V|K=∣V∣；（2）set 权重矩阵为identity；（3）使用一个合适的哈希函数作为aggregator，这样算法一就等价于WL同构测试。此时，如果用算法1计算两个图的节点嵌入完全一样，那么WL test会输出两个图为同构图。 因此，算法1可以看做是对WL test的一种近似，即用神经网络替代WL test中的哈希函数。不过GraphSAGE使用来计算节点嵌入的，而不是用来判断图是否同构。不过GraphSAGE和WL test之间的关联从理论上佐证了GraphSAGE可以学习节点邻域的拓扑结构信息。 三、邻域的定义 算法1中如果聚合节点所有邻居的信息，计算代价过大，因此需要重新定义节点的邻域。作者定义N(v)\\mathcal N(v)N(v)为固定大小集合，从{u∈V:(u,v)∈E}\\{u\\in \\mathcal V:(u,v)\\in\\mathcal E\\}{u∈V:(u,v)∈E}中采样得到。如果不固定N(v)\\mathcal N(v)N(v)大小，那么每个batch的复杂度是不可预测的，最糟糕的情况可能达到O(∣V∣)O(|\\mathcal V|)O(∣V∣)。 2.2 参数的优化 作者使用一个graph-based损失函数，来优化权重矩阵Wk,∀k∈{1,...,K}\\mathbf W^k,\\forall k\\in\\{1,...,K\\}Wk,∀k∈{1,...,K}和聚合器参数： JG(zu)=−log⁡(σ(zu⊤zv))−Q⋅Evn∼Pn(v)log⁡(σ(−zu⊤zvn))(1)J_{\\mathcal{G}}\\left(\\mathbf{z}_{u}\\right)=-\\log \\left(\\sigma\\left(\\mathbf{z}_{u}^{\\top} \\mathbf{z}_{v}\\right)\\right)-Q \\cdot \\mathbb{E}_{v_{n} \\sim P_{n}(v)} \\log \\left(\\sigma\\left(-\\mathbf{z}_{u}^{\\top} \\mathbf{z}_{v_{n}}\\right)\\right)\\tag 1 JG​(zu​)=−log(σ(zu⊤​zv​))−Q⋅Evn​∼Pn​(v)​log(σ(−zu⊤​zvn​​))(1) 该损失函数鼓励距离近的节点有相似的节点嵌入，而不同节点的嵌入高度不同。其中vvv表示在固定长度随机游走中和u共现的节点，σ\\sigmaσ表示sigmoid函数，Pn(v)P_n(v)Pn​(v)表示负采样分布，Q表示负样本数量。该公式为无监督场景下的损失函数，在下游具体任务中可以替换成其他损失函数，比如交叉熵损失。 2.3 聚合器的选取 和N-D格子数据（比如图像、句子）不同，一个节点的邻居是无序的，因此聚合器的输入是一个无序的向量集合。理想情况下，aggregator函数应该是对称的（即具有置换不变性，和输入顺序无关），同时还要是trainable并且能够比较高的表征能力。作者测试了三种候选aggregator函数： Mean aggregator 直接计算邻居向量的平均值，这样算法1的4、5行可以替换为： hvk←σ(W⋅MEAN⁡({hvk−1}∪{huk−1,∀u∈N(v)})(2)\\mathbf{h}_{v}^{k} \\leftarrow \\sigma\\left(\\mathbf{W} \\cdot \\operatorname{MEAN}\\left(\\left\\{\\mathbf{h}_{v}^{k-1}\\right\\} \\cup\\left\\{\\mathbf{h}_{u}^{k-1}, \\forall u \\in \\mathcal{N}(v)\\right\\}\\right)\\right.\\tag 2 hvk​←σ(W⋅MEAN({hvk−1​}∪{huk−1​,∀u∈N(v)})(2) LSTM aggregator 采用LSTM聚合邻居信息，和Mean aggregator相比计算开销更大。但是LSTM不是symmetric，对输入顺序敏感，作者通过简单地将LSTM应用于节点邻居的随机排列，使LSTM能够操作一个无序集合。 Pooling aggregator 将节点所有邻居分别输入到一个全连接神经网络中，然后在用一个elementwise最大池化操作聚合邻居信息： AGGREGATE kpool =max⁡({σ(Wpool huik+b),∀ui∈N(v)}),(3)\\text { AGGREGATE }_{k}^{\\text {pool }}=\\max \\left(\\left\\{\\sigma\\left(\\mathbf{W}_{\\text {pool }} \\mathbf{h}_{u_{i}}^{k}+\\mathbf{b}\\right), \\forall u_{i} \\in \\mathcal{N}(v)\\right\\}\\right),\\tag 3 AGGREGATE kpool ​=max({σ(Wpool ​hui​k​+b),∀ui​∈N(v)}),(3) 需要注意的时max池化可以替换成任何symmetric vector函数，作者用mean池化代替max池化，模型性能并没有改变，因此作者下文所有实验都采用最大池化。 3. 实验 **数据集：**Citation，Reddit，PPI。所有实验都是在训练师unseen节点或者graph上进行的。 **baseline：**采用随机分类器、逻辑回归、DeepWalk、DeepWalk+features四个； GraphSAGE变体：（1）GraphSAGE-GCN，将GraphSAGE用于GCN中；（2）分别使用上述三种聚合器。 3.1 实验结果 3.2 时间复杂度及参数敏感性","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GCN","slug":"GCN","permalink":"http://rookieyin.github.io/tags/GCN/"}]},{"title":"Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification","slug":"3 论文笔记/小样本图学习/11.Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.827Z","comments":true,"path":"37ae227372b3/","link":"","permalink":"http://rookieyin.github.io/37ae227372b3/","excerpt":"https://arxiv.org/pdf/2003.08246 Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification，CIKM，2020","text":"https://arxiv.org/pdf/2003.08246 Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification，CIKM，2020 1. 简介 1.1 摘要 Graph classification aims to extract accurate information fromgraph-structured data for classification and is becoming more andmore important in graph learning community. Although GraphNeural Networks (GNNs) have been successfully applied to graph classification tasks, most of them overlook the scarcity of labeledgraph data in many applications. For example, in bioinformatics, obtaining protein graph labels usually needs laborious experiments. Recently, few-shot learning has been explored to alleviate this prob-lem with only a few labeled graph samples of test classes. The shared sub-structures between training classes and test classes are essential in few-shot graph classification. Existing methods assume that the test classes belong to the same set of super-classes clus-tered from training classes. However, according to our observations, the label spaces of training classes and test classes usually do not overlap in real-world scenario. As a result, the existing methods don’t well capture the local structures of unseen test classes. To overcome the limitation, in this paper, we propose a direct method to capture the sub-structures with well initialized meta-learner within a few adaptation steps. More specifically, (1) we propose a novel framework consisting of a graph meta-learner, which uses GNNs based modules for fast adaptation on graph data, and a step controller for the robustness and generalization of meta-learner; (2) we provide quantitative analysis for the framework and give a graph-dependent upper bound of the generalization error based on our framework; (3) the extensive experiments on real-world datasets demonstrate that our framework gets state-of-the-art results on several few-shot graph classification tasks compared to baselines. 图分类旨在从图结构数据中提取准确信息用于分类，在图学习领域越来越重要了。尽管GNNs已经成功应用于图分类任务中，但是大多数方法都忽略了许多场景下存在有标签数据稀疏问题。例如，在生物信息领域，获取蛋白质图的标签通常需要进行实际实验，难以获取大量有标签数据。最近提出的小样本学习正是用来解决这一问题的，只需要少量有标签样本就能取得不错的效果。现有的方法都是假设用于测试的类别和用于训练的类别都属于同一个超类（什么意思？）但是根据我们的观察，真实场景下，训练类别的标签空间和测试类别的标签空间通常是不重叠的。因此，现有的方法不能很好地捕捉到不可见的测试类别的局部结构。为了解决这个问题，本文作者提出了一个新的方法，利用已经初始化过的meta-learner只需要优化很少次就能捕捉到sub-structures。具体来说：（1）作者提出了一个架构，包含一个graph meta-learner（用于图数据场景下的快速适应）以及一个step controller（用于保证meta-learner的稳定性和通用性）；（2）作者对提出的架构进行了分析，给出了一个通用的错误上界；（3）真实数据集上的大量实验表明作者提出的架构在一些小样本图分类任务下性能优于baseline方法。 1.2 本文工作 虽然很多GNNs方法已经成功应用于图分类任务，但是这些方法都忽略了有标签图数据获取代价很高这一现实问题。如何只通过少量有标签样本完成图分类任务十分具有挑战。目前只有Chauhan等人正对小样本下的图分类任务，基于graph spectral measures提出了一种模型并且取得了不错的效果。从数据集的全局结构来看，Chauhan通过假设测试类别所属的超类属于从训练类别聚类得到的超类，来关联测试类别和训练类别。这种基于图谱度量的方法存在一些弊端：（1）在小样本设定下，训练类别和测试类别的标签空间通常不重合；（2）这种关联方式会削弱模型捕捉测试数据局部结构信息的能力。 从图的局部结构来看，作者发现训练类别和测试类别具有相似的子结构。例如，不同的社交网络通常有一些相似的群组；不同的蛋白质分子通常有相似的刺突蛋白。作者发现通过一个well initialized的meta-learner，经过少数次调整后就能捕捉到这种相似性。下图展示了Chauhan的模型和作者提出的模型： 现有GNNs通过卷积和池化操作捕捉局部结构的能力已经很强了，但是当处理从来没有见过的graph类别时无法快速适应。受MAML的启发，作者利用GNNs作为图嵌入骨架、元学习作为训练策略，在图分类任务中快速捕捉task-specific知识并将捕捉到的知识传递到新的任务中。但是直接使用MAML来实现快速适应是sub-optimal的： 和图片不同，图的节点数和子结构是任意的，会给自适应带来不确定性 MAML需要复杂的超参搜索，提高模型稳定性和泛化能力 已经有一些MAML的变体来解决上述问题，但是它们都不是针对图结构数据的。本文作者提出了一种adaptive step controller，来学习一个自适应的opimal step，提高模型稳定性和泛化能力。controller根据两个输入来决定什么时候终止adaptation： 图嵌入的质量，即元特征，反映了平均节点信息 meta-learner的训练状态，反映了训练分类损失 作者提出的模型命名为AS-MAML，即Adaptive Step MAML，是首个从图局部结构考虑小样本图分类问题的模型，并通过元学习实现图上的快速适应。 2. 方法 2.1 问题定义 定义N-way-K-shot图分类问题。 给定图数据G={(G1,y1),(G2,y2),⋯ ,(Gn,yn)}\\mathcal G=\\left\\{\\left(G_{1}, \\mathbf{y}_{1}\\right),\\left(G_{2}, \\mathbf{y}_{2}\\right), \\cdots,\\left(G_{n}, \\mathbf{y}_{n}\\right)\\right\\}G={(G1​,y1​),(G2​,y2​),⋯,(Gn​,yn​)}，其中Gi=(Vi,Ei,Xi)G_{i}=\\left(\\mathcal{V}_{i}, \\mathcal{E}_{i}, \\mathbf{X}_{i}\\right)Gi​=(Vi​,Ei​,Xi​)，用ni=∣Vi∣n_i=|\\mathcal V_i|ni​=∣Vi​∣表示节点数量，故Ai∈Rni×ni\\mathbf{A}_{i} \\in \\mathbb{R}^{n_{i} \\times n_{i}}Ai​∈Rni​×ni​，Xi∈Rni×d\\mathbf{X}_{i} \\in \\mathbb{R}^{n_{i} \\times d}Xi​∈Rni​×d，d表示节点属性的维度。 根据图标签y\\mathbb yy，将G\\mathcal GG分成{(Gtrain ,ytrain )}\\left\\{\\left(G^{\\text {train }}, \\mathbf{y}^{\\text {train }}\\right)\\right\\}{(Gtrain ,ytrain )} and {(Gtest ,ytest )}\\left\\{\\left(\\mathcal{G}^{\\text {test }}, \\mathbf{y}^{\\text {test }}\\right)\\right\\}{(Gtest ,ytest )}分别表示训练集和测试集，ytrain\\mathbb y^{train}ytrain和ytest\\mathbb y^{test}ytest不重合。 采用episodic方法训练模型，在训练阶段每次采样一个任务T\\mathcal TT，每个任务包含支持集Dsuptrain={(Gitrain,yitrain)}i=1sD_{s u p}^{t r a i n}=\\left\\{\\left(G_{i}^{t r a i n}, \\mathbf{y}_{i}^{t r a i n}\\right)\\right\\}_{i=1}^{s}Dsuptrain​={(Gitrain​,yitrain​)}i=1s​和查询集Dquetrain ={(Gitrain ,yitrain )}i=1qD_{q u e}^{\\text {train }}=\\left\\{\\left(G_{i}^{\\text {train }}, \\mathbf{y}_{i}^{\\text {train }}\\right)\\right\\}_{i=1}^{q}Dquetrain ​={(Gitrain ​,yitrain ​)}i=1q​，其中s和q分别表示支持集和查询集大小。 **训练阶段：**给定有标签的支持集，模型目标是最小化查询集的分类损失。如果s=N×Ks=N\\times Ks=N×K即支持集包含N个类别，每个类别有K个有标签样本，我们称该任务为N-way-K-shot小样本分类任务。 **测试阶段：**使用支持集样本对模型进行微调，计算模型在查询集中的分类表现 2.2 架构 整个小样本图分类架构包含两部分： GNNs为骨架的meta-learner：采用MAML作为快速适应机制 step controller：Du等人提出一种基于RL的step controller来指导meta-learner用于链路预测，作者本文提出了一种新的step controller来加速训练，避免过拟合。 2.2.1 Graph Embedding 这部分由图卷积模块和池化模块构成嵌入骨架。采用GraphSAGE获取图中的节点嵌入： hvl=σ(W⋅mean⁡({hvl−1}∪{hul−1,∀u∈N(v)}).\\mathbf{h}_{v}^{l}=\\sigma\\Big(\\mathbf{W} \\cdot \\operatorname{mean}(\\{\\mathbf{h}_{v}^{l-1}\\} \\cup\\{\\mathbf{h}_{u}^{l-1}, \\forall u \\in \\mathcal{N}(v)\\}\\Big). hvl​=σ(W⋅mean({hvl−1​}∪{hul−1​,∀u∈N(v)}). 其中hvlh_v^lhvl​表示第l层节点v的表示，σ\\sigmaσ是sigmoid函数，W\\mathbf WW是参数，V(v)\\mathcal V(v)V(v)表示节点v的所有邻居。 对于池化操作，鉴于在小样本设定下，元学习器需要一种灵活的池化策略来加强模型的泛化能力。本文作者采用SAGPool作为池化层，因为其具有灵活的注意力参数。SAGPool的主要步骤就是计算一个注意力得分矩阵： Si=σ(D~i−12Λ~iD~i−12XiΘatt)\\mathrm{S}_{i}=\\sigma\\left(\\tilde{\\mathbf{D}}_{i}^{-\\frac{1}{2}} \\tilde{\\Lambda}_{i} \\tilde{\\mathbf{D}}_{i}^{-\\frac{1}{2}} \\mathbf{X}_{i} \\Theta_{a t t}\\right) Si​=σ(D~i−21​​Λ~i​D~i−21​​Xi​Θatt​) 其中SiS_iSi​表示自注意力得分，nin_ini​表示图中节点数量；σ\\sigmaσ表示激活函数比如tanh；A~i∈Rni×ni\\tilde A_i\\in\\mathbb R^{n_i\\times n_i}A~i​∈Rni​×ni​表示带有self-connection的邻接矩阵；D~i∈Rni×ni\\tilde D_i\\in\\mathbb R^{n_i\\times n_i}D~i​∈Rni​×ni​表示度对角矩阵；Xi∈Rni×dX_i\\in\\mathbb R^{n_i\\times d}Xi​∈Rni​×d表示维度为d的输入特征；Θatt\\Theta_{att}Θatt​表示可学习的注意力参数。基于注意力得分，选取等分排名前c的节点，保持其边不变。 为了保证得到维度固定的图嵌入，我们还需要一个Read-Out操作，为每个图生成一个固定维度的特征向量。参照Zhang等人的做法，作者通过拼接平均池化和最大池化来计算每一层图嵌入： ril=R(Hil)=σ(1nil∑p=1Hil(p,:)∥max⁡q=1dHil(:,q))\\mathbf{r}_{i}^{l}=\\mathcal{R}\\left(\\mathbf{H}_{i}^{l}\\right)=\\sigma\\left(\\frac{1}{n_{i}^{l}} \\sum_{p=1} \\mathbf{H}_{i}^{l}(p,:) \\| \\max _{q=1}^{d} \\mathbf{H}_{i}^{l}(:, q)\\right) ril​=R(Hil​)=σ(nil​1​p=1∑​Hil​(p,:)∥q=1maxd​Hil​(:,q)) 其中ril∈R2d\\mathbf{r}_{i}^{l} \\in \\mathbb{R}^{2 d}ril​∈R2d表示第l层的嵌入；niln_i^lnil​表示第l层的节点数量；HilH_i^lHil​表示第l层的节点表示矩阵；∣∣||∣∣表示拼接操作；σ\\sigmaσ是激活函数比如ReLU。得到每一层的图嵌入后，按照如下方式计算最终的图嵌入： zi=ri1+ri2+⋯+riL\\mathbf{z}_{i}=\\mathbf{r}_{i}^{1}+\\mathbf{r}_{i}^{2}+\\cdots+\\mathbf{r}_{i}^{L} zi​=ri1​+ri2​+⋯+riL​ 得到最终图嵌入后，将其放进MLP分类其中进行分类，计算交叉熵损失。 2.2.2 Fast Adaptation θe\\theta_eθe​和θc\\theta_cθc​分别表示图嵌入和MLP分类器的参数，为了使其快速适应新图，作者采用MAML中的调优方法训练模型。算法流程如下图所示： 2~17行为一个外循环，3 ~16行为一个内循环。 2.2.3 Adaptation Controller 对于MAML模型，找到learning rate和step size之间的最优组合十分困难，尤其在图数据中图的结构和大小都是任意的。本文作者设计了一个基于RL的controller来获取最优的step size。 作者利用ANI（average node information）反映节点嵌入的质量，GiG_iGi​计算方法如下： ANIil=1nil∑j=1∥[(Iil−(Dil)−1Ail)Hil]j∥1(5)A N I_{i}^{l}=\\frac{1}{n_{i}^{l}} \\sum_{j=1}\\left\\|\\left[\\left(\\mathbf{I}_{i}^{l}-\\left(\\mathbf{D}_{i}^{l}\\right)^{-1} \\mathbf{A}_{i}^{l}\\right) \\mathbf{H}_{i}^{l}\\right]_{j}\\right\\|_{1}\\tag 5 ANIil​=nil​1​j=1∑​∥∥∥∥∥​[(Iil​−(Dil​)−1Ail​)Hil​]j​∥∥∥∥∥​1​(5) 其中l表示嵌入的层数；niln_i^lnil​表示节点数；j表示行index或者是j-th节点；∥⋅∥1\\|\\cdot\\|_{1}∥⋅∥1​表示L1L_1L1​范式；AilA_i^lAil​表示邻接矩阵；DilD_i^lDil​表示度矩阵；HilH_i^lHil​表示第l层隐藏表示矩阵。作者采用一个标量值作为ANI，计算方法如下： ANI=1/n∗∑i=1nANIiL(6)A N I=1 / n * \\sum_{i=1}^{n} A N I_{i}^{L}\\tag 6 ANI=1/n∗i=1∑n​ANIiL​(6) 其中n表示batch的大小；L表示第L层的embedding。 TiT_iTi​表示初始的step大小；M∈RTi×1\\mathbf M\\in\\mathbb R^{T_i\\times 1}M∈RTi​×1表示TiT_iTi​steps内所有的ANI值。然后计算在步骤t时刻的停止概率： h(t)=LSTM⁡([L(t),M(t)],h(t−1)),p(t)=σ(Wh(t)+b)(7)\\boldsymbol{h}^{(t)}=\\operatorname{LSTM}\\left(\\left[\\mathbf{L}^{(t)}, \\mathbf{M}^{(t)}\\right], \\boldsymbol{h}^{(t-1)}\\right), p^{(t)}=\\sigma\\left(\\mathbf{W h}^{(t)}+\\mathbf{b}\\right)\\tag 7 h(t)=LSTM([L(t),M(t)],h(t−1)),p(t)=σ(Wh(t)+b)(7) σ\\sigmaσ表示sigmoid函数；h(t)h^{(t)}h(t)表示LSTM模块的输出。需要注意的是当前任务不会提前终止，知道TiT_iTi​步骤执行完毕了，即是否终止adaptation和p(t)p^{(t)}p(t)无关。利用p(t)p^{(t)}p(t)计算下一个任务的step size： Ti+1=⌊1p(Ti)⌋(8)T_{i+1}=\\left\\lfloor\\frac{1}{p^{\\left(T_{i}\\right)}}\\right\\rfloor\\tag 8 Ti+1​=⌊p(Ti​)1​⌋(8) 可以得到controller的损失如下： Q(t)=∑t=1Tr(t)=∑t=1T(eT−et−η∗t)(9)Q^{(t)}=\\sum_{t=1}^{T} r^{(t)}=\\sum_{t=1}^{T}\\left(e_{T}-e_{t}-\\eta * t\\right)\\tag 9 Q(t)=t=1∑T​r(t)=t=1∑T​(eT​−et​−η∗t)(9) T表示总的步数；ete_tet​表示步骤t时查询集上的分类准确度；η∗t\\eta * tη∗t为惩罚项。采用如下方式进行梯度更新： θs=θs+α3Q(t)▽θslnp(t)\\theta_s=\\theta_s+\\alpha_3\\mathcal Q^{(t)}\\bigtriangledown_{\\theta_s}lnp(t) θs​=θs​+α3​Q(t)▽θs​​lnp(t) 2.3 3. 实验 3.1 准备 两个目的：（1）模型在小样本图分类任务中的表现如何？（2）controller是如何工作的？ 数据集： COIL-DEL、R52、Letter-High和TRIANGLES四个公共数据集。 3.2实验结果 和Graph Kernel、Finetuning、GNNs-Pro对比 和基于GraphSAGE和SAGPool的微调方法相比，作者的模型性能更好，说明meta-learner工作良好。 在Graph-R52数据集上，基于kernel的方法性能很好，作者认为可能有两个原因： 数据集的文本图中有许多定义良好的子图，这些子图有文本主题及其邻近的次组成，这对kernel方法有利 基于kernel的方法参数远远少于GNNs，这可以有效防止过拟合。而过拟合在小样本场景下是GNNs模型常见的问题之一。 虽然kernal方法效果不错，但是很难找到一种合适的kernel。 和GSM对比 从t-SNE结果来看，作者的方法确实由于GSM方法。因为作者假设测试类别的超类属于从训练类别中聚类得到的超类集合，但这在小样本场景下是不成立的（因为训练类别和测试类别通常不重叠）。 3.3 消融实验 根据表2的实验结果可以发现作者提出的step controller在模型中有很大作用。 上图展示了在COIL-DEL数据集中，5-way-10-shot设定下的学习过程。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"图分类","slug":"图分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%88%86%E7%B1%BB/"}]},{"title":"Graph Prototypical Networks for Few-shot Learning on Attributed Networks","slug":"3 论文笔记/小样本图学习/12.Graph Prototypical Networks for Few-shot Learning on Attributed Networks","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.813Z","comments":true,"path":"eb45e1654185/","link":"","permalink":"http://rookieyin.github.io/eb45e1654185/","excerpt":"https://arxiv.org/pdf/2006.12739 https://github.com/kaize0409/GPN Graph Prototypical Networks for Few-shot Learning on Attributed Networks，CIKM，2020 总结：整个思想是原型网络+GNN，将元学习中的原型网络拓展到属性网络中。另外，对原型网络中原型计算方法针对属性网络做了改进，即计算节点对其所属类别的重要程度z作为计算类别原型时的权重。本文实验部分还比较充实，作为图学习领域为数不多的小样本学习方法，总体来说还可以。","text":"https://arxiv.org/pdf/2006.12739 https://github.com/kaize0409/GPN Graph Prototypical Networks for Few-shot Learning on Attributed Networks，CIKM，2020 总结：整个思想是原型网络+GNN，将元学习中的原型网络拓展到属性网络中。另外，对原型网络中原型计算方法针对属性网络做了改进，即计算节点对其所属类别的重要程度z作为计算类别原型时的权重。本文实验部分还比较充实，作为图学习领域为数不多的小样本学习方法，总体来说还可以。 1. 简介 1.1 摘要 Attributed networks nowadays are ubiquitous in a myriad of high-impact applications, such as social network analysis, financial frauddetection, and drug discovery. As a central analytical task on at-tributed networks, node classification has received much attentionin the research community. In real-world attributed networks, alarge portion of node classes only contains limited labeled instances,rendering a long-tail node class distribution. Existing node clas-sification algorithms are unequipped to handle thefew-shotnodeclasses. As a remedy, few-shot learning has attracted a surge ofattention in the research community. Yet, few-shot node classifi-cation remains a challenging problem as we need to address thefollowing questions: (i) How to extract meta-knowledge from anattributed network for few-shot node classification? (ii) How toidentify the informativeness of each labeled instance for building arobust and effective model? To answer these questions, in this paper,we propose a graph meta-learning framework – Graph PrototypicalNetworks (GPN). By constructing a pool of semi-supervised nodeclassification tasks to mimic the real test environment, GPN is ableto performmeta-learningon an attributed network and derive ahighly generalizable model for handling the target classificationtask. Extensive experiments demonstrate the superior capability ofGPN in few-shot node classification . 如今属性网络普遍存在于很多应用场景中，比如社交网络分析、金融欺诈检测以及药物发现等等。节点分类作为属性网络上最重要的任务之一吸引了很多人的关注。在现实世界的属性网络中呈长尾分布，即存在很多类别的节点数量很少，现有的节点分类算法很难处理这些样本数量很少的类别。最近小样本学习得到了业内很多人的关注。但是小样本节点分类仍然具有很大挑战，需要解决以下问题：（1）如何从属性网络中提取元知识用于小样本节点分类？（2）如何确定每个有标签节点蕴含的信息，来建立稳定有效的模型？为了解决这些问题，本文作者提出了一种元学习架构——Graph Prototypical Networks（GPN）。通过构建一个半监督节点分类任务池来模拟真实的测试环境，GPN可以在属性网络上进行元学习，得到一个泛化能力很好地模型来处理目标分类任务。大量实验证明了作者提出GPN模型在下样本场景下的优越性。 1.2 本文工作 1.2.1 背景 在许多真实世界的属性网络中，许多节点类别只包含少量有标签节点，呈现一种长尾分布。如下图所示，展示了DBLP数据集中每个类别包含的样本数量： 超过30%的类别拥有的有标签样本数量少于10个。另外，许多实际应用场景也需要模型能够处理这种小样本问题。一个典型的例子就是Traffic网络上的入侵检测问题，这种情况下，攻击者不断开发新的攻击和威胁。但是标记成本高，对于一些特定类型的攻击，只能获取到少量样本。因此只通过少量标记样本了解这些攻击类型，来提出有效的对策是很重要的。因此在小样本设定下研究节点分类模型是十分重要的。 1.2.2 挑战 虽然小样本学习已经取得了不错的成功，但是属性网络上的小样本学习仍然有待探索，面临着下面两个挑战： 元训练任务的构建过程依赖于这样一个假设：数据是独立同分布的，但是这个假设在属性网络中并不成立。直接将现有的FSL方法应用到属性网络中是不可行的，无法捕捉到潜在的数据结构，使得最终学习到的节点表示很差。因此如何在将元学习应用到属性网络，是从数据中提取元知识的必要条件。 现有的大多数FSL方法都假设所有有标签样本重要程度是一样的，但是在真实属性网络中，忽略有标签样本的individual信息会限制模型的性能。一方面这会使得FSL模型对噪声和异常点十分敏感，另一方面属性网络中节点的重要程度差异性可能很大（通常一个community中的中心节点可能更representative），这和传统FSL方法的假设不相符。因此如何在属性网络中捕捉到每个节点的信息是另一个挑战。 1.2.3 作者方法 针对上面两个挑战，作者提出了Graph Prototypical Networks（GPN）模型，一种用于解决属性网络上小样本节点分类问题的元学习架构。GPN尝试学习一个可迁移的度量空间，在整个空间中根据测试节点和各个类别原型之间的距离预测测试节点所属类别。GPN包含两个重要的组成部分： network encoder：通过GNNs学习网络中的节点表示 node valuator：GNN-based，利用编码在网络中的额外信息，评估每个有标签样本的informativeness，帮助GPN计算出稳定的表示能力强的类别原型 另外通过构建一个用于元学习的任务池，GPN可以从属性网络中提取出元知识，实现更好地泛化能力，可以用于目标阿小样本分类任务。 1.2.4 问题定义 文章中所有的符号含义如下表所示： 属性网络 G=(V,E,X)G=(\\mathcal V,\\mathcal E,\\mathbf X)G=(V,E,X)， V={v1,...,vn}\\mathcal V=\\{v_1,...,v_n\\}V={v1​,...,vn​}表示所有节点，E={e1,...,em}\\mathcal E=\\{e_1,...,e_m\\}E={e1​,...,em​}表示所有边，X=[x1;...;xn],xi∈R1×d\\mathbf X=[x_1;...;x_n],x_i\\in\\mathbb R^{1\\times d}X=[x1​;...;xn​],xi​∈R1×d表示节点属性特征向量。更通用的一种表示为G=(A,X)G=(A,X)G=(A,X)，其中A={0,1}n×nA=\\{0,1\\}^{n\\times n}A={0,1}n×n为邻接矩阵，Ai,j=0A_{i,j}=0Ai,j​=0表示viv_ivi​和vjv_jvj​之间没有边，Ai,j=1A_{i,j}=1Ai,j​=1表示viv_ivi​和vjv_jvj​之间有边。问题定义为： 给定一个属性网络G={A,X}\\mathcal G=\\{A,X\\}G={A,X}，假设对于类别集合CtrainC_{train}Ctrain​，每个类别都有充足的有标签节点。模型经过CtrainC_{train}Ctrain​中的数据训练后，希望模型能够准确预测disjoint类别集合CtestC_{test}Ctest​中节点的类别。需要注意的时每个类别只有少量有标签节点可利用。 按照通用的FSL设定，如果CtestC_{test}Ctest​中包含N个类别，支持集SSS包含K个有标签节点，该问题称之为N-way-K-shot节点分类问题。整个模型的目标是学习一个元分类器，能够适用于新任务（还有少量有标签节点的新类任务）。 因此如何从CtrainC_{train}Ctrain​中提取可迁移的元知识是解决这个问题的关键。 2. 模型 GPN模型主要为了解决下面三个问题而设计的： 如何将元学习应用到属性网络（不满足i.i.d）中，提取元知识？ 如何同时考虑节点属性和网络拓扑结构学习expressive的节点表示？ 如何区分每个有标签节点的informativeness，即重要程度，学习稳定、具有判别力的类别原型？ 整个模型的架构如下图所示： 2.1 Episodic训练 GPN在很多meta-training任务之间不断迭代训练。在每个episode，构建一个N-way-K-shot元训练任务： St={(v1,y1),(v2,y2),...,(vN×K,yN×K)},Qt={(v1∗,y1∗),(v2∗,y2∗),...,(vN×K∗,yN×K∗)},Tt={St,Qt}(1)\\begin{aligned} S_t&amp;=\\{(v_1,y_1),(v_2,y_2),...,(v_{N\\times K},y_{N\\times K})\\},\\\\ Q_t&amp;=\\{(v_1^*,y_1^*),(v_2^*,y_2^*),...,(v^*_{N\\times K},y^*_{N\\times K})\\},\\\\ \\mathcal T_t&amp;=\\{S_t,Q_t\\} \\end{aligned}\\tag 1 St​Qt​Tt​​={(v1​,y1​),(v2​,y2​),...,(vN×K​,yN×K​)},={(v1∗​,y1∗​),(v2∗​,y2∗​),...,(vN×K∗​,yN×K∗​)},={St​,Qt​}​(1) 其中StS_tSt​和QtQ_tQt​采样自CtrainC_{train}Ctrain​，分别是元训练任务Tt\\mathcal T_tTt​的支持集和查询集。支持集StS_tSt​中每个类别有K个有标签节点，查询集QtQ_tQt​包含M个查询节点。整个训练过程都是在任务集合Ttrain={Tt}t=1T\\mathcal T_{train}=\\{\\mathcal T_t\\}_{t=1}^TTtrain​={Tt​}t=1T​，训练目标是最小化每个任务中查询集上的分类误差。模型不断在这些元任务上进行训练，可以逐渐学到元知识，将模型推广到元测试任务Ttest={S,Q}\\mathcal T_{test}=\\{S,Q\\}Ttest​={S,Q}（样本采样自不可见类别CtestC_{test}Ctest​）。 和传统的episodic训练不同，作者采用的半监督训练方式：在每个episode，作者采样N-way K-shot个节点作为有标签节点，mask其余节点作为unlabeld节点。通过这种方式构建半监督节点分类任务，模型可以学到更具有表征能力的节点表示用于小样本节点分类。 2.2 网络表示学习 一、节点表示 利用GNNs学习节点表示，具体来说通过堆叠多个GNN层学习节点表示： H1=GNN1(A,X)...Z=GNNL(A,HL−1)(3)\\begin{aligned} &amp;H^1=GNN^1(A,X)\\\\ &amp;...\\\\ &amp;Z=GNN^L(A,H^{L-1}) \\end{aligned}\\tag 3 ​H1=GNN1(A,X)...Z=GNNL(A,HL−1)​(3) 作者用fθ(⋅)f_\\theta(·)fθ​(⋅)表示所有L个GNN层。 二、类别原型 学习到节点表示后，需要为每个类别计算原型向量，即表示这个类别整体特征的向量： pc=PROTO({zi∣∀i∈Sc})(4)p_c=PROTO\\Big(\\{z_i|\\forall i\\in S_c\\}\\Big)\\tag 4 pc​=PROTO({zi​∣∀i∈Sc​})(4) 其中ScS_cSc​表示类别c中所有有标签节点，PROTOPROTOPROTO表示原型计算函数。一种简单有效的方式就是计算该类别下所有节点表示的平均值作为该类别的原型： pc=1∣Sc∣∑i∈Sczi(5)p_c=\\frac{1}{|S_c|}\\sum_{i\\in S_c}z_i\\tag 5 pc​=∣Sc​∣1​i∈Sc​∑​zi​(5) 2.3 节点重要性评估 尽管在计算类别原型的时候采用平均值方法也可以取得不错的效果，但是否认的是该类别下不同节点的重要程度是不同的。另外按照平均值方法计算类别原型会导致算法很不稳定，对噪声数据很敏感。因此作者优化了类别原型计算方法，提高模型的性能和稳定性。 作者参考 Estimating nodeimportance in knowledge graphs using graph neural networks 这篇文章的做法，从节点邻居的重要性来评估节点的重要程度。作者设计了如下图所示的节点评估器gϕ(⋅)g_\\phi(·)gϕ​(⋅)： 首先通过Scoring Layer计算每个节点初始重要程度得分： $$ s_i^0=tanh(w_s^Tx_i+b_s)\\tag 8 $$ 其中$w_s\\in\\mathbb R^d$是可学习的权重向量，$b_s\\in\\mathbb R^1$是偏置。然后通过Score Aggregation Layer对邻居节点重要程度得分进行聚合，聚合结果作为节点$v_i$的最终得分。计算公式如下： $$ s_i^l=\\sum_{j\\in\\mathcal N_i\\cup v_i}\\alpha_{ij}^ls_j^{l-1}\\tag 6 $$ 其中$s_i^l$表示节点$v_i$在l层$l=(1,...,L)$的重要程度得分。$\\alpha_{ij}^l$表示聚合时$v_i$和$v_j$之间的注意力权重，计算方法如下： $$ \\alpha_{ij}^l=\\frac{exp(LeakyReLU(a^T[s_i^{l-1}||s_j^{l-1}]))}{\\sum_{k\\in\\mathcal N_i\\cup v_i}exp(LeakyReLU(a^T[s_j^{l-1}||s_k^{l-1}]))}\\tag 7 $$ 其中$||$表示拼接操作，$a$是权重向量。根据之前的节点重要性计算方法的建议，节点的重要程度和节点在图中的centrality是相关的。节点centrality的一种常用表示方法是节点的入度$deg(i)$，节点$v_i$初始centrality $C(i)$计算方法如下： $$ \\tilde s_i=sigmoid(C(i)·s_i^L)\\tag {10} $$ 这样我们就能够利用编码在网络中的其他信息调整支持集中节点的重要程度。 2.4 小样本节点分类 得到每个节点的重要程度得分后，首先对其进行正则化处理： βi=exp(S~i)∑k∈Scexp(s~K)(11)\\beta_i=\\frac{exp(\\tilde S_i)}{\\sum_{k\\in S_c}exp(\\tilde s_K)}\\tag {11} βi​=∑k∈Sc​​exp(s~K​)exp(S~i​)​(11) 然后计算每个类别的原型： pc=∑i∈Scβizi(12)p_c=\\sum_{i\\in S_c}\\beta_iz_i\\tag {12} pc​=i∈Sc​∑​βi​zi​(12) 对于查询集中的节点我们只需要计算该节点和所有类别原型之间的距离，然后选取距离最近的类别原型代表的类别作为预测结果即可。对于测试节点vi∗v_i^*vi∗​，其属于类别c的概率为： p(c∣vi∗)=exp(−d(zi∗,pc))∑c′exp(−d(zi∗,pc′)(13)p(c|v_i^*)=\\frac{exp(-d(z_i^*,p_c))}{\\sum_{c&#x27;}exp(-d(z_i^*,p_{c&#x27;})}\\tag {13} p(c∣vi∗​)=∑c′​exp(−d(zi∗​,pc′​)exp(−d(zi∗​,pc​))​(13) 其中d(⋅)d(·)d(⋅)表示距离度量函数，通常采用欧式距离的平方。每个元训练任务的损失定义如下： L=−1N×M∑i=1N×Mlog(p(yi∗∣vi∗))(14)\\mathcal L=-\\frac{1}{N\\times M}\\sum_{i=1}^{N\\times M}log(p(y_i^*|v_i^*))\\tag{14} L=−N×M1​i=1∑N×M​log(p(yi∗​∣vi∗​))(14) 整个算法流程如下图所示： # 3. 实验 数据集：Amazon-Clothing、Amazon-Electronics、DBLP和Reddit 对比方法：DeepWalk、node2vec（基于随机游走）、GCN、SGC、PN（基于GNN）、MAML、Meta-GNN（小样本学习） 在四个数据集上，作者的方法都取得了最好的结果。 作者针对N-Way和K-Shot进行了消融实验，其中GPN-naive表示去掉了node valuator后的GPN变体。 作者还针对查询集大小进行了笑容实验。 上图展示了Meta-GNN和GPN在DBLP数据集上查询集合支持集节点之间的相似度，可以发现GPN模型下，查询集合支持集间相同类别节点的距离更小。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"原型网络","slug":"原型网络","permalink":"http://rookieyin.github.io/tags/%E5%8E%9F%E5%9E%8B%E7%BD%91%E7%BB%9C/"}]},{"title":"High-order structure preserving graph neural network for few-shot learning","slug":"3 论文笔记/小样本图学习/13.High-order structure preserving graph neural network for few-shot learning","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.846Z","comments":true,"path":"a6fe6734d0b6/","link":"","permalink":"http://rookieyin.github.io/a6fe6734d0b6/","excerpt":"https://arxiv.org/pdf/2005.14415 https://github.com/yangfeifei02/HOSP High-order structure preserving graph neural network for few-shot learning，2020 总结：文章提出的HOSP-GNN是对EGNN模型的改进，创新点在于将高阶结构引入GNN中，近似统一了不同任务中的度量标准，提高了小样本元学习算法的准确度。另外在GNN逐层迭代的过程中增加了流行结构约束，进一步提高了模型性能。","text":"https://arxiv.org/pdf/2005.14415 https://github.com/yangfeifei02/HOSP High-order structure preserving graph neural network for few-shot learning，2020 总结：文章提出的HOSP-GNN是对EGNN模型的改进，创新点在于将高阶结构引入GNN中，近似统一了不同任务中的度量标准，提高了小样本元学习算法的准确度。另外在GNN逐层迭代的过程中增加了流行结构约束，进一步提高了模型性能。 1. 简介 1.1 摘要 Few-shot learning can find the latent structure information between the prior knowl-edge and the queried data by the similarity metric of meta-learning to construct thediscriminative model for recognizing the new categories with the rare labeled samples.Most existing methods try to model the similarity relationship of the samples in the intra tasks, and generalize the model to identify the new categories. However, the relationship of samples between the separated tasks is difficultly considered because of thedifferent metric criterion in the respective tasks. In contrast, the proposed high-orderstructure preserving graph neural network(HOSP-GNN) can further explore the richstructure of the samples to predict the label of the queried data on graph that enablesthe structure evolution to explicitly discriminate the categories by iteratively updat-ing the high-order structure relationship (the relative metric in multi-samples,insteadof pairwise sample metric) with the manifold structure constraints. HOSP-GNN cannot only mine the high-order structure for complementing the relevance between sam-ples that may be divided into the different task in meta-learning, and but also generatethe rule of the structure updating by manifold constraint. Furthermore, HOSP-GNNdoesn’t need retrain the learning model for recognizing the new classes, and HOSP-GNN has the well-generalizable high-order structure for model adaptability. Experi-ments show that HOSP-GNN outperforms the state-of-the-art methods on supervised and semi-supervised few-shot learning in three benchmark datasets that are miniIma-geNet, tieredImageNet and FC100. 小样本学习能够通过元学习的相似度度量学习先验知识和查询数据之间的潜在结构信息，来构建判别模型，用于区分只有少量标记样本的新类。现有的方法大多都是对任务内的样本间的相似度关系进行建模，对模型进行泛化来识别新类。但是不同任务之间的度量标准不同，因此不同任务之间的样本间的关系难以考量。相比之下，本文提出的HOSP-GNN模型能够更进一步挖掘样本间丰富的结构，来预测图上查询数据的标签，从而使结构演化能够通过迭代更新模型来明确区分类别，具有流形结构的约束（乱吹）。HOSP-GNN不仅能够挖掘高阶结构来补充样本之间的相关性，这些样本在元学习中可能被划分到了不同任务中，还能生成流形约束下的结构更新规则。另外，HOSP-GNN不需要重新训练就能用于新的类别，而且HOSP-GNN具有well-generalizable高阶结构，模型自适应性更好。miniImageNet、tieredImageNet和FC100三个数据集上的实验表明作者的方法在全监督和半监督小样本学习任务上的性能要优于当前最先进方法。 1.2 本文工作 1.2.1 背景 利用在大规模标记数据集上训练的基于深度学习的判别模型，视觉内容的识别和理解取得了很大进展。事实上，有两个原因限制了深度学习方法在新类上的学习效率：一是大规模数据集上人工标记成本过高，二是新类上的少量样本不足以支撑判别模型的训练。因此如何在只有少量样本的新类上学习判别模型仍然具有很大挑战。为了解决这个问题，受人类视觉系统的启发，即人类只需要少量样本通过feature learning或者meta-learning就能学会判别一个新的类别，研究人员提出了小样本学习。Feature learning主要强调基于各种可迁移信息来学习特征生成和提取模型，而Meta-learning主要关注于relevance模型，通过episode训练挖掘数据样本之间的共同关系。 元学习在不同任务之间迁移知识，传播潜在的结构信息以提高模型的泛化能力避免过拟合，是当前小样本学习最重要的方向之一。**但是元学习的构建依赖于大规模独立的任务，不同任务之间独立的度量标准导致了不同任务的样本之间难以迁移信息。**尽管现有的方法通过将相同的样本填充到不同的任务中，可以在一定程度上缓解这一差距，但是还是很难在不同任务之间构建相似的度量标准，进行有效的信息迁移和传播。 1.2.2 本文工作 本文作者针对上述讨论的元学习存在的问题，提出了HOSP-GNN模型。作者尝试通过挖掘高阶结构来构建相似的度量标准，并且通过约束数据流形结构来更新样本之间的度量值，实现小样本学习。下图展示了HOSP-GNN和现有的元学习方法之间的差异： 2. 方法 2.1 问题定义 CeC_eCe​和CnC_nCn​分别表示有大量标记样本的已知类集合和只有少量标记样本的新类集合，$C_e\\cap C_n= \\emptyset $。 De={(xi,yi)∣yi∈Ce,i=1,...,∣De∣}D_e=\\{(x_i,y_i)|y_i\\in C_e,i=1,...,|D_e|\\}De​={(xi​,yi​)∣yi​∈Ce​,i=1,...,∣De​∣}，其中xix_ixi​表示第i张图片，类别标签为yiy_iyi​，∣De∣|D_e|∣De​∣表示集合DeD_eDe​中元素数量。 Dn={(xi,yi)∣yi∈Cn,i=1,...,∣Dn∣}D_n=\\{(x_i,y_i)|y_i\\in C_n,i=1,...,|D_n|\\}Dn​={(xi​,yi​)∣yi​∈Cn​,i=1,...,∣Dn​∣}，其中xix_ixi​表示第i张图片，类别标签为yiy_iyi​，∣Dn∣|D_n|∣Dn​∣表示集合DnD_nDn​中元素数量。 如果新类CnC_nCn​中每个类别只有K个标记样本，则称之为K-shot问题，即∣Dn∣=K∣Cn∣|D_n|=K|C_n|∣Dn​∣=K∣Cn​∣。小样本学习的目标就是从DnD_nDn​学习一个判别模型，能够准确预测测试集DtD_tDt​中数据的类别（来自CnC_nCn​），Dn∩Dt=∅D_n\\cap D_t=\\emptysetDn​∩Dt​=∅。 2.2 基于图神经网络的元学习 元学习的训练阶段通过构建一个任务集合来训练分类器模型，每个任务T={S,Q}\\mathcal T=\\{S,Q\\}T={S,Q}包含有标签的支持集S⊆DnS\\subseteq D_nS⊆Dn​和用于测试的查询集Q⊆DtQ\\subseteq D_tQ⊆Dt​。其中S包含N个类别，每个类别有K个有标签样本，此时称之为N-way-K-shot小样本分类。 在实际应用中，使用只有少量标记样本的DnD_nDn​数据集训练处的分类模型，在DtD_tDt​上难以取得好的分类表现。因此大多数方法都会从DeD_eDe​（有大量有标签样本）中进行数据采样来训练分类模型。一种常用的元学习方法就是episodic training，从DeD_eDe​中进行数据采样来模拟DnD_nDn​和DtD_tDt​下的N-way-K-shot分类任务。每个episodic都从DeD_eDe​中采样数据构建任务Tep=(Sep,Qep)\\mathcal T_{ep}=(S_{ep},Q_{ep})Tep​=(Sep​,Qep​)，称之为N-way-K-shot T查询样本的小样本分类任务。其中Sep={(xi,yi)∣yi∈Cep,i=1,...,N×K}S_{ep}=\\{(x_i,y_i)|y_i\\in C_{ep},i=1,...,N\\times K\\}Sep​={(xi​,yi​)∣yi​∈Cep​,i=1,...,N×K}，Qep={(xi,yi)∣yi∈Cep,i=1,...,N×T}Q_{ep}=\\{(x_i,y_i)|y_i\\in C_{ep},i=1,...,N\\times T\\}Qep​={(xi​,yi​)∣yi​∈Cep​,i=1,...,N×T}，Sep∩Qep=∅S_{ep}\\cap Q_{ep}=\\emptySep​∩Qep​=∅，∣Cep∣=N|C_{ep}|=N∣Cep​∣=N。在训练阶段Cep∈CeC_{ep}\\in C_eCep​∈Ce​，在测试阶段Cep∈CnC_{ep}\\in C_nCep​∈Cn​。 在每个episodic，作者构建一个图Gep=(Vep,Eep,Tep)G_{ep}=(\\mathcal V_{ep},\\mathcal E_{ep},\\mathcal T_{ep})Gep​=(Vep​,Eep​,Tep​)来描述样本间的结构特征，其中Vep\\mathcal V_{ep}Vep​表示顶点集合，Eep\\mathcal E_{ep}Eep​表示边集合，Tep\\mathcal T_{ep}Tep​表示图片特征。模型损失如下： Lep=−∑l=1L∑(xi,yi)∈Qepyilog(hWl(f(xi,Wf);Sep,Gep))=−∑l=1L∑(xi,yi)∈Qepyilog(y^il)(1)\\begin{aligned} L_{ep}&amp;=-\\sum_{l=1}^L\\sum_{(x_i,y_i)\\in Q_{ep}}y_ilog(h_W^l(f(x_i,W_f);S_{ep},G_{ep}))\\\\ &amp;=-\\sum_{l=1}^L\\sum_{(x_i,y_i)\\in Q_{ep}}y_ilog(\\hat y_i^l) \\end{aligned}\\tag 1 Lep​​=−l=1∑L​(xi​,yi​)∈Qep​∑​yi​log(hWl​(f(xi​,Wf​);Sep​,Gep​))=−l=1∑L​(xi​,yi​)∈Qep​∑​yi​log(y^​il​)​(1) y^il=softmax(∑j≠i and c∈Cepeijlδ(yi=c))(2)\\begin{aligned} \\hat y_i^l=softmax(\\sum_{j\\neq i\\ and\\ c\\in C_{ep}}e_{ij}^l\\delta(y_i=c)) \\end{aligned} \\tag 2 y^​il​=softmax(j​=i and c∈Cep​∑​eijl​δ(yi​=c))​(2) 其中δ\\deltaδ是指示函数，yi=cy_i=cyi​=c时值为1，否则为0。 2.3 高阶结构 在每个元任务中，现有的小样本方法都是采用pairwise的方式计算样本之间的结构关系，根据图中的相似度矩阵生成一个具有唯一度量标准的独立的度量空间。在不同的元任务中，不同的度量标准导致不同样本之间结构关系存在差异，如下图所示： 这种差异影响了模型在新类任务中的分类准确度。为了降低不同任务度量标准的差异，作者尝试通过不可见的潜在联系来获取样本的高阶结构信息。由于样本是在每个独立任务中分别进行标准化的，因此传统的pairwise度量方式不具备一个统一的度量标准。而绝对统一的bench marking难以在不同任务的样本之间构建高阶关系结构。因此作者将任务中的**多样本的相对度量图**定义为高阶关系结构。 相对度量图G^ep=(V^ep,E^ep,Tep)\\hat G_{ep}=(\\hat{\\mathcal V}_{ep},\\hat{\\mathcal E}_{ep},\\mathcal T_{ep})G^ep​=(V^ep​,E^ep​,Tep​)，其中Tep={(xi,yi)∣(xi,yi)∈Sep or (xi,yi)∈Qep,Sep∩Qep=∅,i=1,...,N×(K+T)}\\mathcal T_{ep}=\\{(x_i,y_i)|(x_i,y_i)\\in S_{ep}\\ or\\ (x_i,y_i)\\in Q_{ep},S_{ep}\\cap Q_{ep}=\\empty,i=1,...,N\\times (K+T)\\}Tep​={(xi​,yi​)∣(xi​,yi​)∈Sep​ or (xi​,yi​)∈Qep​,Sep​∩Qep​=∅,i=1,...,N×(K+T)}，V^ep={vi∣i=1,...,N×(K+T)}\\hat{\\mathcal V}_{ep}=\\{v_i|i=1,...,N\\times(K+T)\\}V^ep​={vi​∣i=1,...,N×(K+T)}，E^ep={eij∣i=1,..,N×(K+T) and j=1,...,N×(K+T)}\\hat{\\mathcal E}_{ep}=\\{e_{ij}|i=1,..,N\\times(K+T)\\ and\\ j=1,...,N\\times(K+T)\\}E^ep​={eij​∣i=1,..,N×(K+T) and j=1,...,N×(K+T)}。作者构建一个L层图神经网络来学习边特征eijle_{ij}^leijl​和节点特征vilv_i^lvil​。节点初始特征vi0v_i^0vi0​计算方法如下： ui0=f(xi),i=1,...,N×(K+T)(3)u_i^0=f(x_i),\\qquad i=1,...,N\\times(K+T)\\tag 3 ui0​=f(xi​),i=1,...,N×(K+T)(3) vi0={ui0−ui+10,i=1,...,N×(K+T)−1,ui0−u10,i=1N×(K+T),(4)v_i^0=\\left\\{ \\begin{aligned} &amp;u_i^0-u_{i+1}^0,\\quad i=1,...,N\\times(K+T)-1, \\\\ &amp;u_i^0-u_1^0,\\qquad i=1N\\times(K+T), \\end{aligned} \\right.\\tag 4 vi0​={​ui0​−ui+10​,i=1,...,N×(K+T)−1,ui0​−u10​,i=1N×(K+T),​(4) 其中f(⋅)f(·)f(⋅)表示特征提取网络，ui0u_i^0ui0​表示节点的原始特征，vi0v_i^0vi0​表示在第0层基于ui0u_i^0ui0​的相对度量。作者希望基于这些相对度量vilv_i^lvil​构建高阶结构eij1le_{ij1}^leij1l​表示第l层节点i和节点j之间的边特征，eij2le_{ij2}^leij2l​表示pairwise相似度，eij3le_{ij3}^leij3l​表示不相似度。初始值eij0e_{ij}^0eij0​计算方法如下： eij0={[eij10∣∣eij20=1∣∣eij30=0],yi=yj and (xi,yi)∈Sep[eij10∣∣eij20=0∣∣eij30=1],yi≠yj and (xi,yi)∈Sep[eij10∣∣eij20=0.5∣∣eij30=0.5],otherwise(5)e_{ij}^0=\\left\\{ \\begin{aligned} &amp;[e_{ij1}^0||e_{ij2}^0=1||e_{ij3}^0=0],\\quad y_i=y_j\\ and\\ (x_i,y_i)\\in S_{ep}\\\\ &amp;[e_{ij1}^0||e_{ij2}^0=0||e_{ij3}^0=1], \\quad y_i\\neq y_j\\ and\\ (x_i,y_i)\\in S_{ep}\\\\ &amp;[e_{ij1}^0||e_{ij2}^0=0.5||e_{ij3}^0=0.5],\\quad otherwise \\end{aligned} \\right.\\tag 5 eij0​=⎩⎪⎪⎨⎪⎪⎧​​[eij10​∣∣eij20​=1∣∣eij30​=0],yi​=yj​ and (xi​,yi​)∈Sep​[eij10​∣∣eij20​=0∣∣eij30​=1],yi​​=yj​ and (xi​,yi​)∈Sep​[eij10​∣∣eij20​=0.5∣∣eij30​=0.5],otherwise​(5) eij10e_{ij1}^0eij10​计算方法如下： eij10=1−∣∣vi0−vj0∣∣2/∑k∣∣vi0−vk0∣∣2,(xi,yi)∈Sep∪Qep(6)e_{ij1}^0=1-||v_i^0-v_j^0||_2/\\sum_k||v_i^0-v_k^0||_2,\\quad (x_i,y_i)\\in S_{ep}\\cup Q_{ep}\\tag 6 eij10​=1−∣∣vi0​−vj0​∣∣2​/k∑​∣∣vi0​−vk0​∣∣2​,(xi​,yi​)∈Sep​∪Qep​(6) 下图展示了pairwise度量和high-order度量之间的区别： ## 2.4 高阶结构的保留 HOSP-GNN构建一个L层的GNN来更新顶点和边特征，更新方式如下列公式所示： $$ \\begin{array}{c} u_{i}^{l}=f_{v}^{l}\\left(\\left[\\sum_{j} \\tilde{e}_{i j 1}^{l-1} v_{j}^{l-1}\\left\\|\\sum_{j} \\tilde{e}_{i j 2}^{l-1} u_{j}^{l-1}\\right\\| \\sum_{j} \\tilde{e}_{i j 3}^{l-1} u_{j}^{l-1}\\right], W_{v}^{l}\\right) \\\\ \\end{array}\\tag 7 $$ vil={uil−ui+1l,i=1,…,N×(K+T)−1uil−u1l,i=N×(K+T)(8)\\begin{array}{c} v_{i}^{l}=\\left\\{\\begin{array}{ll} u_{i}^{l}-u_{i+1}^{l}, &amp; i=1, \\ldots, N \\times(K+T)-1 \\\\ u_{i}^{l}-u_{1}^{l}, &amp; i=N \\times(K+T) \\end{array}\\right. \\end{array}\\tag 8 vil​={uil​−ui+1l​,uil​−u1l​,​i=1,…,N×(K+T)−1i=N×(K+T)​​(8) uilu_i^luil​通过uil−1u_i^{l-1}uil−1​，vil−1v_i^{l-1}vil−1​，eijl−1e_{ij}^{l-1}eijl−1​计算得到，再计算得到vilv_i^lvil​。其中∣∣||∣∣表示concatenation操作，e~ijkl−1=eijkl−1/∑keijkl−1(k=1,2,3)\\tilde{e}_{i j k}^{l-1}=e_{ijk}^{l-1}/\\sum_ke_{ijk}^{l-1}(k=1,2,3)e~ijkl−1​=eijkl−1​/∑k​eijkl−1​(k=1,2,3)，fvl(⋅)f_v^l(·)fvl​(⋅)表示顶点特征更新网络，WvlW_v^lWvl​表示第l层的参数。 上面顶点的更新过程中，高阶结构影响下一层节点特征，但是不能有效地逐层传递下去，因此作者对边特征也逐层进行更新。更新方式如下列公式所示： eˉij1l=fhl(∥vil−vjl∥2,Whl)eij1l−1∑kfhl(∥vil−vkl∥2,Whl)eik1l−1/∑keik1l−1,(10)\\bar{e}_{i j 1}^{l}=\\frac{f_{h}^{l}\\left(\\left\\|v_{i}^{l}-v_{j}^{l}\\right\\|_{2}, W_{h}^{l}\\right) e_{i j 1}^{l-1}}{\\sum_{k} f_{h}^{l}\\left(\\left\\|v_{i}^{l}-v_{k}^{l}\\right\\|_{2}, W_{h}^{l}\\right) e_{i k 1}^{l-1} / \\sum_{k} e_{i k 1}^{l-1}},\\tag {10} eˉij1l​=∑k​fhl​(∥∥∥​vil​−vkl​∥∥∥​2​,Whl​)eik1l−1​/∑k​eik1l−1​fhl​(∥∥∥​vil​−vjl​∥∥∥​2​,Whl​)eij1l−1​​,(10) eˉij2l=fpl(∥uil−ujl∥2,Wpl)eij2l−1∑kfpl(∥uil−ukl∥2,Wpl)eik2l−1/∑keik2l−1(11)\\bar{e}_{i j 2}^{l}=\\frac{f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{j}^{l}\\right\\|_{2}, W_{p}^{l}\\right) e_{i j 2}^{l-1}}{\\sum_{k} f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{k}^{l}\\right\\|_{2}, W_{p}^{l}\\right) e_{i k 2}^{l-1} / \\sum_{k} e_{i k 2}^{l-1}}\\tag {11} eˉij2l​=∑k​fpl​(∥∥∥​uil​−ukl​∥∥∥​2​,Wpl​)eik2l−1​/∑k​eik2l−1​fpl​(∥∥∥​uil​−ujl​∥∥∥​2​,Wpl​)eij2l−1​​(11) eˉij3l=(1−fpl(∥uil−ujl∥2,Wpl))eij3l−1∑k(1−fpl(∥uil−ukl∥2,Wpl))eik3l−1/∑keik3l−1,(12)\\bar{e}_{i j 3}^{l}=\\frac{\\left(1-f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{j}^{l}\\right\\|_{2}, W_{p}^{l}\\right)\\right) e_{i j 3}^{l-1}}{\\sum_{k}\\left(1-f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{k}^{l}\\right\\|_{2}, W_{p}^{l}\\right)\\right) e_{i k 3}^{l-1} / \\sum_{k} e_{i k 3}^{l-1}},\\tag {12} eˉij3l​=∑k​(1−fpl​(∥∥∥​uil​−ukl​∥∥∥​2​,Wpl​))eik3l−1​/∑k​eik3l−1​(1−fpl​(∥∥∥​uil​−ujl​∥∥∥​2​,Wpl​))eij3l−1​​,(12) eijl=eˉijl/∣∣eˉijl∣∣1(13)e_{ij}^l=\\bar e_{ij}^l/||\\bar e_{ij}^l||_1\\tag {13} eijl​=eˉijl​/∣∣eˉijl​∣∣1​(13) 其中fhl(⋅)f_h^l(·)fhl​(⋅)表示计算高阶度量的网络，fplf_p^lfpl​表示计算pairwise度量的网络，WhlW_h^lWhl​和WplW_p^lWpl​分别表示这两个网络的参数。 根据manifold learning和structure fusion，数据从一个空间映射到另一个空间时，要想保留结构信息，可以通过最小化这两个空间度量差异来实现。高阶结构信息也遵循这样一个规则，因此作者构建了损失函数LmlL_{ml}Lml​来约束模型的优化： Lml=∑i,j,lfhl(∥vil−vjl∥2,Whl)eij1l−1+∑i,j,lfpl(∥uil−ujl∥2,Wpl)eij2l−1+∑i,j,l(1−fpl(∥uil−ujl∥2,Whl))eij3l−1(9)\\begin{aligned} L_{m l}=&amp; \\sum_{i, j, l} f_{h}^{l}\\left(\\left\\|v_{i}^{l}-v_{j}^{l}\\right\\|_{2}, W_{h}^{l}\\right) e_{i j 1}^{l-1}+\\\\ &amp; \\sum_{i, j, l} f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{j}^{l}\\right\\|_{2}, W_{p}^{l}\\right) e_{i j 2}^{l-1}+\\\\ &amp; \\sum_{i, j, l}\\left(1-f_{p}^{l}\\left(\\left\\|u_{i}^{l}-u_{j}^{l}\\right\\|_{2}, W_{h}^{l}\\right)\\right) e_{i j 3}^{l-1} \\end{aligned}\\tag {9} Lml​=​i,j,l∑​fhl​(∥∥∥​vil​−vjl​∥∥∥​2​,Whl​)eij1l−1​+i,j,l∑​fpl​(∥∥∥​uil​−ujl​∥∥∥​2​,Wpl​)eij2l−1​+i,j,l∑​(1−fpl​(∥∥∥​uil​−ujl​∥∥∥​2​,Whl​))eij3l−1​​(9) 这样整个模型的损失函数LtotalL_{total}Ltotal​包含LepL_{ep}Lep​和LmlL_{ml}Lml​两部分： Ltotal=Lep+λLmlL_{total}=L_{ep}+\\lambda L_{ml} Ltotal​=Lep​+λLml​ HOSP-GNN的伪代码如下图所示： 整个算法分成四步，第一步初始化节点特征和边特征，第二步逐层更新节点特征，第三步逐层更新边特征，第四步预测查询样本的标签。 3. 实验 3.1 简介 baseline对比实验 state-of-the-art方法对比实验 半监督小样本学习 一些消融实验 3.1.1 数据集 miniImageNet，tieredImageNet和FC100 ### 3.1.2 **实验设置** 特征提取部分和现有的其他方法一致，采用3×33\\times 33×3的卷积核，1个线性单元，1个batch正则化，1个leakReLU单元。 为了方便和其他方法作对比，作者设定层数L为3。 3.2 baseline对比实验 HOSP-GNN的主要架构是基于EGNN模型构建的，区别在于EGNN只考虑了相似性和不相似性，并且在逐层迭代的时候没有考虑manifold structure constraint，而HOSP-GNN尝试捕捉多个样本（不是两个）之间的高阶结构，将样本间的相似性和不相似性融合到一起，并且在更新过程中增加了约束条件。 作者设置的baseline方法有：EGNN，HOSP-GNN-H-S，HOSP-GNN-H-D，HOSP-GNN-H，HOSP-GNN-S，HOSP-GNN-D。（其中H表示高阶结构关系，S表示相似关系，D表示不相似关系） ## 3.3 半监督实验 和GNN、EGNN、CML-BGNN三种方法进行对比，三种方法的不同之处在于样本结构的描述。GNN采用的时最通用的方式挖掘结构信息，EGNN强调节点特征的更新方式，CML-BGNN关注episode任务的连续信息用于结构补全。 ## 3.4 消融实验 层数 损失函数 损失函数中λ\\lambdaλ","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Few-Shot Knowledge Graph Completion","slug":"3 论文笔记/小样本图学习/14.Few-Shot Knowledge Graph Completion","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.839Z","comments":true,"path":"3ec77d34ddfd/","link":"","permalink":"http://rookieyin.github.io/3ec77d34ddfd/","excerpt":"http://www.meng-jiang.com/pubs/fsrl-aaai20/fsrl-aaai20-paper.pdf Few-Shot Knowledge Graph Completion ，AAAI，2020","text":"http://www.meng-jiang.com/pubs/fsrl-aaai20/fsrl-aaai20-paper.pdf Few-Shot Knowledge Graph Completion ，AAAI，2020 1. 简介 1.1 摘要 Knowledge graphs (KGs) serve as useful resources for various natural language processing applications. Previous KGcompletion approaches require a large number of training instances (i.e., head-tail entity pairs) for every relation. The realcase is that for most of the relations, very few entity pairs areavailable. Existing work of one-shot learning limits method generalizability for few-shot scenarios and does not fully use the supervisory information; however, few-shot KG completion has not been well studied yet. In this work, we propose a novel few-shot relation learning model (FSRL) that aims at discovering facts of new relations with few-shot references. FSRL can effectively capture knowledge from heterogeneous graph structure, aggregate representations of few-shot references, and match similar entity pairs of reference set for every relation. Extensive experiments on two public datasets demonstrate that FSRL outperforms the state-of-the-art. 知识图谱（KG）在很多自然语言处理应用中是一种非常有用的形式。现有的KG补全方法需要每种关系都要大量的训练实例（head-tail实体对），但是在实际应用中只能获取到少量的实体对。现有的one-shot学习方法通用性差，并且没有充分利用监督信息，而few-shot KG补全还缺乏相关研究。在这篇工作中，作者提出了一种原生的小样本关系学习模型FSRL，旨在利用少量references来挖掘新的relations。FSRL能够从异构图结构中有效地捕捉知识，聚合few-shot references的表示，并为每个关系都匹配一个相似的reference set实体对。两个公共数据集上的大量实验表明FSRL的性能要优于state-of-the-art。 1.2 背景 现有的KG补全方法都需要大量实体对，但是在真实数据集中关系出现的频率往往呈现长尾分布，即很多关系只有少量实体对和其相关联。2018年Xiong等人提出了GMatching方法，通过一个局部邻居编码器来学习实体嵌入，在one-shot relation 推理上取得了不错的效果，但是存在一些弊端： GMatching假设所有的局部邻居对于entity embedding的贡献度是一样的，然而这和事实是相违背的，导致模型不能充分学习图的结构知识，影响了模型性能 GMatching设定的场景是one-shot，将其拓展到few-shot场景下会影响模型性能 因此设计一个在few-shot场景下可以有效complete relation的模型十分重要，作者据此提出了Few-Shot Relation Learning模型（FSRL）。 1.3 问题定义 知识图谱G表示为：{(h,r,t)}⊆E×R×E\\{(h,r,t)\\}\\subseteq \\mathcal E\\times\\mathcal R\\times\\mathcal E{(h,r,t)}⊆E×R×E，E\\mathcal EE和R\\mathcal RR表示表示实体集合和关系集合。 KG补全任务的目标：给定头实体hhh和关系，预测可能的尾实体，即(h,r,?)(h,r,?)(h,r,?)；或者给定尾实体和头实体，预测可能存在的关系，即(h,?,r)(h,?,r)(h,?,r)。本文作者针对的任务场景为前者。（和其他KG补全方法不同，作者针对的是只有少量实体对的应用场景） 模型的学习目标是：让正确实体ttruet_{true}ttrue​的排名高于错误实体tfalset_{false}tfalse​的排名。 和标准小样本学习方法一样，构建一个training tasks集合。集合中每个元任务Tmtr\\mathcal T_{mtr}Tmtr​都包含一种关系r∈Rr\\in\\mathcal Rr∈R，及用于训练/测试的实体对Dr={Prtrain,Prtest}D_r=\\{P_r^{train},P_r^{test}\\}Dr​={Prtrain​,Prtest​}，其中PrtrainP_r^{train}Prtrain​只包含少量实体对(hk,tk)∈Rr(h_k,t_k)\\in R_r(hk​,tk​)∈Rr​，Prtest={(hi,ti,Chi,r∣(hi,r,ti)∈G}P_r^{test}=\\{(h_i,t_i,C_{h_i,r}|(h_i,r,t_i)\\in G\\}Prtest​={(hi​,ti​,Chi​,r​∣(hi​,r,ti​)∈G}则包含所有真实的尾实体tit_iti​和所有候选实体ti∈Chi,rt_i\\in C_{h_i,r}ti​∈Chi​,r​。模型关于关系r的排名损失表示为LΘ(hi,ti∣Chi,r,Prtrain)\\mathcal L_\\Theta(h_i,t_i|C_{h_i,r},P_r^{train})LΘ​(hi​,ti​∣Chi​,r​,Prtrain​)，则模型学习目标为： minΘETmtr[∑(hi,ti,Chi,r)∈PrtestLΘ(hi,ti∣Chi,r,Prtrain)∣Prtest∣](1)min_\\Theta\\mathbb E_{\\mathcal T_{mtr}}\\Big[\\sum_{(h_i,t_i,C_{h_i,r})\\in P_r^{test}}\\frac{\\mathcal L_\\Theta(h_i,t_i|C_{h_i,r},P_r^{train})}{|P_r^{test}|}\\Big]\\tag 1 minΘ​ETmtr​​[(hi​,ti​,Chi​,r​)∈Prtest​∑​∣Prtest​∣LΘ​(hi​,ti​∣Chi​,r​,Prtrain​)​](1) 其中∣Prtest∣|P_r^{test}|∣Prtest​∣表示PrtestP_r^{test}Prtest​中的元组数量。 在元训练结束后，在新关系r′∈R′r^\\prime\\in\\mathcal R^\\primer′∈R′上对模型进行测试，R∩R′=∅\\mathcal R\\cap\\mathcal R^\\prime=\\emptyR∩R′=∅。元测试阶段和元训练时一样，会构建若干个元测试任务。 2. 模型 FSRL包含三部分：（1）encoding（2）aggregating（3）matching ## 2.1 Encoding 作者考虑邻居影响力的差异性，利用注意力机制，设计了一个relation-aware异构邻居编码器，节点嵌入h的计算方式如下： fθ(h)=σ(∑iαieti)αi=exp⁡{urtT(Wrt(eri⊕eti)+brt)}∑jexp⁡{urtT(Wrt(erj⊕etj)+brt)}(2)\\begin{array}{c} f_{\\theta}(h)=\\sigma\\left(\\sum_{i} \\alpha_{i} e_{t_{i}}\\right) \\\\ \\alpha_{i}=\\dfrac{\\exp \\left\\{u_{r t}^{T}\\left(\\mathcal{W}_{r t}\\left(e_{r_{i}} \\oplus e_{t_{i}}\\right)+b_{r t}\\right)\\right\\}}{\\sum_{j} \\exp \\left\\{u_{r t}^{T}\\left(\\mathcal{W}_{r t}\\left(e_{r_{j}} \\oplus e_{t_{j}}\\right)+b_{r t}\\right)\\right\\}} \\end{array}\\tag 2 fθ​(h)=σ(∑i​αi​eti​​)αi​=∑j​exp{urtT​(Wrt​(erj​​⊕etj​​)+brt​)}exp{urtT​(Wrt​(eri​​⊕eti​​)+brt​)}​​(2) 其中σ\\sigmaσ表示激活单元，eri,eti∈Rd×1e_{r_i},e_{t_i}\\in\\mathbb R^{d\\times 1}eri​​,eti​​∈Rd×1分别表示预训练好的tit_iti​和rir_iri​的嵌入。urt∈Rd×1u_{rt}\\in\\mathbb R^{d\\times 1}urt​∈Rd×1，Wrt∈Rd×2d\\mathcal W_{rt}\\in\\mathbb R^{d\\times 2d}Wrt​∈Rd×2d以及brt∈Rd×1b_{rt}\\in\\mathbb R^{d\\times 1}brt​∈Rd×1为可学习参数。 2.2 Aggregating 经过Encoding后，我们可以得到所有实体对(hk,tk)∈Rr(h_k,t_k)\\in R_r(hk​,tk​)∈Rr​的表示Ehk,tk=[fθ(hk)⊕fθ(tk)]\\mathcal E_{h_k,t_k}=[f_\\theta(h_k) \\oplus f_\\theta(t_k)]Ehk​,tk​​=[fθ​(hk​)⊕fθ​(tk​)]。如何只通过少量实体对学习到reference set RiR_iRi​的表示是很困难的，因为需要对不同实体对之间的交互进行建模并累积它们的表征能力。作者参考NLP中的一些方法，通过聚合所有关系r下所有实体对的embedding来计算RrR_rRr​的embedding： fϵ(Rr)=AG(hk,tk)∈Rr{Ehk,tk}(3)f_{\\epsilon}\\left(R_{r}\\right)=\\mathcal{A} \\mathcal{G}_{\\left(h_{k}, t_{k}\\right) \\in R_{r}}\\left\\{\\mathcal{E}_{h_{k}, t_{k}}\\right\\}\\tag 3 fϵ​(Rr​)=AG(hk​,tk​)∈Rr​​{Ehk​,tk​​}(3) 其中AG\\mathcal{AG}AG表示聚合函数，可以是一个池化操作，也可以是一个前馈神经网络。作者这里采用RNN的思想对实体对信息进行聚合，将Ehk,tk∈Rr\\mathcal E_{h_k,t_k}\\in R_rEhk​,tk​​∈Rr​喂给一个循环自编码器： Eh1,t1→m1→⋯→mK→dK→⋯→d1(4)\\mathcal{E}_{h_{1}, t_{1}} \\rightarrow m_{1} \\rightarrow \\cdots \\rightarrow m_{K} \\rightarrow d_{K} \\rightarrow \\cdots \\rightarrow d_{1}\\tag 4 Eh1​,t1​​→m1​→⋯→mK​→dK​→⋯→d1​(4) 其中K表示reference set的大小（即few-shot size）。编码器和解码器hidden state计算方式如下: mk=RNNencoder (Ehk,tk,mk−1)dk−1=RNNdecoder (dk)(5)\\begin{array}{c} m_{k}=\\mathrm{RNN}_{\\text {encoder }}\\left(\\mathcal{E}_{h_{k}, t_{k}}, m_{k-1}\\right) \\\\ d_{k-1}=\\mathrm{RNN}_{\\text {decoder }}\\left(d_{k}\\right) \\end{array}\\tag 5 mk​=RNNencoder ​(Ehk​,tk​​,mk−1​)dk−1​=RNNdecoder ​(dk​)​(5) 自编码器的重构损失定义为： Lre(Rr)=∑k∥dk−Ehk,tk∥22(6)\\mathcal{L}_{r e}\\left(R_{r}\\right)=\\sum_{k}\\left\\|d_{k}-\\mathcal{E}_{h_{k}, t_{k}}\\right\\|_{2}^{2}\\tag 6 Lre​(Rr​)=k∑​∥dk​−Ehk​,tk​​∥22​(6) 为了聚合编码器每一层的hidden state，作者借鉴深度残差网络的思想，fE(Rr)f_\\mathcal E(R_r)fE​(Rr​)计算方式如下： mk′=mk+Ehk,tkβk=exp⁡{uRT(WRmk′+bR)}∑k′exp⁡{uRT(WRmk′′+bR)}fϵ(Rr)=∑kβkmk′(7)\\begin{array}{c} m_{k}^{\\prime}=m_{k}+\\mathcal{E}_{h_{k}, t_{k}} \\\\ \\beta_{k}=\\dfrac{\\exp \\left\\{u_{R}^{T}\\left(\\mathcal{W}_{R} m_{k}^{\\prime}+b_{R}\\right)\\right\\}}{\\sum_{k^{\\prime}} \\exp \\left\\{u_{R}^{T}\\left(\\mathcal{W}_{R} m_{k^{\\prime}}^{\\prime}+b_{R}\\right)\\right\\}} \\\\ f_{\\epsilon}\\left(R_{r}\\right)=\\sum_{k} \\beta_{k} m_{k}^{\\prime} \\end{array}\\tag 7 mk′​=mk​+Ehk​,tk​​βk​=∑k′​exp{uRT​(WR​mk′′​+bR​)}exp{uRT​(WR​mk′​+bR​)}​fϵ​(Rr​)=∑k​βk​mk′​​(7) 其中uR∈Rd×1,WR∈Rd×2d,bR∈Rd×1u_R\\in\\mathbb R^{d\\times 1},\\mathcal W_R\\in\\mathbb R^{d\\times 2d},b_R\\in\\mathbb R^{d\\times 1}uR​∈Rd×1,WR​∈Rd×2d,bR​∈Rd×1为可学习参数。 2.3 Matching 经过encoder和aggregation后，我们可以得到两个向量： Ehl,tl=[fθ(hl)⊕fθ(tl)]\\mathcal E_{h_l,t_l}=[f_\\theta(h_l)\\oplus f_\\theta(t_l)]Ehl​,tl​​=[fθ​(hl​)⊕fθ​(tl​)]：表示实体对(hl,tl)(h_l,t_l)(hl​,tl​)的embedding fE(Rr)f_\\mathcal E(R_r)fE​(Rr​)：关系的embedding 这里作者参考one-shot learning中匹配网络的方法，用RNN做一个multiple steps的匹配： gt′,ct=RNNmatch (Ehl,tl,[gt−1⊕fϵ(Rr)],ct−1)gt=gt′+Ehl,tl(8)\\begin{array}{c} g_{t}^{\\prime}, c_{t}=\\mathrm{RNN}_{\\text {match }}\\left(\\mathcal{E}_{h_{l}, t_{l}},\\left[g_{t-1} \\oplus f_{\\epsilon}\\left(R_{r}\\right)\\right], c_{t-1}\\right) \\\\ g_{t}=g_{t}^{\\prime}+\\mathcal{E}_{h_{l}, t_{l}} \\end{array}\\tag 8 gt′​,ct​=RNNmatch ​(Ehl​,tl​​,[gt−1​⊕fϵ​(Rr​)],ct−1​)gt​=gt′​+Ehl​,tl​​​(8) 其中RNNmatchRNN_{match}RNNmatch​是一个LSTM单元，输入为Ehl,tl\\mathcal E_{h_l,t_l}Ehl​,tl​​，hidden state为gt−1g_{t-1}gt−1​，cell state为ctc_tct​。最后一步（第T步）的隐藏状态gTg_TgT​作为实体对(hl,tl)(h_l,t_l)(hl​,tl​)优化后的嵌入，然后计算gtg_tgt​和fE(Rr)f_\\mathcal E(R_r)fE​(Rr​)的内积作为最终的matching score。 2.4 学习目标 对于关系r，首先随机选取少量positive实体对{(hk,tk)∣(hk,r,tk)∈G}\\{(h_k,t_k)|(h_k,r,t_k)\\in G\\}{(hk​,tk​)∣(hk​,r,tk​)∈G}，将其视为支持集，其余的positive实体对PEr\\mathcal{PE}_rPEr​用来测试。同时向测试样本里面添加一些negative实体对NEr\\mathcal{NE}_rNEr​来污染测试样本。这样最终的排名损失定义如下： Lrank =∑r∑(hl,tl)∈PEr∑(hl,tl−)∈NEr[ξ+s(hl,tl−)−s(hl,tl)]+(9)\\mathcal{L}_{\\text {rank }}=\\sum_{r} \\sum_{\\left(h_{l}, t_{l}\\right) \\in \\mathcal{P} \\mathcal{E}_{r}} \\sum_{\\left(h_{l}, t_{l}^{-}\\right) \\in \\mathcal{N} \\mathcal{E}_{r}}\\left[\\xi+s_{\\left(h_{l}, t_{l}^{-}\\right)}-s_{\\left(h_{l}, t_{l}\\right)}\\right]_{+}\\tag 9 Lrank ​=r∑​(hl​,tl​)∈PEr​∑​(hl​,tl−​)∈NEr​∑​[ξ+s(hl​,tl−​)​−s(hl​,tl​)​]+​(9) 其中[x]+=max[0,x][x]_+=max[0,x][x]+​=max[0,x]（一种损失定义方式），ξ\\xiξ表示safety margin距离，s(hl,tl−)s_{(h_l,t_l^-)}s(hl​,tl−​)​和s(hl,tl)s_{(h_l,t_l)}s(hl​,tl​)​分别表示positive实体对和negative实体对的得分。再结合自编码器的重构损失Lre\\mathcal L_{re}Lre​，最终模型整体的损失定义为： Ljoint=Lrank+γLre(10)\\mathcal L_{joint}=\\mathcal L_{rank}+\\gamma\\mathcal L_{re}\\tag {10} Ljoint​=Lrank​+γLre​(10) 整个模型训练过程伪代码如下图所示： # 3. 实验 3.1 基础实验 数据集 对比实验 不同关系上对比实验 3.2 消融实验 各组件的作用 AS_1：探究relation-aware异构邻居编码器的作用，用平均池化代替自编码器 AS_2：aggregation部分采用不同模型，AS_2a用平均池化代替循环自编码器，AS_2b采用一个平均池化层代替循环自编码器的注意力层，AS_2c去除decoder，只使用encoder来聚合 AS_3：探究matching网络的作用，去除LSTM，采用内积计算实体对和关系之间的得分 few-shot的大小 3.3 可视化","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}]},{"title":"Graph Few-shot Learning via Knowledge Transfer","slug":"3 论文笔记/小样本图学习/2. Graph Few-shot Learning via Knowledge Transfer","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.866Z","comments":true,"path":"c45493e889ef/","link":"","permalink":"http://rookieyin.github.io/c45493e889ef/","excerpt":"https://arxiv.org/pdf/1910.03053 Graph Few-shot Learning via Knowledge Transfer，2020，AAAI 总结：本文利用FSL中元学习思想，随机采样一系列图（等同于元学习中的一系列任务），提出的GFL模型主要背靠原型网络，计算每个类别的原型，然后根据节点和类别原型之间的距离判断节点所属类别。然后在这个基础上做了很多缝合和优化工作： 借鉴Diffpool方法，学习图的层级表示，并融合到PGNN参数中，使得每个图都有独特的ϕi\\phi_iϕi​ 在初始节点嵌入的基础上，在属于同一个类别的所以节点之间构造关系结构R，弥补原始节点嵌入只聚合了距离较近的邻居信息这一缺陷 在损失函数中引入图自编码器损失，来提高训练的稳定性和节点表示的质量","text":"https://arxiv.org/pdf/1910.03053 Graph Few-shot Learning via Knowledge Transfer，2020，AAAI 总结：本文利用FSL中元学习思想，随机采样一系列图（等同于元学习中的一系列任务），提出的GFL模型主要背靠原型网络，计算每个类别的原型，然后根据节点和类别原型之间的距离判断节点所属类别。然后在这个基础上做了很多缝合和优化工作： 借鉴Diffpool方法，学习图的层级表示，并融合到PGNN参数中，使得每个图都有独特的ϕi\\phi_iϕi​ 在初始节点嵌入的基础上，在属于同一个类别的所以节点之间构造关系结构R，弥补原始节点嵌入只聚合了距离较近的邻居信息这一缺陷 在损失函数中引入图自编码器损失，来提高训练的稳定性和节点表示的质量 1. 简介 1.1 摘要 Towards the challenging problem of semi-supervised node classification, there havebeen extensive studies. As a frontier, Graph Neural Networks (GNNs) have arousedgreat interest recently, which update the representation of each node by aggregatinginformation of its neighbors. However, most GNNs have shallow layers with alimited receptive field and may not achieve satisfactory performance especiallywhen the number of labeled nodes is quite small. To address this challenge, weinnovatively propose a graph few-shot learning (GFL) algorithm that incorporatesprior knowledge learned from auxiliary graphs to improve classification accuracyon the target graph. Specifically, a transferable metric space characterized by a nodeembedding and a graph-specific prototype embedding function is shared betweenauxiliary graphs and the target, facilitating the transfer of structural knowledge.Extensive experiments and ablation studies on four real-world graph datasetsdemonstrate the effectiveness of our proposed model. 对于半监督节点分类这个难题，业内已经有了很多相关研究。GNN作为研究前沿，通过聚合邻居信息来更新节点表示，最近吸引了很多关注。但是，大部分GNNs都是浅层模型，接受域有限，很难取得令人满意的表现，尤其在有标签节点数量很少的时候。为了解决这个问题，我们创新地提出了图小样本学习（GFL）算法，利用从辅助图中学习到的先验知识来提高目标图中的分类准确率。具体来说，利用结构化知识的可迁移性，辅助图和目标图共享一个由节点嵌入和图原型嵌入函数构成的可迁移度量空间。在真实图数据集上的大量实验表明我们提出的模型十分有效。 1.2 本文工作 图中的半监督节点分类问题时十分重要且具有挑战的，在标注数据（获取成本高）有限的情况下更是如此。最近，GNN通过聚合邻居信息来不断更新节点特征，在这些任务中取得了不错的表现。但是随着层数增加，GNN训练难度加大，并且会出现过平滑问题，这限制了GNN的表现。尤其在有标签数据很少的情况下，GNNs无法获取足够多的的全局信息，表现很差。 受小样本学习的启发，本文作者希望利用从辅助图中学习到的知识来提高目标图中节点分类的准确性。其背后的想法是：辅助图和目标图之间很可能共享局部拓补结构和类相关的节点特征。 最近小样本学习的两个方向是：gradient-based方法和metric-based方法，前者将可迁移的知识视作初始参数，后者将可迁移的知识视作一个度量空间。本文作者提出了一种基于度量学习的原生的图小样本学习模型GFL。 GFL学习一个可迁移的度量空间，节点的标签被预测为距离最近的类原型所代表的类别。度量空间通过两个嵌入函数来刻画：节点嵌入和类别原型。具体来说： GFL首先通过图自编码器（GNN为骨架）学习每个节点的表示 然后为了更好地捕捉全局信息，作者为每个类别构建一个关系结构，通过prototype GNN来学习每个类别的原型。 最重要的是这两个嵌入函数都编码了从辅助图中学习到的结构知识，以此来弥补标注数据不足的问题。除了这两个节点层面的结构，作者还通过一个层次图门来描述graph-level的表示，进一步强化“相似的图有相似的度量空间”。 1.3 问题定义 按照ε\\varepsilonε概率分布采样一系列图{G1,...,GNt}\\{\\mathcal G_1,...,\\mathcal G_{N_t}\\}{G1​,...,GNt​​}，每个图Gi∼ε\\mathcal G_i\\sim\\varepsilonGi​∼ε，且提供少量nsin^{s_i}nsi​个有标签节点support集合Si={(xi,jsi,yi,jsi)}j=1nsiS_i=\\{(x_{i,j}^{s_i},y_{i,j}^{s_i})\\}_{j=1}^{n^{s_i}}Si​={(xi,jsi​​,yi,jsi​​)}j=1nsi​​和query节点集合Qi={(xi,jqi,yi,jqi)}j=1nqiQ_i=\\{(x_{i,j}^{q_i},y_{i,j}^{q_i})\\}_{j=1}^{n^{q_i}}Qi​={(xi,jqi​​,yi,jqi​​)}j=1nqi​​。Query集QiQ_iQi​中的每个节点jjj，我们假设可以通过相似度量ddd来关联其节点嵌入fθ(A,xi,jqi):Rh→Rh′f_\\theta(A,x_{i,j}^{q_i}):\\mathbb R^h\\rightarrow \\mathbb R^{h&#x27;}fθ​(A,xi,jqi​​):Rh→Rh′和支持集中的表示(fθ(A,xi,jsi),yi,jsi)(f_\\theta(A,x_{i,j}^{s_i}),y_{i,j}^{s_i})(fθ​(A,xi,jsi​​),yi,jsi​​)，以此预测节点jjj对应的label。 具体来说，在原型网络中，类别kkk的原型ciKc_i^KciK​定义为cik=∑xi,jsi∈Sikfθ(A,xi,jsi)/∣Sik∣c_i^k=\\sum_{x_{i,j}^{s_i}\\in S_i^k}f_\\theta(A,x_{i,j}^{s_i})/|S_i^k|cik​=∑xi,jsi​​∈Sik​​fθ​(A,xi,jsi​​)/∣Sik​∣（就是类别k下所有节点表示的平均值）。对于图Gi\\mathcal G_iGi​，其查询集QiQ_iQi​上的损失定义为Li=∑kLik\\mathcal L_i=\\sum_k\\mathcal L_i^kLi​=∑k​Lik​，其中： Lik=−∑(xi,jqi,yi,jqi)∈Qiklogexp(−d(fθ(A,xi,jqi),cik))∑k′exp(−d(fθ(A,xi,jqi),cik′))\\mathcal L_i^k=-\\sum\\limits_{(x_{i,j}^{q_i},y_{i,j}^{q_i})\\in Q_i^k}log\\frac{exp(-d(f_\\theta(A,x_{i,j}^{q_i}),c_i^k))}{\\sum_{k&#x27;}exp(-d(f_\\theta(A,x_{i,j}^{q_i}),c_i^{k&#x27;}))} Lik​=−(xi,jqi​​,yi,jqi​​)∈Qik​∑​log∑k′​exp(−d(fθ​(A,xi,jqi​​),cik′​))exp(−d(fθ​(A,xi,jqi​​),cik​))​ 在训练阶段，嵌入函数fθf_\\thetafθ​的参数通过minθ∑i=1NtLimin_\\theta\\sum_{i=1}^{N_t}\\mathcal L_iminθ​∑i=1Nt​​Li​来优化。训练完毕后，给定一个只有少量support nodes的新图Gt\\mathcal G_tGt​，学习到的嵌入函数可以用来提高学习效率。 2. 方法 GFL架构如上图所示，共包含三个组件：graph structured prototype，hierachical graph representation gate和auxiliary graph reconstruction。 2.1 Graph Structured Prototype 总结：在属于同一类别的节点之间构建关系结构R，并将GNN模型应用于R进一步完善节点表示。随后根据原型网络（小样本中的方法）思想，计算每个类别原型c。 大多数情况下，图中一个节点扮演**两个重要角色**： 一个是和邻居（可能属于不同类别）之间的局部交互（embedding结果ZiZ_iZi​来描述这种局部信息） 另一个是和同类别节点（距离可能相对较远）之间的交互（作者通过prototype GNN模型来对支持集节点之间的关系结构建模，并学习其原型） 给定每个节点的表示，首先提取属于类别k的所有样本的关系结构。对于每一个图Gi\\mathcal G_iGi​，样本集SikS_i^kSik​的关系结构构建方法为： 基于一些相似度度量，比如k-hop共同邻居的数量。为了提高RikR_i^kRik​的稳定性，避免异常节点的影响，本文中作者引入了一个阈值μ\\muμ，如果两个节点之间的相似度小于μ\\muμ，那么边权重设置为一个固定值μ0\\mu_0μ0​。 然后，作者通过PGNN模型对相同类别间的节点的关系进行建模，对原始节点嵌入进一步优化PGNNϕ(Rik,fθ(Sik))PGNN_\\phi(\\mathcal R^k_i,f_\\theta(S_i^k))PGNNϕ​(Rik​,fθ​(Sik​))，其中PGNN的参数为ϕ\\phiϕ，这是一个全局共享的参数。 类别原型计算方法如下，jjj表示j-th节点的表示： cik=Poolj=1nsik(PGNNϕ(Rik,fθ(Sik))[j])c_i^k=Pool_{j=1}^{n^{s_i^k}}(PGNN_\\phi(\\mathcal R_i^k,f_\\theta(S_i^k))[j]) cik​=Poolj=1nsik​​(PGNNϕ​(Rik​,fθ​(Sik​))[j]) 其中PoolPoolPool表示最大或这平均池化操作，nsikn^{s_i^k}nsik​表示SikS_i^kSik​中节点数量。 2.2 Hierachical Graph Representation Gate 总结：2.1节中类别原型的计算高度依赖PGNN模型，而PGNN的参数ϕ\\phiϕ是全局共享的。考虑到不同图可能有不同的拓扑结构，所以作者参照Diffpool学习每个图的层级表示hhh，然后通过门函数将其于ϕ\\phiϕ融合到一起形成新的参数ϕ′\\phi&#x27;ϕ′，这样每个图都有自己独特的PGNN参数ϕ′\\phi&#x27;ϕ′，可以学到作者所谓的graph-specific信息。 如上图所示，层级图模型和Diffpool中的类似，包含Node Assignment和Representation Fusion两部分。 Node Assignment 该阶段学习一个从当前层节点映射到下一层节点的分配概率矩阵。KrK^rKr表示第r层图的节点数，XirX_i^rXir​表示特征矩阵，AirA_i^rAir​表示邻接矩阵，从krk^rkr节点到kr+1k^{r+1}kr+1节点的assignment value计算方法如下： pikr→kr+1=exp(AGNN(Air,Xir)[kr,kr+1])∑kˉr+1=1Kr+1exp(AGNN(Air,Xir)[kr,kˉr+1])p_i^{k^r\\rightarrow k^{r+1}}=\\frac{exp(AGNN(A_i^r,X_i^r)[k^r,k^{r+1}])}{\\sum_{\\bar k^{r+1}=1}^{K^{r+1}}exp(AGNN(A_i^r,X_i^r)[k^r,\\bar k^{r+1}])} pikr→kr+1​=∑kˉr+1=1Kr+1​exp(AGNN(Air​,Xir​)[kr,kˉr+1])exp(AGNN(Air​,Xir​)[kr,kr+1])​ 其中exp(AGNN(Air,Xir)[kr,kr+1])∈R1exp(AGNN(A_i^r,X_i^r)[k^r,k^{r+1}])\\in\\mathbb R^1exp(AGNN(Air​,Xir​)[kr,kr+1])∈R1表示从rrr层krk^rkr节点到r+1r+1r+1层kr+1k^{r+1}kr+1的分配概率，整个rrr层到r+1r+1r+1层的分配矩阵为Pir→r+1∈RKr×Kr+1P^{r\\rightarrow r+1}_i\\in\\mathbb R^{K^r\\times K^{r+1}}Pir→r+1​∈RKr×Kr+1。 Representation Fusion 得到assignment矩阵Pir→r+1P_i^{r\\rightarrow r+1}Pir→r+1​后，r+1r+1r+1层的邻接矩阵Air+1=(Pir→r+1)TAirPir→r+1A_i^{r+1}=(P_i^{r\\rightarrow r+1})^TA_i^rP_i^{r\\rightarrow r+1}Air+1​=(Pir→r+1​)TAir​Pir→r+1​，特征矩阵Xir+1=(Pir→r+1)TFGNN(Air,Xir)X_i^{r+1}=(P_i^{r\\rightarrow r+1})^TFGNN(A_i^r,X_i^r)Xir+1​=(Pir→r+1​)TFGNN(Air​,Xir​)。 这样聚合r+1r+1r+1层所有节点的特征表示就是该层整图的特征表示： hir+1=Poolkr+1=1Kr+1((Pir→r+1)TFGNN(Air,Xir)[kr+1])h_i^{r+1}=Pool_{k^{r+1}=1}^{K^{r+1}}((P_i^{r\\rightarrow r+1})^TFGNN(A_i^r,X_i^r)[k^{r+1}]) hir+1​=Poolkr+1=1Kr+1​((Pir→r+1​)TFGNN(Air​,Xir​)[kr+1]) 得到所有层的图表示{hi1,...,hiR}\\{h_i^1,...,h_i^R\\}{hi1​,...,hiR​}后，在通过聚合其将所有表示聚合到一起作为最终的表示。本文采用的聚合方式是加权聚合，权重向量qiq_iqi​是可学习参数： hi=AGGatt({hi1,...,hiR})=∑r=1Rβirhir=∑r=1RqiThir∑r′=1RqiThir′hirh_i=AGG_{att}(\\{h_i^1,...,h_i^R\\})=\\sum\\limits_{r=1}^R\\beta_i^rh_i^r=\\sum\\limits_{r=1}^R\\frac{q_i^Th_i^r}{\\sum_{r&#x27;=1}^Rq_i^Th_i^{r&#x27;}}h_i^r hi​=AGGatt​({hi1​,...,hiR​})=r=1∑R​βir​hir​=r=1∑R​∑r′=1R​qiT​hir′​qiT​hir​​hir​ 得到最终图层级表示hih_ihi​后，作者引入门函数将其和PGNN参数ϕ\\phiϕ融合到一起，得到graph-specific参数ϕi\\phi_iϕi​： ϕi=gi∘ϕ=T(hi)∘ϕ\\phi_i=g_i\\circ\\phi=\\mathcal T(h_i)\\circ\\phi ϕi​=gi​∘ϕ=T(hi​)∘ϕ 其中∘\\circ∘表示element-wise乘法，gi=T(hi)=σ(Wghi+bg)g_i=\\mathcal T(h_i)=\\sigma(W_gh_i+b_g)gi​=T(hi​)=σ(Wg​hi​+bg​)，WgW_gWg​和bgb_gbg​是可学习参数。 2.3 Auxiliary Graph Recontruction 在实际中，只通过类别匹配的损失函数很难学习到非常有效的节点表示，这激励这我们要设计一个新约束条件来训练稳定、高质量的节点表示。因此，对于节点嵌入函数，我们使用一个图自编码器对其进行优化，重构损失定义如下： Lr(Ai,Xi)=∣∣Ai−GNNdec(Zi)GNNdecT(Zi)∣∣F2\\mathcal L_r(A_i,X_i)=||A_i-GNN_{dec}(Z_i)GNN^T_{dec}(Z_i)||_F^2 Lr​(Ai​,Xi​)=∣∣Ai​−GNNdec​(Zi​)GNNdecT​(Zi​)∣∣F2​ 其中Zi=GNNenc(Ai,Hi)Z_i=GNN_{enc}(A_i,H_i)Zi​=GNNenc​(Ai​,Hi​)是每个节点的表示。回顾1.3问题定义中定义的损失函数，这样GFL的整体优化目标就是minΘ∑i=1NtLi+γLr(Ai,Xi)min_\\Theta\\sum_{i=1}^{N_t}\\mathcal L_i+\\gamma\\mathcal L_r(A_i,X_i)minΘ​∑i=1Nt​​Li​+γLr​(Ai​,Xi​)，Θ\\ThetaΘ表示所有的可学习参数。 3. 实验 3.1 数据集 3.2 实验设置 每个图中每个类别有N个有标签节点作为Support集，其余的节点作为query节点用于评估表现。 节点初始嵌入是通过一个2层GCN得到的，每层32个神经元。 PGNN，AGNN和FGNN都是一个单层GCN。 节点和类别原型之间的距离度量d是内积距离。 GFL-mean表示聚合层次图表示的时候采用平均池化聚合，GFL-att表示使用注意力加权聚合。 3.3 实验目的 GFL表现是否优于baseline方法？ 图结构原型和层次图表示门是否提高了模型的表现？ GFL模型学到的节点表示是否由于其他模型？ 一些敏感性实验 Support集的大小 阈值μ\\muμ 构造关系结构R时的相似度函数 计算节点和类原型间距离的函数d","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"原型网络","slug":"原型网络","permalink":"http://rookieyin.github.io/tags/%E5%8E%9F%E5%9E%8B%E7%BD%91%E7%BB%9C/"}]},{"title":"Heterogeneous graph neural networks for noisy few-shot relation classification","slug":"3 论文笔记/小样本图学习/3.Heterogeneous graph neural networks for noisy few-shot relation","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.877Z","comments":true,"path":"7a5512915802/","link":"","permalink":"http://rookieyin.github.io/7a5512915802/","excerpt":"https://reader.elsevier.com/reader/sd/pii/S0950705120300447 Heterogeneous graph neural networks for noisy few-shot relation classification 未完待续","text":"https://reader.elsevier.com/reader/sd/pii/S0950705120300447 Heterogeneous graph neural networks for noisy few-shot relation classification 未完待续 1. 简介 1.1 摘要 Relation classification is an essential and fundamental task in natural language processing. Distant supervised methods have achieved great success on relation classification, which improve the per-formance of the task through automatically extending the dataset. However, the distant supervisedmethods also bring the problem of wrong labeling. Inspired by people learning new knowledge fromonly a few samples, we focus on predicting formerly unseen classes with a few labeled data. In thispaper, we propose a heterogeneous graph neural network for few-shot relation classification, whichcontains sentence nodes and entity nodes. We build the heterogeneous graph based on the messagepassing between entity nodes and sentence nodes in the graph, which can capture rich neighborhoodinformation of the graph. Besides, we introduce adversarial learning for training a robust model andevaluate our heterogeneous graph neural networks under the scene of introducing different rates ofnoise data. Experimental results have demonstrated that our model outperforms the state-of-the-artbaseline models on the FewRel dataset. 关系分类是NLP中一项非常重要且基础的任务。远程监督方法通过自动扩展数据集来提高模型表现，在关系分类任务中取得了很好地表现。但是远程监督方法也存在一些问题——错误判别标签。受人类只需从少量样本中学习到知识启发，我们希望模型能够只通过少量有标签样本就能够识别之前未见过的类别样本。在这篇文章中我们提出了一种用于小样本关系分类的异构图神经网络，其包含句子节点和实体节点。我们基于图中实体节点和句子节点之间的消息传播构建了这个异构图，可以捕捉到图中丰富的邻居信息。另外，我们引入了对抗学习来提高模型稳定性，并且在引入不同比例噪声数据的场景下对我们的模型进行了评估。实验结果表明我们的模型在一些真实数据集上的表现要优于当前最好的方法。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}]},{"title":"Meta-Graph Few Shot Link Prediction Via Meta Learning","slug":"3 论文笔记/小样本图学习/6.Meta-Graph Few Shot Link Prediction Via Meta Learning","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.879Z","comments":true,"path":"3c8b6460d9e9/","link":"","permalink":"http://rookieyin.github.io/3c8b6460d9e9/","excerpt":"https://arxiv.org/pdf/1912.09867 https://github.com/joeybose/Meta-Graph Meta-Graph Few Shot Link Prediction Via Meta Learning，2019，arxiv e-preprint 总结：基于梯度的元学习+图签名函数，采用VGAE作为链路预测模型。基于梯度的元学习在多个任务之间学习一个共享参数使得使得新图上的VGAE具有一个较好的初始参数；图签名函数（GCN实现）为每个图学习一个图签名融合到VGAE模型使得每个图的VGAE模型graph specific化。","text":"https://arxiv.org/pdf/1912.09867 https://github.com/joeybose/Meta-Graph Meta-Graph Few Shot Link Prediction Via Meta Learning，2019，arxiv e-preprint 总结：基于梯度的元学习+图签名函数，采用VGAE作为链路预测模型。基于梯度的元学习在多个任务之间学习一个共享参数使得使得新图上的VGAE具有一个较好的初始参数；图签名函数（GCN实现）为每个图学习一个图签名融合到VGAE模型使得每个图的VGAE模型graph specific化。 1. 简介 1.1 摘要 We consider the task offew shot link prediction, where the goal is to predict missing edges across multiple graphs using only a small sample of known edges. We show that current link prediction methods are generally ill-equipped to handle thistask—as they cannot effectively transfer knowledge between graphs in a multi-graph setting and are unable to effectively learn from very sparse data. To address this challenge, we introduce a new gradient-based meta learning framework,Meta-Graph, that leverages higher-order gradients along with a learned graph signature function that conditionally generates a graph neural network initialization.Using a novel set of few shot link prediction benchmarks, we show that Meta-Graph enables not only fast adaptation but also better final convergence and can effectively learn using only a small sample of true edges. 本文作者考虑小样本链路预测任务，其目标是仅仅通过少量真实边就能够跨多个图正确预测图中缺失的边。现有的链路预测算法基本都难以处理这类问题，因为他们无法在不同的图之间传递知识，也无法仅仅通过少量真实边进行有效地学习。为了解决这个难题，本文作者提出了一种新的基于梯度的元学习架构Meta-Graph，它利用高阶梯度和图签名函数（对图神经网络进行条件初始化）。在一些小样本链路预测标准数据集上，实验结果表明Meta-Graph不仅可以快速适应新任务，还能得到一个比较好的收敛，仅仅通过少量真实边就能进行有效地预测。 1.2 本文工作 现有的链路预测算法通常都是在单个大型图上进行的，并且假设图相对完整（至少保留50%的边用于训练）。本文作者提出了针对小样本链路预测的模型，其目标是在多个只包含少量边的图上进行链路预测，应用于这样一个场景：可以获取到来自同一个域的大量图，但是每个图只包含少量真实边。例如在生物领域，不同的组织、细胞生物体之间存在交互反映形成相互作用网络，但是这些关系可能是noisy和sparse的，我们需要学习多个图之间的信息来克服这种稀疏性。 本文作者将传统小样本学习领域的基于梯度的元学习方法拓展到图上来，提出了一种新的架构Meta-Graph用于小样本链路预测。采样多个服从同一分布的图作为任务，学习一个全局参数集合，并应用策略来训练可以完成小样本链路预测任务的GNN。另外，为了让模型更快地适应新图，作者提出了一个图签名函数，根据输入图的结构对GNN链路预测模型进行初始化。 1.3 问题定义 假设存在一个图分布p(G)p(\\mathcal G)p(G)（比如从同一个大图中采样得到），随机采样图Gi∼p(G)\\mathcal G_i\\sim p(\\mathcal G)Gi​∼p(G)用于训练，图Gi\\mathcal G_iGi​定义为Gi=(Vi,Ei,Xi)\\mathcal G_i=(\\mathcal V_i,\\mathcal E_i, X_i)Gi​=(Vi​,Ei​,Xi​)，Vi\\mathcal V_iVi​和Ei\\mathcal E_iEi​分别表示节点集合和边集合，Xi∈R∣Vi∣×dX_i\\in\\mathbb R^{|\\mathcal V_i|\\times d}Xi​∈R∣Vi​∣×d表示节点属性。 假设采样的每个图Gi\\mathcal G_iGi​都是一个简单图，即只包含一种类型的关系且不存在self-loop，图中的每个节点v∈Viv\\in\\mathcal V_iv∈Vi​都存在一个来自同一个向量空间的属性向量xv∈Rdx_v\\in\\mathbb R^dxv​∈Rd。 假设训练期间，对于每个Gi\\mathcal G_iGi​只要少量边可见，即Eitrain⊂E\\mathcal E_i^{train}\\subset\\mathcal EEitrain​⊂E，且∣Eitrain∣&lt;&lt;∣Ei∣|\\mathcal E_i^{train}|&lt;&lt;|\\mathcal E_i|∣Eitrain​∣&lt;&lt;∣Ei​∣。 学习目标：利用Gi∼p(G),i=1...n\\mathcal G_i\\sim p(\\mathcal G),i=1...nGi​∼p(G),i=1...n训练Meta-Graph，可以快速在一个新图上G∗∼p(G)\\mathcal G_*\\sim p(\\mathcal G)G∗​∼p(G)有效地实现链路预测。具体来说就是学习到一个全局参数集合θ\\thetaθ和一个图签名函数ϕ(G∗)\\mathcal \\phi(\\mathcal G_*)ϕ(G∗​)，生成一个有效的初始参数ϕ∗\\phi_*ϕ∗​，用于图G∗\\mathcal G_*G∗​上进行链路预测。 对比传统链路预测 Meta-Graph不是在单个图上学习，而是从来自同一个分布域的多个图{G1,...,Gn}\\{\\mathcal G_1,...,\\mathcal G_n\\}{G1​,...,Gn​}上学习。 小样本，假设只有非常少量的边在训练是可见≤0.3\\leq0.3≤0.3（传统的通常≥0.5\\geq0.5≥0.5）。 区分global参数（对图之间的一些共性知识进行编码，图的潜在分布）和local参数（针对某个图进行优化），这策略让我们可以兼顾图之间的共性知识和每个图特有的知识。 2. 方法 分两部分：Local链路预测模型（针对每个图）；global模型（基于梯度的元学习）。 Meta-Graph的核心思想是使用基于梯度的元学习方法为local模型学习一个全局共享参数，同时为每个图Gi\\mathcal G_iGi​学习一个编码器，对初始参数进行graph-specific调整。 2.1 局部链路预测模型 本文使用变分图自编码器VGAEs作为链路预测架构的基础。给定图G=(V,A,X)\\mathcal G=(\\mathcal V,A,X)G=(V,A,X)，VGAE学习一个预测模型qϕ(Z∣A,X)q_\\phi(Z|A,X)qϕ​(Z∣A,X)，Z∈R∣V∣×dZ\\in\\mathbb R^{|\\mathcal V|\\times d}Z∈R∣V∣×d的每一行zv∈Rdz_v\\in\\mathbb R^dzv​∈Rd表示节点嵌入，可以用来评估两个节点之间是否存在边。定义qϕ(zv∣A,X)=N(zv∣μv,diag⁡(σv2))q_{\\phi}\\left(z_{v} \\mid A, X\\right)=\\mathcal{N}\\left(z_{v} \\mid \\mu_{v}, \\operatorname{diag}\\left(\\sigma_{v}^{2}\\right)\\right)qϕ​(zv​∣A,X)=N(zv​∣μv​,diag(σv2​))，其中正态分布的参数通过GNNs学习得到： μ=GNN⁡μ(A,X), and log⁡(σ)=GNN⁡σ(A,X)(1)\\mu=\\operatorname{GNN}_{\\mu}(A, X), \\quad \\text { and } \\quad \\log (\\sigma)=\\operatorname{GNN}_{\\sigma}(A, X)\\tag 1 μ=GNNμ​(A,X), and log(σ)=GNNσ​(A,X)(1) VGAE的生成器定义为： p(A∣Z)=∏i=1N∏j=1Np(Au,v∣zu,zv) with p(Au,v∣zu,zv)=σ(zu⊤zv)(2)\\begin{aligned} &amp;p(A \\mid Z)=\\prod_{i=1}^{N} \\prod_{j=1}^{N} p\\left(A_{u, v} \\mid z_{u}, z_{v}\\right) &amp;\\text { with } \\quad p\\left(A_{u, v} \\mid z_{u}, z_{v}\\right)=\\sigma\\left(z_{u}^{\\top} z_{v}\\right) \\end{aligned}\\tag 2 ​p(A∣Z)=i=1∏N​j=1∏N​p(Au,v​∣zu​,zv​)​ with p(Au,v​∣zu​,zv​)=σ(zu⊤​zv​)​(2) 节点u和v之间是否存在一条边和节点嵌入的点积成正比。这样负责预测的GNN模型的优化函数定义为： LG=Eqϕ[log⁡p(Atrain ∣Z)]−KL[qϕ(Z∣X,Atrain )∥p(z)](3)\\mathcal{L}_{G}=\\mathbb{E}_{q_{\\phi}}\\left[\\log p\\left(A^{\\text {train }} \\mid Z\\right)\\right]-K L\\left[q_{\\phi}\\left(Z \\mid X, A^{\\text {train }}\\right) \\| p(z)\\right]\\tag 3 LG​=Eqϕ​​[logp(Atrain ∣Z)]−KL[qϕ​(Z∣X,Atrain )∥p(z)](3) 2.2 整体架构 Meta-Graph的核心思想就是：**基于梯度的元学习方法优化一个共享的用于VGAE的初始参数$\\theta$，同时也学习一个图编码函数$\\psi\\left(\\mathcal{G}_{i}\\right)$对初始参数$\\theta$进行调整，使其graph-specific化。**具体来说，利用下面两个模块为每个图$\\mathcal G_i$上的VGAE模型分配一个特有的初始化参数$q_{\\phi_i}$用于链路预测： 全局共享的初始参数θ\\thetaθ，通过元学习获得，采用二阶梯度下降进行优化，为所有图提供一个有效的初始化参数点。 图签名函数sGi=ψ(Gi)s_{\\mathcal{G}_{i}}=\\psi\\left(\\mathcal{G}_{i}\\right)sGi​​=ψ(Gi​)，调整推理模型的参数ϕi\\phi_iϕi​。调整推理模型为qϕi(Z∣A,X,sGi)q_{\\phi_{i}}\\left(Z \\mid A, X, s_{\\mathcal{G}_{i}}\\right)qϕi​​(Z∣A,X,sGi​​)，把图的签名sGis_{\\mathcal G_i}sGi​​作为条件输入。作者采用k层GCN计算图签名： sG=ψ(G)=MLP⁡(∑v∈Vzv) with Z=GCN⁡(A,X)(4)\\begin{aligned} &amp;s_{\\mathcal{G}}=\\psi(\\mathcal{G})=\\operatorname{MLP}\\left(\\sum_{v \\in \\mathcal{V}} z_{v}\\right) &amp;\\text { with } \\quad Z=\\operatorname{GCN}(A, X) \\end{aligned}\\tag 4 ​sG​=ψ(G)=MLP(v∈V∑​zv​)​ with Z=GCN(A,X)​(4) 其中GCN表示k层卷积神经网络，MLP表示全连接层神经网络。和全局参数θ\\thetaθ一样，图签名模型ψ\\psiψ也是通过二阶梯度下降进行优化。 1. 采样一个batch的训练图 2. 使用全局参数$\\theta$和图签名$\\psi$初始化每个图的链路预测模型VGAE 3. 对VGAE模型执行K次梯度下降（这里冻结$s_\\mathcal G$） 4. 添加验证集的边后采用二阶梯度下降法优化全局参数$\\theta$和签名函数 2.3 Meta-Graph的变体 在具体实现Meta-Graph架构的时候，作者考虑了几种不同的将图签名函数用到VGAE的方式。对于所有变体，都是采用标准的GCN作为VGAE的骨架，按照如下方式堆叠K层： hv(k)=ReLU⁡(∑u∈N(v)∪{v}msG(W(k)hu(k−1))∣N(v)∣∣N(u)∣)(5)h_{v}^{(k)}=\\operatorname{ReLU}\\left(\\sum_{u \\in \\mathcal{N}(v) \\cup\\{v\\}} \\frac{m_{s_{\\mathcal{G}}}\\left(W^{(k)} h_{u}^{(k-1)}\\right)}{\\sqrt{|\\mathcal{N}(v)||\\mathcal{N}(u)|}}\\right)\\tag 5 hv(k)​=ReLU⎝⎜⎛​u∈N(v)∪{v}∑​∣N(v)∣∣N(u)∣​msG​​(W(k)hu(k−1)​)​⎠⎟⎞​(5) 上面公式和标准GCN传播方法最大的不同就是加了一个调整函数msGm_{s_\\mathcal G}msG​​，用图签名对传播的消息进行调整。直觉上，作者是希望图签名能够编码图结构信息，然后用图签名调整VGAE模型的参数，使其适应于当前的图。 2.3.1 GS-Modulation 受 Gnn-film启发，采用basic feature-wise linear modulation定义调整函数msGm_{s_\\mathcal G}msG​​： βk,γk,=ψ(G)mβk,γk(W(k)hu(k−1))=γk⊙Wh(k−1)+βk(6)\\begin{array}{c} \\beta_{k}, \\gamma_{k},=\\psi(\\mathcal{G}) \\\\ m_{\\beta_{k}, \\gamma_{k}}\\left(W^{(k)} h_{u}^{(k-1)}\\right)=\\gamma_{k} \\odot W h^{(k-1)}+\\beta_{k} \\end{array}\\tag 6 βk​,γk​,=ψ(G)mβk​,γk​​(W(k)hu(k−1)​)=γk​⊙Wh(k−1)+βk​​(6) 这里通过对公式4的输出添加tanh函数，限制βk\\beta_kβk​和γk\\gamma_kγk​的范围为[−1,1][-1,1][−1,1]。 2.3.2 GS-Gating 公式6定义的调整函数比较简单、直观，但是存在一个问题就是“always on”，有时候这种调节可能对学习起到反作用。为了让模型能够自适应的进行调整，对feature-wise线性调整做了改进，增加一个gating term ρk\\rho_kρk​： βk,γk,ρk=ψ(G)βk=ρk⊙βk+(1−ρk)⊙1γk=ρk⊙γk+(1−ρk)⊙1mβk,γk(W(k)hu(k−1))=γk⊙Wh(k−1)+βk\\begin{aligned} \\beta_{k}, \\gamma_{k}, \\rho_{k} &amp;=\\psi(\\mathcal{G}) \\\\ \\beta_{k} &amp;=\\rho_{k} \\odot \\beta_{k}+\\left(\\mathbb{1}-\\rho_{k}\\right) \\odot \\mathbb{1} \\\\ \\gamma_{k} &amp;=\\rho_{k} \\odot \\gamma_{k}+\\left(\\mathbb{1}-\\rho_{k}\\right) \\odot \\mathbb{1} \\\\ m_{\\beta_{k}, \\gamma_{k}}\\left(W^{(k)} h_{u}^{(k-1)}\\right) &amp;=\\gamma_{k} \\odot W h^{(k-1)}+\\beta_{k} \\end{aligned} βk​,γk​,ρk​βk​γk​mβk​,γk​​(W(k)hu(k−1)​)​=ψ(G)=ρk​⊙βk​+(1−ρk​)⊙1=ρk​⊙γk​+(1−ρk​)⊙1=γk​⊙Wh(k−1)+βk​​ 2.3.3 GS-Weights 结合gating思想和feature-wise线性调整思想，分别求出调整前和调整后的信息，然后通过门向量将两者结合到一起： βk,γk,ρk=ψ(G)hv(k),1=ReLU⁡(∑u∈N(v)∪{v}W(k)hu(k−1)∣N(v)∥N(u)∣)hv(k),2=ReLU⁡(∑u∈N(v)∪{v}msβk,γk(W(k)hu(k−1))∣N(v)∥N(u)∣)hv(k)=ρk⊙hv(k),1+(I−ρk)⊙hv(k),2,\\begin{aligned} \\beta_{k}, \\gamma_{k}, \\rho_{k} &amp;=\\psi(\\mathcal{G}) \\\\ h_{v}^{(k), 1} &amp;=\\operatorname{ReLU}\\left(\\sum_{u \\in \\mathcal{N}(v) \\cup\\{v\\}} \\frac{W^{(k)} h_{u}^{(k-1)}}{\\sqrt{|\\mathcal{N}(v) \\| \\mathcal{N}(u)|}}\\right) \\\\ h_{v}^{(k), 2} &amp;=\\operatorname{ReLU}\\left(\\sum_{u \\in \\mathcal{N}(v) \\cup\\{v\\}} \\frac{m_{s_{\\beta_{k}, \\gamma_{k}}}\\left(W^{(k)} h_{u}^{(k-1)}\\right)}{\\sqrt{|\\mathcal{N}(v) \\| \\mathcal{N}(u)|}}\\right) \\\\ h_{v}^{(k)} &amp;=\\rho_{k} \\odot h_{v}^{(k), 1}+\\left(\\mathbb{I}-\\rho_{k}\\right) \\odot h_{v}^{(k), 2}, \\end{aligned} βk​,γk​,ρk​hv(k),1​hv(k),2​hv(k)​​=ψ(G)=ReLU⎝⎜⎛​u∈N(v)∪{v}∑​∣N(v)∥N(u)∣​W(k)hu(k−1)​​⎠⎟⎞​=ReLU⎝⎜⎛​u∈N(v)∪{v}∑​∣N(v)∥N(u)∣​msβk​,γk​​​(W(k)hu(k−1)​)​⎠⎟⎞​=ρk​⊙hv(k),1​+(I−ρk​)⊙hv(k),2​,​ 3. 实验 设计了三个用于小样本链路预测任务的benchmark，三个benchmark中的图集合都是采样自同一个domain。80%的图用于训练，10%的图用于验证，这些图用来优化Meta-Graph的global参数和baseline的参数。剩余的10%的图用于测试，学习目标就是训练好的模型在测试图中能准确预测边。 一、数据集 PPI网络和3D点云数据FirstMMDB以及AMINER引用数据。 **二、baseline方法** 对Meta-Graph调整后作为baseline 直接使用MAML，预训练改进的VGAE（Finetune），直接将VGAE应用到每个测试图（No Finetune）。还有一些其他的Adamic和Deepwalk。 三、实验结果 实验部分主要研究四个问题： 和不同baseline方法相比，Meta-Graph的性能如何？ 在只保留10%的边的情况下，Meta-Graph仍然具有很强大的性能。在Ego-AMINER数据集上的实验结果比较奇怪，和另外两个数据集不同，保留更多的边模型性能并没有呈递增趋势。作者猜测可能是因为MAML中使用的高阶梯度优化是不稳定的，这在一定程度上抵消了GS-gating（不是很懂）。作者在附录中贴了另一个实验结果，在训练时使用更多的边，模型性能会随着边密度增大而变好。 Meta-Graph的快速适应能力如何？在测试图上Meta-Graph执行少量梯度下降后效果如何？ 模型执行5次梯度下降，发现Meta-Graph效果最好。同样地，在Ego-AMINER数据集上效果还是比较差。 下图展示了梯度下降过程中的AUC曲线，Meta-Graph少量梯度下降后就过拟合了需要提前终止梯度。 3. 图签名函数是否起到作用了？Meta-Graph的不同变体之间相比如何？ 图签名函数学到了什么？比如学习到的图签名和图的结构属性有什么关系或者对节点特征信息更敏感吗？","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Meta-GNN: On Few-shot Node Classification in Graph Meta-learning","slug":"3 论文笔记/小样本图学习/9.Meta-GNN On Few-shot Node Classfication in Graph Meta-Learning","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.881Z","comments":true,"path":"58fc871ab75a/","link":"","permalink":"http://rookieyin.github.io/58fc871ab75a/","excerpt":"https://dl.acm.org/doi/pdf/10.1145/3357384.3358106 https://github.com/ChengtaiCao/Meta-GNN Meta-GNN: On Few-shot Node Classification in Graph Meta-learning，CIKM，2019 总结：本篇文章非常简单，单纯的将MAML和GNN相结合解决图小样本节点分类问题。工作做得非常浅，论文正文只有3页多，但是胜在是第一篇将元学习拓展到图小样本学习领域的文章，所以文章也能发在CIKM上。另一点就是本文提供了实验源码可以参考一下。","text":"https://dl.acm.org/doi/pdf/10.1145/3357384.3358106 https://github.com/ChengtaiCao/Meta-GNN Meta-GNN: On Few-shot Node Classification in Graph Meta-learning，CIKM，2019 总结：本篇文章非常简单，单纯的将MAML和GNN相结合解决图小样本节点分类问题。工作做得非常浅，论文正文只有3页多，但是胜在是第一篇将元学习拓展到图小样本学习领域的文章，所以文章也能发在CIKM上。另一点就是本文提供了实验源码可以参考一下。 1. 简介 1.1 摘要 Meta-learning has received a tremendous recent attention as a possible approach for mimicking human intelligence, i.e., acquiring new knowledge and skills with little or even no demonstration. Most of the existing meta-learning methods are proposed to tackle few-shot learning problems such as image and text, in rather Euclidean domain. However, there are very few works applying meta-learning to non-Euclidean domains, and the recently proposed graph neural networks (GNNs) models do not perform effectively on graph fewshot learning problems. Towards this, we propose a novel graph meta-learning framework – Meta-GNN – to tackle the few-shot node classification problem in graph meta-learning settings. It obtains the prior knowledge of classifiers by training on many similar few-shot learning tasks and then classifies the nodes from new classes with only few labeled samples. Additionally, Meta-GNN is a general model that can be straightforwardly incorporated into any existing state-of-the-art GNN. Our experiments conducted on three benchmark datasets demonstrate that our proposed approach not only improves the node classification performance by a large margin on few-shot learning problems in meta-learning paradigm, but also learns a more general and flexible model for task adaption. 元学习作为模拟人类学习提供了一种可能的方式，即只需要少量训练就能够学习到新知识，近年来吸引了很多关注。现有的元学习方法大多用于欧式空间比如图像、文本中的小样本问题，目前只有少数方法将元学习应用到非欧式空间的小样本问题中。另外，最近比较火的GNNs在小样本场景下性能较差。基于此，本\\无作者提出了一种图元学习架构——Meta-GNN，来解决图元学习设定下的小样本节点分类问题。Meta-GNN利用在许多相似的小样本任务中学习先验知识，用于解决不可见类上的节点分类问题。另外，Meta-GNN是一个通用的模型，可以和任何现有的表现优良的GNN模型相结合。作者在三个标准数据集上的实验表明作者提出的方法不仅节点分类准确度高，还能学习一个更通用、灵活的任务自适应模型。 1.2 本文工作 本文提出的Meta-GNN架构是最早将元学习和GNNs相结合，用来解决图领域的小样本问题。 给定无向图G=(V,E, A,X)\\mathcal G=(V, E, \\mathrm{~A}, \\mathrm{X})G=(V,E, A,X)，其中V={v1,v2,…,vi,…,vn}V=\\left\\{v_{1}, v_{2}, \\ldots, v_{i}, \\ldots, v_{n}\\right\\}V={v1​,v2​,…,vi​,…,vn​}，E={ei,j=(vi,vj)}⊆(V×V)E=\\left\\{e_{i, j}=\\left(v_{i}, v_{j}\\right)\\right\\} \\subseteq(V \\times V)E={ei,j​=(vi​,vj​)}⊆(V×V)，邻接矩阵A∈Rn×n\\mathrm{A} \\in \\mathbb{R}^{n \\times n}A∈Rn×n，aija_{ij}aij​表示节点viv_ivi​和vjv_jvj​之间是否存在边，X∈Rn×aX \\in \\mathbb{R}^{n \\times a}X∈Rn×a是特征矩阵，xi∈Rdx_i\\in\\mathbb R^dxi​∈Rd表示节点viv_ivi​的特征向量。问题定义 学习目标：学习一个分类器，可以使用与训练期间未见到的新类别，且每个新类别只有少量样本。 训练期间所有节点viv_ivi​的类别都属于C1C_1C1​，模型学习一个分类器fθf_\\thetafθ​。测试阶段所有节点类别都属于C2C_2C2​，C2C_2C2​和C1C_1C1​中的类别完全不同，分类器要尽可能准确的判别测试集中无标签节点的类别。 如果每个类别中有标签节点的数量为K，该任务就称之为∣C2∣−way k−shot|C_2|-way\\ k-shot∣C2​∣−way k−shot学习问题，其中K的值很小。 2. 方法 通过GNN+MAML搭建Meta-GNN的框架，通过大量元训练任务使得模型能够快速适应只有少量有标签样本的新任务。 fθf_\\thetafθ​表示Meta-GNN模型，参数为θ\\thetaθ； Dtrain ={(x1,y1),…,(xi,yi),…,(xN,yN)}\\mathcal{D}_{\\text {train }}=\\left\\{\\left(x_{1}, y_{1}\\right), \\ldots,\\left(x_{i}, y_{i}\\right), \\ldots,\\left(x_{N}, y_{N}\\right)\\right\\}Dtrain ​={(x1​,y1​),…,(xi​,yi​),…,(xN​,yN​)}表示所有训练样本集合； Dtrain :T={T1,T2,⋯ ,TM}\\mathcal{D}_{\\text {train }}: \\mathcal{T}=\\left\\{\\mathcal{T}_{1}, \\mathcal{T}_{2}, \\cdots, \\mathcal{T}_{M}\\right\\}Dtrain ​:T={T1​,T2​,⋯,TM​}表示M个元任务，每个任务的支持集Si\\mathcal S_iSi​和查询集Qi\\mathcal Q_iQi​都采样自Dtrain \\mathcal{D}_{\\text {train }}Dtrain ​； 支持集Si={vi1,vi2,…,vis}={(xi1,yi1),(xi2,yi2),…,(xis,yis)}\\mathcal S_i=\\left\\{v_{i 1}, v_{i 2}, \\ldots, v_{i s}\\right\\}=\\left\\{\\left(x_{i 1}, y_{i 1}\\right),\\left(x_{i 2}, y_{i 2}\\right), \\ldots,\\left(x_{i s}, y_{i s}\\right)\\right\\}Si​={vi1​,vi2​,…,vis​}={(xi1​,yi1​),(xi2​,yi2​),…,(xis​,yis​)}，其中s=∣Si∣s=\\left|\\mathcal{S}_{i}\\right|s=∣Si​∣，xisx_{is}xis​和yisy_{is}yis​分别表示节点visv_{is}vis​的特征向量和标签。 Meta-GNN的整体框架如下图所示： 一、任务采样 C1C_1C1​表示所有类别，从C1C_1C1​中采样∣C2∣|C_2|∣C2​∣个类别，然后每个类别再分别采样K个节点，整个流程如下所示： ​ (1) C←C \\leftarrowC← RANDOMSAMPLE (C1,∣C2∣)\\left(C_{1},\\left|C_{2}\\right|\\right)(C1​,∣C2​∣); ​ (2) Si←\\mathcal{S}_{i} \\leftarrowSi​← RANDOMSAMPLE (DC,K×∣C2∣)\\left(\\mathcal{D}_{C}, K \\times\\left|C_{2}\\right|\\right)(DC​,K×∣C2​∣) ​ (3) Qi←Q_{i} \\leftarrowQi​← RANDOMSAMPLE (DC−Si,P)\\left(\\mathcal{D}_{C}-\\mathcal{S}_{i}, P\\right)(DC​−Si​,P); ​ (4) Ti=Si+Qi\\mathcal{T}_{i}=\\mathcal{S}_{i}+Q_{i}Ti​=Si​+Qi​ ​ (5) Repeat step (1) - (4) for MMM times; 二、元训练 分别使用采样到的元任务训练Meta-GNN，损失函数定义为交叉熵损失： LTl(fθ)=−(∑xis,yisyislog⁡fθ(xis)+(1−yis)log⁡(1−fθ(xis)))\\mathcal{L}_{T_{l}}\\left(f_{\\theta}\\right)=-\\left(\\sum_{\\boldsymbol{x}_{i s}, y_{i s}} y_{i s} \\log f_{\\theta}\\left(\\boldsymbol{x}_{i s}\\right)+\\left(1-y_{i s}\\right) \\log \\left(1-f_{\\theta}\\left(x_{i s}\\right)\\right)\\right) LTl​​(fθ​)=−(xis​,yis​∑​yis​logfθ​(xis​)+(1−yis​)log(1−fθ​(xis​))) 每个元任务上分别执行1次或多次如下的梯度更新： θi′=θ−α1∂LTi(fθ)∂θ\\theta_{i}^{\\prime}=\\theta-\\alpha_{1} \\frac{\\partial \\mathcal{L}_{\\mathcal{T}_{i}}\\left(f_{\\theta}\\right)}{\\partial \\theta} θi′​=θ−α1​∂θ∂LTi​​(fθ​)​ 所有元任务都完成一次训练后通常可以称之为一次内循环，所有元任务上的训练目标是： θ=arg⁡min⁡θ∑Ti∼p(T)LTi(fθi′)\\theta=\\underset{\\theta}{\\arg \\min } \\sum_{\\mathcal{T}_{i} \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_{i}}\\left(f_{\\theta_{i}^{\\prime}}\\right) θ=θargmin​Ti​∼p(T)∑​LTi​​(fθi′​​) 所有元任务上元训练的整体目标优化采用SGC方法，模型参数更新方式如下： θ←θ−α2∂∑Ti∼p(T)LTi(fθi′)∂θ\\theta \\leftarrow \\theta-\\alpha_{2} \\frac{\\partial \\sum \\mathcal{T}_{i \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{T}_{i}}\\left(f_{\\theta_{i}^{\\prime}}\\right)}{\\partial \\theta} θ←θ−α2​∂θ∂∑Ti∼p(T)​LTi​​(fθi′​​)​ 三、元测试 将新的小样本元学习任务Tmt\\mathcal T_{mt}Tmt​喂给Meta-GNN，使用查询集对Meta-GNN的参数进行微调，然后使用查询集对Meta-GNN进行评估即可。整个元训练和元测试的算法流程如下所示： 3. 实验 数据集采用：Cora、Citesser和Reddit，数据集划分如下： 其中∣C1∣|C_1|∣C1​∣表示用于元训练的类别数量，∣C2∣|C_2|∣C2​∣表示用于元测试的类别数量。 作者发现在有标签样本很少的情况下，模型性能对节点的选取十分敏感，因此作者每个模型都运行50次计算平均性能。实验结果如下：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Few-shot Lifelong Learning","slug":"3 论文笔记/小样本学习/1.Few-Shot Lifelong Learning","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.883Z","comments":true,"path":"7a615dfbd4a4/","link":"","permalink":"http://rookieyin.github.io/7a615dfbd4a4/","excerpt":"https://arxiv.org/pdf/2103.00991 Few-shot Lifelong Learning，AAAI，2021 总结：针对小样本下的class increatmental，或者称之为continual learning场景，作者提出了FSLL模型。为了模拟calss increatmental，作者设定了多个session，每个session类别集合都不相交。在session 1， 每个类别都有大量样本，按照常规小样本学习方式进行训练（即预训练模型）。在之后t&gt;1的每个session，每个数据集只包含C各类别，每个类别只有K个样本。为了实现continual learning，防止灾难遗忘并提高模型精确度，作者采取了四个措施：1. 部分更新参数，2.正则化，3.最大化原型距离，4.添加自监督辅助任务。","text":"https://arxiv.org/pdf/2103.00991 Few-shot Lifelong Learning，AAAI，2021 总结：针对小样本下的class increatmental，或者称之为continual learning场景，作者提出了FSLL模型。为了模拟calss increatmental，作者设定了多个session，每个session类别集合都不相交。在session 1， 每个类别都有大量样本，按照常规小样本学习方式进行训练（即预训练模型）。在之后t&gt;1的每个session，每个数据集只包含C各类别，每个类别只有K个样本。为了实现continual learning，防止灾难遗忘并提高模型精确度，作者采取了四个措施：1. 部分更新参数，2.正则化，3.最大化原型距离，4.添加自监督辅助任务。 1. 简介 1.1 摘要 Many realworld classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and maybe given incrementally. Deep learning models need to deal with this two fold problem in order to perform well in reallife situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong / continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the fullmodel. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset. 在许多真实分类问题中，经常出现只有少量有标签训练样本，甚至一些类别在训练时是unavailable的。为了能够适应这种场景，深度学习模型需要处理好这个two-fold问题。本文中，作者提出了一种原生的小样本学习算法，帮助深度学习模型在小样本场景下实现lifelong/continual学习。对于每个新的类别集合，作者的方法只选取模型少量参数用于训练而不是同时训练整个模型，这样可以有效防止过拟合。每轮参数选取的方式是：选取当前情景下不重要的那些参数。通过保持模型中重要参数不变，作者的方法可以最小化灾难遗忘。另外，作者通过最小化新类别原型和旧类别原型之间的余弦相似度来最大程度地分离它们，从而改善了分类性能。作者还表明了将自监督整合到他们的方法中可以有效提高模型性能。miniImageNet，CIFAR-100和CUB-200上的大量实验表明我们的方法由于现有方法，尤其在CUB数据集上的表现比当前最好方法高19%多。 1.2 本文工作 现实世界的深度学习任务面临两个问题：（1）有标签数据数量比较少，而人工标记的成本很大，这要求模型能够适应小样本场景；（2）不断有新的类别添加进来，因此需要模型能够lifelong/continual学习，来适应这种场景。 注：lifelong-learning，即在一系列类别互不相交的任务上训练模型，为所有类别学习一个通用的分类器，这种称之为class-incremental setting of lifelong learning；另一种更简单的设置是为每个任务单独学习一个分类器，称为task-incremental setting。 本文作者提出了一个用于小样本class-incremental学习的模型FSCIL。这种设定下，一方面由于只有少量有标签样本会导致模型过拟合；另一方面模型在新类别集合上训练时，不会接触到之前旧的类别，这会导致灾难遗忘。 1.3 问题定义 FSCIL设定下，有一系列有标签数据集D(1),D(2),⋅⋅⋅D^{(1)},D^{(2)},···D(1),D(2),⋅⋅⋅，其中D(t)={(xj(t),yj(t))}j=1∣D(t)∣D^{(t)}=\\{(x_j^{(t)},y_j^{(t)})\\}_{j=1}^{|D^{(t)}|}D(t)={(xj(t)​,yj(t)​)}j=1∣D(t)∣​。L(t)L^{(t)}L(t)表示第ttht^{th}tth训练集涉及到的类别集合，并且对于任意i≠ji\\neq ji​=j，L(i)∩L(j)=∅L^{(i)}\\cap L^{(j)}=\\emptyL(i)∩L(j)=∅。第一个训练集D(1)D^{(1)}D(1)每个类别都有充足的样本，其余的训练集D(t&gt;1)D^{(t&gt;1)}D(t&gt;1)，包含C个类别，每个类别包含K个样本。 模型依次在D(1),D(2),⋅⋅⋅D^{(1)},D^{(2)},···D(1),D(2),⋅⋅⋅上训练，并且D(t)D^{(t)}D(t)只出现在ttht^{th}tthtraining session。在D(t)D^{(t)}D(t)上训练完后，模型分别计算L(1),⋅⋅⋅,L(t)L^{(1)},···,L^{(t)}L(1),⋅⋅⋅,L(t)这t个类别集合上的损失。 2. 方法 网络包含两部分：ΘF\\Theta_FΘF​特征提取器，ΘC\\Theta_CΘC​全连接分类器。首先在D(1)D^{(1)}D(1)数据集上预训练，此时采用的就是常规的小样本学习模式，损失函数定义如下： LD(1)(x,y)=FCE(ΘC(ΘF(x)),y)(1)L_{D^{(1)}}(\\mathrm{x}, y)=F_{C E}\\left(\\Theta_{C}\\left(\\Theta_{F}(\\mathrm{x})\\right), y\\right)\\tag 1 LD(1)​(x,y)=FCE​(ΘC​(ΘF​(x)),y)(1) 其中(x,y)∈D(1)(x,y)\\in D^{(1)}(x,y)∈D(1)，FCEF_{CE}FCE​表示交叉熵损失。训练完毕后，丢弃ΘC\\Theta_CΘC​的参数，保留ΘF\\Theta_FΘF​参数用于作为其他数据集上的初始参数，并且基于此计算每个D(1)D^{(1)}D(1)中每个类别的原型： Pr⁡[c]=1Nc∑k=1NI(yk=c)(ΘF(xk))(2)\\operatorname{Pr}[c]=\\frac{1}{N_{c}} \\sum_{k=1}^{N} \\mathbb{I}_{\\left(y_{k}=c\\right)}\\left(\\Theta_{F}\\left(\\mathrm{x}_{k}\\right)\\right)\\tag 2 Pr[c]=Nc​1​k=1∑N​I(yk​=c)​(ΘF​(xk​))(2) 为了实现continual learning并进一步提高模型精度，作者使用了下面四种方法。 一、部分更新 在session t&gt;1t&gt;1t&gt;1阶段，选取ΘF\\Theta_FΘF​中少量不重要（绝对值小）的参数进行训练，称之为PSTtP_{ST}^tPSTt​。具体来说，为特征提取器ΘF\\Theta_FΘF​每一层分别设置一个阈值，将小于这个阈值的参数作为PSTtP_{ST}^tPSTt​，其余的参数作为知识参数保留，称之为PKRtP_{KR}^tPKRt​，在训练阶段PKRtP_{KR}^tPKRt​会被冻结。 由于在训练阶段只更新那些不重要的参数，因此这种方法能够最大程度保留之前训练过程中学习到的知识，缓解灾难遗忘。PSTtP_{ST}^tPSTt​采用三元损失方式进行训练： LTL(xi,xj,xk)=max⁡(d(ΘF(xi),ΘF(xj))−d(ΘF(xi),ΘF(xk)),0)(3)\\begin{array}{r} L_{T L}\\left(x_{i}, x_{j}, x_{k}\\right)=\\max \\left(d\\left(\\Theta_{F}\\left(x_{i}\\right), \\Theta_{F}\\left(x_{j}\\right)\\right)-\\right. \\\\ \\left.\\quad d\\left(\\Theta_{F}\\left(x_{i}\\right), \\Theta_{F}\\left(x_{k}\\right)\\right), 0\\right) \\end{array}\\tag 3 LTL​(xi​,xj​,xk​)=max(d(ΘF​(xi​),ΘF​(xj​))−d(ΘF​(xi​),ΘF​(xk​)),0)​(3) 其中xi,xj,xkx_i,x_j,x_kxi​,xj​,xk​为D(t&gt;1)D^{(t&gt;1)}D(t&gt;1)中的图片，yi=yj,yi≠yky_i=y_j,y_i\\neq y_kyi​=yj​,yi​​=yk​，LTLL_{TL}LTL​表示三元损失，ddd表示欧式距离。 二、正则化 作者还希望当前session中可训练参数能够被适度更新，即不要一下次变化太大。为了实现这一效果，作者对原始参数和更新后的参数添加了一个正则化损失： LRL=∑i=1Npt∥wit−wit−1∥1(4)L_{R L}=\\sum_{i=1}^{N_{p}^{t}}\\left\\|w_{i}^{t}-w_{i}^{t-1}\\right\\|_{1}\\tag 4 LRL​=i=1∑Npt​​∥∥∥​wit​−wit−1​∥∥∥​1​(4) 其中NptN_p^{t}Npt​表示当前session下可训练参数PST(t)P_{ST}^{(t)}PST(t)​的数量，witw_i^twit​和wit−1w_i^{t-1}wit−1​分别表示更新后和更新前的参数值。 三、最大化原型间距离 另外，为了提高模型性能，作者在不同类别原型之间添加一个余弦相似度损失，最小化older类别原型PrprevPr^{prev}Prprev和新类别PrtPr^tPrt原型之间的相似度： LCL=∑i=1NPrL∑j=1NPrprvFcos⁡(Pr⁡t[i],Pr⁡prev[j])(5)L_{C L}=\\sum_{i=1}^{N_{P r}^{L}} \\sum_{j=1}^{N_{P r}^{p r v}} F_{\\cos }\\left(\\operatorname{Pr}^{t}[i], \\operatorname{Pr}^{p r e v}[j]\\right)\\tag 5 LCL​=i=1∑NPrL​​j=1∑NPrprv​​Fcos​(Prt[i],Prprev[j])(5) 其中PrtPr^tPrt表示D(t)D^{(t)}D(t)中涉及的类别的原型，PrprevPr^{prev}Prprev表示之前训练过程中涉及到的所有类别的原型，FcosF_{cos}Fcos​表示余弦距离。 这样最终的模型损失函数定义为： L(D(t&gt;1))=LTL+LCL+λLRL(6)L\\left(D^{(t&gt;1)}\\right)=L_{T L}+L_{C L}+\\lambda L_{R L}\\tag 6 L(D(t&gt;1))=LTL​+LCL​+λLRL​(6) 其中λ\\lambdaλ为超参，决定正则损失的权重。 四、自监督辅助任务 作者在D(1)D^{(1)}D(1)数据集上添加一个辅助的自监督损失，进一步提高模型性能。具体来说，在ΘF\\Theta_FΘF​之后添加了一个和ΘC\\Theta_CΘC​并行的rotation预测网络ΘR\\Theta_RΘR​。通过将训练样本旋转0,90,180,270度，训练ΘR\\Theta_RΘR​来预测样本旋转角度。这样D(1)D^{(1)}D(1)上的整体损失定义如下： LD(1)(x,y)=FCE(ΘC(ΘF(x)),y)+FCE(ΘR(ΘF(x)),yr)(7)\\begin{array}{r} L_{D^{(1)}}(\\mathrm{x}, y)=F_{C E}\\left(\\Theta_{C}\\left(\\Theta_{F}(\\mathrm{x})\\right), y\\right)+ \\\\ F_{C E}\\left(\\Theta_{R}\\left(\\Theta_{F}(\\mathrm{x})\\right), y^{r}\\right) \\end{array}\\tag 7 LD(1)​(x,y)=FCE​(ΘC​(ΘF​(x)),y)+FCE​(ΘR​(ΘF​(x)),yr)​(7) 其中yTy^TyT表示图片旋转角度。 3. 实验 3.1 实验设置 一、数据集：CIFAR-100，miniImageNet，CUB-200 对于CIFAR-100，miniImageNet数据集，分别选取60、40个类别作为base classes和new classes。对于每个小样本训练集合，使用5-way 5-shot设定，因此一共有1个base training set和8个few-shot training set。 对于CUB-200，分别选取100、100个类别作为base classes和new classes。对于每个小样本训练集合，使用10-way 10-shot设定，因此一共有1个base training set和10个few-shot training set。 每个类别随机选取5个样本用于训练，其余样本用于测试。 二、实验细节 采用ResNet-18架构作为主体，ResNet-18的最后一层作为分类器ΘC\\Theta_CΘC​，其余层作为特征提取器ΘF\\Theta_FΘF​。 D(1)D^{(1)}D(1)数据集上的预训练：学习率0.1，mini-batch size128，30、40轮训练后学习率分别调低为0.01和0.001，训练50个epoch。训练完成后丢弃ΘC(1)\\Theta_C^{(1)}ΘC(1)​。 Dt&gt;1D^{t&gt;1}Dt&gt;1上微调特征提取器参数：训练30个epoch，学习率1e−41e^{-4}1e−4（1e−31e^{-3}1e−3 for CUB-200），每层删选参数的阈值为选取10%，mini-bath包含所有样本。 3.2 实验结果 一、CUB-200数据集 实验过程中，作者发现初始学习率设置为0.01效果有所提升。FSLL∗FSLL^*FSLL∗表示初始学习率设置为0.01；FSLL∗+SSFSLL^*+SSFSLL∗+SS表示使用自监督学习。 二、miniImageNet和CIFAR-100 3.3 消融实验 一、训练参数比例，去除正则化 session11下的实验结果，横轴表示该session下保留参数比例，纵轴表示精度，黑线表示去除正则化。 二、正则损失超参数 λ\\lambdaλ 三、余弦相似度损失的重要性 去掉余弦相似度后，CUB-200数据集S11S_{11}S11​上的准确度从45.55%降低到了44.32%。 四、自监督辅助任务 在t&gt;1的session中使用自监督辅助任务。session11上的准确度为54.34%低于55.82%，所以在t&gt;1的session中使用自监督学习没有效果。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"图像分类","slug":"图像分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"}]},{"title":"Free Lunch For Few-Shot Learning: Distribution Calibration","slug":"3 论文笔记/小样本学习/2.Free Lunch For Few-Shot Learning Distribution Calibration","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.885Z","comments":true,"path":"c4fbf25419fc/","link":"","permalink":"http://rookieyin.github.io/c4fbf25419fc/","excerpt":"https://arxiv.org/pdf/2101.06395v2.pdf https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration Free Lunch For Few-Shot Learning: Distribution Calibration，ICLR，2021 总结：迁移学习比较类似，从有充足样本的基类中学习特征分布，迁移到新类数据集，修正新类数据集特征分布，再从修正后的分布中做采样，生成大量样本用于分类器的训练。从迁移特征分布这个角度切入，再进行样本生成，感觉角度找的很好。","text":"https://arxiv.org/pdf/2101.06395v2.pdf https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration Free Lunch For Few-Shot Learning: Distribution Calibration，ICLR，2021 总结：迁移学习比较类似，从有充足样本的基类中学习特征分布，迁移到新类数据集，修正新类数据集特征分布，再从修正后的分布中做采样，生成大量样本用于分类器的训练。从迁移特征分布这个角度切入，再进行样本生成，感觉角度找的很好。 1. 简介 1.1 摘要 Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples.Then an adequate number of examples can be sampled from the calibrated dis-tribution to expand the inputs to the classifier. We assume every dimension inthe feature representation follows a Gaussian distribution so that the mean andthe variance of the distribution can borrow from that of similar classes whosestatistics are better estimated with an adequate number of samples. Our methodcan be built on top of off-the-shelf pretrained feature extractors and classifica-tion models without extra parameters. We show that a simple logistic regressionclassifier trained using the features sampled from our calibrated distribution canoutperform the state-of-the-art accuracy on three datasets (5% improvement onminiImageNet compared to the next best). The visualization of these generatedfeatures demonstrates that our calibrated distribution is an accurate estimation.The code is available at: https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration 从有限样本中学习知识是一个具有很大挑战的任务，因为基于少量样本形成的biased distribution很容易让模型过拟合。本文作者通过从具有充足样本的其他类别中迁移统计数据到只有少量样本的类别中，来修正biased distribution。然后可以从修正后的分布中采样充足样本来扩充输入到分类器中的样本数量。我们假设特征表示的每个维度都遵从高斯分布，这样分布的均值和方差就可以从那些具有充足样本的相似类别借用得到。我们的方法可以建立在预训练好的特征提取器和分类器上，无需额外参数。三个数据集上的实验表明，即使是简单地逻辑回归分类器，使用从我们修正后的分布中采样得到特征，其性能也优于当前最好方法（miniImageNet数据集上相比较当前最优方法提升5%）。对生成特征的可视化结果表明我们修正后的分布是准确的。 1.2 本文工作 在训练集样本数量很少的情况下，模型会出现过拟合问题，得到一个biased distribution，如下图所示： 本文作者希望通过修正得到的biased distribution，使其更接近真实的分布状态。然后从修正分布中采样样本，来训练模型，提高模型泛化能力。本文作者并不是修正原始数据空间的分布，而是尝试修正特征空间的分布，因为它维度更低，更容易修正。 作者假设：特征向量的每一个维度都服从高斯分布，并且相似的类别有相似均值和方差。 如下表所示，展示了不同类别样本特征分布之间的相似度： 这样我们就能在相似类别之间传递高斯分布的均值和方差。基于此，作者将有充足的样本类别中的特征分布迁移到小样本类别中，根据类别之间的相似度，来更好地估计小样本类别的特征分布。根据得到的分布，我们能采样到充足的样本来更好地训练分类模型。 3. 方法 3.1 问题定义 和典型的小样本分类一样。给定有标签数据集D={(xi,yi)}\\mathcal D=\\{(x_i,y_i)\\}D={(xi​,yi​)}，其中xi∈Rdx_i\\in\\mathbb R^dxi​∈Rd表示特征向量，yi∈Cy_i\\in Cyi​∈C表示样本类别标签。整个数据集被划分成两部分base classes CbC_bCb​和novel classes CnC_nCn​，并且Cb∩Cn=∅, Cb∪Cn=CC_b\\cap C_n=\\empty,\\ C_b\\cup C_n=CCb​∩Cn​=∅, Cb​∪Cn​=C。模型的目标是：在base classes上训练，在novel classes上能取得很好地效果。 为了评估模型的快速适应能力和泛化能力，和小样本其他方法一样，构建N-way-K-shot任务，每个任务中有support集合S={(xi,yi)}i=1N×KS=\\{(x_i,y_i)\\}_{i=1}^{N\\times K}S={(xi​,yi​)}i=1N×K​和query集合Q={(xi,yi}i=N×K+1N×K+N×qQ=\\{(x_i,y_i\\}_{i=N\\times K +1}^{N\\times K+N\\times q}Q={(xi​,yi​}i=N×K+1N×K+N×q​。 3.2 校正特征分布 根据前面的描述我们可以知道，如果假设样本特征分布服从高斯分布，那么特征分布的均值和方差和类别之间语义相似度是高度相关的。比如北极狐和白狼之间的特征分布就高度相似。 我们知道用于训练的base classes样本数量充足，基于此，如果我们能学习到不同类别之间的相似度的话，就可以将从基类样本中学习到的特征分布迁移到novel classes中。 现在需要讨论的问题有三个： 如何计算两个类别之间的语义相似度？ 如何利用base classes中学习到的特征分布，校准 classes中的特征分布? 如何利用校准后的特征分布提高小样本学习的性能？ 这三个问题弄清楚了，就理解了该论文中提出的方法。 一、计算样本特征 采用预训练好WideResNet计算样本特征向量。 二、计算特征分布 假定base calsses的特征服从高斯分布，base class i的特征分布计算方式如下： μi=∑j=1nixjni(1)\\boldsymbol{\\mu}_{i}=\\frac{\\sum_{j=1}^{n_{i}} \\boldsymbol{x}_{j}}{n_{i}}\\tag 1 μi​=ni​∑j=1ni​​xj​​(1) 其中xjx_jxj​表示类别iii下第j个样本的特征向量，nin_ini​表示类别iii下样本总数。因为特征向量xjx_jxj​通常都是多个维度的，因此采用covariance可以更好地表示特征分布的方差，协方差矩阵计算方式如下： Σi=1ni−1∑j=1ni(xj−μi)(xj−μi)T(2)\\boldsymbol{\\Sigma}_{i}=\\frac{1}{n_{i}-1} \\sum_{j=1}^{n_{i}}\\left(\\boldsymbol{x}_{j}-\\boldsymbol{\\mu}_{i}\\right)\\left(\\boldsymbol{x}_{j}-\\boldsymbol{\\mu}_{i}\\right)^{T}\\tag 2 Σi​=ni​−11​j=1∑ni​​(xj​−μi​)(xj​−μi​)T(2) 考虑从novel classes中采样的某个N-way-K-shot任务。 三、特征转换 为了让特征分布更Gaussian-like，作者采用Tukey‘s Ladder of Powers transformation技术（一系列幂变换来减少分布的偏态，使分布更像高斯分布）来调整样本特征。计算方法如下： x~={xλ if λ≠0log⁡(x) if λ=0(3)\\tilde{\\mathrm{x}}=\\left\\{\\begin{array}{ll} \\boldsymbol{x}^{\\lambda} &amp; \\text { if } \\lambda \\neq 0 \\\\ \\log (\\boldsymbol{x}) &amp; \\text { if } \\lambda=0 \\end{array}\\right.\\tag 3 x~={xλlog(x)​ if λ​=0 if λ=0​(3) 其中λ\\lambdaλ为超参，如果λ=1\\lambda = 1λ=1，则表示不对特征进行调整，减小λ\\lambdaλ会使得分布的正偏态减小，反之亦然。 四、特征分布的修正 基于特征空间中类别之间的欧式距离进行分布的修正。具体来说，从base classes中选取top k个距离x~\\tilde xx~最近的base类别，计算方法如下： \\begin{align} \\mathbb{S}_{d}=\\left\\{-\\left\\|\\mu_{i}-\\tilde{\\boldsymbol{x}}\\right\\|^{2} \\mid i \\in C_{b}\\right\\}, \\tag 4 \\\\ \\mathbb{S}_{N}=\\left\\{i \\mid-\\left\\|\\mu_{i}-\\tilde{\\boldsymbol{x}}\\right\\|^{2} \\in \\operatorname{topk}\\left(\\mathbb{S}_{d}\\right)\\right\\},\\tag 5 \\end{align} 其中Sd\\mathbb S_dSd​表示基类别和样本x~\\tilde xx~之间的欧氏距离，topk(Sd)topk(\\mathbb S_d)topk(Sd​)表示距离最小的前k个类别，储存在SN\\mathbb S_NSN​中。然后利用距离最近的这k个类别对特征分布校准： μ′=∑i∈SNμi+x~k+1,Σ′=∑i∈SNΣik+α(6)\\mu^{\\prime}=\\frac{\\sum_{i \\in \\mathbb{S}_{N}} \\mu_{i}+\\tilde{x}}{k+1}, \\Sigma^{\\prime}=\\frac{\\sum_{i \\in \\mathbb{S}_{N}} \\Sigma_{i}}{k}+\\alpha\\tag 6 μ′=k+1∑i∈SN​​μi​+x~​,Σ′=k∑i∈SN​​Σi​​+α(6) 其中α\\alphaα是超参，决定校准分布的分散程度。对于超过one-shot的小样本任务，上述校准过程应进行K-shot次，每次使用一个样本进行校准。 经过校准后，对于每一个y∈Cny\\in C_ny∈Cn​，我们可以得到一系列高斯分布Sy={(μ1′,Σ1′),…,(μK′,ΣK′)}\\mathbb{S}_{y}=\\left\\{\\left(\\boldsymbol{\\mu}_{1}^{\\prime}, \\boldsymbol{\\Sigma}_{1}^{\\prime}\\right), \\ldots,\\left(\\boldsymbol{\\mu}_{K}^{\\prime}, \\boldsymbol{\\Sigma}_{K}^{\\prime}\\right)\\right\\}Sy​={(μ1′​,Σ1′​),…,(μK′​,ΣK′​)}，其中μi′\\mu_i&#x27;μi′​和∑i′\\sum_i&#x27;∑i′​分别表示均值和协方差，K即为N-way-K-shot中的K。 五、如何利用校准后的分布 利用校准后的分布Sy\\mathbb S_ySy​大量生成类别标签为y下的样本： Dy={(x,y)∣x∼N(μ,Σ),∀(μ,Σ)∈Sy}(7)\\mathbb{D}_{y}=\\left\\{(\\boldsymbol{x}, y) \\mid \\boldsymbol{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}), \\forall(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) \\in \\mathbb{S}^{y}\\right\\}\\tag 7 Dy​={(x,y)∣x∼N(μ,Σ),∀(μ,Σ)∈Sy}(7) 然后将生成的样本和原有的support集样本作为训练集合，利用交叉熵损失训练一个分类器： ℓ=∑(x,y)∼S~∪Dy,y∈YT−log⁡Pr⁡(y∣x;θ),(8)\\ell=\\sum_{(\\boldsymbol{x}, y) \\sim \\tilde{S} \\cup \\mathbb{D}_{y, y \\in \\mathcal{Y}} \\mathcal{T}}-\\log \\operatorname{Pr}(y \\mid \\boldsymbol{x} ; \\theta),\\tag 8 ℓ=(x,y)∼S~∪Dy,y∈Y​T∑​−logPr(y∣x;θ),(8) 其中YT\\mathcal Y^TYT表示任务T\\mathcal TT中的类别集合，S~\\tilde SS~表示经过特征转换后的support集，θ\\thetaθ为分类器参数。 3. 实验 **数据集：**miniInamgeNet，tieredImageNet，CUB **实验细节：**利用预训练好的WideResNet提取特征，用base classes训练特征提取器，novel classes测试特征提取器。具体超参数设置间原文。 3.1 实验结果 3.2 可视化 3.3 消融实验 将分布校正用于不同的特征提取器上 DS消融 特征转换和样本生成的消融 特征转换和样本生成超参消融","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"迁移学习","slug":"迁移学习","permalink":"http://rookieyin.github.io/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"},{"name":"样本生成","slug":"样本生成","permalink":"http://rookieyin.github.io/tags/%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/"}]},{"title":"Heterogeneous Graph Neural Network","slug":"3 论文笔记/图学习/异构网络/1. Heterogeneous Graph Neural Network","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.898Z","comments":true,"path":"3b1aeb046948/","link":"","permalink":"http://rookieyin.github.io/3b1aeb046948/","excerpt":"https://dl.acm.org/doi/pdf/10.1145/3292500.3330961 https://github.com/chuxuzhang/KDD2019_HetGNN Heterogeneous Graph Neural Network，KDD，2019 总结：解决异构网络嵌入中存在的三个挑战：（1）如何为每个节点采样高相关性的邻居？（2）如何设计一个node content编码器，解决不同节点携带的信息是异构这一问题？（3）如何考虑节点类型的影响，整合不同类型邻居节点的信息？针对这三个问题作者分别提出了解决方案：（1）采用RWR采样，按照出现频率选取前10各节点作为目标节点v的邻居，这样可以保证每个节点邻居数量相同，且高相关性邻居被采样到；（2）采用双向LSTM对节点内容信息进行编码，将文本、图像等多模态特征整合成一个特征向量；（3）将节点邻居按类型分类，计算每个类型邻居节点的信息，再通过注意力机制聚合所有类型邻居节点的信息。","text":"https://dl.acm.org/doi/pdf/10.1145/3292500.3330961 https://github.com/chuxuzhang/KDD2019_HetGNN Heterogeneous Graph Neural Network，KDD，2019 总结：解决异构网络嵌入中存在的三个挑战：（1）如何为每个节点采样高相关性的邻居？（2）如何设计一个node content编码器，解决不同节点携带的信息是异构这一问题？（3）如何考虑节点类型的影响，整合不同类型邻居节点的信息？针对这三个问题作者分别提出了解决方案：（1）采用RWR采样，按照出现频率选取前10各节点作为目标节点v的邻居，这样可以保证每个节点邻居数量相同，且高相关性邻居被采样到；（2）采用双向LSTM对节点内容信息进行编码，将文本、图像等多模态特征整合成一个特征向量；（3）将节点邻居按类型分类，计算每个类型邻居节点的信息，再通过注意力机制聚合所有类型邻居节点的信息。 1. 简介 1.1 摘要 Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.д., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes “deep” feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification &amp; clustering and inductive node classification &amp; clustering. 异构网络中的表示学习旨在为每个节点寻找一个有意义的表示向量，来解决链路预测、个性推荐、节点分类等下游任务。但是这个任务是十分具有挑战性的，一方面需要整合包含等多种类型节点和边组成的异构结构信息，另一方面还要考虑每个节点具有的异构属性或者内容。尽管对于异构网络嵌入、属性网络嵌入以及GNNs等问题已经有了大量研究，但是很少有研究能够有效地同时考虑异构结构信息和每个节点的异构内容信息。本文，作者提出了HetGNN模型，一种用来解决上述问题的异构图神经网络模型。具体来说，作者首先介绍了一个restart随机游走策略来为每个节点采样一个固定大小的、高相关的异构邻居，并对这些采样的邻居节点按照节点类型进行分类。然后设计一个包含两个模块的神经网络架构来整合这些采样到的邻居节点的信息。第一个模块对异构内容信息进行深度编码，为每个节点生成content embedding。第二个模块分别整合每个类别下所有邻居节点的content embedding（组内整合），然后按照每组节点的影响力，对conten embedding进行进一步整合（组间整合）得到最终的node embedding。·最后了利用一个graph context损失和mini-batch梯度下降来端到端的训练模型。几个数据集上的大量实验表明HetGNN模型比现有的最优模型在链路预测、推荐、节点分类、聚类等任务上性能更优。 1.2 本文工作 现有的图表示学习方法中，DeepWalk、metapath2vec、ASNE等方法都是直接学习节点潜在特征，不能很好地捕捉丰富的邻居信息。能力更强的GNNs比如GCN、GraphSAGE、GAT等可以学习到更好的节点embedding，但是大多数GNNs都是用于同构网络，将其应用于HetG中还存在如下挑战： HetG中很多节点的邻居没有覆盖所有节点类型，并且不同节点的邻居数目各不相同。现有的大多数GNN都是直接聚合一阶邻居信息，这导致“hub”节点（度高的节点）embedding的生成会受到噪声节点的影响（邻居很多，里面会掺杂噪声邻居，削弱相关性强的邻居的影响力），而“cold-start”节点（度低的节点）embedding学习到的信息不够充分（因为邻居很少，聚合到的信息也很少）。因此，这产生了第一个Change：如何为每个节点采样高相关性的邻居？ HetG中的一个节点可能会携带非结构化信息，比如属性、文本、图像等，并且不同类型的节点可能会携带不同类型的信息。现有GNNs直接的concatenation操作或者线性转换无法对节点异构信息之间的深层次交互进行建模。另外，不同类型的节点不能共用一个特征转换函数，因为不同类型节点携带的信息是不同的（有的是文本，有的是图片）。因此，第二个挑战是：如何设计一个node content编码器，解决不同节点携带的信息是异构这一问题？ HetG中不同类型的邻居节点对node embedding的影响是不同的，例如在学术网络中，和venue节点相比，作者和论文节点对于作者节点嵌入的影响应该更大，而现有的GNNs大多用于同构网络，没有考虑节点类型的影响。因此，第三个挑战是：如何考虑节点类型的影响，整合不同类型邻居节点的信息？ 为了解决上述3个问题，作者提出了HetGNN模型。 首先设计一个restart随机游走策略，为每个节点采样固定大小的高相关邻居节点，并将其按照节点类型分类。 然后设计一个包含两个模块的神经网络架构 第一个模块采用RNN对节点携带的异构信息进行编码，得到每个节点的content embedding 第二个模块利用另一个RNN按照节点类型整合每组邻居的content embedding（组内），再用一个注意力机制整合所有组的content embedding（组间）得到最终的节点嵌入。 最后，利用graph context损失和mini-batch梯度下降训练模型。 1.3 问题定义 本文的方法针对“Content-associated Heterogeneous Graph”，该类型图定义如下：C-HetG表示为G=(V,E,OV,RE)G=(V,E,O_V,R_E)G=(V,E,OV​,RE​)，包含多种类型的节点和边，OVO_VOV​和RER_ERE​分别表示节点类型和边类型，另外每个节点还携带者和节点相关的异构信息比如属性、文本和图像。如下图所示： 异构网络表示学习定义为：给定一个C-HetG G=(V,E,OV,RE)G=(V,E,O_V,R_E)G=(V,E,OV​,RE​)，以及content信息CCC，我们要训练一个模型FΘ\\mathcal F_\\ThetaFΘ​，给每个节点学习一个d维嵌入E∈R∣V∣×d(d≪∣V∣)\\mathcal E\\in\\mathbb R^{|V|\\times d}(d\\ll|V|)E∈R∣V∣×d(d≪∣V∣)，这个embedding同时编码了异构结构信息和异构内容信息，用于各种图挖掘任务如链路预测、推荐、多标签分类等。 2. HetGNN HetGNN包含四个部分：（1）异构邻居采样；（2）节点异构信息编码；（3）聚合异构邻居信息；（4）构造目标函数和模型训练过程 。 2.1 异构邻居采样 采用RWR进行邻居节点采样，包含下面两步： 采样固定长度的RWR：从节点v∈Vv\\in Vv∈V开始随机游走，有一定概率p返回开始节点重新游走，直到采集到足够数量节点（游走过程中会添加约束确保每种类型节点都被采样到）。 按类型对采样到的节点进行分类，对于每个类型t，按照其在RWR(v)中的出现频率选取top k个节点，将它们视为节点v在t类型下最相关的邻居节点 这种采样方式可以有效解决上面提到的三个问题： RWR采样的节点覆盖了所有节点类型 对邻居节点按类型分组，这样可以分组整合邻居节点的信息 2.2 编码异构内容信息 节点内容CvC_vCv​中第i项表示为xi∈Rdf×1x_i\\in \\mathbb R^{d_f\\times 1}xi​∈Rdf​×1，xix_ixi​是不同预训练好的模型计算出的content特征。现有的方法针对异构内容信息，大多采用concatenate操作或者线性转换，将异构信息特征转换成单个向量。本文作者设计了一个新的架构来编码异构内容信息，利用双向LSTM来捕捉深层次的特征交互，得到表达能力更强的content embedding。具体计算方式如下： f1(v)=∑i∈Cv[LSTM→{FCθx(xi)}⊕LSTM←{FCθx(xi)}]∣Cv∣(1)f_{1}(v)=\\frac{\\sum_{i \\in C_{v}}\\left[\\overrightarrow{L S T M}\\left\\{\\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)\\right\\} \\oplus \\overleftarrow{L S T M}\\left\\{\\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)\\right\\}\\right]}{\\left|C_{v}\\right|}\\tag 1 f1​(v)=∣Cv​∣∑i∈Cv​​[LSTM{FCθx​​(xi​)}⊕LSTM{FCθx​​(xi​)}]​(1) 其中f1(v)∈Rd×1f_1(v)\\in R^{d\\times 1}f1​(v)∈Rd×1表示最终的节点内容嵌入，FCθx\\mathcal{FC}_{\\theta_x}FCθx​​表示参数为θx\\theta_xθx​的全连接层，⊕\\oplus⊕表示拼接操作。LSTM的具体计算方式如下： zi=σ(UzFCθx(xi)+Wz hi−1+bz)fi=σ(UfFCθx(xi)+Wf hi−1+bf)oi=σ(UoFCθx(xi)+Wo hi−1+bo)c^i=tanh⁡(UcFCθx(xi)+Wc hi−1+bc)ci=fi∘ci−1+zi∘c^i hi=tanh⁡(ci)∘oi(2)\\begin{aligned} \\mathrm{z}_{i} &amp;=\\sigma\\left(\\mathcal{U}_{z} \\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)+\\mathcal{W}_{z} \\mathrm{~h}_{i-1}+\\mathrm{b}_{z}\\right) \\\\ \\mathrm{f}_{i} &amp;=\\sigma\\left(\\mathcal{U}_{f} \\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)+\\mathcal{W}_{f} \\mathrm{~h}_{i-1}+\\mathrm{b}_{f}\\right) \\\\ \\mathrm{o}_{i} &amp;=\\sigma\\left(\\mathcal{U}_{o} \\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)+W_{o} \\mathrm{~h}_{i-1}+\\mathrm{b}_{o}\\right) \\\\ \\hat{\\mathrm{c}}_{i} &amp;=\\tanh \\left(\\mathcal{U}_{c} \\mathcal{F} C_{\\theta_{x}}\\left(\\mathrm{x}_{i}\\right)+\\mathcal{W}_{c} \\mathrm{~h}_{i-1}+\\mathrm{b}_{c}\\right) \\\\ \\mathrm{c}_{i} &amp;=\\mathrm{f}_{i} \\circ \\mathrm{c}_{i-1}+\\mathrm{z}_{i} \\circ \\hat{\\mathrm{c}}_{i} \\\\ \\mathrm{~h}_{i} &amp;=\\tanh \\left(\\mathrm{c}_{i}\\right) \\circ \\mathbf{o}_{i} \\end{aligned}\\tag 2 zi​fi​oi​c^i​ci​ hi​​=σ(Uz​FCθx​​(xi​)+Wz​ hi−1​+bz​)=σ(Uf​FCθx​​(xi​)+Wf​ hi−1​+bf​)=σ(Uo​FCθx​​(xi​)+Wo​ hi−1​+bo​)=tanh(Uc​FCθx​​(xi​)+Wc​ hi−1​+bc​)=fi​∘ci−1​+zi​∘c^i​=tanh(ci​)∘oi​​(2) 其中hih_ihi​表示xix_ixi​的hidden state，∘\\circ∘表示哈达玛积，Ui∈R(d/2)×df\\mathcal U_i\\in\\mathbb R^{(d/2)\\times d_f}Ui​∈R(d/2)×df​，Wj∈R(d/2)×(d/2)\\mathcal W_j\\in\\mathbb R^{(d/2)\\times(d/2)}Wj​∈R(d/2)×(d/2)，bj∈R(d/2)×2\\mathcal b_j\\in\\mathbb R^{(d/2)\\times 2}bj​∈R(d/2)×2为可学习参数，ziz_izi​，fif_ifi​，oio_ioi​分别为forget、input和output三个门向量。 2.3 聚合异构邻居信息 包含两步：（1）same type neighbors aggregation；（2）types combination 对于节点v的t-type邻居，按照如下方式进行聚合： f2t(v)=AGv′∈Nt(v)t{f1(v′)}(3)f_{2}^{t}(v)=\\mathcal{A} \\mathcal{G}_{v^{\\prime} \\in N_{t}(v)}^{t}\\left\\{f_{1}\\left(v^{\\prime}\\right)\\right\\}\\tag 3 f2t​(v)=AGv′∈Nt​(v)t​{f1​(v′)}(3) 其中f2t(v)∈Rd×1f_2^t(v)\\in\\mathbb R^{d\\times 1}f2t​(v)∈Rd×1表示t类型邻居聚合后的embedding，AGt\\mathcal{AG}^tAGt表示t类型邻居节点聚合器，可以是全连接NN，也可以是GCN或者RNN。在本文中作者采用Bi-LSTM来分别聚合每个类型的邻居，f2t(v)f_2^t(v)f2t​(v)计算方式如下： f2t(v)=∑v′∈Nt(v)[LSTM→{f1(v′)}⨁LSTM←{f1(v′)}]∣Nt(v)∣(4)f_{2}^{t}(v)=\\frac{\\sum_{v^{\\prime} \\in N_{t}(v)}\\left[\\overrightarrow{L S T M}\\left\\{f_{1}\\left(v^{\\prime}\\right)\\right\\} \\bigoplus \\overleftarrow{L S T M}\\left\\{f_{1}\\left(v^{\\prime}\\right)\\right\\}\\right]}{\\left|N_{t}(v)\\right|}\\tag 4 f2t​(v)=∣Nt​(v)∣∑v′∈Nt​(v)​[LSTM{f1​(v′)}⨁LSTM{f1​(v′)}]​(4) 对于types combination，考虑到不同类型节点对embedding的影响力不同，节点v最终的embedding计算方式如下： Ev=αv,vf1(v)+∑t∈OVαv,tf2t(v)(5)\\mathcal{E}_{v}=\\alpha^{v, v} f_{1}(v)+\\sum_{t \\in O_{V}} \\alpha^{v, t} f_{2}^{t}(v)\\tag 5 Ev​=αv,vf1​(v)+t∈OV​∑​αv,tf2t​(v)(5) 公式前半部分表示节点content嵌入，后半部分表示聚合邻居的embedding。αv,∗\\alpha^{v,*}αv,∗表示不同节点embedding的重要程度，f1(v)f_1(v)f1​(v)表示节点的content embedding，f2t(v)f_2^t(v)f2t​(v)表示t-type邻居节点的embedding。用F(v)={f1(v)∪(f2t(v),t∈OV)}\\mathcal{F}(v)=\\left\\{f_{1}(v) \\cup\\left(f_{2}^{t}(v), t \\in O_{V}\\right)\\right\\}F(v)={f1​(v)∪(f2t​(v),t∈OV​)}表示所有的embedding集合，节点embedding的计算方式调整如下： Ev=∑fi∈F(v)αv,ifiαv,i=exp⁡{ Leak yReL⁡U(uT[fi⊕f1(v)])}∑fj∈F(v)exp⁡{ LeakyReLU(u T[fj⊕f1(v)])}(6)\\begin{array}{c} \\mathcal{E}_{v}=\\sum_{f_{i} \\in \\mathcal{F}(v)} \\alpha^{v, i} f_{i} \\\\ \\alpha^{v, i}=\\frac{\\exp \\left\\{\\text { Leak } y \\operatorname{ReL} U\\left(u^{T}\\left[f_{i} \\oplus f_{1}(v)\\right]\\right)\\right\\}}{\\left.\\sum_{f_{j} \\in \\mathcal{F}(v)} \\exp \\left\\{\\text { LeakyReLU(u }^{T}\\left[f_{j} \\oplus f_{1}(v)\\right]\\right)\\right\\}} \\end{array}\\tag 6 Ev​=∑fi​∈F(v)​αv,ifi​αv,i=∑fj​∈F(v)​exp{ LeakyReLU(u T[fj​⊕f1​(v)])}exp{ Leak yReLU(uT[fi​⊕f1​(v)])}​​(6) 其中LeakyReLUctant为激活单元，u∈R2d×1u\\in\\mathcal R^{2d\\times 1}u∈R2d×1为注意力参数。 2.4 目标函数和模型的训练 3. 实验 在各种图数据挖掘任务中，HetGNN和当前最优方法相比表现如何？ 节点分类、聚类任务中，HetGNN和当前最优方法相比表现如何？ HetGNN各个components对模型是否有用？ 超参，比如嵌入维度、采样邻居大小对模型性能的影响如何？ 一、数据集 二、baseline metapath2vec，ASNE，SHNE，GraphSAGE和GAT 三、设置 embedding维度128，采样邻居大小23（author，paper和venue三种类型分别为10,10,3）和10（user和item分别为10,10），ParVec作为text信息预训练模型，CNN作为image信息预训练模型。 3.2 应用 一、链路预测 二、推荐 三、多标签分类和节点聚类 四、inductive classification和clustering 3.3 消融实验和敏感性实验 一、各个component的作用 二、超参敏感性","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"随机采样","slug":"随机采样","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7/"}]},{"title":"Metapath2vec: Scalable Representation Learning forHeterogeneous Networks","slug":"3 论文笔记/图学习/异构网络/2.metapath2vec Scalable Representation Learning for Heterogeneous Networks","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.901Z","comments":true,"path":"03ccb56ea1df/","link":"","permalink":"http://rookieyin.github.io/03ccb56ea1df/","excerpt":"https://dl.acm.org/doi/pdf/10.1145/3097983.3098036 https://github.com/apple2373/metapath2vec Metapath2vec: Scalable Representation Learning forHeterogeneous Networks ，KDD，2017 总结：未完待续… …","text":"https://dl.acm.org/doi/pdf/10.1145/3097983.3098036 https://github.com/apple2373/metapath2vec Metapath2vec: Scalable Representation Learning forHeterogeneous Networks ，KDD，2017 总结：未完待续… … 1. 简介 1.1 摘要 We study the problem of representation learning in heterogeneousnetworks. Its unique challenges come from the existence of mul-tiple types of nodes and links, which limit the feasibility of theconventional network embedding techniques. We develop twoscalable representation learning models, namelymetapath2vecandmetapath2vec++. The metapath2vec model formalizes meta-path-based random walks to construct the heterogeneous neighborhoodof a node and then leverages a heterogeneous skip-gram modelto perform node embeddings. The metapath2vec++ model furtherenables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects. 本文主要研究异构网络表示学习。异构网络中存在多种类型的边和节点，这限制了很多传统表示学习方法的可行性，因此异构网络表示学习存在很多挑战。作者设计了两种scalable表示学习模型，metapath2vec和metapath2vec++。metapath2vec对基于元路径的随机游走进行格式化来构建每个节点的异构邻居，再用一个异构skip-gram模型来学习节点embedding。metapath2vec++模型则进一步对网络中的结构和语义相关性同时进行建模。大量实验表明作者提出的这两个模型不仅在各种异构网络挖掘任务中表现优秀，还能识别不同网络对象之间结构和语义上的相关性。 1.2 本文工作 受NLP领域一些模型启发，DeepWalk、LINE和node2vec等被提出用于网络表示学习，但是这些工作都是针对于同构网络表示学习的，将其直接用于异构网络存在诸多问题。比如在异构学术网络中，如何获取多种类型节点之间的上下文关系？可以直接将DeepWalk中的随机游走应用于有多种类型节点的网络中吗？能直接将同构网络中的嵌入架构（比如skip-gram）直接应用到异构网络中吗？ 本文作者针对上述challenges，提出了metapath2vec模型，学习潜在的异构网络嵌入，用于各种网络挖掘任务。和传统的基于meta-path的方法相比，潜在空间表示学习的优势在于可以对没有元路径相连接的两个节点的相似性进行建模。 作者在metapath2vec中首先基于meta-path的随机游走，针对各种类型节点生成具有网络语义的异构领域。然后在利用skip-gram模型对位置上和语义上相近的节点进行建模。最后作者设计了一种基于异构负采样的方法，称为metapath2vec++，可以准确有效地预测节点的异构邻居。 1.3 问题定义 2. MetaPath2Vec metapath2vec主要参考DeepWalk和node2vec方法，利用基于metapath的随机游走，将这两个算法拓展到异构网络中。DeepWalk和node2vec这两个方法大概思想是：给定一个图G=(V,E)G=(V,E)G=(V,E)，进行随机游走，将节点看做单词，游走路径看做NLP中的句子，再利用skip-gram模型进行训练，目标是最大化邻居共现概率，即： arg⁡max⁡θ∏v∈V∏c∈N(v)p(c∣v;θ)(1)\\arg \\max _{\\theta} \\prod_{v \\in V} \\prod_{c \\in N(v)} p(c \\mid v ; \\theta)\\tag 1 argθmax​v∈V∏​c∈N(v)∏​p(c∣v;θ)(1) 其中N(v)N(v)N(v)表示节点v的邻居，邻居定义方式有很多种可以是一阶邻居、二阶邻居、语义上的邻居等等。p(c∣v;θ)p(c|v;\\theta)p(c∣v;θ)表示给定节点v，上下文节点c出现的概率。 skip-gram 基于meta-path的随机游走 普通随机游走 将随机游走器放在网络中，第i步，以p(vi+1∣vi)p(v^{i+1}|v^i)p(vi+1∣vi)概率从节点viv^ivi前进到节点vi+1v^{i+1}vi+1，以此类推。当游走路径长度达到要求后，将得到的游走路径作为node2vec和DeepWalk的输入。 sun等人证明了直接将随机游走应用在异构网络中存在问题。因此作者设计了一种基于元路径的游走策略。 定义一种元路径模式P\\mathcal PP，表示V1⟶R1V2⟶R2⋯Vt⟶RtVt+1⋯⟶Rl−1VlV_{1} \\stackrel{R_{1}}{\\longrightarrow} V_{2} \\stackrel{R_{2}}{\\longrightarrow} \\cdots V_{t} \\stackrel{R_{t}}{\\longrightarrow} V_{t+1} \\cdots \\stackrel{R_{l-1}}{\\longrightarrow} V_{l}V1​⟶R1​​V2​⟶R2​​⋯Vt​⟶Rt​​Vt+1​⋯⟶Rl−1​​Vl​，R=R1∘R2∘⋅⋅⋅∘Rl−1R=R_1\\circ R_2\\circ···\\circ R_{l-1}R=R1​∘R2​∘⋅⋅⋅∘Rl−1​表示从V1V_1V1​类型节点到VlV_lVl​类型节点路径上的所有边的关系集合。 QQ截图20210408155753.png 比如上图中，元路径“APA”表示合作者关系，元路径“APVPA”表示两个作者在同一个会议/期刊上发表了文章。之前很多工作都表明meta-path对于异构信息网络上的数据挖掘很有用。 本文作者提出的基于meta-path的随机游走具体细节如下： 给定一个异构网络G=(V,E,T)G=(V,E,T)G=(V,E,T)，一种元路径模式P:V1⟶R1V2⟶R2⋯Vt⟶RtVt+1⋯⟶Rl−1Vl\\mathcal P:V_{1} \\stackrel{R_{1}}{\\longrightarrow} V_{2} \\stackrel{R_{2}}{\\longrightarrow} \\cdots V_{t} \\stackrel{R_{t}}{\\longrightarrow} V_{t+1} \\cdots \\stackrel{R_{l-1}}{\\longrightarrow} V_{l}P:V1​⟶R1​​V2​⟶R2​​⋯Vt​⟶Rt​​Vt+1​⋯⟶Rl−1​​Vl​，第i步的转换概率定义如下： p(vi+1∣vti,P)={1∣Nt+1(vti)∣(vi+1,vti)∈E,ϕ(vi+1)=t+10(vi+1,vti)∈E,ϕ(vi+1)≠t+10(vi+1,vti)∉E(3)p\\left(v^{i+1} \\mid v_{t}^{i}, \\mathcal{P}\\right)=\\left\\{\\begin{array}{cl} \\frac{1}{\\left|N_{t+1}\\left(v_{t}^{i}\\right)\\right|} &amp; \\left(v^{i+1}, v_{t}^{i}\\right) \\in E, \\phi\\left(v^{i+1}\\right)=t+1 \\\\ 0 &amp; \\left(v^{i+1}, v_{t}^{i}\\right) \\in E, \\phi\\left(v^{i+1}\\right) \\neq t+1 \\\\ 0 &amp; \\left(v^{i+1}, v_{t}^{i}\\right) \\notin E \\end{array}\\right.\\tag 3 p(vi+1∣vti​,P)=⎩⎪⎪⎨⎪⎪⎧​∣Nt+1​(vti​)∣1​00​(vi+1,vti​)∈E,ϕ(vi+1)=t+1(vi+1,vti​)∈E,ϕ(vi+1)​=t+1(vi+1,vti​)∈/​E​(3) 其中vti∈Vtv_t^i\\in V_tvti​∈Vt​表示类型为t的节点，Nt+1(vti)N_{t+1}(v_t^i)Nt+1​(vti​)表示vtiv_t^ivti​邻居中类型为Vt+1V_{t+1}Vt+1​的节点。 注：元路径通常都定义成对称的 基于元路径的随机游走策略可以保证不同类型节点之间的语义关系可以被整合到skip-gram模型中。还以下图为例，如果采用普通的随机游走，从CMU节点转移到a4a_4a4​（A）节点后，下一步可能转移到a2,a3,a5,p2,p3,CMUa_2,a_3,a_5,p_2,p_3,CMUa2​,a3​,a5​,p2​,p3​,CMU中任意一个节点（这包括了三种类型）。但是如果定义“OAPVPAO”形式元路径对其进行约束，鉴于前一个节点类型是‘O’，那么下一步模型会遵循元路径的语义信息，更倾向于像Paper类型节点转移。 QQ截图20210408155753.png 唯一的区别，最后一层skip-gram中，按照节点类型分组进行softmax p(ct∣v;θ)=eXct⋅Xv∑ut∈VteXut⋅Xv(5)p\\left(c_{t} \\mid v ; \\theta\\right)=\\frac{e^{X_{c_{t}} \\cdot X_{v}}}{\\sum_{u_{t} \\in V_{t}} e^{X_{u_{t}} \\cdot X_{v}}}\\tag 5 p(ct​∣v;θ)=∑ut​∈Vt​​eXut​​⋅Xv​eXct​​⋅Xv​​(5) 微信截图_20210408183132.png 受PTE启发，。。。，目标函数定义如下： O(X)=log⁡σ(Xct⋅Xv)+∑m=1MEutm∼Pt(ut)[log⁡σ(−Xutm⋅Xv)](6)O(\\mathrm{X})=\\log \\sigma\\left(X_{c_{t}} \\cdot X_{v}\\right)+\\sum_{m=1}^{M} \\mathbb{E}_{u_{t}^{m} \\sim P_{t}\\left(u_{t}\\right)}\\left[\\log \\sigma\\left(-X_{u_{t}^{m}} \\cdot X_{v}\\right)\\right]\\tag 6 O(X)=logσ(Xct​​⋅Xv​)+m=1∑M​Eutm​∼Pt​(ut​)​[logσ(−Xutm​​⋅Xv​)](6) 算法伪代码如下： 微信截图_20210408184924.png 3.实验 数据集：Aminer的CS数据集，DBIS数据集 baseline：DeepWalk/node2vec，LINE，PTE，Spectral Clustering/Graph Factorization四种 元路径：之前学术网络中最常用的格式为APA和APVPA，作者本文采用APVPA形式 任务：多类别节点分类，节点聚类，相似度搜索 节点分类 整图上学习每个节点的embedding，5%~90%节点用于分类器的训练，其余的用于测试。 参数敏感性（metapath2vec++） 节点聚类 k-means聚类算法 参数敏感性 相似性搜索 从Aminer数据集CS的子领域中选取16个会议，DBIS数据集中选5个会议，然后计算其余会议和这21个会议之间的相似度，下表展示了相似度前10的会议： Scalability","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"元路径","slug":"元路径","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E8%B7%AF%E5%BE%84/"}]},{"title":"MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding","slug":"3 论文笔记/图学习/异构网络/3.MAGNN Metapath Aggregated Graph Neural Network forHeterogeneous Graph Embedding","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.913Z","comments":true,"path":"92a0f6b94a16/","link":"","permalink":"http://rookieyin.github.io/92a0f6b94a16/","excerpt":"https://qiniu.pattern.swarma.org/pdf/arxiv/2002.01680.pdf https://github.com/cynricfu/MAGNN MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding ，KDD，2020 总结：现有的利用元路径做异构网络嵌入的方法存在一些限制：“要么忽略了节点的内容特征，要么丢弃了元路径上的中间节点，要么仅仅考虑一条元路径”。为了解决这些问题，作者提出了MAGNN模型，包含三个组件：（1）node content转换器，用一个简单的线性映射把异构特征信息（比如图像和文本）映射到同一个特征空间；（2）intra-metapaht聚合器，将同一个类型元路径的多条实例合并成单个向量，表示该类型元路径的语义信息（这块参考RotatE，用一个Relational rotation encoder进行整合）；（3）inter-metapath聚合器，将不同类型元路径的语义信息整合到一起（用一个注意力机制）。","text":"https://qiniu.pattern.swarma.org/pdf/arxiv/2002.01680.pdf https://github.com/cynricfu/MAGNN MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding ，KDD，2020 总结：现有的利用元路径做异构网络嵌入的方法存在一些限制：“要么忽略了节点的内容特征，要么丢弃了元路径上的中间节点，要么仅仅考虑一条元路径”。为了解决这些问题，作者提出了MAGNN模型，包含三个组件：（1）node content转换器，用一个简单的线性映射把异构特征信息（比如图像和文本）映射到同一个特征空间；（2）intra-metapaht聚合器，将同一个类型元路径的多条实例合并成单个向量，表示该类型元路径的语义信息（这块参考RotatE，用一个Relational rotation encoder进行整合）；（3）inter-metapath聚合器，将不同类型元路径的语义信息整合到一起（用一个注意力机制）。 1. 简介 1.1 摘要 A large number of real-world graphs or networks are inherently het-erogeneous, involving a diversity of node types and relation types.Heterogeneous graph embedding is to embed rich structural and se-mantic information of a heterogeneous graph into low-dimensionalnode representations. Existing models usually define multiple meta-paths in a heterogeneous graph to capture the composite relationsand guide neighbor selection. However, these models either omitnode content features, discard intermediate nodes along the meta-path, or only consider one metapath. To address these three lim-itations, we propose a new model namedMetapath AggregatedGraph Neural Network(MAGNN) to boost the final performance.Specifically, MAGNN employs three major components, i.e., thenode content transformation to encapsulate input node attributes,the intra-metapath aggregation to incorporate intermediate seman-tic nodes, and the inter-metapath aggregation to combine mes-sages from multiple metapaths. Extensive experiments on threereal-world heterogeneous graph datasets for node classification,node clustering, and link prediction show that MAGNN achievesmore accurate prediction results than state-of-the-art baselines. 现实世界中的很多网络都是异构的，涉及到多种类型的节点和边。异构网络嵌入旨在将网络中丰富的结构和语义信息嵌入到一个低维节点表示中。现有的模型通常在异构网络中定义多个元路径来捕捉复杂的关系并指导领域的原则。但是这些方法要么忽略了节点的内容特征，要么丢弃了元路径上的中间节点，要么仅仅考虑一条元路径。为了解决这三个限制，本文作者提出了一个MAGNN的新模型。具体来说，MAGNN包含三个组件：（1）node content转换器，捕捉节点属性信息（2）intra-metapath聚合器，合并元路径中间语义节点信息（3）inter-metapath聚合器，组合多个元路径中的信息。三个异构网络上的大量实验表明，在节点分类、链路预测和节点聚类三个任务上，MAGNN和当前最优方法相比都取得了更好结果。 1.2 本文工作 现有的基于元路径的嵌入方法比如ESim，metapath2vec，HIN2vec、HERec等虽然传统方法性能好，但是也存在一些limitations： 没有利用node content信息，在具有丰富节点内容特征的异构网络上表现不好 丢弃了元路径上中间节点，只考虑了路径两端的节点 模型只依赖于一条元路径，需要手动选取一条元路径，丢失了其他元路径信息，达不到最优效果 为了解决这些问题，作者提出了MAGNN模型。 1.3 问题定义 异构网络：G=(V,E)\\mathcal{G=(V,E)}G=(V,E)，节点类型映射ϕ:V→E\\mathcal{\\phi:V\\rightarrow E}ϕ:V→E，边类型映射ψ:E→R\\psi: \\mathcal{E} \\rightarrow \\mathcal{R}ψ:E→R，A\\mathcal AA和R\\mathcal RR分别表示节点类型和边类型集合且∣A∣+∣R∣&gt;2|\\mathcal A|+|\\mathcal R|&gt;2∣A∣+∣R∣&gt;2 元路径：A1⟶R1A2⟶R2⋯⟶RlAl+1A_{1} \\stackrel{R_{1}}{\\longrightarrow} A_{2} \\stackrel{R_{2}}{\\longrightarrow} \\cdots \\stackrel{R_{l}}{\\longrightarrow} A_{l+1}A1​⟶R1​​A2​⟶R2​​⋯⟶Rl​​Al+1​，A1∼AlA_1\\sim A_lA1​∼Al​为节点类型，R1∼RlR_1\\sim R_lR1​∼Rl​为边类型 **基于元路径的neighbor：**给定元路径P，通过元路径实例连接到节点v的路径上节点定义为NvPN_v^PNvP​（注：如果一个neighbor通过两个不同的元路径实例连接到v，那么这个neighbor看做NvPN_v^PNvP​中两个不同的节点；如果P是对称的，那么NvPN_v^PNvP​包含节点v本身） **基于元路径的graph：**给定元路径P，G\\mathcal GG中所有metapath-P-based neighbor pairs构成的图称之为metapath-based Graph，表示为GP\\mathcal G^PGP（注：如果P是对称的，那么GP\\mathcal G^PGP是同构的） **异构网络嵌入：**给定异构网络G=(V,E)\\mathcal {G=(V,E)}G=(V,E)，节点属性XAi∈R∣VAi∣×dAiX_{A_i}\\in\\R^{|\\mathcal V_{A_i}|\\times d_{A_i}}XAi​​∈R∣VAi​​∣×dAi​​，学习d维节点表示hv∈Rdh_v\\in\\R ^dhv​∈Rd，d≪∣V∣d\\ll|\\mathcal V|d≪∣V∣，能够同时捕捉丰富的结构和语义信息 2. MAGNN 2.1 Node Content Transformation 带有节点属性的异构网络中，不同类型节点的特征向量的维度不同，即使相同也可能处于不同的特征空间（比如图像特征和文本特征）。因此，在将节点特征喂给MAGNN之前，需要将节点的特征向量映射到同一个潜在空间。 对于v∈VAv\\in\\mathcal V_Av∈VA​，A∈AA\\in\\mathcal AA∈A，有： hv′=WA⋅xvAh_v&#x27;=W_A·x_v^A hv′​=WA​⋅xvA​ 其中xv∈RdAx_v\\in\\R^{d_A}xv​∈RdA​表示原始特征向量，hv′h_v&#x27;hv′​表示映射后的特征向量，WAW_AWA​表示类型A矩阵特征映射的参数。 2.2 Intra-metapath Aggregation P(v,u)P(v,u)P(v,u)表示一条连接目标节点v和邻域节点u的元路径实例，其中u∈NvPu\\in\\mathcal N_v^Pu∈NvP​ 定义元路径实例内部节点为{mP(v,u)}=P(v,u)\\{u,v}\\left\\{m^{P(v, u)}\\right\\}=P(v, u) \\backslash\\{u, v\\}{mP(v,u)}=P(v,u)\\{u,v}。 Intra-metapath aggregation利用一个encoder，将元路径实例中涉及到的所有内部节点特征整合成一个向量： hP(v,u)=fθ(P(v,u))=fθ(hv′,hu′,{ht′,∀t∈{mP(v,u)}})(2)\\mathbf{h}_{P(v, u)}=f_{\\theta}(P(v, u))=f_{\\theta}\\left(\\mathbf{h}_{v}^{\\prime}, \\mathbf{h}_{u}^{\\prime},\\left\\{\\mathbf{h}_{t}^{\\prime}, \\forall t \\in\\left\\{m^{P(v, u)}\\right\\}\\right\\}\\right)\\tag 2 hP(v,u)​=fθ​(P(v,u))=fθ​(hv′​,hu′​,{ht′​,∀t∈{mP(v,u)}})(2) hP(v,u)∈Rd′h_{P(v,u)}\\in\\R^{d&#x27;}hP(v,u)​∈Rd′表示该条元路径实例的特征。对于encoder fθ(⋅)f_\\theta(·)fθ​(⋅)作者提供了三种方案： Mean encoder hP(v,u)=MEAN⁡({ht′,∀t∈P(v,u)})(8)\\mathbf{h}_{P(v, u)}=\\operatorname{MEAN}\\left(\\left\\{\\mathbf{h}_{t}^{\\prime}, \\forall t \\in P(v, u)\\right\\}\\right)\\tag 8 hP(v,u)​=MEAN({ht′​,∀t∈P(v,u)})(8) Linear encoder hP(v,u)=WP⋅MEAN⁡({ht′,∀t∈P(v,u)})(9)\\mathrm{h}_{P(v, u)}=\\mathrm{W}_{P} \\cdot \\operatorname{MEAN}\\left(\\left\\{\\mathbf{h}_{t}^{\\prime}, \\forall t \\in P(v, u)\\right\\}\\right)\\tag 9 hP(v,u)​=WP​⋅MEAN({ht′​,∀t∈P(v,u)})(9) Relational rotation encoder 基于知识图谱方法RotatE提出来的，mean和linear方法都只是将元路径实例看做一个集合，忽略了元路径的序列结构。给定P(v,u)=(t0,t1,...,tn)P(v,u)=(t_0,t_1,...,t_n)P(v,u)=(t0​,t1​,...,tn​)，t0=ut_0=ut0​=u，tn=vt_n=vtn​=v，RiR_iRi​表示ti−1t_{i-1}ti−1​和tit_iti​之间的关系，rir_iri​为RiR_iRi​的关系向量。relational rotation encoder定义如下： o0=ht0′=hu′oi=hti′+oi−1⊙rihP(v,u)=onn+1(10)\\begin{array}{l}\\mathbf{o}_{0}=\\mathbf{h}_{t_{0}}^{\\prime}=\\mathbf{h}_{u}^{\\prime} \\\\\\mathbf{o}_{i}=\\mathbf{h}_{t_{i}}^{\\prime}+\\mathbf{o}_{i-1} \\odot \\mathbf{r}_{i} \\\\\\mathbf{h}_{P(v, u)}=\\frac{\\mathbf{o}_{n}}{n+1}\\end{array}\\tag {10} o0​=ht0​′​=hu′​oi​=hti​′​+oi−1​⊙ri​hP(v,u)​=n+1on​​​(10) 其中hti′h_{t_i}&#x27;hti​′​和rir_iri​都是复向量（前半部分看做实部，后半部分看做虚部），⊙\\odot⊙表示element-wise乘。 注：为什么是复向量？rir_iri​怎么来的？ 得到hP(v,u)h_{P(v,u)}hP(v,u)​后，利用一个graph attention layer整合P类型元路径下的所有实例对节点v的影响（每条路径实例对v的影响程度不同，所以采用注意力机制）： evuP= LeakyReLU (aP⊤⋅[hv′∥hP(v,u)])αvuP=exp⁡(evuP)∑s∈NvPexp⁡(evsP),hvP=σ(∑u∈NvPαvuP⋅hP(v,u))(3)\\begin{array}{l} e_{v u}^{P}=\\text { LeakyReLU }\\left(\\mathrm{a}_{P}^{\\top} \\cdot\\left[\\mathbf{h}_{v}^{\\prime} \\| \\mathbf{h}_{P(v, u)}\\right]\\right) \\\\ \\alpha_{v u}^{P}=\\frac{\\exp \\left(e_{v u}^{P}\\right)}{\\sum_{s \\in \\mathcal{N}_{v}^{P}} \\exp \\left(e_{v s}^{P}\\right)}, \\\\ \\mathbf{h}_{v}^{P}=\\sigma\\left(\\sum_{u \\in \\mathcal{N}_{v}^{P}} \\alpha_{v u}^{P} \\cdot \\mathbf{h}_{P(v, u)}\\right) \\end{array}\\tag 3 evuP​= LeakyReLU (aP⊤​⋅[hv′​∥hP(v,u)​])αvuP​=∑s∈NvP​​exp(evsP​)exp(evuP​)​,hvP​=σ(∑u∈NvP​​αvuP​⋅hP(v,u)​)​(3) aPa_PaP​为注意力参数，∣∣||∣∣表示拼接操作，evuPe_{vu}^PevuP​表示该实例的重要程度，αvuP\\alpha_{vu}^PαvuP​表示正则化后的重要程度，最后所有路径实例的影响加权求和作为最终输出。此处注意力机制也可以拓展成多头的，提高模型稳定性： hvP=∥k=1Kσ(∑u∈NvP[αvuP]k⋅hP(v,u))(4)\\mathbf{h}_{v}^{P}=\\|_{k=1}^{K} \\sigma\\left(\\sum_{u \\in \\mathcal{N}_{v}^{P}}\\left[\\alpha_{v u}^{P}\\right]_{k} \\cdot \\mathbf{h}_{P(v, u)}\\right)\\tag 4 hvP​=∥k=1K​σ⎝⎜⎛​u∈NvP​∑​[αvuP​]k​⋅hP(v,u)​⎠⎟⎞​(4) **总结：**给定经2.1转换后的节点特征和所有以节点类型为A∈AA\\in\\mathcal AA∈A开始或结尾的元路径集合PA={P1,P2,...,PM}\\mathcal P_A=\\{P_1,P_2,...,P_M\\}PA​={P1​,P2​,...,PM​}，经过intra-metapath aggregation后可以得到M个metapath-specific向量表示：{hvP1,hvP2,...,hvPM}\\{h_v^{P_1},h_v^{P_2},...,h_v^{P_M}\\}{hvP1​​,hvP2​​,...,hvPM​​}。 2.3 Inter-metapath Aggregation 首先对每个类型元路径Pi∈PAP_i\\in\\mathcal P_APi​∈PA​，计算该类型路径在所有节点v∈VAv\\in\\mathcal V_Av∈VA​下线性转换后的平均值： sPi=1∣VA∣∑v∈VAtanh⁡(MA⋅hvPi+bA)(5)\\mathrm{s}_{P_{i}}=\\frac{1}{\\left|\\mathcal{V}_{A}\\right|} \\sum_{v \\in \\mathcal{V}_{A}} \\tanh \\left(\\mathbf{M}_{A} \\cdot \\mathbf{h}_{v}^{P_{i}}+\\mathbf{b}_{A}\\right)\\tag 5 sPi​​=∣VA​∣1​v∈VA​∑​tanh(MA​⋅hvPi​​+bA​)(5) 其中MAM_AMA​和bAb_AbA​为线性转换层的参数。然后按照下面的方式对{hvP1,hvP2,...,hvPM}\\{h_v^{P_1},h_v^{P_2},...,h_v^{P_M}\\}{hvP1​​,hvP2​​,...,hvPM​​}进行注意力整合： ePi=qA⊤⋅sPiβPi=exp⁡(ePi)∑P∈PAexp⁡(eP)hvPA=∑P∈PAβP⋅hvP(6)\\begin{array}{l} e_{P_{i}}=\\mathrm{q}_{A}^{\\top} \\cdot \\mathrm{s}_{P_{i}} \\\\ \\beta_{P_{i}}=\\frac{\\exp \\left(e_{P_{i}}\\right)}{\\sum_{P \\in \\mathcal{P}_{A}} \\exp \\left(e_{P}\\right)} \\\\ \\mathbf{h}_{v}^{\\mathcal{P}_{A}}=\\sum_{P \\in \\mathcal{P}_{A}} \\beta_{P} \\cdot \\mathbf{h}_{v}^{P} \\end{array}\\tag 6 ePi​​=qA⊤​⋅sPi​​βPi​​=∑P∈PA​​exp(eP​)exp(ePi​​)​hvPA​​=∑P∈PA​​βP​⋅hvP​​(6) 其中qAq_AqA​为注意力参数，ePie_{P_i}ePi​​为hvPih_v^{P_i}hvPi​​的重要程度，βPi\\beta_{P_i}βPi​​为hvP1h_v^{P_1}hvP1​​的正则化后的重要程度，hvPAh_v^{\\mathcal P_A}hvPA​​为最终输出。 最后MAGNN再利用一个额外的线性转换成计算最终节点嵌入： hv=σ(Wo⋅hvPA)(7)\\mathbf{h}_{v}=\\sigma\\left(\\mathbf{W}_{o} \\cdot \\mathbf{h}_{v}^{\\mathcal{P}_{A}}\\right)\\tag 7 hv​=σ(Wo​⋅hvPA​​)(7) 2.4 Training 两种方式：半监督学习和无监督学习 半监督 利用一小部分有标签节点进行训练，交叉熵损失定义如下： L=−∑v∈VL∑c=1Cyv[c]⋅log⁡hv[c](11)\\mathcal{L}=-\\sum_{v \\in \\mathcal{V}_{L}} \\sum_{c=1}^{C} \\mathrm{y}_{v}[c] \\cdot \\log \\mathrm{h}_{v}[c]\\tag {11} L=−v∈VL​∑​c=1∑C​yv​[c]⋅loghv​[c](11) 其中VL\\mathcal V_LVL​为有标签节点，CCC表示类别数量，yvy_vyv​是节点one-hot向量，hvh_vhv​为预测的节点类型概率向量。 无监督学习 通过负采样，最小化下列损失函数： L=−∑(u,v)∈Ωlog⁡σ(hu⊤⋅hv)−∑(u′,v′)∈Ω−log⁡σ(−hu′⊤⋅hv′)(12)\\mathcal{L}=-\\sum_{(u, v) \\in \\Omega} \\log \\sigma\\left(\\mathbf{h}_{u}^{\\top} \\cdot \\mathbf{h}_{v}\\right)-\\sum_{\\left(u^{\\prime}, v^{\\prime}\\right) \\in \\Omega^{-}} \\log \\sigma\\left(-\\mathbf{h}_{u^{\\prime}}^{\\top} \\cdot \\mathbf{h}_{v^{\\prime}}\\right)\\tag {12} L=−(u,v)∈Ω∑​logσ(hu⊤​⋅hv​)−(u′,v′)∈Ω−∑​logσ(−hu′⊤​⋅hv′​)(12) 其中σ(⋅)\\sigma(·)σ(⋅)是sigmoid函数，Ω\\OmegaΩ表示observed（positive）节点对，Ω−\\Omega^-Ω−为unobserved节点对（Ω\\OmegaΩ的补集）。 模型伪代码如下图所示： 3. 实验 解决5个问题： 节点分类任务中MAGNN如何？ 节点聚类任务中MAGNN如何？ 链路预测任务中MAGNN如何？ 三个components中，哪个最有用？ 不同的图嵌入方法表征能力为何不同？ 3.1 数据集 数据集：IMDb（节点分类），DBLP（节点聚类），Last.fm（链路预测） 3.2 Baselines traditional homogeneous models：LINE，node2vec traditional heterogeneous models ：ESim，metapath2vec，HERec homogeneous GNNs：GCN，GAT heterogeneous GNNs ：GATNE，HAN 3.3 基础实验 一、 节点分类 将各个模型生成的node embedding喂给一个SVM分类器，以此比较个模型性能。下表Training表示SVM中用多少数据用于训练。 二、节点聚类 学到的embedding放到K-Means中，重复10次试验取平均值，结果如下表： 三、链路预测 3.4 消融实验 MAGNNrotMAGNN_{rot}MAGNNrot​表示2.2节的encoder使用rotation encoder，MAGNNsmMAGNN_{sm}MAGNNsm​表示只考虑单个最好的元路径，MAGNNavgMAGNN_{avg}MAGNNavg​表示2.2节的encoder使用mean encoder，MAGNNlinearMAGNN_{linear}MAGNNlinear​表示用linear encoder，MAGNNfeatMAGNN_{feat}MAGNNfeat​表示不适用content feature。 3.5 可视化 Last.fm数据集中随机选取30个user-artist对，然后将它们的embedding投影到二维空间中。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"元路径","slug":"元路径","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E8%B7%AF%E5%BE%84/"}]},{"title":"Heterogeneous Graph Transformer","slug":"3 论文笔记/图学习/异构网络/4.Heterogeneous Graph Transformer","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.915Z","comments":true,"path":"d2722120e7b0/","link":"","permalink":"http://rookieyin.github.io/d2722120e7b0/","excerpt":"https://arxiv.org/pdf/2003.01332 https://github.com/acbull/pyHGT Heterogeneous Graph Transformer，WWW，2020 总结：未完待续","text":"https://arxiv.org/pdf/2003.01332 https://github.com/acbull/pyHGT Heterogeneous Graph Transformer，WWW，2020 总结：未完待续 1. 简介 1.1摘要 Recent years have witnessed the emerging success of graph neu-ral networks (GNNs) for modeling structured data. However, mostGNNs are designed for homogeneous graphs, in which all nodesand edges belong to the same types, making them infeasible torepresent heterogeneous structures. In this paper, we present theHeterogeneous Graph Transformer (HGT) architecture for mod-eling Web-scale heterogeneous graphs. To model heterogeneity,we design node- and edge-type dependent parameters to charac-terize the heterogeneous attention over each edge, empoweringHGT to maintain dedicated representations for different types ofnodes and edges. To handle dynamic heterogeneous graphs, we in-troduce the relative temporal encoding technique into HGT, whichis able to capture the dynamic structural dependency with arbitrarydurations. To handle Web-scale graph data, we design the hetero-geneous mini-batch graph sampling algorithm—HGSampling—forefficient and scalable training. Extensive experiments on the OpenAcademic Graph of 179 million nodes and 2 billion edges showthat the proposed HGT model consistently outperforms all thestate-of-the-art GNN baselines by 9%–21%on various downstreamtasks. The dataset and source code of HGT are publicly available at https://github.com/acbull/pyHGT. 最近几年GNNs在结构化数据建模中取得了很大的成功，但是大多数GNNs模型都是用于同构网络（节点和边属于同一个类型），无法直接用于异构网络的表示学习。在本文中，作者介绍了Heterogeneous Graph Transformer（HGT）模型，用于web-scale异构网络的建模。为了对异构性进行建模，作者为node-type和edge-type分别使用独立的参数来characterize每一条边的heterogeneous attention，让HGT模型能够为每种类型的节点和边维护一个特定表示。为了处理动态异构图，作者引入了relative temporal编码技术。为了能够出来了web-scale图数据，作者设计了一种异构mini-batch图采样算法——HGSampling，采样子图进行有效地训练。在有179million节点和2billion边的Academic Graph数据集上的大量实验表明作者提出的HGT模型在各种下游任务上的表现优于state-of-art GNN 9%~21%。数据集和HGT源码发布在https://github.com/acbull/pyHGT。 1.2 本文工作 异构图挖掘主要有两种方式：（1）通过定义元路径来对异构结构进行建模，比如PathSim，Metapath2vec等等；（2）GNNS，比如R-CGNs，HetGNN和HAN。这些方法存在一些弊端： 大多数方法都需要针对不同类型的图单独设计元路径，这就需要我们对图数据有一定了解。 这些方法要么假设不同类型的节点和边具有具有相同的特征空间，要么只是针对不同类型节点或边使用不同的共享权重。这对于捕捉异构图的属性信息是不够的。 大多数方法都忽略了图的动态特性。 这些方法无法适用于大规模异构图的建模。 针对这些limitations，作者提出了HGT模型。（1）为了处理图的异构性，作者分别引入了node-type和edge-type独立的注意力机制；（2）如下图所示，HGT把one-hop edges作为输入，不需要手动设计元路径； 1.3 问题定义 异构网络 有向图G=(V,E,A,R)G=\\mathcal{(V,E,A,R)}G=(V,E,A,R)，图中节点v∈Vv\\in\\mathcal Vv∈V，边e∈Ee\\in\\mathcal Ee∈E，以及类型映射τ(v):V→A\\tau(v):V\\rightarrow\\mathcal Aτ(v):V→A和ϕ(e):E→R\\phi(e):E\\rightarrow\\mathcal Rϕ(e):E→R。 元关系 每一条边e=(s,t)e=(s,t)e=(s,t)连接source node s和target node t，元关系定义为&lt;τ(s),ϕ(e),τ(t)&gt;&lt;\\tau(s),\\phi(e),\\tau(t)&gt;&lt;τ(s),ϕ(e),τ(t)&gt;，ϕ(e)−1\\phi(e)^{-1}ϕ(e)−1表示ϕ(e)\\phi(e)ϕ(e)的转置。 动态异构图 每一条边e=(s,t)e=(s,t)e=(s,t)都分配一个时间戳T，表示节点s和t在T时刻有一条边相连。如果s是第一次出现，那么T绑定为s出现的时间。如果一条边出现在多个时间点，允许一条边有多个时间戳T。 2. HGT 三个部分组成：Heterogeneous Mutual Attention，Heterogeneous Message Passing和Target-Specific Aggregation。 2.1 Heterogeneous Mutual Attention（聚合邻居信息） 计算目标节点t和其邻居节点s之间的相互注意力，计算方法如下： Hl[t]← Aggregate ∀s∈N(t),∀e∈E(s,t)( Attention (s,t)⋅ Message (s))(2)H^{l}[t] \\leftarrow \\underset{\\forall s \\in N(t), \\forall e \\in E(s, t)}{\\text { Aggregate }}(\\text { Attention }(s, t) \\cdot \\text { Message }(s))\\tag 2 Hl[t]←∀s∈N(t),∀e∈E(s,t) Aggregate ​( Attention (s,t)⋅ Message (s))(2) 包含三个部分：（1）Attention，评估每个source node的重要性；（2）Message，source node的信息（上一层的embedding）；（3）Aggregate，根据注意力权重聚合邻居节点信息。GAT模型聚合邻居信息的方式如下： Attention GAT(s,t)=Softmax⁡∀s∈N(t)(a⃗(WHl−1[t]∥WHl−1[s])) Message GAT(s)=WHl−1[s] Aggregate GAT(⋅)=σ(Mean⁡(⋅))\\begin{aligned} \\text { Attention }_{G A T}(s, t) &amp;=\\operatorname{Softmax}_{\\forall s \\in N(t)}\\left(\\vec{a}\\left(W H^{l-1}[t] \\| W H^{l-1}[s]\\right)\\right) \\\\ \\quad \\text { Message }_{G A T}(s) &amp;=W H^{l-1}[s] \\\\ \\text { Aggregate }_{G A T}(\\cdot) &amp;=\\sigma(\\operatorname{Mean}(\\cdot)) \\end{aligned} Attention GAT​(s,t) Message GAT​(s) Aggregate GAT​(⋅)​=Softmax∀s∈N(t)​(a(WHl−1[t]∥WHl−1[s]))=WHl−1[s]=σ(Mean(⋅))​ 虽然GAT中的注意力机制能够有效的识别重要程度高的节点，但是它假设s节点和t节点的特征分布相同，使用了相同的权重参数W。这一假设在异构网络中是不成立的，因为不同类型的节点和边特征分布不同。鉴于这一限制，作者提出了异构相互注意力机制。给定目标节点t以及其所有邻居s∈N(t)s\\in N(t)s∈N(t)，按照元关系&lt;τ(s),ϕ(e),τ(t)&gt;&lt;\\tau(s),\\phi(e),\\tau(t)&gt;&lt;τ(s),ϕ(e),τ(t)&gt;分别计算每种类型元关系的相互注意力。 受Transformer的启发，作者将目标节点t看做Query向量，t的邻居节点看做Key向量，计算它们之间的点积作为attention。和Transformer的不同之处在于，普通的transformer只有一个用于所有单词的set of projections，而作者这里每种类型元关系都有自己的映射权重。 为了保证每种元关系都有自己的专属特征的同时，尽可能实现参数共享，降低模型复杂度， we propose to parameterize the weight matrices of the interac-tion operators into a source node projection, an edge projection,and a target node projection. Attention HGT(s,e,t)=Softmax⁡∀s∈N(t)(∥i∈[1,h] ATT-head i(s,e,t)) ATT-head i(s,e,t)=(Ki(s)Wϕ(e)ATTQi(t)T)⋅μ⟨τ(s),ϕ(e),τ(t)⟩dKi(s)= K-Linear τ(s)i(H(l−1)[s])Qi(t)=Q -Linear τ(t)i(H(l−1)[t])(3)\\begin{aligned} \\text { Attention }_{H G T}(s, e, t) &amp;=\\underset{\\forall s \\in N(t)}{\\operatorname{Softmax}}\\left(\\|_{i \\in[1, h]} \\text { ATT-head }^{i}(s, e, t)\\right) \\\\ \\text { ATT-head }^{i}(s, e, t) &amp;=\\left(K^{i}(s) W_{\\phi(e)}^{A T T} Q^{i}(t)^{T}\\right) \\cdot \\frac{\\mu_{\\langle\\tau(s), \\phi(e), \\tau(t)\\rangle}}{\\sqrt{d}} \\\\ K^{i}(s) &amp;=\\text { K-Linear }_{\\tau(s)}^{i}\\left(H^{(l-1)}[s]\\right) \\\\ Q^{i}(t) &amp;=Q \\text { -Linear }_{\\tau(t)}^{i}\\left(H^{(l-1)}[t]\\right) \\end{aligned}\\tag 3 Attention HGT​(s,e,t) ATT-head i(s,e,t)Ki(s)Qi(t)​=∀s∈N(t)Softmax​(∥i∈[1,h]​ ATT-head i(s,e,t))=(Ki(s)Wϕ(e)ATT​Qi(t)T)⋅d​μ⟨τ(s),ϕ(e),τ(t)⟩​​= K-Linear τ(s)i​(H(l−1)[s])=Q -Linear τ(t)i​(H(l−1)[t])​(3) 2.2 Target-Specific Aggregation 利用公式3，利用聚合多头注意力后得到的注意力向量作为权重，加权平均所有邻居节点的信息，来更新目标节点t的embedding： H~(l)[t]=⨁∀s∈N(t)( Attention HGT(s,e,t)⋅ Message HGT(s,e,t))\\widetilde{H}^{(l)}[t]=\\bigoplus_{\\forall s \\in N(t)}\\left(\\text { Attention }_{H G T}(s, e, t) \\cdot \\text { Message }_{H G T}(s, e, t)\\right) H(l)[t]=∀s∈N(t)⨁​( Attention HGT​(s,e,t)⋅ Message HGT​(s,e,t)) 之后，再利用A−Linearτ(t)A-Linear_{\\tau(t)}A−Linearτ(t)​将t节点的嵌入映射回原有类型空间（作者这里还采用了残差连接，即将l-1层节点嵌入也作为输入）： H(l)[t]= A-Linear τ(t)(σ(H~(l)[t]))+H(l−1)[t](5)H^{(l)}[t]=\\text { A-Linear }_{\\tau(t)}\\left(\\sigma\\left(\\widetilde{H}^{(l)}[t]\\right)\\right)+H^{(l-1)}[t]\\tag 5 H(l)[t]= A-Linear τ(t)​(σ(H(l)[t]))+H(l−1)[t](5) 2.3 Relative Temporal Encoding 传统的利用图动态信息的方式是在每个时间节点分别构建一个异构图，但是这种方式会丢失大量结构依赖性。另外，t时刻某个节点的表示可能依赖于其他时刻的边。因此对动态网络建模的一种合适方式是保留所有时刻的边和节点信息，将它们整合到一张图上，这样不同时刻的节点和边也能交互。 针对这个问题，受Transformer’s positional encoding方法的启发，作者提出RTE机制。具体来说，给定目标节点t和邻居节点s，以及它们对应的时间戳T(s)T(s)T(s)和T(t)T(t)T(t)，用ΔT(t,s)=T(t)−T(s)\\Delta T(t,s)=T(t)-T(s)ΔT(t,s)=T(t)−T(s)作为index来获取一个relative temporal encoding RTE(ΔT(t,s))RTE(\\Delta T(t,s))RTE(ΔT(t,s))。具体计算方式如下： Base⁡(ΔT(t,s),2i)=sin⁡(ΔTt,s/100002id)(6)\\operatorname{Base}(\\Delta T(t, s), 2 i) =\\sin \\left(\\Delta T_{t, s} / 10000^{\\frac{2 i}{d}}\\right)\\tag 6 Base(ΔT(t,s),2i)=sin(ΔTt,s​/10000d2i​)(6) Base⁡(ΔT(t,s),2i+1)=cos⁡(ΔTt,s/100002i+1d)(7)\\operatorname{Base}(\\Delta T(t, s), 2 i+1) =\\cos \\left(\\Delta T_{t, s} / 10000^{\\frac{2 i+1}{d}}\\right)\\tag 7 Base(ΔT(t,s),2i+1)=cos(ΔTt,s​/10000d2i+1​)(7) RTE⁡(ΔT(t,s))= T-Linear (Base⁡(ΔTt,s))(8)\\operatorname{RTE}(\\Delta T(t, s)) =\\text { T-Linear }\\left(\\operatorname{Base}\\left(\\Delta T_{t, s}\\right)\\right)\\tag 8 RTE(ΔT(t,s))= T-Linear (Base(ΔTt,s​))(8) 最后，再将RTE(ΔT(t,s))RTE(\\Delta T(t,s))RTE(ΔT(t,s))添加到GNN的H(l−1)[s]H^{(l-1)}[s]H(l−1)[s]中： H^(l−1)[s]=H(l−1)[s]+RTE(ΔT(t,s))(9)\\widehat{H}^{(l-1)}[s]=H^{(l-1)}[s]+R T E(\\Delta T(t, s))\\tag 9 H(l−1)[s]=H(l−1)[s]+RTE(ΔT(t,s))(9) 2.4 训练 作者提出两个方法，将HGT用于带有动态信息的大规模异构网络：（1）异构mini-batch图采样算法——HGSampling；（2）inductive timestamp assignment method。 2.4.1 HGSampling Full-Batch GNN训练时每一层都要计算所有节点的表示，无法用于大规模图数据。为了解决这个问题，研究人员提出了很多基于采样的方法来训练GNNs。但是，因为每种类型的节点度分布和节点总数差异很大，直接将这些方法用于异构网络进行子图采样是行不通的，这会导致子图在不同节点类型上极不平衡。 思想：为每种节点类型τ\\tauτ维护一个独立的node budget B[τ]B[\\tau]B[τ]，保证每种类型节点被采样到的数量尽可能一致。 采样步骤如下： 给定初始点，并将初始点的邻居通过Add-In-Budget算法添加到budget中 budget中每种类型节点按照概率都pop n个节点，将这些节点添加到输出节点集合中 新添加到输出节点集合的每一个节点，都执行Add-In-Budget操作 重复2~3，知道Budget为空为止 算法伪代码如下： 下图展示了一个简单的子图采样过程： 2.4.2 Inductive Timestamp Assignment 上述算法可以正确执行的一个前提是：每个节点只有一个时间戳。但是在真实数据集中，这个前提条件可能不成立。比如学术网络中WWW会议在2019年、1974年都举办了，因此WWW节点会有两个时间戳（称之为plain节点）。还有一些节点的时间戳是和它邻居节点相关联的，比如论文节点的时间戳和它的发表时间相关联。因此，在子图采样过程中需要作一些特殊处理，确保每个节点有且只有一个准确的时间戳。作者采取的策略是：plani node继承event node的时间戳（算法2伪代码第6行）。检测节点是否是一个event节点，如果是（比如论文节点），则保持节点时间戳不变。如果不是（比如会议节点），则继承和该节点相关联的event节点的时间戳。 3. 实验 在大规模学术网络上：（1）Paper-Feild预测；（2）Paper-Venue预测；（3）Author消歧；（4）case study：HGT如何自动学习提取元路径的 3.1 实验设置 一、数据集 二、Baselines 同构网络学习：GCN，GAT 异构网络GNNs：RGCN，HetGNN，HAN HGT变体：HGT−Heter−RTEHGT_{-Heter}^{-RTE}HGT−Heter−RTE​，HGT−Heter+RTEHGT_{-Heter}^{+RTE}HGT−Heter+RTE​，HGT+Heter−RTEHGT_{+Heter}^{-RTE}HGT+Heter−RTE​，HGT+Heter+RTEHGT_{+Heter}^{+RTE}HGT+Heter+RTE​。其中−RTE-RTE−RTE表示去除相对时间编码RTE部分，−Heter-Heter−Heter表示不同的元关系采用相同的权重参数（即不考虑网络异构性）。 3.2 实验结果 3.3 Case Study 为了进一步研究RTE是如何捕捉图的动态特征的，作者做了一个关于会议动态演化的实验。 3.4 可视化 这一部分主要解释HGT中使用的Meta Relation Attention可以自动学习到有效的元路径，无需人工手动定义。如下图所示，作者展示了HGT前两层权重值最大的schema： 如上图左半部分，如果要计算一篇论文的embedding， ⟨Paper,is_published_at, Venue,is_published_at−1, Paper⟩，⟨Paper,has_L2_field_o f, Field,has_L5_field_of−1, Paper⟩和⟨Institute,is_a f f iliated_with−1, Author,is_first_author_of，Paper⟩ 是三个注意力权重最大的元关系序列。这三个序列可以看做PVP，PFP和IAP三种类型元路径。这也就是说模型可以自动学出有用的元路径，无需人工手动定义。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"动态网络","slug":"动态网络","permalink":"http://rookieyin.github.io/tags/%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/"}]},{"title":"图拉普拉斯的前世今生","slug":"4.图拉普拉斯的前世今生","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.949Z","comments":true,"path":"3338ae8e1a08/","link":"","permalink":"http://rookieyin.github.io/3338ae8e1a08/","excerpt":"图拉普拉斯的前世今生 博客搬运工 # 1. 拉普拉斯算子 1.1 散度 二维平面上的通量 先看一道物理题： 小明乘帆船出行，刮来一阵妖风，假设帆的面积为SSS, 和妖风的夹角为α\\alphaα ，妖风在每单位面积上的垂直风压为SSS，求妖风对帆的推动力 。 显然答案是F=S×P×sin(α)F=S\\times P\\times sin(\\alpha)F=S×P×sin(α)。如果用A→\\overrightarrow{A}A表示风的向量∣∣A→∣∣=P||\\overrightarrow{A}||=P∣∣A∣∣=P，用n→\\overrightarrow nn表示帆的法向量，那么n→\\overrightarrow nn与风的夹角即为π2−α\\frac{\\pi}{2}-\\alpha2π​−α，那么此时F=S⋅A→⋅n→F=S·\\overrightarrow A·\\overrightarrow nF=S⋅A⋅n。","text":"图拉普拉斯的前世今生 博客搬运工 # 1. 拉普拉斯算子 1.1 散度 二维平面上的通量 先看一道物理题： 小明乘帆船出行，刮来一阵妖风，假设帆的面积为SSS, 和妖风的夹角为α\\alphaα ，妖风在每单位面积上的垂直风压为SSS，求妖风对帆的推动力 。 显然答案是F=S×P×sin(α)F=S\\times P\\times sin(\\alpha)F=S×P×sin(α)。如果用A→\\overrightarrow{A}A表示风的向量∣∣A→∣∣=P||\\overrightarrow{A}||=P∣∣A∣∣=P，用n→\\overrightarrow nn表示帆的法向量，那么n→\\overrightarrow nn与风的夹角即为π2−α\\frac{\\pi}{2}-\\alpha2π​−α，那么此时F=S⋅A→⋅n→F=S·\\overrightarrow A·\\overrightarrow nF=S⋅A⋅n。 三维曲面上的通量 假设题目中的帆是空间中的一个曲面∑\\sum∑，在∑\\sum∑中每一点的法向量用n→\\overrightarrow nn表示，空间中的风力用A→\\overrightarrow AA表示，那么此时F=\\displaystyle\\iint_\\sum\\overrightarrow A·\\overrightarrow ndS，这就是通量Φ\\PhiΦ的定义\\Phi_A(\\sum)=\\displaystyle\\iint_\\sum\\overrightarrow A·\\overrightarrow ndS。 封闭曲面的通量 上图中红色箭头表示曲面在此处的法向量，在计算通量的时候我们通常认为向量场会穿过曲面，不会被挡住，此时\\Phi_A(\\sum)= \\displaystyle∮_\\sum\\overrightarrow A·\\overrightarrow ndS。容易看出，根据向量乘法原理，上图中射入曲面和射出曲面的通量一正一负，相互抵消了，最终整个封闭曲面的总通量为0。（其实通量的概念和高中所学的磁通量一样，磁场中，通过封闭曲面的磁通量为0） 散度 所谓散度，其实从名字上来看描述的是：向量场中某个点它的发散程度，向量在这一点是向外发散的，还是向内收敛的，它的发散或收敛强度如何。如下图所示： 显然，这一向量场中，红色曲面的总统量为负，而绿色曲面上的总通量为正。如果我们无限缩小这个曲面，直至接近一个点{x}\\{x\\}{x}，用δV\\delta VδV表示这个曲面围成的体积，那么： ΔA=limδV→xΦA(∑)δV\\Delta A=\\mathop{lim}\\limits_{\\delta V\\rightarrow x}\\frac{\\Phi_A(\\sum)}{\\delta V} ΔA=δV→xlim​δVΦA​(∑)​ ΔA\\Delta AΔA就表示点{x}\\{x\\}{x}处的散度。上图中，红圈的圆心处的散度为负，而绿圈的圆心出散度为正。 因此， 散度衡量了一个点处的向量场是被发射还是被吸收，或者说，对于散度为正的点，散度越大，意味着相应的向量场越强烈地在此发散，而对于散度为负的点，意味着相应的向量场在此汇聚 。 1.2 拉普拉斯算子 定义 拉普拉斯算子是n维欧式空间中的一个二阶微分算子，定义为梯度Δf\\Delta fΔf的散度Δ⋅Δf\\Delta·\\Delta fΔ⋅Δf。 涵义 以三维为例，在直角坐标系中，一个函数f(x,y,z)f(x,y,z)f(x,y,z)在点(x0,y0,z0)(x_0,y_0,z_0)(x0​,y0​,z0​)处的梯度是一个向量(∂f∂x,∂f∂y,∂f∂z)∣x=x0,y=y0,z=z0(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y},\\frac{\\partial f}{\\partial z})|_{x=x_0,y=y_0,z=z_0}(∂x∂f​,∂y∂f​,∂z∂f​)∣x=x0​,y=y0​,z=z0​​。因此函数f的梯度函数为Δf=∂f∂x⋅i→+∂f∂y⋅j→+∂f∂z⋅k→\\Delta f=\\frac{\\partial f}{\\partial x}·\\overrightarrow i+\\frac{\\partial f}{\\partial y}·\\overrightarrow j+\\frac{\\partial f}{\\partial z}·\\overrightarrow kΔf=∂x∂f​⋅i+∂y∂f​⋅j​+∂z∂f​⋅k，这就构成了一个在三维空间下的向量场。我们再对这个向量场Δf\\Delta fΔf求散度Δ⋅Δf\\Delta·\\Delta fΔ⋅Δf即可得到fff的拉普拉斯算子Δ2f\\Delta^2 fΔ2f。 这样定义的原因 让我们想像一座山，根据梯度的定义，在山峰周围，所有的梯度向量向此汇聚，所以每个山峰处的拉普拉斯算子为负；而在山谷周围，所有梯度从此发散，所以每个山谷处的拉普拉斯算子为正。所以说，对于一个函数，拉普拉斯算子实际上衡量了在空间中的每一点处，该函数梯度是倾向于增加还是减少 。 （调和函数，Δ2f=0\\Delta^2f=0Δ2f=0） 2. 图拉普拉斯 2.1 图论下的函数 函数即从定义域到值域的一个映射。在图中，如果用VVV表示图中所有顶点构成的结合，EEE表示所有边构成的集合，我们可以定义一个图函数FG:V→RF_G:V\\rightarrow RFG​:V→R，使得图中每个节点v∈Vv\\in Vv∈V，都被映射到RRR中的一个实数。以下图社交网络为例： 图中每一条边表示两个人之间信息的流通程度。 现在我们想要分析这个社交网络上的信息传播，我们不仅需要知道信息流通的程度，我们还要知道每个人发动态的活跃程度，于是我们现在给这个图一个函数FGF_GFG​ ，使得： FG(A)=3, FG(B)=5, FG(C)=−2, FG(D)=1, FG(E)=−5F_G(A)=3,\\ F_G(B)=5,\\ F_G(C)=-2,\\ F_G(D)=1,\\ F_G(E)=-5 FG​(A)=3, FG​(B)=5, FG​(C)=−2, FG​(D)=1, FG​(E)=−5 这里的负数可以理解为：C和E是聊天终结者，可以阻止信息的传播。这样我们可以得到下面这张图： 2.2 图函数的梯度 梯度描述的时函数在每一点处正交方向上的变化（笛卡尔坐标系中的坐标轴），如f(x,y,z)f(x,y,z)f(x,y,z)的梯度在x方向的分量为∂f∂x=f(x+dx)−f(x)(x+dx)−x\\frac{\\partial f}{\\partial x}=\\frac{f(x+dx)-f(x)}{(x+dx)-x}∂x∂f​=(x+dx)−xf(x+dx)−f(x)​。类比到图中，我们把节点看做欧式空间中的一个点，把边看做是正交的两个分量（笛卡尔坐标系中的坐标轴），并且对于两个节点，我们定义其距离d是其边权值的倒数。那么对于一个节点v0v_0v0​，我们认为其梯度在一条通向v1v_1v1​的边e01e_{01}e01​上的分量为： (FG(v0)−FG(v1))d01=(FG(v0)−FG(v1))⋅e01\\frac{(F_G(v_0)-F_G(v_1))}{d_{01}}=(F_G(v_0)-F_G(v_1))·e_{01} d01​(FG​(v0​)−FG​(v1​))​=(FG​(v0​)−FG​(v1​))⋅e01​ 为了计算梯度，我们首先定义下面的矩阵KGK_GKG​： 其中每一行代表一个点，每一列代表一条边，使得对于每条边，如果该条边冲改点发出的，且权值为X，那么将矩阵中对应的位置的元素置为−X-X−X，如果该条边指向改点，那么将对应元素设为+X+X+X。 同时根据之前图函数F(G)F(G)F(G)的定义，我们有下面的列向量fGf_GfG​： 下面我们计算KGT×fGK_G^T\\times f_GKGT​×fG​： 经观察可以发现，计算结果即为根据(FG(v0)−FG(v1))⋅e01(F_G(v_0)-F_G(v_1))·e_{01}(FG​(v0​)−FG​(v1​))⋅e01​计算出的整个图的梯度向量，其中每一行表示梯度在这一条边上的分量。因此，对于图G，我们有ΔG=KGT\\Delta_G=K_G^TΔG​=KGT​，使得ΔGFG=KGT×fG\\Delta_GF_G=K_G^T\\times f_GΔG​FG​=KGT​×fG​。 2.3 拉普拉斯矩阵 2.3.1 拉普拉斯算子 在函数中，拉普拉斯算子定义为函数梯度的散度，即每一点上其梯度的增加/减少。类别到图中，我们显然可以这样定义图函数的散度：即从该节点射出的梯度，减去射入该节点的梯度。我们可以按照下面方法计算散度，即将原来的梯度向量左乘一个矩阵KG′K_G&#x27;KG′​： KG′K_G&#x27;KG′​中每一行代表一个点，每一列代表一条边， 使得对于每个点每条边，如果该条边从该点发射出去，则将矩阵中对应的这一元素置为-1，如果该条边指向该点，则将对应的元素置为 +1。将KGK_GKG​中正元素变成1，负元素变成-1即可得到KG′K_G&#x27;KG′​。 这样我们就有： \\begin{align} \\Delta_G^2F_G&amp;=K_G&#039;\\times\\Delta_GF_G\\\\ &amp;=K_G&#039;\\times(K_G^T\\times f_G)\\\\ &amp;=(K_G&#039;K_G^T)f_G \\end{align} 于是我们就得到了图函数中拉普拉斯算子的定义Δ2=KG′KGT\\Delta^2=K_G&#x27;K_G^TΔ2=KG′​KGT​，即拉普拉斯矩阵。需要注意的是，拉普拉斯矩阵的值与图中每一条边的方向无关，所以拉普拉斯矩阵一般用于表述无向图。计算KG′KGTK_G&#x27;K_G^TKG′​KGT​的值，我们可以得到： 计算结果为对称矩阵，对角线为每个节点的度，而其余元素则是负的邻接矩阵，于是可以得到拉普拉斯的经典算式： L=D−WL=D-W L=D−W 拉普拉斯矩阵的一个重要性质就是：具有n个非负特征值λ1,λ2,...λn\\lambda_1,\\lambda_2,...\\lambda_nλ1​,λ2​,...λn​，且0=λ1≤λ2≤...≤λn0=\\lambda_1\\leq\\lambda_2\\leq...\\leq\\lambda_n0=λ1​≤λ2​≤...≤λn​。同时根据拉普拉斯矩阵和瑞利熵的概念R(L,h)=h∗Lhh∗hR(L,h)=\\frac{h^*Lh}{h^*h}R(L,h)=h∗hh∗Lh​，通过拉格朗日乘子法可以得出：瑞利熵的最大值，等于L的最大特征值，瑞利熵的最小值等于L的最小值。 2.3.2 差分角度看拉普拉斯 在欧式空间的函数中，拉普拉斯算子是这样定义的：Δ=∑iδ2δxi2\\Delta=\\sum\\limits_i\\frac{\\delta^2}{\\delta x_i^2}Δ=i∑​δxi2​δ2​，即非混合二阶偏导的和，其余所有的XXXX拉普拉斯算子都是其中的一个特例，或者是其某种情况下的一种近似。 图像上的拉普拉斯 图像是一种离散数据，那么我们图像上的拉普拉斯必然要进行离散化处理： 导数的定义：f′(x)=δf(x)δx≈f(x+1)−f(x)f&#x27;(x)=\\frac{\\delta f(x)}{\\delta x}\\approx f(x+1)-f(x)f′(x)=δxδf(x)​≈f(x+1)−f(x) 二阶导数：δ2f(x)δx2=f′′(x)≈f′(x)−f′(x−1)=f(x+1)+f(x−1)−2f(x)\\frac{\\delta^2f(x)}{\\delta x^2}=f&#x27;&#x27;(x)\\approx f&#x27;(x)-f&#x27;(x-1)=f(x+1)+f(x-1)-2f(x)δx2δ2f(x)​=f′′(x)≈f′(x)−f′(x−1)=f(x+1)+f(x−1)−2f(x) 这样我们可以得到两个结论： 结论1：二阶导数近似等于其二阶差分 结论2：二阶导数等于其在所有自由度上微扰后获得的增益。（自由度可以理解为笛卡尔坐标系中的坐标轴，比如1维函数的自由度可以理解为2，有+1和-1两个方向，而2为函数的自 由度则为4，分别是x+1，x-1，y+1，y-1四个方向） 如上，对于二维图像来说共有两个方向，4个自由度可以变化，即如果对(x,y)(x,y)(x,y)处的像素进行扰动，其可以变成四种状态(x+1,y),(x−1,y),(x,y+1),(x,y−1)(x+1,y),(x-1,y),(x,y+1),(x,y-1)(x+1,y),(x−1,y),(x,y+1),(x,y−1)。当然如果我们考虑对角线方向也是一种自由度的话，还会增加四种，这个还是看个人的设定。如果我们只考虑二维图像上4个自由度的变化，那么可以得到： \\begin{align} \\Delta&amp;=\\frac{\\delta^2f(x,y)}{\\delta x^2}+\\frac{\\delta^2f(x,y)}{\\delta y^2}\\\\ &amp;\\approx f(x+1,y)+f(x-1,y)-2f(x,y)+[f(x,y+1)+f(x,y-1)-2f(x,y)]\\\\ &amp;= f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y) \\end{align} 上式可以理解为对(x,y)(x,y)(x,y)点的像素进行轻微扰动后， 使其变化到相邻像素后得到的增益。 这给我们一种形象的结论：拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。 图上的拉普拉斯 推广到图上，对于N个节点的图，假设其邻接矩阵为W，这个图的自由度是多少呢？最多是N。如果这个图是完全图，那么对任意一个节点进行微扰，它就可能变成任意一个节点。此时类比图像中的f(x,y)f(x,y)f(x,y)，图中的函数应该就是一个N维向量f=(f1,...,fN)f=(f_1,...,f_N)f=(f1​,...,fN​)，其中fif_ifi​表示函数在节点iii出的函数值。 根据图像上的拉普拉斯，拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。对于Graph，从节点i变化到节点j增益是多少呢？比较容易想到的就是利用节点之间边的权值来计算： ∑j∈NiWij[fj−fi]\\sum\\limits_{j\\in\\mathcal N_i}W_{ij}[f_j-f_i] j∈Ni​∑​Wij​[fj​−fi​] 因此，对于图来说，其拉普拉斯算计如下： (Δf)i=∑iδ2fδi2≈∑j∈NiWij[fj−fi](\\Delta f)_i=\\sum\\limits_i\\frac{\\delta^2f}{\\delta i^2}\\approx\\sum\\limits_{j\\in\\mathcal N_i}W_{ij}[f_j-f_i] (Δf)i​=i∑​δi2δ2f​≈j∈Ni​∑​Wij​[fj​−fi​] 上式中j∈Nij\\in\\mathcal N_ij∈Ni​可以去掉，因为节点i和j不相连的话，Wij=0W_{ij}=0Wij​=0，所以上式可以继续化简为： \\begin{align} \\sum\\limits_{j\\in\\mathcal N_i}W_{ij}[f_j-f_i]&amp;=\\sum\\limits_jW_{ij}f_j-\\sum\\limits_jW_{ij}f_i\\\\ &amp;=(Wf)_i-(Df)i\\\\ &amp;=[(W-D)f]_i \\end{align} 上式对于任何i都成立，也就有：Δf=(W−D)f\\Delta f=(W-D)fΔf=(W−D)f，即图上的拉普拉斯算子为W−DW-DW−D。 2.3.3 瑞利熵 普通瑞利熵 R(A,x)=xTAxxTxR(A,x)=\\frac{x^TAx}{x^Tx} R(A,x)=xTxxTAx​ 其中A为n阶Hermitian阵，在机器学习中通常处理的都是实数，所以A为实对称矩阵（图中的拉普拉斯是不是满足A的条件？）。通过拉格朗日乘子可以证明： R的最大值就是A的最大特征值，R的最小值就是A的最小特征值 x的解，就是A的特征值对应的特征向量 瑞利熵经常出现在聚类和降维任务中，因为降维、聚类任务往往会导出最大化最小化瑞利熵的式子，从而通过特征值分解的方式找到降维空间。 PCA、谱聚类、RatioCut等算法都是瑞利熵的一个应用。 泛化瑞利熵 对于R(L,x)=xTLxxTxR(L,x)=\\frac{x^TLx}{x^Tx}R(L,x)=xTxxTLx​，其分子是一般形式，而分母是xTDxx^TDxxTDx在D取单位阵时的特殊情况，将其一般化： R(L,h)=xTLxxTDxR(L,h)=\\frac{x^TLx}{x^TDx} R(L,h)=xTDxxTLx​ 同理，通过拉格朗日乘子可以导出： R(L,h)=xT[D−12LD−12]xxTxR(L,h)=\\frac{x^T[D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}]x}{x^Tx} R(L,h)=xTxxT[D−21​LD−21​]x​ 这样又回到了普通瑞利熵问题了。（D−12LD−12D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}D−21​LD−21​这个和正则化的图拉普拉斯是不是一样？） Fisher线性判别器（LDA）、Ncut等算法就是泛化瑞利熵的一种应用。 3. 谱聚类 （该部分主要从刘建平博文https://www.cnblogs.com/pinard/p/6221564.html搬运而来） 谱聚类是从图论中演化出来的算法，后来在聚类中的到了广泛的应用。它的主要思想是：把所有数据看作空间中的点，这些点可以用边连接起来，距离较远的点之间的边的权重较低，距离近的边的权重较高，这样就构成了图。通过对所有数据点组成的图进行切图，让切图后得到的子图之间的边的权重之和尽可能低，而子图内边权重之和尽可能高，从而达到聚类的目的。 3.1 构建无向权重图 对于图G，我们通常用顶点集合V和边集合E来表述，即G(V,E)G(V,E)G(V,E)。对于V中的任意两个顶点，可以有边连接，也可以没有边连接。我们定义wijw_{ij}wij​表示点viv_ivi​和vjv_jvj​之间的权重。因为我们的图是无向的，所以wij=wjiw_{ij}=w_{ji}wij​=wji​。 对于有边连接的两个点viv_ivi​和vjv_jvj​，wij&gt;0w_{ij}&gt;0wij​&gt;0。对于没有边连接的两个点viv_ivi​和vjv_jvj​，wij=0w_{ij}=0wij​=0。对于图中的任意一个点viv_ivi​，它的度did_idi​定义为和它相连的所有边的权重之和，即： di=∑j=1nwijd_i=\\sum\\limits_{j=1}^nw_{ij} di​=j=1∑n​wij​ 这样我们可以得到一个n阶对角矩阵D： 批注 2020-12-06 142153.png 它只有对角线元素有值，对应第i行的第i个点的度。利用所有点之间的权重值，我们可以得到图的邻接矩阵W，它是一个n阶对称矩阵，第i行第j个元素表示点viv_ivi​和点vjv_jvj​之间边的权重。 另外，对于点集V的一个子集A⊂VA\\subset VA⊂V，我们定义： ∣A∣:=子集A中节点的个数vol(A):=∑i∈Adi|A|:=子集A中节点的个数\\\\ vol(A):=\\sum\\limits_{i\\in A}d_i ∣A∣:=子集A中节点的个数vol(A):=i∈A∑​di​ 3.2 构造相似矩阵 在构造加权无向图的过程中，需要使用到边的权重来构造邻接矩阵。但是我们只有数据点的定义，并没有边的定义，如何构造图的邻接矩阵呢？ 一个基本的思想就是：距离较远的两个点之间权重值较低，而距离较近的两个点之间的边的权重较高。通常我们使用样本点距离度量的相似矩阵S来获得邻接矩阵W。常用的构建邻接矩阵W的方法有三类：ϵ\\epsilonϵ-邻近法，K邻近法和全连接法。 ϵ\\epsilonϵ-邻近法 设置一个距离阈值ϵ\\epsilonϵ，然后用欧式距离sij=∣∣xi−xj∣∣22s_{ij}=||x_i-x_j||_2^2sij​=∣∣xi​−xj​∣∣22​度量任意两个点xix_ixi​和xjx_jxj​的距离，然后根据sijs_{ij}sij​和ϵ\\epsilonϵ的大小关系来定义邻接矩阵W如下： \\begin{equation} w_{ij}= \\left\\{ \\begin{array}{lr} 0&amp;\\quad s_{ij}&gt;\\epsilon\\\\ \\epsilon&amp;\\quad s_{ij}\\leq\\epsilon \\end{array} \\right. \\end{equation} 两点之间的权重要么是ϵ\\epsilonϵ，要么是0，没有其他信息了。由于距离远近度量很不精确，因此在实际应用中，我们很少使用ϵ\\epsilonϵ-近邻法。 K近邻 使用KNN算法遍历所有的样本点，取每个样本的最近的k个点作为近邻，只有和距离最近的k个点之间的wij&gt;0w_{ij}&gt;0wij​&gt;0，其余点之间的wij=0w_{ij}=0wij​=0。但是这种方法会导致得到的邻接矩阵W非对称，为了解决这种问题一般采取下面两种方法之一： 第一种K近邻法只要一个点在另一个点的K近邻中，就保留sijs_{ij}sij​ \\begin{equation} w_{ij}=w_{ji} \\left\\{ \\begin{array}{lr} 0&amp; x_i\\notin KNN(x_j)\\ and\\ x_j\\notin KNN(x_i)\\\\ exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2})&amp; x_i\\in KNN(x_j)\\ or\\ x_j\\in KNN(x_i) \\end{array} \\right. \\end{equation} 第二种K邻近法是必须两个点互为K近邻，才能保留sijs_{ij}sij​ \\begin{equation} w_{ij}=w_{ji} \\left\\{ \\begin{array}{lr} 0&amp; x_i\\notin KNN(x_j)\\ or\\ x_j\\notin KNN(x_i)\\\\ exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2})&amp; x_i\\in KNN(x_j)\\ and\\ x_j\\in KNN(x_i) \\end{array} \\right. \\end{equation} 全连接法 和前两种方法相比，这种方法所有点之间的权重值都大于0，因此称之为全连接法。我们可以选择不同的核函数来定义边权重，常用的有多项式核函数，高斯核函数和Sigmoid核函数。最常用的时搞死核函数RBF，此时相似矩阵和邻接矩阵相同： wij=sij=exp(−∣∣xi−xj∣∣222σ2)w_{ij}=s_{ij}=exp(-\\frac{||x_i-x_j||_2^2}{2\\sigma^2}) wij​=sij​=exp(−2σ2∣∣xi​−xj​∣∣22​​) 在实际应用中，使用全连接方法来建立邻接矩阵是最普遍的，而在全脸接法中使用高斯径向核RBF是最普遍的。 3.3 无向图切图 对于无向图G的切图，我们的目标是将图G(V,E)G(V,E)G(V,E)切成相互没有连接的k个子图，每个子图中点的集合为：A1,A2,...,AkA_1,A_2,...,A_kA1​,A2​,...,Ak​，它们满足A_i\\cap A_j=\\O，且A1∪A2∪...∪Ak=VA_1\\cup A_2\\cup...\\cup A_k=VA1​∪A2​∪...∪Ak​=V。对于任意两个子图A,B\\subset V,A\\cap B=\\O，我们定义A和B之间的切图权重为： W(A,B)=∑i∈A,j∈BwijW(A,B)=\\sum\\limits_{i\\in A,j\\in B}w_{ij} W(A,B)=i∈A,j∈B∑​wij​ 那么我们定义切图cut为： cut(A1,A2,...,Ak)=12∑i=1kW(Ai,Aˉi)cut(A_1,A_2,...,A_k)=\\frac{1}{2}\\sum\\limits_{i=1}^kW(A_i,\\bar A_i) cut(A1​,A2​,...,Ak​)=21​i=1∑k​W(Ai​,Aˉi​) 其中Aˉi\\bar A_iAˉi​表示AiA_iAi​的补集，即除AiA_iAi​外的其他V的子集的并集。那么如何切图可以让子图内的点权重和高，子图间的权重和低呢？一个自然的想法就是最小化cut(A1,A2,...,Ak)cut(A_1,A_2,...,A_k)cut(A1​,A2​,...,Ak​)，但是发现，这种最小化方式存在下图所示的问题： 批注 2020-12-06 145842.png 此时，如果我们选择一个权重最小的边缘点，比如C和H之间进行cut，只要可以最小化cut(A1,A2,...,Ak)cut(A_1,A_2,...,A_k)cut(A1​,A2​,...,Ak​)，但是得到的却不是最优的切图。如何避免这种切图，并且找到类似图中“Best Cut”这样的最优切图呢？我们需要对每个子图的规模做出限定，下面就来介绍两种常用的切图方式。 3.3.1 RatioCut切图 RatioCut切图为了避免上图中的最小切图，对每个切图，不光考虑最小化cut(A1,A2,...,Ak)cut(A_1,A_2,...,A_k)cut(A1​,A2​,...,Ak​)，它还同时考虑最大化每个子图的数量，即： RatioCut(A1,A2,...,Ak)=12∑i=1kW(Ai,Aˉi)∣Ai∣RatioCut(A_1,A_2,...,A_k)=\\frac{1}{2}\\sum\\limits_{i=1}^k\\frac{W(A_i,\\bar A_i)}{|A_i|} RatioCut(A1​,A2​,...,Ak​)=21​i=1∑k​∣Ai​∣W(Ai​,Aˉi​)​ 那么如何最小化上面这个RatioCut函数呢？牛人们发现，RatioCut函数可以通过如下方式表示： 3.3.2 Ncut切图 4. GCN 5. 参考链接 https://zhuanlan.zhihu.com/p/67336297 https://cloud.tencent.com/developer/article/1686060 https://zh.m.wikipedia.org/zh-sg/拉普拉斯算子 https://www.cnblogs.com/xingshansi/p/6702188.html?utm_source=itdadao&amp;utm_medium=referral https://zhuanlan.zhihu.com/p/50742283 https://www.cnblogs.com/xingshansi/articles/6702188.html https://zhuanlan.zhihu.com/p/58718563 https://www.cnblogs.com/pinard/p/6221564.html","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"拉普拉斯","slug":"拉普拉斯","permalink":"http://rookieyin.github.io/tags/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/"},{"name":"谱聚类","slug":"谱聚类","permalink":"http://rookieyin.github.io/tags/%E8%B0%B1%E8%81%9A%E7%B1%BB/"}]},{"title":"你真的了解Softmax吗？","slug":"5.你真的了解Softmax吗？","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.932Z","comments":true,"path":"09a1698381db/","link":"","permalink":"http://rookieyin.github.io/09a1698381db/","excerpt":"2. 逻辑回归 Logistic回归主要用于二分类任务，其本质是假设数据服从某个分布，然后使用极大似然估计做参数估计。 2.1 对比线性回归 逻辑回归和线性回归都是一种广义线性模型。看下面这个例子： 对于Tumor的良性和恶性这个二分类问题，0表示负类为良性，1表示正类为恶性。下图展示了在这8个训练样本下，使用线性回归模型hθ(x)=ΘTxh_\\theta(x)=\\Theta^Txhθ​(x)=ΘTx可能拟合出下图中的红线。 此时我们可以正确判别肿瘤是良性还是恶性的：根据这条直线可以找到一个阈值，比如 hθ(x)=0.5h_\\theta(x)=0.5hθ​(x)=0.5，当hθ(x)≥0.5h_\\theta(x)\\geq0.5hθ​(x)≥0.5时预测y=1y=1y=1为恶性，当hθ(x)&lt;0.5h_\\theta(x)&lt;0.5hθ​(x)&lt;0.5时预测y=0y=0y=0为良性。","text":"2. 逻辑回归 Logistic回归主要用于二分类任务，其本质是假设数据服从某个分布，然后使用极大似然估计做参数估计。 2.1 对比线性回归 逻辑回归和线性回归都是一种广义线性模型。看下面这个例子： 对于Tumor的良性和恶性这个二分类问题，0表示负类为良性，1表示正类为恶性。下图展示了在这8个训练样本下，使用线性回归模型hθ(x)=ΘTxh_\\theta(x)=\\Theta^Txhθ​(x)=ΘTx可能拟合出下图中的红线。 此时我们可以正确判别肿瘤是良性还是恶性的：根据这条直线可以找到一个阈值，比如 hθ(x)=0.5h_\\theta(x)=0.5hθ​(x)=0.5，当hθ(x)≥0.5h_\\theta(x)\\geq0.5hθ​(x)≥0.5时预测y=1y=1y=1为恶性，当hθ(x)&lt;0.5h_\\theta(x)&lt;0.5hθ​(x)&lt;0.5时预测y=0y=0y=0为良性。 现在如果我们添加一个训练样本，线性回归可能拟合出下面的蓝线： 此时如果我们任然选取hθ(x)=0.5h_\\theta(x)=0.5hθ​(x)=0.5作为阈值，此时线性回归模型表现十分差劲，它会把正类样本错误分类成负类。这是因为：对于分类任务y=0 or 1y=0\\ or\\ 1y=0 or 1，但是线性回归的假设函数hθ(x)h_\\theta(x)hθ​(x)可能远远大于1或者小于0，这回导致线性回归模型在分类任务中表现很差。 2.2 假设函数 在逻辑回归中，我们选取的假设函数满足0≤hθ(x)≤10\\leq h_\\theta(x)\\leq 10≤hθ​(x)≤1。我们对线性回归模型做如下改变： \\begin{equation} h_\\theta(x)=g(\\theta^Tx)\\\\ g(z)=\\frac{1}{1+e^{-z}} \\end{equation} 其中g(z)g(z)g(z)就是我们常说的Sigmoid函数或者称之为Logistic函数。Sigmoid函数如下如下图所示，可以保证假设函数0≤hθ(x)≤10\\leq h_\\theta(x)\\leq 10≤hθ​(x)≤1。 对于Logistic回归模型，给定输入x和拟合的参数θ\\thetaθ，模型会输出该样本为正例的概率hθ(1∣x;θ)h_\\theta(1|x;\\theta)hθ​(1∣x;θ)。以肿瘤分类问题为例，x=[x0,x1]T=[1,tumorSize]Tx=[x_0,x_1]^T=[1,tumorSize]^Tx=[x0​,x1​]T=[1,tumorSize]T，hθ(x)=0.7h_\\theta(x)=0.7hθ​(x)=0.7，表示该肿瘤有70%的概率为恶性肿瘤。 2.3 决策边界 上面介绍了逻辑回归的假设函数，那么这个假设函数到底在计算什么呢？模型是如何完成分类任务的呢？下面就介绍一下逻辑回归的分类原理——决策边界。 在逻辑回归中hθ(x)=g(θTx)h_\\theta(x)=g(\\theta^Tx)hθ​(x)=g(θTx)，g(z)=11+e−zg(z)=\\frac{1}{1+e^{-z}}g(z)=1+e−z1​。假设hθ(x)≥0.5h_\\theta(x)\\ge0.5hθ​(x)≥0.5时预测y=1y=1y=1，hθ(x)&lt;0.5h_\\theta(x)&lt;0.5hθ​(x)&lt;0.5时预测y=0y=0y=0，也就是： 当z≥0z\\ge0z≥0时，g(z)≥0.5g(z)\\ge0.5g(z)≥0.5，hθ(x)≥0.5h_\\theta(x)\\ge0.5hθ​(x)≥0.5，预测y=1y=1y=1 当z&lt;0z&lt;0z&lt;0时，g(z)&lt;0.5g(z)&lt;0.5g(z)&lt;0.5，hθ(x)&lt;0.5h_\\theta(x)&lt;0.5hθ​(x)&lt;0.5，预测y=0y=0y=0 可以发现：决策边界只取决于我们拟合出的参数和特征维度，和训练集无关。换句话说，一旦我们拟合出了模型参数，我们就唯一确定了模型的决策边界，模型也就训练成功了。那么我们如何拟合模型参数θ\\thetaθ呢？ 2.4 如何拟合参数θ\\thetaθ 首先我们重新梳理下逻辑回归模型的主体： 训练集：{(x(1),y(1)),(x(2),y(2)),...,(x(m),y(m))}\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}{(x(1),y(1)),(x(2),y(2)),...,(x(m),y(m))}m个训练样本 特征：x∈[x0,x1,...,xn]Tx\\in[x_0,x_1,...,x_n]^Tx∈[x0​,x1​,...,xn​]T，x0=1,y∈{0,1}x_0=1,y\\in\\{0,1\\}x0​=1,y∈{0,1} 假设函数：hθ(x)=11+e−θTxh_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}}hθ​(x)=1+e−θTx1​ **学习目标：**拟合出最优的模型参数θ\\thetaθ 2.4.1 代价函数 首先回顾下线性回归中的代价函数：J(\\theta)=\\frac{1}{m}\\sum_\\limits{i+1}^m\\frac{1}{2}(h_\\theta(x^{i})-y^{(i)})^2。我们令Cost(hθ(x),y)=12(hθ(x)−y)2Cost(h_\\theta(x),y)=\\frac{1}{2}(h_\\theta(x)-y)^2Cost(hθ​(x),y)=21​(hθ​(x)−y)2，则J(θ)=1m∑i+1mCost(hθ(x(i)),y(i))J(\\theta)=\\frac{1}{m}\\sum\\limits_{i+1}^mCost(h_\\theta(x^{(i)}),y^{(i)})J(θ)=m1​i+1∑m​Cost(hθ​(x(i)),y(i))，这个代价函数在线性回归中很好用。但是在逻辑回归中，hθ(x)h_\\theta(x)hθ​(x)是非线性的Sigmoid函数，这会如下图所示，导致代价函数是非凸的，使用梯度下降优化模型时无法保证收敛到全局最优点： 所以，在我们需要改进代价函数，设计如下代价函数： f(x)={−log(hθ(x))if y=1−log(1−hθ(x))if y=0f(x)=\\left\\{ \\begin{aligned} -log(h_\\theta(x))\\quad if\\ y=1\\\\ -log(1-h_\\theta(x))\\quad if\\ y=0 \\end{aligned} \\right. f(x)={−log(hθ​(x))if y=1−log(1−hθ​(x))if y=0​ 我们可以绘制出y=−log(z)y=-log(z)y=−log(z)和y=−log(1−hθ(x))y=-log(1-h_\\theta(x))y=−log(1−hθ​(x))的函数图像： 此时我们可以发现这样的代价函数具有很好地性质，以y=1为例： 在z=hθ(x)=1z=h_\\theta(x)=1z=hθ​(x)=1时，表明我们的预测完全正确，代价函数值为0 在z=hθ(x)z=h_\\theta(x)z=hθ​(x)趋向于0时，表明我们的预测完全错误，代价函数值趋向于无穷大 这和我们的逻辑是相符合的。 2.4.2 梯度下降 为了求代价函数的导数，我们可以将上面的代价函数变形为：Cost(hθ(x),y)=−ylog(hθ(x))−(1−y)log(1−hθ(x))Cost(h_\\theta(x),y)=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x))Cost(hθ​(x),y)=−ylog(hθ​(x))−(1−y)log(1−hθ​(x))，不难验证这和上面的分段函数是等价的。所以我们的整体代价函数为： J(θ)=1m∑i=1mCost(hθ(x(i),y(i))=−1m[∑i=1my(i)loghθ(x(i))+(1−y(i))log(1−hθ(x(i)))]\\begin{aligned} J(\\theta)&amp;=\\frac{1}{m}\\sum\\limits_{i=1}^mCost(h_\\theta(x^{(i)},y^{(i)})\\\\ &amp;=-\\frac{1}{m}[\\sum\\limits_{i=1}^my^{(i)}logh_\\theta(x^{(i)})+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))] \\end{aligned} J(θ)​=m1​i=1∑m​Cost(hθ​(x(i),y(i))=−m1​[i=1∑m​y(i)loghθ​(x(i))+(1−y(i))log(1−hθ​(x(i)))]​ 为了拟合最优的参数θ\\thetaθ，我们需要最小化代价函数，即minθJ(θ)\\mathop{min}\\limits_\\theta J(\\theta)θmin​J(θ)。最小化代价函数的方法就是梯度下降，不断执行下面的操作，直到收敛： \\begin{equation} \\theta_j:=\\theta_j-\\alpha\\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j}=\\sum\\limits_{i=1}^m(h_\\theta(x^{i})-y^{(i)})x_j^{i} \\end{equation} 3. Softmax 上面的逻辑回归通常用于二分类问题，对于多分类问题，比如将动物分成猫、狗、其他三个类别，此时要想完成该分类任务需要两个逻辑回归分类器，首先使用一个分类器将其分成猫和其他两个类别，如果分类结果为其他，再使用另外一个分类器将“其他”分类成狗和其他两个类别。如果分类的类别很多，这样分类会非常麻烦，所以大家就提出了Softmax用于多分类任务。 3.1 计算方法 Softmax用于多分类过程，通常是神经网络的最后一层，它将前一层神经元的输出映射到（0,1）区间内，将其看成属于某个类别的概率来进行多分类。因此，Softmax层的神经元个数就等于类别数，其计算方法如下： Si=ezi∑jezjS_i=\\frac{e^{z^i}}{\\sum_je^{z^j}} Si​=∑j​ezjezi​ 其中ziz^izi表示第i个元素的值，SiS_iSi​表示该元素计算出的Softmax值，更形象的如下图所示： 不难验证计算出的所有的Softmax值得和为1，我么可以将这些softmax值视为概率，我们选取其中值最大的（也就是概率最大）的节点作为我们的预测类别。 Softmax具有一些比较好的性质： 单调性，如果ziz_izi​增大，那么yiy_iyi​增大，yj,i≠jy_j,i\\neq jyj​,i​=j减小（可以通过导数进行验证） 非局部性，任何输出的yiy_iyi​都依赖所有带权输入，因为计算公式的分母为∑kezk\\sum_ke^{z_k}∑k​ezk​ 归一化，所有输出之和为1，可以将输出看做概率 3.2 在神经网络中的应用 用于分类任务的深度神经网络最后一层往往都是Softmax层，其通常由全连接层+Softmax组成，如下图所示： 其计算过程y^=softmax(z)=softmax(WTx+b)\\hat y=softmax(z)=softmax(W^Tx+b)y^​=softmax(z)=softmax(WTx+b)包含两步，其中softmax(zj)=ezj∑Kezjsoftmax(z_j)=\\frac{e^{z_j}}{\\sum_Ke^{z_j}}softmax(zj​)=∑K​ezj​ezj​​： 第一步：全连接层将权重矩阵与输入向量想乘再加上偏置，即z=w⋅x+bz=w·x+bz=w⋅x+b，将n个(−∞,+∞)(-\\infty,+\\infty)(−∞,+∞)的实数映射为K个(−∞,+∞)(-\\infty,+\\infty)(−∞,+∞)的实数 第二步：Softmax将K个(−∞,+∞)(-\\infty,+\\infty)(−∞,+∞)的实数映射为K个(0,1)(0,1)(0,1)的实数，且K个数之和为1 3.3 理解Softmax 3.3.1 加权角度 通常把网络最后一个全连接层（Softmax层）的输入x看作网络提取到的特征： zj=wj⋅x+bj=wj1x1+wj2x2+...+wjnxn+bjz_j=w_j·x+b_j=w_{j1}x_1+w_{j2}x_2+...+w_{jn}x_n+b_j zj​=wj​⋅x+bj​=wj1​x1​+wj2​x2​+...+wjn​xn​+bj​ 其中zjz_jzj​可以看做该样本属于类别jjj的得分，然后通过softmax(zj)softmax(z_j)softmax(zj​)对分数进行归一化，将其映射为属于类别jjj的概率。从这个角度可以这样理解上式：特征x的每一个维度xix_ixi​都对该样本是否属于j类别有一定的影响，我们对所有维度进行加权求和就能够得到该样本属于j类的总分，而其中wjiw_{ji}wji​表示加权求和时特征第i个维度的值的权重。 3.3.2 模板匹配角度 如下图所示，我们可以将wjw_jwj​视为第j类的特征模板，Softmax层的计算可以看做是特征与每个模板进行模板匹配，计算样本特征和每个类别特征模板之间的相似度，最后再通过softmax计算将其映射成概率。 如果只有一个全连接层的神经网络（等价于线性分类器），我们可以将每个类别的特征模板直接可视化如下： 如果是多层神经网络，最后一个全连接层的模板是特征空间的模板，可视化需要映射回输入空间。 3.3.3 几何角度 将最后一个全连接层的输入x看做特征，一个特征对应多维空间中的一个点。 对于二分类问题，使用线性分类器y^=w⋅x+b\\hat y=w·x+by^​=w⋅x+b，若y^≥0\\hat y\\ge0y^​≥0即位于超平面上方为正类，若y^&lt;0\\hat y&lt;0y^​&lt;0位于超平面下方为负类。 对于多分类问题，我们就需要为每个类别都设置一个超平面，通过空间中特征点到各个超平面的距离判断样本所属类别。wjw_jwj​为每个超平面的法向量，指向正值方向，特征点到各个超平面的距离为： dj=wj⋅x+bj∣∣wj∣∣d_j=\\frac{w_j·x+b_j}{||w_j||} dj​=∣∣wj​∣∣wj​⋅x+bj​​ softmax层计算的得分zj=∣∣wj∣∣djz_j=||w_j||d_jzj​=∣∣wj​∣∣dj​，再通过softmax将zjz_jzj​映射为概率。如下图所示： 3.4 Softmax的反向传播 3.4.1 损失函数 多分类问题中通常采用交叉熵作为损失函数： L=−∑i=1myilogaiLL = -\\sum\\limits_{i=1}^{m}y_iloga_i^L L=−i=1∑m​yi​logaiL​ 其中a=[a1L,a2L,...,amL]Ta=[a_1^L,a_2^L,...,a_m^L]^Ta=[a1L​,a2L​,...,amL​]T，y=[y1,y2,...,ym]my=[y_1,y_2,...,y_m]^my=[y1​,y2​,...,ym​]m。 在分类任务中y通常为one-hot向量，所以损失函数可以简化为： L=−logaoLL=-loga_o^L L=−logaoL​ 其中ooo为目标类赌赢的维度，即one-hot向量中1对应的维度。 3.4.2 反向传播 要进行反向传播，我们首先需要计算下面这个偏导向量（梯度）： δL=∂C∂zL\\delta^L=\\frac{\\partial C}{\\partial z^L} δL=∂zL∂C​ 然后根据这个梯度δL\\delta^LδL更新相应的参数。下面我们来计算上面公式具体等于什么： 首先根据链式法则，有δL=∂C∂zL=∂C∂aL∂aL∂zL\\delta^L=\\frac{\\partial C}{\\partial z^L}=\\frac{\\partial C}{\\partial a^L}\\frac{\\partial a^L}{\\partial z^L}δL=∂zL∂C​=∂aL∂C​∂zL∂aL​ C为交叉熵损失函数C=−logaoLC=-loga_o^LC=−logaoL​，下面计算∂C∂aL\\frac{\\partial C}{\\partial a^L}∂aL∂C​ 如果i=oi=oi=o，那么∂C∂aiL=−1aiL\\frac{\\partial C}{\\partial a_i^L}=-\\frac{1}{a_i^L}∂aiL​∂C​=−aiL​1​ 注：这里的log的底数默认是e，信息论理交叉熵使用的底数是2。这里使用什么底数并不重要，只是导致最终的损失相差一个常数倍而已。 如果i≠oi\\neq oi​=o，那么∂C∂aiL=0\\frac{\\partial C}{\\partial a_i^L}=0∂aiL​∂C​=0 所以∂C∂aL=[0,0,...,1aoL,...,0]\\frac{\\partial C}{\\partial a^L}=[0,0,...,\\frac{1}{a_o^L},...,0]∂aL∂C​=[0,0,...,aoL​1​,...,0]，其中o是目标类对应的维度。 ∂aL∂zL\\frac{\\partial a^L}{\\partial z^L}∂zL∂aL​对应全连接层，aLa^LaL是一个向量，zLz^LzL也是一个向量，∂aL∂zL\\frac{\\partial a^L}{\\partial z^L}∂zL∂aL​得到的是一个雅克比矩阵： ∂aL∂zL=[∂a1L∂z1L∂a1L∂z2L...∂a1L∂zmL∂a2L∂z1L∂a2L∂z2L...∂a2L∂zmL............∂amL∂z1L∂amL∂z2L...∂amL∂zmL]\\frac{\\partial a^L}{\\partial z^L}=\\left[ \\begin{matrix} \\frac{\\partial a_1^L}{\\partial z_1^L} &amp; \\frac{\\partial a_1^L}{\\partial z_2^L} &amp; ... &amp;\\frac{\\partial a_1^L}{\\partial z_m^L} \\\\ \\frac{\\partial a_2^L}{\\partial z_1^L} &amp; \\frac{\\partial a_2^L}{\\partial z_2^L} &amp; ... &amp;\\frac{\\partial a_2^L}{\\partial z_m^L} \\\\ ... &amp; ...&amp; ...&amp; ...&amp;\\\\ \\frac{\\partial a_m^L}{\\partial z_1^L} &amp; \\frac{\\partial a_m^L}{\\partial z_2^L} &amp; ... &amp;\\frac{\\partial a_m^L}{\\partial z_m^L} \\end{matrix} \\right] ∂zL∂aL​=⎣⎢⎢⎢⎢⎢⎡​∂z1L​∂a1L​​∂z1L​∂a2L​​...∂z1L​∂amL​​​∂z2L​∂a1L​​∂z2L​∂a2L​​...∂z2L​∂amL​​​............​∂zmL​∂a1L​​∂zmL​∂a2L​​...∂zmL​∂amL​​​​⎦⎥⎥⎥⎥⎥⎤​ softmax公式为：aiL=eziL∑j=1mezjLa_i^L=\\frac{e^{z_i^L}}{\\sum_{j=1}^me^{z_j^L}}aiL​=∑j=1m​ezjL​eziL​​，根据求导公式有： ∂aiL∂zjL=∂eziL∂zjL∑k=1mezkL−eziL∂∑k=1mezkL∂zjL(∑k=1mezkL)2=∂eziL∂zjL∑k=1mezkL−eziLezjL(∑k=1mezkL)2\\frac{\\partial a_i^L}{\\partial z_j^L}=\\frac{\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}\\frac{\\partial \\sum_{k=1}^me^{z_k^L}}{\\partial z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}=\\frac{\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2} ∂zjL​∂aiL​​=(∑k=1m​ezkL​)2∂zjL​∂eziL​​∑k=1m​ezkL​−eziL​∂zjL​∂∑k=1m​ezkL​​​=(∑k=1m​ezkL​)2∂zjL​∂eziL​​∑k=1m​ezkL​−eziL​ezjL​​ 其中∂eziL∂zjL\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}∂zjL​∂eziL​​需要讨论i和j的关系： 当i=ji=ji=j时，∂eziL∂zjL=eziL=ezjL\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}=e^{z_i^L}=e^{z_j^L}∂zjL​∂eziL​​=eziL​=ezjL​ ∂aiL∂zjL=∂eziL∂zjL∑k=1mezkL−eziLezjL(∑k=1mezkL)2=eziL∑k=1mezkL−eziLezjL(∑k=1mezkL)2=eziL∑k=1mezkL−eziLezjL(∑k=1mezkL)2−eziL∑k=1mezkLezjL∑k=1mezkL=aiL−aiLajL=aiL(1−aiL)\\begin{aligned} \\frac{\\partial a_i^L}{\\partial z_j^L}&amp;=\\frac{\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}\\\\ &amp;=\\frac{e^{z_i^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}\\\\ &amp;=\\frac{e^{z_i^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}-\\frac{e^{z_i^L}}{\\sum_{k=1}^me^{z_k^L}}\\frac{e^{z_j^L}}{\\sum_{k=1}^me^{z_k^L}}\\\\ &amp;=a_i^L-a_i^La_j^L\\\\ &amp;=a_i^L(1-a_i^L) \\end{aligned} ∂zjL​∂aiL​​​=(∑k=1m​ezkL​)2∂zjL​∂eziL​​∑k=1m​ezkL​−eziL​ezjL​​=(∑k=1m​ezkL​)2eziL​∑k=1m​ezkL​−eziL​ezjL​​=(∑k=1m​ezkL​)2eziL​∑k=1m​ezkL​−eziL​ezjL​​−∑k=1m​ezkL​eziL​​∑k=1m​ezkL​ezjL​​=aiL​−aiL​ajL​=aiL​(1−aiL​)​ 当i≠ji\\neq ji​=j时，∂eziL∂zjL=0\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}=0∂zjL​∂eziL​​=0 ∂aiL∂zjL=∂eziL∂zjL∑k=1mezkL−eziLezjL(∑k=1mezkL)2=0∑k=1mezkL−eziLezjL(∑k=1mezkL)2=−eziL∑k=1mezkLezjL∑k=1mezkL=−aiLajL\\begin{aligned} \\frac{\\partial a_i^L}{\\partial z_j^L}&amp;=\\frac{\\frac{\\partial e^{z_i^L}}{\\partial z_j^L}\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}\\\\ &amp;=\\frac{0\\sum_{k=1}^me^{z_k^L}-e^{z_i^L}e^{z_j^L}}{(\\sum_{k=1}^me^{z_k^L})^2}\\\\ &amp;=-\\frac{e^{z_i^L}}{\\sum_{k=1}^me^{z_k^L}}\\frac{e^{z_j^L}}{\\sum_{k=1}^me^{z_k^L}}\\\\ &amp;=-a_i^La_j^L \\end{aligned} ∂zjL​∂aiL​​​=(∑k=1m​ezkL​)2∂zjL​∂eziL​​∑k=1m​ezkL​−eziL​ezjL​​=(∑k=1m​ezkL​)20∑k=1m​ezkL​−eziL​ezjL​​=−∑k=1m​ezkL​eziL​​∑k=1m​ezkL​ezjL​​=−aiL​ajL​​ 最终我们可以得到： ∂aL∂zL=[a1L(1−a1L)−a2La1L...−amLa1L−a1La2La2L(1−a2L)...−amLa2L............−a1LamL−a2LamL...amL(1−amL)]\\frac{\\partial a^L}{\\partial z^L}=\\left[ \\begin{matrix} a_1^L(1-a_1^L) &amp; -a_2^La_1^L &amp; ... &amp;-a_m^La_1^L \\\\ -a_1^La_2^L &amp; a_2^L(1-a_2^L) &amp; ... &amp;-a_m^La_2^L \\\\ ... &amp; ...&amp; ...&amp; ...&amp;\\\\ -a_1^La_m^L &amp; -a_2^La_m^L &amp; ... &amp;a_m^L(1-a_m^L) \\end{matrix} \\right] ∂zL∂aL​=⎣⎢⎢⎢⎡​a1L​(1−a1L​)−a1L​a2L​...−a1L​amL​​−a2L​a1L​a2L​(1−a2L​)...−a2L​amL​​............​−amL​a1L​−amL​a2L​...amL​(1−amL​)​​⎦⎥⎥⎥⎤​ 我们对上面2、3步的推导结果合并后可得： δL=∂C∂zL=∂C∂aL∂aL∂zL=[a1L(1−a1L)−a2La1L...−amLa1L−a1La2La2L(1−a2L)...−amLa2L............−a1LamL−a2LamL...amL(1−amL)][000⋅−1ao0⋅0]=[a1L,a2L,...,aoL−1,...,amL]T=[a1L−0,a2L−0,...,aoL−1,...,amL−0]T=aL−y\\begin{aligned} \\delta^L&amp;=\\frac{\\partial C}{\\partial z^L}=\\frac{\\partial C}{\\partial a^L}\\frac{\\partial a^L}{\\partial z^L}\\\\ &amp;=\\left[ \\begin{matrix} a_1^L(1-a_1^L) &amp; -a_2^La_1^L &amp; ... &amp;-a_m^La_1^L \\\\ -a_1^La_2^L &amp; a_2^L(1-a_2^L) &amp; ... &amp;-a_m^La_2^L \\\\ ... &amp; ...&amp; ...&amp; ...&amp;\\\\ -a_1^La_m^L &amp; -a_2^La_m^L &amp; ... &amp;a_m^L(1-a_m^L) \\end{matrix} \\right]\\left[\\begin{matrix}0\\\\0\\\\0\\\\·\\\\-\\frac{1}{a_o}\\\\0\\\\·\\\\0\\end{matrix}\\right]\\\\ &amp;=[a_1^L,a_2^L,...,a_o^L-1,...,a_m^L]^T\\\\ &amp;=[a_1^L-0,a_2^L-0,...,a_o^L-1,...,a_m^L-0]^T\\\\ &amp;=a^L-y \\end{aligned} δL​=∂zL∂C​=∂aL∂C​∂zL∂aL​=⎣⎢⎢⎢⎡​a1L​(1−a1L​)−a1L​a2L​...−a1L​amL​​−a2L​a1L​a2L​(1−a2L​)...−a2L​amL​​............​−amL​a1L​−amL​a2L​...amL​(1−amL​)​​⎦⎥⎥⎥⎤​⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​000⋅−ao​1​0⋅0​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​=[a1L​,a2L​,...,aoL​−1,...,amL​]T=[a1L​−0,a2L​−0,...,aoL​−1,...,amL​−0]T=aL−y​ 我们可以发现softmax的梯度十分简洁，就是预测概率aLa^LaL和目标类别y的onehot向量之间的差，实现起来十分简单。 3.5 参考资料 https://zhuanlan.zhihu.com/p/40135042 https://zhuanlan.zhihu.com/p/25723112 https://www.cnblogs.com/shine-lee/p/10077961.html 4. 层次Softmax 4.1 简介 层次Softmax方法最先在word2vector模型中提出。word2vector模型有两种：一种是基于上下文预测某个单词的词袋模型CBOW，另一种是基于单词预测其可能的上下文的skip-gram模型。这两种方法在优化过程中都存在一个问题： 问题：从隐藏层到输出 的Softmax层计算量很大，因为词汇表中的每个单词都可以看成一个类别，类别总数等于词汇表大小。 解决方案：一种是负采样技术，另一种就是本文介绍的Hierachical Softmax 层次Softmax根据类别及其出现频率构建霍夫曼树（类别出现频率越高，树的路径越短），树的叶子节点代表类别标签，非叶子节点代表神经元，这样具有以下好处： 假设有N个类别，使用softmax计算类别标签计算量为V，使用层次softmax计算量为logVlogVlogV（N个类别相当于有N个叶子节点，树高度为logVlogVlogV） 使用Huffman树，出现频率高的类别在树上端，这样高频类别标签计算的时间会更短 4.2 计算原理 假设有$C1\\sim C88个类别的数据构成了上图所示的一棵Huffman树，每个叶子节点表示一个类别标签，非叶子节点类似神经元。新来一个节点8个类别的数据构成了上图所示的一棵Huffman树，每个叶子节点表示一个类别标签，非叶子节点类似神经元。新来一个节点8个类别的数据构成了上图所示的一棵Huffman树，每个叶子节点表示一个类别标签，非叶子节点类似神经元。新来一个节点X_i$后，从根节点开始，每个非叶子节点处都要执行一次二分类，计算走左边的概率（负类）和走右边的概率（正类），直到叶子节点： P(右)=σ(Xiθ)=11+exiθP(左)=1−σ(Xiθ)\\begin{aligned} P(右)&amp;=\\sigma(X_i\\theta)=\\frac{1}{1+e^{x_i\\theta}}\\\\ P(左)&amp;=1-\\sigma(X_i\\theta) \\end{aligned} P(右)P(左)​=σ(Xi​θ)=1+exi​θ1​=1−σ(Xi​θ)​ 新节点XiX_iXi​所走路径的最后一个叶子节点代表的类别即模型的预测结果YiY_iYi​，预测XiX_iXi​的标签为YiY_iYi​的概率为： P(Yi∣Xi)=∏j=2lP(dj∣Xi,θj−1)P(Y_i|X_i)=\\prod_{j=2}^lP(d_j|X_i,\\theta_{j-1}) P(Yi​∣Xi​)=j=2∏l​P(dj​∣Xi​,θj−1​) 其中: P(dj∣Xi,θj−1)={σ(Xiθj−1)if dj=11−σ(Xiθj−1)if dj=0P(d_j|X_i,\\theta_{j-1})=\\left\\{ \\begin{aligned} &amp;\\sigma(X_i\\theta_{j-1})\\quad &amp;if\\ d_j=1\\\\ &amp;1-\\sigma(X_i\\theta_{j-1})\\quad &amp;if\\ d_j=0 \\end{aligned} \\right. P(dj​∣Xi​,θj−1​)={​σ(Xi​θj−1​)1−σ(Xi​θj−1​)​if dj​=1if dj​=0​ 主要我们可以得到： P(Yi∣Xi)=∏j=2lP(dj∣Xi,θj−1)=∏j=2l[σ(Xiθj−1)]dj[1−σ(Xiθj−1)]1−djP(Y_i|X_i)=\\prod_{j=2}^lP(d_j|X_i,\\theta_{j-1})=\\prod_{j=2}^l[\\sigma(X_i\\theta_{j-1})]^{d_j}[1-\\sigma(X_i\\theta_{j-1})]^{1-d_j} P(Yi​∣Xi​)=j=2∏l​P(dj​∣Xi​,θj−1​)=j=2∏l​[σ(Xi​θj−1​)]dj​[1−σ(Xi​θj−1​)]1−dj​ 假设ppp为预测XiX_iXi​类别的路径，路径ppp包含lll个节点{p1,p2,...,pl}\\{p_1,p_2,...,p_l\\}{p1​,p2​,...,pl​}，路径中每个非叶子节点执行二分类对应的参数为{θ1,θ2,...,θl−1}\\{\\theta_1,\\theta_2,...,\\theta_{l-1}\\}{θ1​,θ2​,...,θl−1​}（因为最后节点为叶子节点，不需要执行二分类）。 4.3 梯度 如果我们和逻辑回归一样，采用交叉熵作为损失函数，则模型损失函数定义如下： L=−1n∑i=1nlog(P(Yi∣Xi))L=-\\frac{1}{n}\\sum_{i=1}^nlog(P(Y_i|X_i)) L=−n1​i=1∑n​log(P(Yi​∣Xi​)) 注：word2vector中采用的是对数似然函数作为损失函数，即L=1n∑i=1nlog(P(Yi∣Xi))L=\\frac{1}{n}\\sum_{i=1}^nlog(P(Y_i|X_i))L=n1​∑i=1n​log(P(Yi​∣Xi​))，使用梯度上升法进行优化。 假设我们每次只采用一个样本进行梯度更新，则有： L=−log(P(Yi∣Xi))=−log(∏j=2l[σ(Xiθj−1)]dj[1−σ(Xiθj−1)]1−dj)=−∑j=2llog([σ(Xiθj−1)]dj[1−σ(Xiθj−1)]1−dj)=−∑j=2l(djlog[σ(Xiθj−1)]+(1−dj)log[1−σ(Xiθj−1)])\\begin{aligned} L &amp;= -log(P(Y_i|X_i))\\\\ &amp;=-log\\Big(\\prod_{j=2}^l[\\sigma(X_i\\theta_{j-1})]^{d_j}[1-\\sigma(X_i\\theta_{j-1})]^{1-d_j}\\Big)\\\\ &amp;=-\\sum_{j=2}^llog\\Big([\\sigma(X_i\\theta_{j-1})]^{d_j}[1-\\sigma(X_i\\theta_{j-1})]^{1-d_j}\\Big)\\\\ &amp;=-\\sum_{j=2}^l(d_jlog[\\sigma(X_i\\theta_{j-1})]+(1-d_j)log[1-\\sigma(X_i\\theta_{j-1})]) \\end{aligned} L​=−log(P(Yi​∣Xi​))=−log(j=2∏l​[σ(Xi​θj−1​)]dj​[1−σ(Xi​θj−1​)]1−dj​)=−j=2∑l​log([σ(Xi​θj−1​)]dj​[1−σ(Xi​θj−1​)]1−dj​)=−j=2∑l​(dj​log[σ(Xi​θj−1​)]+(1−dj​)log[1−σ(Xi​θj−1​)])​ 这样我们可以求解L对X和θ\\thetaθ的梯度： ∂L∂θj−1=−∂(djlog[σ(Xiθj−1)]+(1−dj)log[1−σ(Xiθj−1)])θj−1=−(1−dj−σ(Xiθj−1))Xi\\begin{aligned} \\frac{\\partial L}{\\partial\\theta_{j-1}}&amp;=-\\frac{\\partial({d_jlog[\\sigma(X_i\\theta_{j-1})]+(1-d_j)log[1-\\sigma(X_i\\theta_{j-1})])}}{\\theta_{j-1}}\\\\ &amp;=-(1-d_j-\\sigma(X_i\\theta_{j-1}))X_i \\end{aligned} ∂θj−1​∂L​​=−θj−1​∂(dj​log[σ(Xi​θj−1​)]+(1−dj​)log[1−σ(Xi​θj−1​)])​=−(1−dj​−σ(Xi​θj−1​))Xi​​ ∂L∂Xi=−∑j=2l(1−dj−σ(Xiθj−1))θj−1\\frac{\\partial L}{\\partial X_i}=-\\sum_{j=2}^{l}(1-d_j-\\sigma(X_i\\theta_{j-1}))\\theta_{j-1} ∂Xi​∂L​=−j=2∑l​(1−dj​−σ(Xi​θj−1​))θj−1​ 这样我们可以采用梯度下降法更新θ\\thetaθ和XXX。","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://rookieyin.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Softmax","slug":"Softmax","permalink":"http://rookieyin.github.io/tags/Softmax/"}]},{"title":"Simple and Deep Graph Convolutional Networks","slug":"3 论文笔记/图学习/2.Simple and Deep Graph Convolutional Networks","date":"2021-06-04T07:08:10.000Z","updated":"2022-04-19T05:48:26.775Z","comments":true,"path":"8c3ac9ec967d/","link":"","permalink":"http://rookieyin.github.io/8c3ac9ec967d/","excerpt":"https://arxiv.org/abs/2007.02133 https://github.com/chennnM/GCNII Simple and Deep Graph Convolutional Networks 我的启发： 这个方法存不存在什么弊端？ 收敛速度和节点度的关系今后能不能利用上？","text":"https://arxiv.org/abs/2007.02133 https://github.com/chennnM/GCNII Simple and Deep Graph Convolutional Networks 我的启发： 这个方法存不存在什么弊端？ 收敛速度和节点度的关系今后能不能利用上？ 1. 简介 1.1 摘要 Graph convolutional networks (GCNs) are a powerful deep learning approach for graph-structured data. Recently, GCNs and subseque-nt variants have shown superior performance in various application areas on real world datasets. Despite their success, most of the current GCN models are shallow, due to the over-smoothing problem. In this paper, we study the problem of designing and analyzing deep graph convolutional networks. We propose the GCNII, an extension of the vanilla GCN model with two simple yet effective techni-ques: Initial residual and Identity mapping. We provide theoretical and empirical evidence that the two techniques effectively relieves the problem of over-smoothing. Our experiments show that the deep GCNII model outperforms the state-of-the-art methods on various semi- and full-supervised tasks. Code is available at https://github.com/chennnM/GCNII. GCN是用于图结构数据的一种强大的深度学习方法。最近，GCN及其一些变体在不同领域的真实数据集上都取得了很好地表现。尽管GCNs已经比较成功了，但是由于过平滑问题，现有的GCN模型都比较shallow。在这篇文章中，我们研究并分析了如何设计深层GNN模型。我们提出了GCNII模型——通过Initial residual和Inentity mapping两个技术对GCN模型进行了改进。我们提供了理论上和经验上的证据表明这两个技术有效的缓解了过平滑问题。我们的实验表明深层GCNII模型可以在不同的半监督和全监督任务中取得最优的表现。代码发布在https://github.com/chennnM/GCNII。 1.2 背景 近些年来，GCNs及其各种变体被成功应用于社交网络、交通预测、生物、推荐系统、计算机视觉中。但是现有的大部分GCN模型都是shallow的，比如GCN和GAT都是在2层时取得最好的效果，这限制了GCN模型从高阶领域中提取信息的能力。但是，通过堆叠模型或者添加非线性层会导致模型性能下降，这也就是我们常说的**“over-smothing”现象——随着模型层数的增加，节点的表示收敛于同一个值，导致节点无法被区分**。 1.2.1 为什么产生过平滑？ https://blog.csdn.net/zhouchen1998/article/details/109741134 https://zhuanlan.zhihu.com/p/124727955 直觉上的理解 一层GCN相当于对一阶邻域信息进行聚合，随着GCN深度的增加，对于连通图，每个节点都逐渐聚合了整个图的信息，所有节点的特征都会趋同化。 从频域角度 GCN可以看作一个低通滤波器（ Revisiting Graph Neural Networks: All We Have is Low-Pass Filters ），这种特性可以让信号变得更加平滑，但是平滑操作过多的话会导致节点特征趋同，丧失多样性。 GCN中一种常用的正则化拉普拉斯矩阵定义为：Lsym~=I−D~−12LD~−12=I−L~s\\tilde {L^{sym}}=I-\\tilde D^{-\\frac{1}{2}L\\tilde D^{-\\frac{1}{2}}}=I-\\tilde L_sLsym~=I−D~−21​LD~−21​=I−L~s​，\\tilde L_s=U\\tilde\\and U^T特征值范围是0∼20\\sim20∼2，所以有： \\tilde{L^{sym}}=I-\\tilde L_s=I-U\\tilde\\and U^T=I-\\tilde L_s=U(I-\\tilde\\and)U^T 可以看出Lsym~\\tilde{L^{sym}}Lsym~的特征值范围是(−1,1)(-1,1)(−1,1)。 在信号与系统中，我们可以将信号转换到频域，通过频率响应函数滤波，再将信号转换到时域完成滤波的操作。这里的频率响应函数为(I-\\tilde\\and)\\in(-1,1)。不难看出，它对信号进行了低通滤波。 (暂时不懂) 堆叠K层GCN时，矩阵Lsym~\\tilde{L^{sym}}Lsym~被乘了k次，我们将其展开： \\begin{aligned} \\tilde{L^{sym}}^k&amp;=(I-\\tilde L_s)^k\\\\ &amp;=U(I-\\tilde\\and)^kU^T\\\\ &amp;=Udiag((1-\\tilde\\lambda_1)^k,(1-\\tilde\\lambda_2)^k,...,(1-\\tilde\\lambda_n)^k)U^T \\end{aligned} 其中(1−λ~i)k(1-\\tilde\\lambda_i)^k(1−λ~i​)k只有在当λ~i=0\\tilde\\lambda_i=0λ~i​=0时，(1−λ~i)k≡1(1-\\tilde\\lambda_i)^k\\equiv 1(1−λ~i​)k≡1，其余情况下(1−λ~i)k(1-\\tilde\\lambda_i)^k(1−λ~i​)k的绝对值都不超过1，所以limk→+∞(1−λ~i)k=0\\mathop{lim}\\limits_{k\\rightarrow +\\infty}(1-\\tilde\\lambda_i)^k=0k→+∞lim​(1−λ~i​)k=0。 由于拉普拉斯具有性质：n维拉普拉斯矩阵具有n个非负特征值，0特征值的个数等于连通图的个数。假设只有1个连通图，将特征值从小到大排列λ1≤λ2≤...≤λn\\lambda_1\\leq\\lambda_2\\leq...\\leq\\lambda_nλ1​≤λ2​≤...≤λn​，则有： limk→+∞(1−λ~1)k=0\\mathop{lim}\\limits_{k\\rightarrow+\\infty}(1-\\tilde\\lambda_1)^k=0 k→+∞lim​(1−λ~1​)k=0 此时有: limk→+∞Lsym~x=Udiag(1,0,...,0)UTx=&lt;x⋅u1&gt;u1=x^(1)⋅u1\\begin{aligned} \\mathop{lim}\\limits_{k\\rightarrow+\\infty}\\tilde{L^{sym}}x&amp;=Udiag(1,0,...,0)U^Tx\\\\ &amp;=&lt;x·u_1&gt;u_1\\\\ &amp;=\\hat x(1)·u_1 \\end{aligned} k→+∞lim​Lsym~x​=Udiag(1,0,...,0)UTx=&lt;x⋅u1​&gt;u1​=x^(1)⋅u1​​ u1=D12⋅1u_1=D^{\\frac{1}{2}}·1u1​=D21​⋅1，是矩阵L~s\\tilde L_sL~s​特征值0对应的特征向量，该向量是一个处处相等的向量。所以，如果对一个图信号不断进行平滑操作，最终会得到一个没有区分性的、处处相等的图信号。 从空域角度 Representation Learning on Graphs with Jumping Knowledge Networks 从空域角度，也就是从空间上来看，GCN本质上是在聚合邻居信息，对于任意一个节点，GCN每增加一层，相当于聚合了更高一阶的邻居节点的信息。我们将聚合的最高邻居节点的阶数称之为聚合半径，可以发现，随着GCN层数增加，节点的聚合半径也在变大，一旦达到某个阈值，该节点可覆盖的节点就会和全图节点一致。如果层数很多，每个节点覆盖的节点都会收敛到全图节点，这样就导致每个节点学习到的特征就趋同化。 上图是论文中的一个实验结果图。a和b分别对两个不同方块节点进行信息聚合，可以看到四层GCN后，两个节点虽然收敛半径一样，但是覆盖到的节点差距很大。如果我们对b在进行一次聚合后发现方块节点的覆盖节点迅速增加到图的中心区域，此时两个方块节点聚合的节点网络趋于一致，对其区分会很困难。 1.2.2 针对过平滑问题的现有工作 最近，一些工作也尝试着解决过平滑问题。 JKNet 通过skip connections整合每一层的输出，来保持节点表示的局部性。 DropEdge 通过去掉输入图中的部分边可以缓解过平滑的影响。 实验表明，上面这两种方法只能缓解过平滑问题，半监督任务中仍然是浅层模型取得最好结果。还有一些方法尝试构建深层简单神经网络。这些模型在每一层都是对邻居信息进行线性聚合，丢失了深层非线性架构的强大表示能力，这也就意味着它们本质上还属于浅层模型。 SGC PPNP和APPNP GDC——对APPNP进行了拓展 1.2.3 作者解决方案 本文作者工作： 作者基于Initial residual和Identity mapping提出了一种GCN改进模型GCNII——一个解决了过平滑问题的深度GCN模型。 Wu等人提出了通过堆叠K层，普通的GCN模型本质上模拟了一个有固定的系数的K-th阶多项式滤波器。作者证明了K层GCNII模型可以模拟一个有任意系数的K阶多项式谱滤波器。 另外作者通过实验得到了普通GCN最终收敛得到的静态向量，分析表明在多层GCN模型中，度更高的节点更可能产生过平滑问题。 符号定义： 连通无向图：G=(V,E)G=(V,E)G=(V,E)，有n个顶点m条边。 G~=(V,E~)\\tilde G=(V,\\tilde E)G~=(V,E~)表示self-looped图。 {1,...,n}\\{1,...,n\\}{1,...,n}表示图中节点ID，djd_jdj​和dj+1d_j+1dj​+1表示图G和G~\\tilde GG~中第j个节点的度。 A表示邻接矩阵，D表示度矩阵，那么图G~\\tilde GG~中的邻接矩阵和度矩阵分别为A~=A+I\\tilde A=A+IA~=A+I和D~=D+I\\tilde D=D+ID~=D+I X∈Rn×dX\\in R^{n\\times d}X∈Rn×d表示节点特征矩阵，每个节点vvv关联一个d维特征向量XvX_vXv​ 正则化的拉普拉斯矩阵：L=In−D−1/2AD−1/2L=I_n-D^{-1/2}AD^{-1/2}L=In​−D−1/2AD−1/2 2. GCNII模型 Wu等人证明通过堆叠K层，GCN在图G~\\tilde GG~模拟了一个K阶多项式滤波器(∑l=1KθlL~l)x(\\sum_{\\mathcal l=1}^{K}\\theta_l\\tilde L^l)x(∑l=1K​θl​L~l)x，其系数为固定的θ\\thetaθ。**这个固定的系数限制了多层GCN的表达能力，从而导致过平滑。**如果我们能让GCN模拟出一个有任意系数的K阶多项式滤波器，那么就能将GCN拓展成真正的深层模型。作者证明了可以通过Initial residual connection和Identity mapping两个简单技术就可以实现这个。作者定义GCNII模型如下： \\begin{equation} H^{(l+1)}=\\sigma\\Big(\\tilde PH^{(l)}W^{(l)}\\Big)\\\\ H^{(l+1)}=\\sigma\\Big(\\Big((1-\\alpha_l)\\tilde PH^{(l)}+\\alpha_lH^{(0)}\\Big)\\Big((1-\\beta_l)I_n+\\beta_lW^{(l)}\\Big)\\Big) \\end{equation} 其中αl\\alpha_lαl​和βl\\beta_lβl​是超参数。和普通GCN相比，作者主要做了两点改进： 将P~H(l)\\tilde PH^{(l)}P~H(l)和初始输入H(0)H^{(0)}H(0)进行了残差连接 给第l层的权重矩阵W(l)W^{(l)}W(l)添加了一个单位矩阵InI_nIn​ 2.1 Initial residual connection 为了模拟计算机视觉中的ResNet，Kipf&amp;Welling在2017年使用残差连接，但是结果表明这种残差连接方式只能减缓过平滑问题，随着层数增加，模型性能还是会下降。 作者提出要和初始特征H(0)H^{(0)}H(0)构建残差连接，这样如果迭代很多层的话，最终得到的节点表示至少包含了一小部分节点的原始特征。在实际应用中，我们可以设置αl=0.1 or 0.2\\alpha_l=0.1\\ or\\ 0.2αl​=0.1 or 0.2。 Klicpera等人在APPNP模型中也在PageRank中采用了类似的初始残差连接方式。但是APPNP这篇论文中发现在特征矩阵上进行多层非线性操作会导致过拟合从而使得模型降低，因此APPNP模型中在不同层之间使用线性连接，所以APPNP本质上还是一个浅层模型。这启发了作者，仅仅和初始特征进行残差连接不足以将GCN变成一个深层模型，所以作者在此基础上添加了一个Identity mapping。 2.2 Identity mapping 为了修正APPNP模型的不足，作者借用ResNet中identity mapping的思想，在第l层给权重矩阵W(l)W^{(l)}W(l)添加一个单位矩阵InI_nIn​。下面是作者提出该想法的动机和目的： 和ResNet的动机一样，identity mapping可以保证深层GCNII模型至少可以取得和浅层模型一样的表现（为什么？）。如果将βl\\beta_lβl​设置的很小，那么模型就会忽略权重矩阵W(l)W^{(l)}W(l)，本质上和APPNP模型类似。 Klicpera等观察到特征矩阵不同维度的频繁地交互会导致模型在半监督任务中性能下降，直接将平滑表示P~H(l)\\tilde PH^{(l)}P~H(l)映射成输出可以减少这类型交互。 Identity mapping已经被证明了在半监督任务中十分有效。在Hardt&amp;Ma的论文中说明了H(l+1)=H(l)(W(l)+In)H^{(l+1)}=H^{(l)}(W^{(l)}+I_n)H(l+1)=H(l)(W(l)+In​)形式的线性残差网络具有以下性质： 优化权重矩阵W(l)W^{(l)}W(l)的norms很小 只有重要的点是全局最小的 第一个性质可以帮助在WlW^lWl添加正则化防止过拟合，第二个性质适用于训练数据很少的半监督任务。 Oono等人从理论上证明了K层GCN提取到的节点特征会收敛到一个子空间，导致信息丢失。特征收敛的概率取决于sKs^KsK，其中s表示权重矩阵W(l)W^{(l)}W(l)的最大特征值。通过用(1−βl)In+βlW(l)(1-\\beta_l)I_n+\\beta_lW^{(l)}(1−βl​)In​+βl​W(l)替代W(l)W^{(l)}W(l)可以让W(l)W^{(l)}W(l)的norm变小，(1−βl)In+βlW(l)(1-\\beta_l)I_n+\\beta_lW^{(l)}(1−βl​)In​+βl​W(l)的特征值会接近1，因此最大特征值s会接近1，这样sKs^KsK会比较大，可以缓解信息损失。 对于超参βl\\beta_lβl​的选择需要保证随着模型层数的增加，权重矩阵逐渐衰减。在实际应用中，我们设置βl=log(λl+1)≈λl\\beta_l=log(\\frac{\\lambda}{l}+1)\\approx\\frac{\\lambda}{l}βl​=log(lλ​+1)≈lλ​，其中λ\\lambdaλ是超参。 3. 谱分析 3.1 多层GCN的谱分析 考虑下面的GCN模型： H(l+1)=σ((P~H(l)+H(l))W(l))H^{(l+1)}=\\sigma\\Big(\\Big(\\tilde PH^{(l)}+H^{(l)}\\Big)W^{(l)}\\Big) H(l+1)=σ((P~H(l)+H(l))W(l)) Wang等人在“ daptive graphconvolutional neural networks”一文中提出：**上面的公式其实模拟的是一个转移矩阵为In+D~−1/2A~D~−1/22\\frac{I_n+\\tilde D^{-1/2}\\tilde A\\tilde D^{-1/2}}{2}2In​+D~−1/2A~D~−1/2​的“lazy random walk”。这样一个lazy random walk最终会收敛成一个静态状态，从而导致过拟合（有待研究）。**作者得到了这个封闭的静态向量并分析其收敛率，得到一个结论：每个节点的收敛速度取决于其度。 3.1.1 定理1 假设自环图G~\\tilde GG~是连通的，h(K)=(In+D~−1/2A~D~−1/22)K⋅xh^{(K)}=\\Big(\\frac{I_n+\\tilde D^{-1/2}\\tilde A\\tilde D^{-1/2}}{2}\\Big)^K·xh(K)=(2In​+D~−1/2A~D~−1/2​)K⋅x表示对图信号进行带有残差连接的正则化图卷积操作，λG~\\lambda_{\\tilde G}λG~​表示图G~\\tilde GG~的spectral gap，即正则化拉普拉斯矩阵L~\\tilde LL~的最小非负特征值。我们有如下结论： 随着K趋向于无穷大，h(K)h^{(K)}h(K)收敛于π=&lt;D~1/21,x&gt;2m+n\\pi=\\frac{&lt;\\tilde D^{1/2}1,x&gt;}{2m+n}π=2m+n&lt;D~1/21,x&gt;​，D~1/21\\tilde D^{1/2}1D~1/21中的1表示全1向量。 收敛速度取决于h(K)=π±(∑i=1nxi)⋅(1−λG~22)Kh^{(K)}=\\pi\\pm\\Big(\\sum\\limits_{i=1}^nx_i\\Big)·\\Big(1-\\frac{\\lambda_{\\tilde G}^2}{2}\\Big)^Kh(K)=π±(i=1∑n​xi​)⋅(1−2λG~2​​)K。 注：±\\pm±操作表示∣h(K)−π∣≤(∑i=1nxi)⋅(1−λG~22)K|h^{(K)}-\\pi|\\leq\\Big(\\sum\\limits_{i=1}^nx_i\\Big)·\\Big(1-\\frac{\\lambda_{\\tilde G}^2}{2}\\Big)^K∣h(K)−π∣≤(i=1∑n​xi​)⋅(1−2λG~2​​)K 其中m和n分别表示原始图G中节点和边的数量。 根据定理1，我们可以得出两个结论： GCN的K阶表示h(K)h^{(K)}h(K)收敛于一个向量π=&lt;D~1/21,x&gt;2m+n\\pi=\\frac{&lt;\\tilde D^{1/2}1,x&gt;}{2m+n}π=2m+n&lt;D~1/21,x&gt;​，由于该向量只包含两种信息：每个节点的度，以及原始图信号x和D1/21D^{1/2}1D1/21之间的内积，从而导致GCN过平滑（这个为什么？因为没有包含图结构信息，而初始节点特征都是1？）。 这个h(K)=π±(∑i=1nxi)⋅(1−λG~22)Kh^{(K)}=\\pi\\pm\\Big(\\sum\\limits_{i=1}^nx_i\\Big)·\\Big(1-\\frac{\\lambda_{\\tilde G}^2}{2}\\Big)^Kh(K)=π±(i=1∑n​xi​)⋅(1−2λG~2​​)K公式表明收敛速度取决于所有特征的和∑i=1n\\sum_{i=1}^n∑i=1n​以及spectral gapλG~\\lambda_{\\tilde G}λG~​。如果我们针对单个节点j，可以得到下列式子： h(K)(j)=dj+1(∑i=1ndi+12m+n±∑i=1nxi(1−λG~22)Kdj+1)h^{(K)}(j)=\\sqrt{d_j+1}\\Big(\\sum\\limits_{i=1}^n\\frac{\\sqrt{d_i+1}}{2m+n}\\pm\\frac{\\sum_{i=1}^nx_i(1-\\frac{\\lambda_{\\tilde G}^2}{2})^K}{\\sqrt{d_j+1}}\\Big) h(K)(j)=dj​+1​(i=1∑n​2m+ndi​+1​​±dj​+1​∑i=1n​xi​(1−2λG~2​​)K​) 这表明：如果节点j的度djd_jdj​越大，dj+1\\sqrt{d_j+1}dj​+1​越大，h(K)(j)h^{(K)}(j)h(K)(j)收敛到静态向量π(j)\\pi(j)π(j)的速度越快。基于这个事实，我们可以得到下列推论： **推论1：**度高的节点遭受过平滑的可能性越大。 3.1.2 证明 引理1Chung：piK=(In+A~D~−12)Keip_i^{K}=(\\frac{I_n+\\tilde A\\tilde D^-1}{2})^Ke_ipiK​=(2In​+A~D~−1​)Kei​表示自环图G~\\tilde GG~中节点i的K-th转移概率向量，\\lambda_\\tilde G表示图G~\\tilde GG~的spectra gap。piKp_i^KpiK​的j-th entry有如下限制： \\Big|p_i^{(K)}(j)-\\frac{d_j+1}{2m+n}\\Big|\\leq\\sqrt{\\frac{d_j+1}{d_i+1}}\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big)^K In=D~−1/2D~1/2I_n=\\tilde D^{-1/2}\\tilde D^{1/2}In​=D~−1/2D~1/2，GCN的K层表示如下： h(K)=(In+D~−1/2A~D~1/22)K⋅x=(D~−1/2(In+A~D~−12)KD~1/2)K⋅x=D~−1/2(In+A~D~−12)K⋅(D~1/2x)\\begin{aligned} h^{(K)} &amp;= \\Big(\\frac{I_n+\\tilde D^{-1/2}\\tilde A\\tilde D^{1/2}}{2}\\Big)^K·x\\\\ &amp;=\\Big(\\tilde D^{-1/2}\\Big(\\frac{I_n+\\tilde A\\tilde D^{-1}}{2}\\Big)^K\\tilde D^{1/2}\\Big)^K·x\\\\ &amp;=\\tilde D^{-1/2}\\Big(\\frac{I_n+\\tilde A\\tilde D^{-1}}{2}\\Big)^K·\\big(\\tilde D^{1/2}x\\big) \\end{aligned} h(K)​=(2In​+D~−1/2A~D~1/2​)K⋅x=(D~−1/2(2In​+A~D~−1​)KD~1/2)K⋅x=D~−1/2(2In​+A~D~−1​)K⋅(D~1/2x)​ 将D~1/2x\\tilde D^{1/2}xD~1/2x按如下方式展开： D~1/2x=(D+In)1/2x=∑i=1n(x(i)di+1)⋅ei\\tilde D^{1/2}x=\\big(D+I_n\\big)^{1/2}x=\\sum\\limits_{i=1}^n\\big(x(i)\\sqrt{d_i+1}\\big)·e_i D~1/2x=(D+In​)1/2x=i=1∑n​(x(i)di​+1​)⋅ei​ 将上式代入hKh^{K}hK中得： h(K)=D~−1/2(In+A~D~−12)K⋅∑i=1n(x(i)di+1)⋅ei=∑i=1ndi+1⋅D~−1/2(In+A~D~−12)K⋅ei\\begin{aligned} h^{(K)}&amp;=\\tilde D^{-1/2}\\Big(\\frac{I_n+\\tilde A\\tilde D^{-1}}{2}\\Big)^K·\\sum\\limits_{i=1}^n\\big(x(i)\\sqrt{d_i+1}\\big)·e_i\\\\ &amp;=\\sum\\limits_{i=1}^n\\sqrt{d_i+1}·\\tilde D^{-1/2}\\Big(\\frac{I_n+\\tilde A\\tilde D^{-1}}{2}\\Big)^K·e_i \\end{aligned} h(K)​=D~−1/2(2In​+A~D~−1​)K⋅i=1∑n​(x(i)di​+1​)⋅ei​=i=1∑n​di​+1​⋅D~−1/2(2In​+A~D~−1​)K⋅ei​​ 我们注意到上式的后两项(In+A~D~−12)K⋅ei\\Big(\\frac{I_n+\\tilde A\\tilde D^{-1}}{2}\\Big)^K·e_i(2In​+A~D~−1​)K⋅ei​刚好就是K-th转移概率向量pi(K)p_i^{(K)}pi(K)​。根据引理1，pi(K)p_i^{(K)}pi(K)​的第j个元素满足下列不等式： \\Big|p_i^{(K)}(j)-\\frac{d_j+1}{2m+n}\\Big|\\leq\\sqrt{\\frac{d_j+1}{d_i+1}}\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big)^K 等价于下列公式： p_i^{(K)}(j)=\\frac{d_j+1}{2m+n}\\pm\\sqrt{\\frac{d_j+1}{d_i+1}}\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big)^K 因此，h(K)h^{(K)}h(K)的第j个元素可以表示为： \\begin{aligned} h^{(K)}(j)&amp;=\\Big(\\sum\\limits_{i=1}^n\\sqrt{d_i+1}x(i)·\\tilde D^{-1/2}p_i^{(K)}\\Big)(j)\\\\ &amp;=\\sum\\limits_{i=1}^{n}\\sqrt{d_i+1}x(i)\\frac{1}{d_j+1}·\\Big(\\frac{d_j+1}{2m+n}\\pm\\sqrt{\\frac{d_j+1}{d_i+1}}\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big)^K\\Big)\\\\ &amp;=\\sum\\limits_{i=1}^{n}\\frac{\\sqrt{(d_j+1)(d_i+1)}}{2m+n}x(i)\\pm\\sum\\limits_{i=1}^nx(i)\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big) \\end{aligned} 因此有： h^{(K)}=\\frac{&lt;\\tilde D^{1/2}1,x&gt;}{2m+n}\\tilde D^{1/2}1\\pm\\sum\\limits_{i=1}^nx(i)\\Big(1-\\frac{\\lambda_\\tilde G^2}{2}\\Big)·1 定理1得证。 3.2 GCNII 的谱分析 对于自环图G~\\tilde GG~，图信号x上的一个K阶多项式滤波器定义为(∑l=0KθlL~l)x\\Big(\\sum_{l=0}^K\\theta_l\\tilde L^l\\Big)x(∑l=0K​θl​L~l)x，其中L~\\tilde LL~是正则化拉普拉斯矩阵，θ\\thetaθ是多项式系数。 Wu等人证明了K层GCN模拟了一个带有固定系数θ\\thetaθ的多项式过滤器，作者证明了正是这个固定的系数限制了GCN的能力，导致过平滑问题。 作者证明了K层GCNII模型模拟了具有任意系数的K阶多项式过滤器（也就是解决了GCN过平滑问题） 3.2.1 定理及证明 **定理2：**考虑自环图G~\\tilde GG~和图信号x，K层GCNII可以模拟一个具有任意系数θ\\thetaθ的K阶多项式滤波器(∑l=0KθlL~l)x\\Big(\\sum_{l=0}^K\\theta_l\\tilde L^l\\Big)x(∑l=0K​θl​L~l)x **证明：**假设信号向量x是非负的，我们考虑一个弱化版本的GCNII：设置αl=0.5\\alpha_l=0.5αl​=0.5，权重矩阵(1−βl)In+βlW(l)(1-\\beta_l)I_n+\\beta_lW^{(l)}(1−βl​)In​+βl​W(l)为γlIn\\gamma_lI_nγl​In​，其中γl\\gamma_lγl​是可学习参数，这样我们有： H(l+1)=σ(D~−1/2A~D~−1/2(H(l)+x)γlIn)H^{(l+1)}=\\sigma\\Big(\\tilde D^{-1/2}\\tilde A\\tilde D^{-1/2}\\Big(H^{(l)}+x\\Big)\\gamma_lI_n\\Big) H(l+1)=σ(D~−1/2A~D~−1/2(H(l)+x)γl​In​) 由于输入特征x是非负的，所以我们可以去掉激活函数ReLU（因为ReLU在x大于0时是线性的）： H(l+1)=γlD~−1/2A~D~−1/2(H(l)+x)=γl((In−L~)⋅(H(l)+x))\\begin{aligned} H^{(l+1)}&amp;=\\gamma_l\\tilde D^{-1/2}\\tilde A\\tilde D^{-1/2}\\Big(H^{(l)}+x\\Big)\\\\ &amp;=\\gamma_l\\Big(\\Big(I_n-\\tilde L\\Big)·\\Big(H^{(l)}+x\\Big)\\Big) \\end{aligned} H(l+1)​=γl​D~−1/2A~D~−1/2(H(l)+x)=γl​((In​−L~)⋅(H(l)+x))​ 因此，我们可以得到最终的表示为： H(K−1)=(∑l=0K−1(∏k=K−l−1K−1γk)(In−L~)l)xH^{(K-1)}=\\Bigg(\\sum\\limits_{l=0}^{K-1}\\Bigg(\\prod_{k=K-l-1}^{K-1}\\gamma_k\\Bigg)\\bigg(I_n-\\tilde L\\bigg)^l\\Bigg)x H(K−1)=(l=0∑K−1​(k=K−l−1∏K−1​γk​)(In​−L~)l)x 而针对图G~\\tilde GG~的一个多项式滤波器可以表示为： (∑k=0K−1θkL~k)=(∑l=0K−1(∑k=lK−1θk(−1)l(kl)(In−L~)l))x\\Bigg(\\sum\\limits_{k=0}^{K-1}\\theta_k\\tilde L^k\\Bigg)=\\Bigg(\\sum\\limits_{l=0}^{K-1}\\Bigg(\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l}\\bigg(I_n-\\tilde L\\bigg)^l\\Bigg)\\Bigg)x (k=0∑K−1​θk​L~k)=(l=0∑K−1​(k=l∑K−1​θk​(−1)l(lk​)(In​−L~)l))x 要证明定理2，只需证明对于所有l=0,...,K−1l=0,...,K-1l=0,...,K−1，都存在γl\\gamma_lγl​使得下列等式成立： ∏k=K−l−1K−1γk=∑k=lK−1θk(−1)l(kl),k=0,...,K−1\\prod_{k=K-l-1}^{K-1}\\gamma_k=\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l},k=0,...,K-1 k=K−l−1∏K−1​γk​=k=l∑K−1​θk​(−1)l(lk​),k=0,...,K−1 对上式做变形： ∏k=K−l−1K−1γk=∑k=lK−1θk(−1)l(kl),k=0,...,K−1γK−l−1∏k=K−lK−1γk=∑k=lK−1θk(−1)l(kl),k=0,...,K−1γK−l−1=∑k=lK−1θk(−1)l(kl)/∏k=K−lK−1γk,k=0,...,K−1γK−l−1=∑k=lK−1θk(−1)l(kl)/∑k=l−1K−1θk(−1)l−1(kl−1),k=0,...,K−1\\begin{aligned} \\prod_{k=K-l-1}^{K-1}\\gamma_k&amp;=\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l},k=0,...,K-1\\\\ \\gamma_{K-l-1}\\prod_{k=K-l}^{K-1}\\gamma_k&amp;=\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l},k=0,...,K-1\\\\ \\gamma_{K-l-1}&amp;=\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l}\\Big/\\prod_{k=K-l}^{K-1}\\gamma_k,k=0,...,K-1\\\\ \\gamma_{K-l-1}&amp;=\\sum\\limits_{k=l}^{K-1}\\theta_k(-1)^l\\binom{k}{l}\\Big/\\sum\\limits_{k=l-1}^{K-1}\\theta_k(-1)^{l-1}\\binom{k}{l-1},k=0,...,K-1 \\end{aligned} k=K−l−1∏K−1​γk​γK−l−1​k=K−l∏K−1​γk​γK−l−1​γK−l−1​​=k=l∑K−1​θk​(−1)l(lk​),k=0,...,K−1=k=l∑K−1​θk​(−1)l(lk​),k=0,...,K−1=k=l∑K−1​θk​(−1)l(lk​)/k=K−l∏K−1​γk​,k=0,...,K−1=k=l∑K−1​θk​(−1)l(lk​)/k=l−1∑K−1​θk​(−1)l−1(l−1k​),k=0,...,K−1​ 上式作除法操作需要保证∑k=l−1K−1θk(−1)l−1(kl−1)\\sum_{k=l-1}^{K-1}\\theta_k(-1)^{l-1}\\binom{k}{l-1}∑k=l−1K−1​θk​(−1)l−1(l−1k​)不为0，如果为0，我们可以设置γK−l−1\\gamma_{K-l-1}γK−l−1​足够大保证上述公式仍然有很好地近似。但是上式分母为0的概率很小，因为这意味着K阶过滤器忽略了l跳邻居的所有特征。 至此，定理2证明完毕。 3.2.2 分析讨论 定理1表明了K层普通GCN模拟了一个具有固定参数的K阶多项式滤波器P~Kx\\tilde P^KxP~Kx，P~\\tilde PP~表示正则化后的图卷积矩阵。过平滑是由于P~Kx\\tilde P^KxP~Kx会收敛到一个和输入信号x无关的分布中，从而导致梯度消失。DropEdge减缓了收敛速度，但是随着K趋向于无穷大，最终还是会出现过平滑问题。 定理2表明深层GCNII会收敛到一个同时包含输入特征信息和图结构信息的分布，这使得即使K趋向于无穷大，GCNII不会遭受过平滑问题。准确地说，定理2表明K层GCNII模拟了一个具有任意系数的K阶多项式滤波器h(K)=(∑l=0KθlL~l)⋅xh^{(K)}=\\Big(\\sum_{l=0}^K\\theta_l\\tilde L^l\\Big)·xh(K)=(∑l=0K​θl​L~l)⋅x，通过选取合适的θ\\thetaθ，即使K趋向于无穷大，h(K)h^{(K)}h(K)也可以同时包含输入特征和图结构信息。 4. 实验 GCNII变体：GCNII∗GCNII^*GCNII∗ H(l+1)=σ(((1−αl)P~H(l)+αlH(0))((1−βl)In+βlW(l)))H^{(l+1)}=\\sigma\\Big(\\Big((1-\\alpha_l)\\tilde PH^{(l)}+\\alpha_lH^{(0)}\\Big)\\Big((1-\\beta_l)I_n+\\beta_lW^{(l)}\\Big)\\Big) H(l+1)=σ(((1−αl​)P~H(l)+αl​H(0))((1−βl​)In​+βl​W(l))) H(l+1)=σ((1−αl)P~H(l)((1−βl)In+βlW1(l))+αlH(0)((1−βl)In+βlW2(l)))H^{(l+1)}=\\sigma\\Big((1-\\alpha_l)\\tilde PH^{(l)}\\Big((1-\\beta_l)I_n+\\beta_lW_1^{(l)}\\Big)+\\alpha_lH^{(0)}\\Big((1-\\beta_l)I_n+\\beta_lW_2^{(l)}\\Big)\\Big) H(l+1)=σ((1−αl​)P~H(l)((1−βl​)In​+βl​W1(l)​)+αl​H(0)((1−βl​)In​+βl​W2(l)​)) 一、数据集 半监督节点分类：Cora，Citesseer和Pubmed三个citation数据集，这三个数据集中节点表示文件，边表示citation，节点特征为文件的bag-of-words表示。 全监督节点分类：Chameleon，Cornell，Texas和Wisconsin四个网络数据集，节点表示网页，边表示页面之间的超链接，节点特征是对应页面的bag-of-words表示。 inductive学习：使用PPI（蛋白质）网络，包含24个图，其中20个图用于训练，2个图用于验证，其余的用于测试。 二、半监督节点分类 三、全监督节点分类 四、inductive学习：9层GCNII 五、消融实验：initial residual连接和Identity mappin的作用","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GCN","slug":"GCN","permalink":"http://rookieyin.github.io/tags/GCN/"},{"name":"过平滑","slug":"过平滑","permalink":"http://rookieyin.github.io/tags/%E8%BF%87%E5%B9%B3%E6%BB%91/"}]},{"title":"Why Do Attributes Propagate in Graph Convolutional Neural Networks","slug":"3 论文笔记/图学习/6.Why Do Attributes Propagate in Graph Convolutional Neural Networks","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.963Z","comments":true,"path":"400ef1348239/","link":"","permalink":"http://rookieyin.github.io/400ef1348239/","excerpt":"https://yangliang.github.io/pdf/aaai21.pdf Why Do Attributes Propagate in Graph Convolutional Neural Networks，2021，AAAI 总结：本文偏理论一点，作者提出了一个图表示学习框架GRL，并基于此从数值优化角度（梯度下降和高阶近似）对GCN及其各种变体做出了解释。最后受共轭梯度法性能优于梯度下降法的启发，提出了图共轭卷积模型。","text":"https://yangliang.github.io/pdf/aaai21.pdf Why Do Attributes Propagate in Graph Convolutional Neural Networks，2021，AAAI 总结：本文偏理论一点，作者提出了一个图表示学习框架GRL，并基于此从数值优化角度（梯度下降和高阶近似）对GCN及其各种变体做出了解释。最后受共轭梯度法性能优于梯度下降法的启发，提出了图共轭卷积模型。 1. 简介 1.1 摘要 Many efforts have been paid to enhance Graph ConvolutionalNetwork from the perspective of propagation under the phi-losophy that “Propagation is the essence of the GCNNs”.Unfortunately, its adverse effect is over-smoothing, whichmakes the performance dramatically drop. To prevent theover-smoothing, many variants are presented. However, theperspective of propagation can’t provide an intuitive and uni-fied interpretation to their effect on prevent over-smoothing.In this paper, we aim at providing a novel explanation tothe question of“Why do attributes propagate in GCNNs?”.which not only gives the essence of the oversmoothing, butalso illustrates why the GCN extensions, including multi-scale GCN and GCN with initial residual, can improve theperformance. To this end, an intuitive Graph RepresentationLearning (GRL) framework is presented. GRL simply con-strains the node representation similar with the original at-tribute, and encourages the connected nodes possess similarrepresentations (pairwise constraint). Based on the proposedGRL, exiting GCN and its extensions can be proved as dif-ferent numerical optimization algorithms, such as gradientdescent, of our proposed GRL framework. Inspired by thesuperiority of conjugate gradient descent compared to com-mon gradient descent, a novel Graph Conjugate Convolu-tional (GCC) network is presented to approximate the solu-tion to GRL with fast convergence. Specifically, GCC adoptstheobtainedinformation of the last layer, which can be rep-resented as the difference between the input and output of thelast layer, as the input to the next layer. Extensive experimentsdemonstrate the superior performance of GCC. 基于“Propagation is the essence of the GCNNs”这一思想，研究人员付出了很多努力来提升图卷积网络的性能。不幸的是，受过平滑影响，模型性能下降很多。为了阻止过平滑现象，人们提出了很多变体。但是，从（信息）传播的角度很难解释这些变体为什么能防止过平滑。本文中作者尝试解释这样一个问题：“Why do attributes propagate in GCNNs”。不仅给出了过平滑的本质，同时解释了各种GCN变体为什么能提高模型性能。最后，作者展示了一种直观的图表示学习框架GRL。GRL只是简单执行两个约束：（1）节点表示和原始特征之间的相似度；（2）相连接点之间的相似度。基于提出的GRL框架，现有的GCN及其变体被证明了是各种不同的数值优化算法，比如梯度下降。受共轭梯度下降比普通梯度下降优越的启发，作者提出了一种新的图共轭卷积神经网络GCC，用于快速逼近GRL的最优解。具体来说，GCC利用前一层输入和输出之间的差作为当前层输入的一部分。大量实验证明了GCC的优越性。 1.2 本文工作 为了提高GCNs的性能，研究人员从propagation角度做出了很多努力，比如GAT，GaAN，Geom-GCN等等。一种普遍的观点是“Propagation is the essence of GCNNs“，并且将GCNs的成功归于propagation引起的拉普拉斯平滑。 针对GNNs的过平滑问题，研究人员也提出了很多方法，比如Disentangled GCN，DropEdge，PageRank-GCN，JKNet，DeepGCN，GCNII等等。但是从propagation角度无法提供一个关于阻止过拟合的直观解释。 本文作者尝试解答“Why do attributes propagate in GCNNs?”，不仅给出了过平滑的本质，并且切实了各类GCN变体为什么能提高模型性能。最后提出了一个直观的图表示学习框架GRL（假设图拓扑结构是准确的）和Robust GRL（考虑图拓扑结构中存在噪声）。 根据提出的GRL和Robust GRL，作者证明了现有的GCN及其变体可以看做不同的数值优化算法比如梯度下降。具体来说带有残差的GCN可以看做GRL的梯度下降，multi-scale GCN可以看做GRL的高阶近似分析方法，带注意力的GCN可以看做是Robust GRL的梯度下降。从数值优化角度理解GCN及其变体，作者得出以下结论：“The propagation as well as its weight learning are not the essence of the GCNs, but induced by the numerical optimization of pairwise similarity requirement.”。 基于这个发现，作者提出了一种新的图共轭卷积网络，用于快速逼近GRL的解。具体来说，鉴于共轭梯度下降的优越性，图共轭卷积层采用上一层输入和输出的差作为当前层输入的一部分。 2. 方法 2.1 先验知识 一、线性系统中的梯度下降 对称正定线性系统定义如下： Au=x(1)Au = x\\tag 1 Au=x(1) 其中x,u∈RN\\mathbb{x,u}\\in\\mathbb R^Nx,u∈RN是N维实向量，A∈RN×N\\mathbf A\\in\\mathbb R^{N\\times N}A∈RN×N为对称正定矩阵，A和x已知，u未知。上述方程组的一个解析解u∗=A−1xu^*=A^{-1}xu∗=A−1x计算代价很大，复杂度为O(N3)O(N^3)O(N3)。 鉴于A是对称正定阵，所以上述方程可以通过梯度下降法求解，通过最小化下列方程得到： f(u)=12uTAu−uTx(2)f(\\mathbf{u})=\\frac{1}{2} \\mathbf{u}^{T} \\mathbf{A} \\mathbf{u}-\\mathbf{u}^{T} \\mathbf{x}\\tag 2 f(u)=21​uTAu−uTx(2) 通过迭代下列公式可以得到公式2的最小值（数值优化中的梯度下降法）： u(t+1)=u(t)−μt∇f(u(t))=u(t)+μt(x−Au(t))(3)\\mathbf{u}^{(t+1)}=\\mathbf{u}^{(t)}-\\mu_{t} \\nabla f\\left(\\mathbf{u}^{(t)}\\right)=\\mathbf{u}^{(t)}+\\mu_{t}\\left(\\mathbf{x}-\\mathbf{A} \\mathbf{u}^{(t)}\\right)\\tag 3 u(t+1)=u(t)−μt​∇f(u(t))=u(t)+μt​(x−Au(t))(3) 其中μt\\mu_tμt​表示步长。在实际应用中，对于对称正定线性方程组，应用更为广泛的方法是共轭梯度法： u(t+1)=u(t)−μt∇f(u(t))+κt(u(t)−u(t−1))=u(t)+μt(x−Au(t))+κt(u(t)−u(t−1))(4)\\begin{aligned} \\mathbf{u}^{(t+1)} &amp;=\\mathbf{u}^{(t)}-\\mu_{t} \\nabla f\\left(\\mathbf{u}^{(t)}\\right)+\\kappa_{t}\\left(\\mathbf{u}^{(t)}-\\mathbf{u}^{(t-1)}\\right) \\\\ &amp;=\\mathbf{u}^{(t)}+\\mu_{t}\\left(\\mathbf{x}-\\mathbf{A} \\mathbf{u}^{(t)}\\right)+\\kappa_{t}\\left(\\mathbf{u}^{(t)}-\\mathbf{u}^{(t-1)}\\right) \\end{aligned}\\tag 4 u(t+1)​=u(t)−μt​∇f(u(t))+κt​(u(t)−u(t−1))=u(t)+μt​(x−Au(t))+κt​(u(t)−u(t−1))​(4) 共轭梯度法收敛速度更快。求解公式1定义的方程组的解还有一种更直接的方法，即计算A的逆矩阵： Δ(s)=∣sI−A∣=sN+α1sN−1+α2sN−2+…+αNΔ(A)=AN+α1AN−1+α2AN−2+…+αNI=0A−1=−1αNAN−1−α1αNAN−2−…−αN−1αNIu∗=−∑k=0N−1αN−k−1αNAkx(5)\\Delta(s)=|s \\mathbf{I}-\\mathbf{A}|=s^{N}+\\alpha_{1} s^{N-1}+\\alpha_{2} s^{N-2}+\\ldots+\\alpha_{N}\\\\ \\Delta(\\mathbf{A})=\\mathbf{A}^{N}+\\alpha_{1} \\mathbf{A}^{N-1}+\\alpha_{2} \\mathbf{A}^{N-2}+\\ldots+\\alpha_{N} \\mathbf{I}=0\\\\ \\mathbf{A}^{-1}=-\\frac{1}{\\alpha_{N}} \\mathbf{A}^{N-1}-\\frac{\\alpha_{1}}{\\alpha_{N}} \\mathbf{A}^{N-2}-\\ldots-\\frac{\\alpha_{N-1}}{\\alpha_{N}} \\mathbf{I}\\\\ \\mathbf{u}^{*}=-\\sum_{k=0}^{N-1} \\frac{\\alpha_{N-k-1}}{\\alpha_{N}} \\mathbf{A}^{k} \\mathbf{x}\\tag 5 Δ(s)=∣sI−A∣=sN+α1​sN−1+α2​sN−2+…+αN​Δ(A)=AN+α1​AN−1+α2​AN−2+…+αN​I=0A−1=−αN​1​AN−1−αN​α1​​AN−2−…−αN​αN−1​​Iu∗=−k=0∑N−1​αN​αN−k−1​​Akx(5) 二、图卷积神经网络 17年Kipf和Welling提出的GCN H(t+1)=ReLU⁡(W(t+1)H(t)A^)(6)\\mathbf{H}^{(t+1)}=\\operatorname{ReLU}\\left(\\mathbf{W}^{(t+1)} \\mathbf{H}^{(t)} \\hat{\\mathbf{A}}\\right)\\tag 6 H(t+1)=ReLU(W(t+1)H(t)A^)(6) 其中A^=D~−12A~D~−12,A~=A+I\\hat{\\mathbf{A}}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}}, \\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}A^=D~−21​A~D~−21​,A~=A+I，上述公式可以写成： H(t+1)=ReLU⁡(W(t+1)H(t)(I+A‾))(7)\\mathbf{H}^{(t+1)}=\\operatorname{ReLU}\\left(\\mathbf{W}^{(t+1)} \\mathbf{H}^{(t)}(\\mathbf{I}+\\overline{\\mathbf{A}})\\right)\\tag 7 H(t+1)=ReLU(W(t+1)H(t)(I+A))(7) 其中Aˉ=D−12AD−12\\bar A=D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}Aˉ=D−21​AD−21​。公式7的node-wise可以表示为： hi(t+1)=σ(W(t+1)∑N(i)∪{i}αijhj(t))(8)\\mathbf{h}_{i}^{(t+1)}=\\sigma\\left(\\mathbf{W}^{(t+1)} \\sum_{N(i) \\cup\\{i\\}} \\alpha_{i j} \\mathbf{h}_{j}^{(t)}\\right)\\tag 8 hi(t+1)​=σ⎝⎜⎛​W(t+1)N(i)∪{i}∑​αij​hj(t)​⎠⎟⎞​(8) 其中αij\\alpha_{ij}αij​是固定的（邻接矩阵中的各个值），N(i)N(i)N(i)表示节点viv_ivi​的所有邻居，σ(⋅)\\sigma(·)σ(⋅)表示非线性函数（比如ReLU）。整个GCN模型唯一的参数就是权重矩阵W(t)W^{(t)}W(t)，可以通过最小化交叉熵损失函数得到： F=−∑vi∈Vl∑k=1Kzikln⁡yik(9)\\mathcal{F}=-\\sum_{v_{i} \\in \\mathcal{V}_{l}} \\sum_{k=1}^{K} z_{i k} \\ln y_{i k}\\tag 9 F=−vi​∈Vl​∑​k=1∑K​zik​lnyik​(9) 其中Y=[yik]=H(L)\\mathbf{Y}=\\left[y_{i k}\\right]=\\mathbf{H}^{(L)}Y=[yik​]=H(L)表示最后一层输出。该GCN模型存在的一个主要缺点就是传播权重αij\\alpha_{ij}αij​是固定的。 Multi-scale Extensions，不同尺度的GCNs Simplifies GCN，丢掉模型非线性层，叠加每一层参数矩阵W H(L)=WXA^L(10)\\mathbf{H}^{(L)}=\\mathbf{W X} \\hat{\\mathbf{A}}^{L}\\tag {10} H(L)=WXA^L(10) N-GCN和MixHop， 拼接multiple hops的结果 H(t+1)=∥j=0Pσ(W(j)H(t)A^j)(11)\\mathbf{H}^{(t+1)}=\\|_{j=0}^{P} \\sigma\\left(\\mathbf{W}^{(j)} \\mathbf{H}^{(t)} \\hat{\\mathbf{A}}^{j}\\right)\\tag {11} H(t+1)=∥j=0P​σ(W(j)H(t)A^j)(11) LanczosNet和Krylov GCN，求和multiple hops的结果 H(t+1)=σ(∑j=0PW(j)H(t)A^j)(12)\\mathbf{H}^{(t+1)}=\\sigma\\left(\\sum_{j=0}^{P} \\mathbf{W}^{(j)} \\mathbf{H}^{(t)} \\hat{\\mathbf{A}}^{j}\\right)\\tag {12} H(t+1)=σ(j=0∑P​W(j)H(t)A^j)(12) Initial Residual in GCN，GCN中使用残差连接（GCNII） Ht+1=σ(W(t+1)((1−γt)HtA^+γtX))=σ(W(t+1)((1−γt)Ht+(1−γt)HtA‾+γtX))(13)\\begin{aligned} \\mathbf{H}^{t+1} &amp;=\\sigma\\left(\\mathbf{W}^{(t+1)}\\left(\\left(1-\\gamma_{t}\\right) \\mathbf{H}^{t} \\hat{\\mathbf{A}}+\\gamma_{t} \\mathbf{X}\\right)\\right) \\\\ &amp;=\\sigma\\left(\\mathbf{W}^{(t+1)}\\left(\\left(1-\\gamma_{t}\\right) \\mathbf{H}^{t}+\\left(1-\\gamma_{t}\\right) \\mathbf{H}^{t} \\overline{\\mathbf{A}}+\\gamma_{t} \\mathbf{X}\\right)\\right) \\end{aligned}\\tag {13} Ht+1​=σ(W(t+1)((1−γt​)HtA^+γt​X))=σ(W(t+1)((1−γt​)Ht+(1−γt​)HtA+γt​X))​(13) Learning Propagation Weight，带注意力的GCNs，比如GAT，GaAN，Probabilistic GCN，按照如下方式计算αij\\alpha_{ij}αij​： αij=exp⁡(eij)/∑k∈Niexp⁡(eik)(14)\\alpha_{i j}=\\exp \\left(e_{i j}\\right) / \\sum_{k \\in N i} \\exp \\left(e_{i k}\\right)\\tag {14} αij​=exp(eij​)/k∈Ni∑​exp(eik​)(14) 其中eije_{ij}eij​表示不同节点之间的相似度。上述三个方法计算eije_{ij}eij​的方式分别为： eijGAT= LeakyReLU (b[Whi∥Whj])(15)e_{i j}^{G A T}=\\quad \\text { LeakyReLU }\\left(\\mathbf{b}\\left[\\mathbf{W h}_{i} \\| \\mathbf{W h}_{j}\\right]\\right)\\tag {15} eijGAT​= LeakyReLU (b[Whi​∥Whj​])(15) eijGaAN=(Whi)TO(Whj)(16)e_{i j}^{G a A N}=\\left(\\mathbf{W h}_{i}\\right)^{T} \\mathbf{O}\\left(\\mathbf{W h}_{j}\\right)\\tag {16} eijGaAN​=(Whi​)TO(Whj​)(16) eijPGCN=−(Whi−Whj)TΣ(Whi−Whj)(17)e_{i j}^{P G C N}=-\\left(\\mathbf{W h}_{i}-\\mathbf{W h}_{j}\\right)^{T} \\boldsymbol{\\Sigma}\\left(\\mathbf{W h}_{i}-\\mathbf{W h}_{j}\\right)\\tag {17} eijPGCN​=−(Whi​−Whj​)TΣ(Whi​−Whj​)(17) 2.2 GRL框架 给定图G=(V,E,X)\\mathcal{G=(V,E,\\mathbf X)}G=(V,E,X)，为了得到节点表示，需要满足下面两个约束： Unary Constraint，节点viv_ivi​的表示uiu_iui​需要和原始属性xix_ixi​相似。 Pairwise Constraint，相邻节点之间需要有相似的表示 两个约束可以公式化为： C(U)=∑i=1Nsim⁡(xi,ui)+λ∑(i,j)∈Eoijdis⁡(ui,uj)(18)\\mathcal{C}(\\mathbf{U})=\\sum_{i=1}^{N} \\operatorname{sim}\\left(\\mathbf{x}_{i}, \\mathbf{u}_{i}\\right)+\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j} \\operatorname{dis}\\left(\\mathbf{u}_{i}, \\mathbf{u}_{j}\\right)\\tag {18} C(U)=i=1∑N​sim(xi​,ui​)+λ(i,j)∈E∑​oij​dis(ui​,uj​)(18) 其中oijo_{ij}oij​表示相似度(即边权值)，sim和dis函数可以取欧式距离： C(U)=∑i=1N∥xi−ui∥22+λ∑(i,j)∈Eoij∥ui−uj∥22(19)\\mathcal{C}(\\mathbf{U})=\\sum_{i=1}^{N}\\left\\|\\mathbf{x}_{i}-\\mathbf{u}_{i}\\right\\|_{2}^{2}+\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j}\\left\\|\\mathbf{u}_{i}-\\mathbf{u}_{j}\\right\\|_{2}^{2}\\tag{19} C(U)=i=1∑N​∥xi​−ui​∥22​+λ(i,j)∈E∑​oij​∥ui​−uj​∥22​(19) 有时候也可以去inner pro作为sim函数： L(U)=−2∑i=1NxiTui+λ∑(i,j)∈Eoij∥ui−uj∥22(20)\\mathcal{L}(\\mathbf{U})=-2 \\sum_{i=1}^{N} \\mathbf{x}_{i}^{T} \\mathbf{u}_{i}+\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j}\\left\\|\\mathbf{u}_{i}-\\mathbf{u}_{j}\\right\\|_{2}^{2}\\tag{20} L(U)=−2i=1∑N​xiT​ui​+λ(i,j)∈E∑​oij​∥ui​−uj​∥22​(20) 用U=[ui]∈RF×NU=[u_i]\\in\\mathbb R^{F\\times N}U=[ui​]∈RF×N表示节点表示集合，公式19和20可以通过求解下列最小线性而成问题来解决（这块不知道为什么）： \\begin{align} \\mathbf{U(I+M)} &amp;=\\mathbf X \\tag{21}\\\\ \\mathbf{UM} &amp;=\\mathbf X\\tag{22} \\end{align} 其中拉普拉斯矩阵M定义为： M=λ∑(i,j)∈Eoij(ei−ej)(ei−ej)T=λ(DO−O)(23)\\mathbf{M}=\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j}\\left(\\mathbf{e}_{i}-\\mathbf{e}_{j}\\right)\\left(\\mathbf{e}_{i}-\\mathbf{e}_{j}\\right)^{T}=\\lambda\\left(\\mathbf{D}_{O}-\\mathbf{O}\\right)\\tag {23} M=λ(i,j)∈E∑​oij​(ei​−ej​)(ei​−ej​)T=λ(DO​−O)(23) 其中M和I+M都是对称正定矩阵，公式21和22可以通过下式求解： U=X(I+M)−1,U=XM−1(24)\\mathbf{U}=\\mathbf{X}(\\mathbf{I}+\\mathbf{M})^{-1}, \\quad \\mathbf{U}=\\mathbf{X M}^{-1}\\tag{24} U=X(I+M)−1,U=XM−1(24) 图拓扑结构带噪音下的GRL 上述第二个约束条件需要图的拓扑结构是完全准确的，但是实际应用中图拓扑结构往往都带有噪声，因此需要对公式19做出调整： C(U)=∑i=1N∥xi−ui∥22+λ∑(i,j)∈Eoijρ(∥ui−uj∥2)(25)\\mathcal{C}(\\mathbf{U})=\\sum_{i=1}^{N}\\left\\|\\mathrm{x}_{i}-\\mathbf{u}_{i}\\right\\|_{2}^{2}+\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j} \\rho\\left(\\left\\|\\mathbf{u}_{i}-\\mathbf{u}_{j}\\right\\|_{2}\\right)\\tag {25} C(U)=i=1∑N​∥xi​−ui​∥22​+λ(i,j)∈E∑​oij​ρ(∥ui​−uj​∥2​)(25) 其中ρ(⋅)\\rho(·)ρ(⋅)表示惩罚函数，比如lol_olo​范式或者Dirac delta函数。为了减轻noisy connection，引入一个辅助变量lijl_{ij}lij​来自动删除虚假连接，公式25可以转换为： C(U,L)=∑i=1N∥xi−ui∥22+λ∑(i,j)∈Eoij(lij∥ui−uj∥22+ψ(lij)),(26)\\begin{aligned} \\mathcal{C}(\\mathbf{U}, \\mathbf{L}) &amp;=\\sum_{i=1}^{N}\\left\\|\\mathbf{x}_{i}-\\mathbf{u}_{i}\\right\\|_{2}^{2} \\\\ &amp;+\\lambda \\sum_{(i, j) \\in \\mathcal{E}} o_{i j}\\left(l_{i j}\\left\\|\\mathbf{u}_{i}-\\mathbf{u}_{j}\\right\\|_{2}^{2}+\\psi\\left(l_{i j}\\right)\\right), \\end{aligned}\\tag{26} C(U,L)​=i=1∑N​∥xi​−ui​∥22​+λ(i,j)∈E∑​oij​(lij​∥ui​−uj​∥22​+ψ(lij​)),​(26) 该公式是关于U、L双凸的，所以要分别优化L和U，即固定L优化U，固定U优化L。 2.3 理论分析 为了简化分析过程，根据SGC中的论述，作者去掉了权重矩阵和非线性函数，只关注传播策略本身。 定理1： The scheme of GCN with initial residual in Eq. (13) is equivalent to solving the Graph RepresentationLearning in Eq. (20), where pairwise similarityO=[oij]O= [o_{ij}]O=[oij​] is set as the symmetric Random-Walk Markov Matrix Aˉ=D−12AD−12\\bar A=D^{−\\frac{1}{2}}AD^{−\\frac{1}{2}}Aˉ=D−21​AD−21​, with gradient descent 证明：UM=X\\mathbf{UM=X}UM=X 等价于公式20表示的图表示学习，根据公式3可以求解： U(t+1)=U(t)+μt(X−U(t)M)=U(t)(I−μtM)+μtX(30)\\mathbf{U}^{(t+1)}=\\mathbf{U}^{(t)}+\\mu_{t}\\left(\\mathbf{X}-\\mathbf{U}^{(t)} \\mathbf{M}\\right)=\\mathbf{U}^{(t)}\\left(\\mathbf{I}-\\mu_{t} \\mathbf{M}\\right)+\\mu_{t} \\mathbf{X}\\tag{30} U(t+1)=U(t)+μt​(X−U(t)M)=U(t)(I−μt​M)+μt​X(30) 根据公式23， 以及O=Aˉ=D−12AD−12O=\\bar A=D^{−\\frac{1}{2}}AD^{−\\frac{1}{2}}O=Aˉ=D−21​AD−21​，M=DO−OM=D_O-OM=DO​−O，公式30可以化为： U(t+1)=(1−μt)U(t)+μtU(t)A‾+μtX(31)\\mathbf{U}^{(t+1)}=\\left(1-\\mu_{t}\\right) \\mathbf{U}^{(t)}+\\mu_{t} \\mathbf{U}^{(t)} \\overline{\\mathbf{A}}+\\mu_{t} \\mathbf{X}\\tag {31} U(t+1)=(1−μt​)U(t)+μt​U(t)A+μt​X(31) 其中U(t)U^{(t)}U(t)，U(t)AˉU^{(t)}\\bar AU(t)Aˉ和X分别对应H(t)H^{(t)}H(t)，H(t)AˉH^{(t)}\\bar AH(t)Aˉ和X，所以和公式13表示的Residual GCN是一致的。 推论1：“ The term X in gradient descent is important to properly approximate the solution to GRL. Thus, the initial residual is important in GCNs ” 定理1和推论1解释了GCNII模型中残差连接的重要性，以及为什么带有残差连接的GCN层能提高模型性能。原文还说了一句“ In contrast, if the residual connection X lacks, the approximation error of each gradient descent step can’t be ignored, thus the cumulative error is very significant in approximating the solution to GRL. Thus, stacking of GCN without initial residual connection degrades the performance. ” 定理2：“ The scheme of the multi-scale extension to GCN in Eq. (12) is equivalent to solving the Graph Representation Learning in Eq. (20), where pairwise similarity O=[oij]O= [o_{ij}]O=[oij​] is set as the symmetric Random-Walk Markov Matrix with selfloopAˉ=D~−12A~D~−12\\bar A= \\tilde D^{−\\frac{1}{2}} \\tilde A \\tilde D^{−\\frac{1}{2}}Aˉ=D~−21​A~D~−21​, with the higher orderapproximation to the inverse of M in Eq. (5) ” **证明：**根据Caley-Hamilton定理，(I−A)−1(I-A)^{-1}(I−A)−1可以近似表示为： (I−A)−1≈∑j=0JβjAj1(3)(\\mathbf{I}-\\mathbf{A})^{-1} \\approx \\sum_{j=0}^{J} \\beta_{j} \\mathbf{A}^{j}\\tag 31 (I−A)−1≈j=0∑J​βj​Aj1(3) 公式24的解析解为：U=XM−1U=XM^{-1}U=XM−1，而M=DO−O=(I−A^)M=D_O-O=(I-\\hat A)M=DO​−O=(I−A^)，所以公式20的解可以表示为： U=X(I−A)−1≈∑j=0JβjXA^j(33)\\mathbf{U}=\\mathbf{X}(\\mathbf{I}-\\mathbf{A})^{-1} \\approx \\sum_{j=0}^{J} \\beta_{j} \\mathbf{X} \\hat{\\mathbf{A}}^{j}\\tag{33} U=X(I−A)−1≈j=0∑J​βj​XA^j(33) GRL框架的近似解等价于公式12定义的multi-scale extension GCNs。 通过定理1和定理2，证明了GCNs的传播等价于作者提出的GRL框架中的优化步骤（梯度下降步骤或者高阶近似步骤）。“ That is, they are induced by the numerical optimization of pairwise similarity requirement. Thus, the pairwise similarity constraints, which determines how to propagate, is the key to GNNs ”。 推论2：“ The solution to our proposed Robust GraphRepresentation Learning with noisy topology refinementshown in Eq. (25) with ρ(·)as in Eq. (27) is similar to the GCNNs with learnable propagation weight as Eq. (17). ” 结合上述定理和推论，作者得出一个结论（即论文标题的答案）： &quot; The propagation as well as its weight learning are notthe essence of the GCNs, but induced by the numericaloptimization of pairwise similarity requirement. &quot; 2.4 GCC 根据前面提出的GRL框架，并从数值优化算法角度解释GCN及其各种变体，作者提出了图共轭卷积网络模型GCC： H(t+1)=σ(W(t+1)((1−γt)H(t)A^+γtX+κt(H(t)−H(t−1))))(34)\\begin{aligned} \\mathbf{H}^{(t+1)}=\\sigma\\left(\\mathbf{W}^{(t+1)}\\right.&amp;\\left(\\left(1-\\gamma_{t}\\right) \\mathbf{H}^{(t)} \\hat{\\mathbf{A}}+\\gamma_{t} \\mathbf{X}\\right.\\\\ +&amp;\\left.\\left.\\kappa_{t}\\left(\\mathbf{H}^{(t)}-\\mathbf{H}^{(t-1)}\\right)\\right)\\right) \\end{aligned}\\tag{34} H(t+1)=σ(W(t+1)+​((1−γt​)H(t)A^+γt​Xκt​(H(t)−H(t−1))))​(34) 其中前两项和GCNII模型中的一样，第三项表示前一层输出和输入的差，如下图所示。 3. 实验 **数据集：**Cora，Citesser，Pubmed等等 **Baselines：**GCN、GAT、PR-GCN、JKNet、GCNII、DropEdge等等 **参数设置：**lr0.001，100epochs，inductive学习γt=0.1\\gamma_t=0.1γt​=0.1，kt=0.2k_t=0.2kt​=0.2，transductive学习γt=0.32\\gamma_t=0.32γt​=0.32，kt=0.32k_t=0.32kt​=0.32，层数从8层、16层、32层中选取 **Transductive学习：**GCA表示Graph Conjugate Attention **Inductive学习：**PPI数据集上","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"GCN","slug":"GCN","permalink":"http://rookieyin.github.io/tags/GCN/"},{"name":"过平滑","slug":"过平滑","permalink":"http://rookieyin.github.io/tags/%E8%BF%87%E5%B9%B3%E6%BB%91/"}]},{"title":"FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES","slug":"3 论文笔记/小样本图学习/1.Few-Shot Learning on Graphs via Superclasses Based on Graph Spectral Measures","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.969Z","comments":true,"path":"a59b92da0529/","link":"","permalink":"http://rookieyin.github.io/a59b92da0529/","excerpt":"https://arxiv.org/abs/2002.12815 https://github.com/chauhanjatin10/GraphsFewShot FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES 个人见解： 小样本在图领域的应用暂时还是个比较新的方向，可能主要有两个方向：一是将已经成熟的小样本训练方法（比如元学习、半监督等等）缝合到最近一些比较好的图学习方法中；二是对图学习方法进行改造，使其适合小样本场景。 本文作者一方面将小样本中的一种训练策略“initialization based strategy”引入到图学习中，另一方面对图学习算法进行改进，作者认为某个样本类别数量很少时，在做消息传播时，如果图神经网络层数比较浅，那么该类别样本很难影响到大范围的其他节点，因此作者提出了一种计算超类并生成超图的方案使得图神经网络更适用于小样本场景。","text":"https://arxiv.org/abs/2002.12815 https://github.com/chauhanjatin10/GraphsFewShot FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES 个人见解： 小样本在图领域的应用暂时还是个比较新的方向，可能主要有两个方向：一是将已经成熟的小样本训练方法（比如元学习、半监督等等）缝合到最近一些比较好的图学习方法中；二是对图学习方法进行改造，使其适合小样本场景。 本文作者一方面将小样本中的一种训练策略“initialization based strategy”引入到图学习中，另一方面对图学习算法进行改进，作者认为某个样本类别数量很少时，在做消息传播时，如果图神经网络层数比较浅，那么该类别样本很难影响到大范围的其他节点，因此作者提出了一种计算超类并生成超图的方案使得图神经网络更适用于小样本场景。 1. 简介 1.1 摘要 We propose to study the problem of few-shot graph classification in graph neural networks (GNNs) to recognize unseen classes, given limited labeled graph examples. Despite several interesting GNN variants being proposed recently for node and graph classification tasks, when faced with scarce labeled examples in the few-shot setting, these GNNs exhibit significant loss in classification performance. Here, we present an approach where a probability measure is assigned to each graph based on the spectrum of the graph’s normalized Laplacian. This enables us to accordingly cluster the graph base-labels associated with each graph into superclasses, where the LpL^pLp Wasserstein distance serves as our underlying distance metric. Subsequently, a super-graph constructed based on the super-classesis then fed to our proposed GNN framework which exploits the latent inter-class relationships made explicit by the super-graph to achieve better class label separation among the graphs. We conduct exhaustive empirical evaluations of our proposed method and show that it outperforms both the adaptation of state-of-the-art graph classification methods to few-shot scenario and our naive baseline GNNs. Additionally, we also extend and study the behavior of our method to semi-supervised and active learning scenarios. 我们提出了一种用GNNs来研究小样本图分类问题的方法，在只给定少量有标签图样本的情况下，识别不可见类。虽然最近已经有一些GNN变体被应用到节点和图分类任务中了，但是当面临样本数量过少的问题时，GNNs的分类效果较差。本文中，我们提出一种方法，根据图的标准化拉普拉斯谱图将概率度量分配给每个图。这可以让我们将每个图的基础标签聚集成超类，其中LpL^pLp Wasserstein距离作为我们基础度量。随后，我们将基于超类构建的超图喂给GNN网络，它利用超图表示的隐藏类间关系来更好地实现图之间的标签分离。我们对提出的方法进行了详细的实验评估，表明我们的模型在小样本场景下优于最新的图分类方法和原生GNN baseline。另外，我们也拓展并研究了我们的方法在半监督和主动学习场景中的表现。 1.2 本文工作简介 GNNs虽然在很多领域都取得了不错的效果，但是在小样本场景下效果比较差。在小样本设定下，novel-class样本数量很少，它需要多轮迭代才能影响到更大范围的领域，因此导致GNN深度过大。但是，实验研究表明，随着GNN层数的增加会导致性能显著下降。基于这个问题，本文提出了一种新解决方案。 超类 作者首先进行一个一次性的预处理步骤：基于图的正则化拉普拉斯矩阵的谱，为每个图分配一个概率度量，我们称之为“图的谱度量”。给定图的谱度量的度量空间和基础距离（LpL^pLp Wasserstein 距离），我们为属于某个基类的一组图计算Wasserstein barycenters，将其看做原型图。通过这些基类的原型图构成的集合，我们将Wasserstein空间中每个和原型图相关联的谱距离进行聚类，创建一个超类标签。 超图 利用超类信息，作者构建了一个graph of graphs，称之为超图。直觉上，这样可以通过谱度量来利用图之间的非显示和隐性类内间关系，并在其上使用GNN来引入relational inductive bias。这样为我们提供了改进的样本复杂性，并且在少量样本下提供了更好地组合泛化。 GNN 得到超类和超图后，作者开始在图上训练GNN模型。作者GNN模型包含：一个GIN模型作为图嵌入特征提取器Fθ(⋅)F_\\theta(·)Fθ​(⋅)，一个分类器C(⋅)C(·)C(⋅)。分类器包含两部分：一个MLP层CsupC^{sup}Csup用于学习和预测图的超类类别；还有一个GAT网络CGATC^{GAT}CGAT，来预测图的实际类别标签。模型的整体损失函数是CsupC^{sup}Csup和CGATC_{GAT}CGAT​的交叉熵损失。作者遵循“initialization based strategy”，使用训练和微调两个阶段。在微调阶段，冻结Fθ(⋅)F_\\theta(·)Fθ​(⋅)和CsupC^{sup}Csup相关的参数，少量有标签新类样本被用于更新CGATC^{GAT}CGAT学习到的权重和注意力。 作者本文的贡献或者创新点可以总结为： 领域上，首次将小样本学习引入到图分类任务中。 使用谱度量生成超类，构造超图，学习潜在的类间关系。 2. 方法 2.1 预备知识 数据 G\\mathcal GG表示无权重无向图，Y\\mathcal YY表示对应的标签类别。GB={(gi(B),yi(B))}i=1nG_B=\\{(g_i^{(B)},y_i^{(B)})\\}_{i=1}^nGB​={(gi(B)​,yi(B)​)}i=1n​表示基类中有标签图，GN=(gi(N),yiN)i=1mG_N={(g_i^{(N)},y_i^{N})}_{i=1}^mGN​=(gi(N)​,yiN​)i=1m​表示新类中有标签图，其中gi(B),gi(N)∈Gg_i^{(B)},g_i^{(N)}\\in\\mathcal Ggi(B)​,gi(N)​∈G，yi(B)∈YB={1,...,K}y_i^{(B)}\\in\\mathcal Y^{B}=\\{1,...,K\\}yi(B)​∈YB={1,...,K}，yi(N)∈Y(N)={K+1,...,K′}y_i^{(N)}\\in\\mathcal Y^{(N)}=\\{K+1,...,K&#x27;\\}yi(N)​∈Y(N)={K+1,...,K′}，K′&gt;KK&#x27;&gt;KK′&gt;K且\\mathcal Y^{(B)}\\cap\\mathcal Y^{(N)}=\\O。需要注意的是：m&lt;&lt;nm&lt;&lt;nm&lt;&lt;n，也就是新类有标签图数量远远小于基类有标签图的数量。另外处理GBG_BGB​和GNG_NGN​，还有t个无标签不可见图GU:={g1U,...,gt(U)∣giU∈π1(GN),i=1...t}G_U:=\\{g_1^{U},...,g_t^{(U)}|g_i^{U}\\in\\pi_1(G_N),i=1...t\\}GU​:={g1U​,...,gt(U)​∣giU​∈π1​(GN​),i=1...t}用于测试。π1(p)\\pi_1(p)π1​(p)和π2(p)\\pi_2(p)π2​(p)分别表示有序对p的左和右投影。 学习过程 受initialization based methodsinitialization\\ based\\ methodsinitialization based methods的启发，作者训练过程包含两个阶段：训练和微调。在训练时，作者用神经网络训练一个图特征提取器Fθ(GB)F_\\theta(G_B)Fθ​(GB​)和一个分类器C(GB)C(G_B)C(GB​)，损失函数采用标准的交叉熵损失函数Lc\\mathcal L_cLc​。为了更好地识别新类上的样本，在微调阶段，Fθ(⋅)F_\\theta(·)Fθ​(⋅)相关的参数被冻结，用新类样本微调C(GN)C(G_N)C(GN​)。（为什么冻结Fθ(⋅)F_\\theta(·)Fθ​(⋅)，微调C(GN)C(G_N)C(GN​)） 问题定义 训练阶段，给定n个基类有标签数据；微调阶段，给定m个有标签新类数据；其中m&lt;&lt;nm&lt;&lt;nm&lt;&lt;n；小样本图分类的目标就是：能够正确分辨t种类型不可见样本的类别。如果令m=qT, T=K′−Km=qT,\\ T=K&#x27;-Km=qT, T=K′−K，其中q表示GnG_nGn​中每个类别标签出现q次，那么该问题就是个T-way，q-shot任务。 Graph spectral distance （1）图拉普拉斯 ​ 对于图g∈Gg\\in\\mathcal Gg∈G，标准的图拉普拉斯定义为Δg=I−D−1/2AD1/2\\Delta_g=I-D^{-1/2}AD^{1/2}Δg​=I−D−1/2AD1/2，其中A和D分别是图g的邻接矩阵和度矩阵。Δg\\Delta_gΔg​的特征值集合{λi}i=1∣V∣\\{\\lambda_i\\}_{i=1}^{|V|}{λi​}i=1∣V∣​称之为Δg\\Delta_gΔg​的谱，表示为σ(g)\\sigma(g)σ(g)。一个标准拉普拉斯矩阵的谱σ(g)\\sigma(g)σ(g)的范围在[0,2][0,2][0,2]。我们给每一个λi∈σ(g)\\lambda_i\\in\\sigma(g)λi​∈σ(g)分配一个Dirac mass δλi\\delta_{\\lambda_i}δλi​​（狄拉克函数），从而将概率度量与[0,2]上的σ(g)\\sigma(g)σ(g)相关联，称之为graph spectral measure μσ(g)\\mu_{\\sigma(g)}μσ(g)​。另外，定义P([0,2])P([0,2])P([0,2])表示区间[0,2]上所有概率度量的集合。 （2）p-th Wasserstein distance Wasserstein距离，一种用于度量两个概率分布之间的距离的方法。 相比于这些度量方式，Wasserstein距离有如下一些好处。 能够很自然地度量离散分布和连续分布之间的距离； 不仅给出了距离的度量，而且给出如何把一个分布变换为另一分布的方案； 能够连续地把一个分布变换为另一个分布，在此同时，能够保持分布自身的几何形态特征。 令p∈[1,+∞]p\\in[1,+\\infty]p∈[1,+∞]，c:[0,2]×[0,2]→[0,+∞]c:[0,2]\\times[0,2]\\rightarrow[0,+\\infty]c:[0,2]×[0,2]→[0,+∞]为概率度量μ,v∈P([0,2])\\mu,v\\in P([0,2])μ,v∈P([0,2])之间的代价函数。μ\\muμ和vvv之间的p-th Wasserstein距离定义为：Wp(μ,v)=(infγ∫[0,2]×[0,2]c(x,y)pdγ∣γ∈Π(μ,v))1pW_p(\\mu,v)=\\Big(\\mathop{inf}\\limits_\\gamma\\int_{[0,2]\\times[0,2]}c(x,y)^pd\\gamma|\\gamma\\in\\Pi(\\mu,v)\\Big)^{\\frac{1}{p}}Wp​(μ,v)=(γinf​∫[0,2]×[0,2]​c(x,y)pdγ∣γ∈Π(μ,v))p1​，其中 Π(μ,v)\\Pi(\\mu,v)Π(μ,v)是transport plans集合，即[0,2]×[0,2][0,2]\\times[0,2][0,2]×[0,2]上所有边界为μ\\muμ和vvv的度量的集合。 （3）graph spectral distance 给定两个图ggg和g′g&#x27;g′，它们之间的谱距离定义为： Wp(g,g′):=Wp(μσ(g),μσ(g′))W^p(g,g&#x27;):=W_p(\\mu_{\\sigma(g)},\\mu_{\\sigma(g&#x27;)}) Wp(g,g′):=Wp​(μσ(g)​,μσ(g′)​) 换句话说，Wp(g,g′)W^p(g,g&#x27;)Wp(g,g′)表示从图g的谱度量到g′g&#x27;g′的最优移动质量代价，其单位移动质量和与区间[0,2]上的实数特征值之差的p次方成正比。 2.2 计算超类 计算每个类别的原型 首先将GBG_BGB​按照类别划分成G(i)，i=1...KG^{(i)}，i=1...KG(i)，i=1...K，表示类别为i的图构成的集合，这样GB=⊔i=1KG(i)G_B=\\sqcup_{i=1}^KG^{(i)}GB​=⊔i=1K​G(i)。然后按照如下方式计算每个类别集合的原型： pi=argmingi∈π1(G(i))1∣G(i)∣∑j=1∣G(i)∣Wp(gi,gj)p_i=\\mathop{argmin}\\limits_{g_i\\in\\pi_1(G^{(i)})}\\frac{1}{|G^{(i)}|}\\sum\\limits_{j=1}^{|G^{(i)}|}W^p(g_i,g_j) pi​=gi​∈π1​(G(i))argmin​∣G(i)∣1​j=1∑∣G(i)∣​Wp(gi​,gj​) 这样每个类别的原型和该类别中所有图的平均谱距离最小。得到所有类别的原型后，使用Lloyd’s的方法（k-means）对其进行聚类。 对原型进行聚类 给定K个无标签原型p1,...,pK∈π1(GB)p_1,...,p_K\\in\\pi_1(G_B)p1​,...,pK​∈π1​(GB​)以及它们对应的谱度量μσ(p1),...μσ(pK)\\mu_{\\sigma(p_1)},...\\mu_{\\sigma(p_K)}μσ(p1​)​,...μσ(pK​)​，我们给谱度量重新命名为s0,...,sKs_0,...,s_Ks0​,...,sK​。我们的目标是将这K个原型聚类成最多k个类别，k≥1k\\geq1k≥1是用户定义的一个参数。k-means聚类方法（具体见下面第3点）会寻找一种划分C={C1,...,Ck}C=\\{C_1,...,C_k\\}C={C1​,...,Ck​}，使得下面的目标函数最小： argminC∑i=1k∑si∈CiWp(si,B(Ci))\\mathop{argmin}\\limits_C\\sum\\limits_{i=1}^{k}\\sum\\limits_{s_i\\in C_i}W_p(s_i,B(C_i)) Cargmin​i=1∑k​si​∈Ci​∑​Wp​(si​,B(Ci​)) 其中sis_isi​是CiC_iCi​中的一个原型，B(Ci)B(C_i)B(Ci​)表示聚类CiC_iCi​中的Wasserstein barycenter，计算方法如下： B(Ci)=argminp∈P([0,2])∑j=1∣Ci∣Wp(p,s(i,j))B(C_i)=\\mathop{argmin}\\limits_{p\\in P([0,2])}\\sum\\limits_{j=1}^{|C_i|}W_p(p,s(i,j)) B(Ci​)=p∈P([0,2])argmin​j=1∑∣Ci​∣​Wp​(p,s(i,j)) 其中s(i,j)s(i,j)s(i,j)表示CiC_iCi​中的第j个spectral measure。 Lloyd’s algorithm 给定t=1t=1t=1时刻的初始Wasserstein barycenters集合B(1)(C1),...B(1)(Ck)B^{(1)}(C_1),...B^{(1)}(C_k)B(1)(C1​),...B(1)(Ck​)，交替执行下面两个公式： \\begin{align} C_i^{(t)}&amp;=\\Big\\{s_p:W_p(s_p,B^{(t)}(C_i))\\leq W_p(s_p,B^{(t)}(C_j)),\\forall j,1\\leq j\\leq k,1\\leq p\\leq K\\Big\\}\\\\ C_i^{(t+1)}&amp;=B(C_i^{(t)}) \\end{align} 最后输出的是将所有原型图划分成k个类别，同时相应的将基类进行了分组。我们称这些类别为超类，用Ysup\\mathcal Y^{sup}Ysup表示超类构成的集合。 2.3 神经网络架构 2.3.1 特征提取器 GNN通常采用如下的消息传播架构： H(j)=M(A,H(j−1),θ(j))H^{(j)}=M(A,H^{(j-1)},\\theta^{(j)}) H(j)=M(A,H(j−1),θ(j)) 其中H(j)∈R∣V∣×dH^{(j)}\\in\\mathbb R^{|V|\\times d}H(j)∈R∣V∣×d表示j轮迭代后的节点嵌入，M是依赖于图邻接矩阵的消息传播函数，θj\\theta^{j}θj表示第j轮的可训练参数，H(j−1)H^{(j-1)}H(j−1)表示上一轮的节点嵌入。本文作者采用GIN作为特征提取器（效果比GCN、Graphsage好）： H(j)=MLP((1+ϵ)j⊙H(j−1)+ATH(j−1))H^{(j)}=MLP((1+\\epsilon)^j\\odot H^{(j-1)}+A^TH^{(j-1)}) H(j)=MLP((1+ϵ)j⊙H(j−1)+ATH(j−1)) 其中ϵ\\epsilonϵ是layer wise的可学习常量。GIN模型迭代R轮后得到的最终节点嵌入表示为H(R)H^{(R)}H(R)，但是GIN考虑到早期迭代得到的特征对于提高模型判别力也有帮助。因此，R轮迭代后，最终的嵌入表示为： Hg=∣∣j=1RH(j)H_g=\\Big|\\Big|_{j=1}^RH^{(j)} Hg​=∣∣∣∣​∣∣∣∣​j=1R​H(j) 其中H(j)=∑v∈VHv(j)H^{(j)}=\\sum_{v\\in V}H_v^{(j)}H(j)=∑v∈V​Hv(j)​，Hi(j)H_i^{(j)}Hi(j)​表示第j轮迭代中，第i个节点的嵌入。∣∣||∣∣表示concatenation操作。这样HgH_gHg​作为整个图的嵌入传递到分类器中进行分类。 2.3.2 分类器 一、训练期间 CsupC^{sup}Csup 将Fθ(⋅)F_\\theta(·)Fθ​(⋅)提取的特征传递给MLP网络CsupC^{sup}Csup来学习对应的超类标签。CGATC^{GAT}CGAT和CsupC^{sup}Csup共同组成了分类器C(⋅)C(·)C(⋅)。 CGATC^{GAT}CGAT 在训练期间，首先在基类的一个batch样本上构建超图gsupg^{sup}gsup作为k-NN图集合，其中每个k-NN图都是基于同一个超类的图构建的。之后将gsupg^{sup}gsup传递给多层GAT网络CGATC^{GAT}CGAT来学习可能的类概率。使用GAT背后的直觉是：通过引入GATR固有的关系归纳偏差来进一步提高聚类效果。 CGATC^{GAT}CGAT和CsupC^{sup}Csup的交叉熵损失相加就是最终分类器C(⋅)C(·)C(⋅)的损失函数。 二、微调期间 微调阶段，将有标签新类图作为输入，Fθ(⋅)F_\\theta(·)Fθ​(⋅)参数固定，CsupC^{sup}Csup用来推断新图的超类标签。然后在新图样本上创建超图，最后通过损失来更新CGATC^{GAT}CGAT的参数。最后，用不可见测试集中的样本进行测试。 2.4 总结 首先使用GIN提取图的特征，用单个向量表示。 然后按照图的标签类别计算每个类别的原型。 再使用k-means对原型进行聚类，构造超类。 训练阶段，一方面每个超类中的图会构造成一个k-NN图，然后通过GAT网络对图进行分类，另一方面训练一个MLP分类器，预测图所属超类类别。 微调阶段，输入新类图，通过特征提取器提取特征，将特征喂给CsupC^{sup}Csup获取图的超类标签，再构造给k-NN超图，调节GAT参数。 3. 实验 3.1 数据集和Baseline 主要采用Reddit-12K，ENZYMES，Letter-High和TRIANGLES四个数据集： 将数据集按照如下方式进行划分： Validation Graphs用于评估模型在训练类别上的表现，检查过拟合以及选择超参。由于TRIANFLES数据集样本数量过大，因此许多DL或者non-DL baseline无法在其上运行。因此作者从每个类别中选取200个图，让其样本总量变成2000。同样地，对Reddit-2K数据集进行降采样，抽取1111个样本（每个类101个样本），否则会导致一些kernel方法和dl方法运行过慢。 3.2 实验结果 作者提出对自己的模型提出了两种变体：第一种使用GCN代替GAT，称之为OurMethod-GCN，用来评估GCN和GAT的效果；第二种变体使用k-NN代替整个分类器，称之为GIN-k-NN，用来强调构建超图并使用GAT来利用关系归纳偏差的重要性。 下表中的结果均是运行50次后取平均值。每次运行时选取不同的新的有标签集合GNG_NGN​来微调模型的分类器。对于TRIANGLES和ENZYMES数据集每次随机选取500个样本作为测试集GUG_UGU​，对于ENZYMES选取150个样本，对于Reddit选取300个样本作为测试集。 从实验结果可以看到：GIN-k-NN性能显著低于OurMethod-GCN和OurMethod-GAT，说明作者构建的以超图作为输入的GNN网络可以显著提高模型在小样本场景下的表现。 3.3 消融实验 研究CsupC^{sup}Csup的作用 原文是这样说的“ Using super-classes help in reducing the sample complexity of the large Hypothesis spaceand makes tuning of the model parameters easier during fine-tuning stage with less samples and few iterations. ”（暂时不懂） 在ENZYMES数据集上两者区别可以忽略不计，因为trainning classes和testing classes的数量都很小，即使不适用super-class，模型效果也很好。 超类类型数量k的选取 基本在2和3个的时候效果最好，超类类型过多会使得每个超类cluster过于稀疏，内部只有很少的图类型，从而导致不同图类型之间的信息不足。 构建超图时k值得选取 Heuristic表示使用bs\\sqrt b_sb​s​个最近邻构建超图，bsb_sbs​为 the number of samples in the mini-batch corresponding to super-classess。 3.4 可视化 作者使用t-SNE对模型最后一层输出的embedding进行可视化：","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding","slug":"3 论文笔记/小样本图学习/5.Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.978Z","comments":true,"path":"7bc0ee17a8f5/","link":"","permalink":"http://rookieyin.github.io/7bc0ee17a8f5/","excerpt":"https://arxiv.org/pdf/2007.02914 https://github.com/llan-ml/MetaTNE Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding，NIPS，2020 总结：最大的创新点就是嵌入转换函数，利用自注意力机制对节点嵌入进行调整使其task-specific。针对小样本设置还是利用元学习思想，学习不同类别间统一的内在模式，提高目标任务上的分类准确度。 目前图上的小样本问题大多都是针对有标签节点数量较少，且基本都是利用元学习思想来做，可以尝试着用小样本学习中的其他方法比如基于生成等等。另外可以探索一下关系或者属性在小样本场景下该如何做。","text":"https://arxiv.org/pdf/2007.02914 https://github.com/llan-ml/MetaTNE Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding，NIPS，2020 总结：最大的创新点就是嵌入转换函数，利用自注意力机制对节点嵌入进行调整使其task-specific。针对小样本设置还是利用元学习思想，学习不同类别间统一的内在模式，提高目标任务上的分类准确度。 目前图上的小样本问题大多都是针对有标签节点数量较少，且基本都是利用元学习思想来做，可以尝试着用小样本学习中的其他方法比如基于生成等等。另外可以探索一下关系或者属性在小样本场景下该如何做。 1.简介 1.1 摘要 We study the problem of node classification on graphs with few-shot novel labels,which has two distinctive properties: (1) There are novel labels to emerge in thegraph; (2) The novel labels have only a few representative nodes for training a clas-sifier. The study of this problem is instructive and corresponds to many applicationssuch as recommendations for newly formed groups with only a few users in onlinesocial networks. To cope with this problem, we propose a novel Meta TransformedNetwork Embedding framework (MetaTNE), which consists of three modules: (1)Astructural moduleprovides each node a latent representation according to thegraph structure. (2) Ameta-learning modulecaptures the relationships between thegraph structure and the node labels as prior knowledge in a meta-learning manner.Additionally, we introduce anembedding transformation functionthat remedies thedeficiency of the straightforward use of meta-learning. Inherently, the meta-learnedprior knowledge can be used to facilitate the learning of few-shot novel labels.(3) Anoptimization moduleemploys a simple yet effective scheduling strategy totrain the above two modules with a balance between graph structure learning andmeta-learning. Experiments on four real-world datasets show that MetaTNE bringsa huge improvement over the state-of-the-art methods. 本文我们研究了具有少量新类标签下的图的节点分类问题，新类标签具有两个特性：（1）新类标签出现在图中；（2）新类标签只有少量代表性节点用于训练分类器。该研究对许多应用场景（如对在线社交网络中只有少数用户的新组建的群体进行推荐）具有重要意义。为了解决这个问题，我们提出了一个原生的Meta Transformed Network Embedding（MetaTNE）架构，它包含三个模块：（1）结构化模块：根据图结构学习每个节点的潜在表示；（2）元学习模块：按照元学习的方式捕捉图结构和节点标签之间的关系作为先验知识，另外我们引入了一个embedding transformation function来弥补直接使用元学习的不足。本质上元学习学到的先验知识可以用来增强在只有少量样本情况下的学习性能。（3）优化模块：采用一种简单但是有效的策略来训练上述两个模块，并在图结构学习和元学习之间取得平衡。4个真实数据集上的实验表明MetaTNE和当前最优方法相比带来了很大的提升。 1.2 本文工作 图被广泛应用于很多领域来表示数据，包括社交网络分析、生物信息、推荐系统以及计算机网络安全中。节点分类、链路预测、社区发现等图分析任务对我们的现实生活具有重大意义。本文我们主要针对节点分类任务，具体来说是小样本情景下的分类任务，即一些新类标签只有少量样本可以用来训练模型。小样本 的图节点分类可以指导很多实际任务，比如： 一些在线社交网络组织如Facebook、Twitter和Flickr，会有很多广告，我们希望知道用户对这些广告是否感兴趣。通过小样本学习，这些组织就可以通过少量用户的反馈更好地预测其他用户的喜好，提供更好的服务或者推荐。 对于生物里面的蛋白质网络，一些研究人员可能发现某些蛋白质之间有一种新的生物反应。给定一些蛋白质（有或者没有这一反应），小样本学习可以预测其他蛋白质之间是否有这一反应，这可以为实验人员提供新的研究方向。 本文作者考虑：图中的不同类别标签可能共享一些内在的演化模式（比如标签信息在图上的传播方式）。假定有部分类别已经有足够多的的支持集节点（有标签），我们希望能从这些节点中提取出共同的内在信息，然后利用这些提取到的信息帮助新类上（只有少量节点有标签）的分类。但是图结构和节点标签之间的关系十分复杂，节点间信息传播模式也多种多样，因此如何建模捕捉这些信息并将其应用到小样本新类上仍然具有很大挑战。 作者借鉴元学习思想，提出了一种原生的Meta Transformed Network Embedding架构，称之为MetaTNE，来捕捉共同的内在模式。如上图所示，MetaTNE共有3个模块：structural module，meta-learning module和optimization module。 2. 方法 MetaTNE包含三部分：结构模块、元学习模块和优化模块。给定一个图和一些已知标签： structural模块首先根据图结构学习每个节点的标签； 元学习模块学习一个转换函数，为每个元学习任务调整节点表示（只和图结构有关），然后使用基于距离的分类器判别节点标签； 最后按照某种概率分别优化结构模块和元学习模块。 2.1 Structural模块 该模块主要利用图结构信息来学习每个节点的潜在表示。从数学角度来看就是：对于每个节点vi∈Vv_i\\in\\mathcal Vvi​∈V，我们要最大化其邻居共现的对数概率即min∑vi∈V∑vj∈N(vi)logP(vj∣vi)min\\sum_{v_i\\in\\mathcal V}\\sum_{v_j\\in\\mathcal N(v_i)}log\\mathbb P(v_j|v_i)min∑vi​∈V​∑vj​∈N(vi​)​logP(vj​∣vi​)，N(vi)\\mathcal N(v_i)N(vi​)表示viv_ivi​的邻居。 关于节点邻居集合N(⋅)\\mathcal N(·)N(⋅)的重构方法有很多，本文采用的是1-hop邻居（Line），通过优化上面的目标函数，我们可以得到一个嵌入矩阵U∈R∣V∣×dU\\in\\mathbb R^{|V|\\times d}U∈R∣V∣×d，其第i行uiu_iui​表示节点viv_ivi​的表示。 2.2 Meta-Learning模块 作者采用基于度量的元学习架构来解决小样本问题，提出了一种转换函数，将与任务无关的嵌入转换成task-specific的嵌入，以便更好地处理多标签问题。 2.2.1 数据设置 和传统的半监督学习不一样，我们根据已知标签Yknown\\mathcal Y_{known}Yknown​（样本数量比较少）建立一个小样本节点分类任务池。和基于元学习的小样本图像分类任务类似，小样本节点分类任务Ti=(Si,Qi,yi)\\mathcal T_i=(S_i,Q_i,y_i)Ti​=(Si​,Qi​,yi​)由支持集SiS_iSi​，查询集QiQ_iQi​以及从Yknown\\mathcal Y_{known}Yknown​随机采样的标签yiy_iyi​（yiy_iyi​表示某个类别标签，判别查询集中样本是否有yiy_iyi​标签，每个任务相当于是2-Way k-shot小样本任务）。其中支持集Si=Si+∪Si−S_i=S_i^+\\cup S_i^-Si​=Si+​∪Si−​，Si+⊂Dyi+S_i^+\\subset\\mathcal D_{y_i}^+Si+​⊂Dyi​+​表示随机采样的正类样本，Si−⊂Dyi−S_i^-\\subset\\mathcal D_{y_i}^-Si−​⊂Dyi​−​表示随机采样的负类样本。Qi=Qi+∪Qi−\\mathcal Q_i=Q_i^+\\cup Q_i^-Qi​=Qi+​∪Qi−​，但是$\\mathcal S_i\\cap Q_i=\\varnothing 。每个∗∗任务的目标是∗∗：给定支持集node−label对，寻找一个分类器。每个**任务的目标是**：给定支持集node-label对，寻找一个分类器。每个∗∗任务的目标是∗∗：给定支持集node−label对，寻找一个分类器f_{\\mathcal T_i}$尽可能正确的预测查询集中节点标签。 2.2.2 元学习方法 对于每一个任务Ti=(Si,Qi,yi)∼p(T∣Yknown)\\mathcal T_i=(S_i,Q_i,y_i)\\sim p(\\mathcal T|\\mathcal Y_{known})Ti​=(Si​,Qi​,yi​)∼p(T∣Yknown​)，我们希望为label yiy_iyi​构建一个分类器fTif_{\\mathcal T_i}fTi​​，给定支持集SiS_iSi​，分类器能够正确判别QiQ_iQi​中节点的类别。对于每一个(vq,lvq,yi)∈Qi(v_q,l_{v_q,y_i})\\in\\mathcal Q_i(vq​,lvq​,yi​​)∈Qi​，模型损失定义为： L(l^vq,yi,lvq,yi)=−lvq,yilogl^vq,yi−(1−lvq,yi)log(1−l^vq,yi)\\mathcal L(\\hat l_{v_q,y_i},l_{v_q,y_i})=-l_{v_q,y_i}log\\hat l_{v_q,y_i}-(1-l_{v_q,y_i})log(1-\\hat l_{v_q,y_i}) L(l^vq​,yi​​,lvq​,yi​​)=−lvq​,yi​​logl^vq​,yi​​−(1−lvq​,yi​​)log(1−l^vq​,yi​​) 其中l^vq,yi\\hat l_{v_q,y_i}l^vq​,yi​​表示预测vqv_qvq​标签为yiy_iyi​的概率（这其实就是二分类逻辑回归的损失）。 对于每一个任务TiT_iTi​，分类器fTif_{T_i}fTi​​有两个参数（d维向量）：c+(i)c_+^{(i)}c+(i)​表示正类原型，c−(i)c_-^{(i)}c−(i)​负类原型。我们基于节点表示和这两个原型之间的距离预测节点标签。从数学角度来看就是：给定每个查询节点vqv_qvq​的嵌入向量uqu_quq​，我们按照下面方式计算概率： l^vq,yi=fTi(vq∣c+(i),c−(i))=exp(−dist(uq,c+(i)))∑m∈{+,−}exp(−dist(uq,cm(i)))(2)\\hat l_{v_q,y_i}=f_{T_i}(v_q|c_+^{(i)},c_-^{(i)})=\\frac{exp(-dist(u_q,c_+^{(i)}))}{\\sum_{m\\in\\{+,-\\}}exp(-dist(u_q,c_m^{(i)}))} \\tag 2 l^vq​,yi​​=fTi​​(vq​∣c+(i)​,c−(i)​)=∑m∈{+,−}​exp(−dist(uq​,cm(i)​))exp(−dist(uq​,c+(i)​))​(2) 即节点表示和正类原型的相似度除以节点表示和正类原型与负类原型相似度之和。其中dist(⋅,⋅):Rd×Rd→[0,+∞)dist(·,·):\\mathbb R^d\\times\\mathbb R^d\\rightarrow[0,+\\infty)dist(⋅,⋅):Rd×Rd→[0,+∞)表示欧氏距离的开方，正类原型和负类原型通常为相应所有节点表示的均值。 2.2.2.1 嵌入转换 公式2是在“每个节点的嵌入向量是相同的或者是任务无关的，与节点的标签或者当前任务无关”这一条件下计算预测概率的。这种方法在单标签小样本分类（每个样本只有一个标签）中是合理的，但是在多标签场景（每个节点可能被分配多个标签）下存在问题。 比如在社交网络中，T1\\mathcal T_1T1​和T2\\mathcal T_2T2​是两个分类任务，其对应的标签分别为&quot;Sports&quot;∈Yknown&quot;Sports&quot;\\in\\mathcal Y_{known}&quot;Sports&quot;∈Yknown​和&quot;Music&quot;∈Ynovel&quot;Music&quot;\\in\\mathcal Y_{novel}&quot;Music&quot;∈Ynovel​。AAA和BBB是这两个任务中涉及到的两个用户，假如A和B对于“Sports”的反馈都是positive，对于“Music”的反馈分别是positive和negative。此时，经过T1\\mathcal T_1T1​任务训练，这种task-agnostic方式得到的A和B的表示会很相似，这种节点表示不适用与T2\\mathcal T_2T2​。 为了解决上述问题，作者提出了一个转换函数Tr(⋅)Tr(·)Tr(⋅)：可以将task-agnostic嵌入转换成task-specific嵌入。 不同的查询节点和支持集中节点的关联模式不同，为了全面挖掘查询节点和支持节点之间的关系，对于每个查询节点我们都要对节点嵌入做针对性调整 为了对查询节点进行分类，我们对查询节点和支持节点（正类或负类）之间的距离的关系更感兴趣，而不是查询节点和支持节点（正类和负类）之间的关系。换句话说就是，查询节点和支持节点之间的关系要将支持节点分为正类和负类单独讨论。因此在转换过程中，分别使用正类支持节点和负类支持节点对查询节点进行调整。 基于这两点，对于每个查询节点，我们首先构建两个集合：一个包含查询节点的task-agnostic嵌入和正类支持节点，另一个包含查询节点的task-agnostic嵌入和负类支持节点。然后分别将这两个集合喂给转换函数，即给定一个任务Ti=(Si,Qi,yi)\\mathcal T_i=(S_i,Q_i,y_i)Ti​=(Si​,Qi​,yi​)，对于每个查询节点vq∈VQiv_q\\in\\mathcal V_{\\mathcal Q_i}vq​∈VQi​​： \\begin{align} \\{\\tilde u_{q,+}^{(i)}\\}\\cup\\{\\tilde u_{k,q}^{(i)}|v_k\\in\\mathcal V_{S_i^+}\\}=Tr(\\{u_q\\}\\cup\\{u_k|v_k\\in\\mathcal V_{S_i^+}\\})\\\\ \\{\\tilde u_{q,-}^{(i)}\\}\\cup\\{\\tilde u_{k,q}^{(i)}|v_k\\in\\mathcal V_{S_i^-}\\}=Tr(\\{u_q\\}\\cup\\{u_k|v_k\\in\\mathcal V_{S_i^-}\\}) \\end{align}\\tag 3 其中u~q,+(i)\\tilde u_{q,+}^{(i)}u~q,+(i)​和u~q,−(i)\\tilde u_{q,-}^{(i)}u~q,−(i)​分别表示用正类支持节点和负类支持节点调整后的查询节点的嵌入，u~k,q(i)\\tilde u_{k,q}^{(i)}u~k,q(i)​表示针对查询节点vqv_qvq​调整后的支持节点的嵌入。这样每个查询节点都有两种调整后的嵌入，可以捕捉节点间多种关系来适应多标签场景。 2.2.2.2 转换函数的具体实现 作者使用“ Attention is all you need ”一文中的自注意力架构来实现转换函数。self-attention中每个输入元素都扮演三个角色： 和其他每个元素进行比较，计算一个权重（反映了它对其他元素的影响） 和其他每个元素进行比较，计算一个权重（反映其他元素对它的影响） 用作每个元素输出的一部分 每个元素都有三个向量：query、key和value，分别表示三个角色。 对于公式3，输入是两个集合{uq}∪{uk∣vk∈VSim},m∈{+,−}\\{u_q\\}\\cup\\{u_k|v_k\\in\\mathcal V_{S_i^m}\\},m\\in\\{+,-\\}{uq​}∪{uk​∣vk​∈VSim​​},m∈{+,−}，对于任意两个节点vi,vj∈{vq}∪VSimv_i,v_j\\in\\{v_q\\}\\cup\\mathcal V_{S_i^m}vi​,vj​∈{vq​}∪VSim​​（viv_ivi​和vjv_jvj​可能相同），我们首先计算viv_ivi​对vjv_jvj​的注意力权重： wij=exp((WQui)⋅(WKuj)/d′1/2)∑vk∈{vq}∪VSimexp((WQui)⋅(WKuk)/d′1/2)(4)w_{ij}=\\frac{exp((W_Qu_i)·(W_Ku_j)/d&#x27;^{1/2})}{\\sum_{v_k\\in\\{v_q\\}\\cup\\mathcal V_{S_i^m}}exp((W_Qu_i)·(W_Ku_k)/d&#x27;^{1/2})}\\tag 4 wij​=∑vk​∈{vq​}∪VSim​​​exp((WQ​ui​)⋅(WK​uk​)/d′1/2)exp((WQ​ui​)⋅(WK​uj​)/d′1/2)​(4) 其中WQ,WK∈Rd′×dW_Q,W_K\\in\\mathbb R^{d&#x27;\\times d}WQ​,WK​∈Rd′×d分别是将输入向量转换成query向量和key向量的trainable矩阵，d′d&#x27;d′表示query、key和value向量的维度，&quot;⋅·⋅&quot;表示点乘操作，1d′\\frac{1}{\\sqrt {d&#x27;}}d′​1​是缩放因子（防止梯度太小）。 wijw_{ij}wij​本质上表示的是：节点vjv_jvj​和viv_ivi​之间的相关程度，或者说是vjv_jvj​对viv_ivi​的影响程度。 这样转换后的节点表示向量（聚合了其他所有节点信息）可以通过加权的方式计算得到：WV∈Rd′×dW_V\\in\\mathbb R^{d&#x27;\\times d}WV​∈Rd′×d表示计算value向量的trainable矩阵，WO∈Rd×d′W_O\\in\\mathbb R^{d\\times d&#x27;}WO​∈Rd×d′表示确保输出向量和输入向量维度相同的另一个trainable矩阵，按照如下方式计算节点vqv_qvq​转换后的向量： u~q,m(i)=WO(wqqWVuq+∑vk∈VSimwqkWVuk)(5)\\tilde u_{q,m}^{(i)}=W_O\\Big(w_{qq}W_Vu_q+\\sum\\limits_{v_k\\in\\mathcal V_{S_i^m}}w_{qk}W_Vu_k\\Big)\\tag 5 u~q,m(i)​=WO​(wqq​WV​uq​+vk​∈VSim​​∑​wqk​WV​uk​)(5) 按照如下方式计算针对查询节点vqv_qvq​的支持节点的表示： u~k,q(i)=WO(wkkWVuk+∑vj∈(VSim\\{vk})∪{vq}wkjWVuj)(6)\\tilde u_{k,q}^{(i)}=W_O\\Big(w_{kk}W_Vu_k+\\sum\\limits_{v_j\\in\\mathcal (V_{S_i^m}\\backslash\\{v_k\\})\\cup\\{v_q\\}}w_{kj}W_Vu_j\\Big)\\tag 6 u~k,q(i)​=WO​(wkk​WV​uk​+vj​∈(VSim​​\\{vk​})∪{vq​}∑​wkj​WV​uj​)(6) 本文作者最终采用的是多头注意力机制，将每个头的输入拼接到一起后再通过WOW_OWO​映射成原始输入维度。得到转换后的节点嵌入后，我们重新计算针对查询节点vqv_qvq​的正类原型和负类原型及其预测概率： c~m,q(i)=1∣Sim∣∑vk∈VSimu~k,q(i),m∈{+,−}l^vq,yi=exp(−dist(u~q,+(i),c~+,q(i)))∑m∈{+,−}exp(−dist(u~q,m(i),c~m,q(i)))(7)\\begin{aligned} \\tilde c_{m,q}^{(i)}&amp;=\\frac{1}{|S_i^m|}\\sum\\limits_{v_k\\in V_{S_i^m}}\\tilde u_{k,q}^{(i)},m\\in\\{+,-\\}\\\\ \\hat l_{v_q,y_i}&amp;=\\frac{exp(-dist(\\tilde u_{q,+}^{(i)},\\tilde c_{+,q}^{(i)}))}{\\sum_{m\\in\\{+,-\\}}exp(-dist(\\tilde u_{q,m}^{(i)},\\tilde c_{m,q}^{(i)}))} \\end{aligned}\\tag 7 c~m,q(i)​l^vq​,yi​​​=∣Sim​∣1​vk​∈VSim​​∑​u~k,q(i)​,m∈{+,−}=∑m∈{+,−}​exp(−dist(u~q,m(i)​,c~m,q(i)​))exp(−dist(u~q,+(i)​,c~+,q(i)​))​​(7) 最终的元学习目标函数也调整为： minU,Θ∑Ti∑(vq,lvq,yi∈Qi)L(l^vq,yi,lvq,yi)+λ∑∣∣Θ∣∣22\\mathop{min}_{U,\\Theta}\\sum_{\\mathcal T_i}\\sum_{(v_q,l_{v_q},y_i\\in\\mathcal Q_i)}\\mathcal L(\\hat l_{v_q,y_i},l_{v_q,y_i})+\\lambda\\sum||\\Theta||_2^2 minU,Θ​Ti​∑​(vq​,lvq​​,yi​∈Qi​)∑​L(l^vq​,yi​​,lvq​,yi​​)+λ∑∣∣Θ∣∣22​ 其中Θ\\ThetaΘ是转换函数的所有参数（WQ,WK和WVW_Q,W_K和W_VWQ​,WK​和WV​），λ&gt;0\\lambda&gt;0λ&gt;0是平衡因子。（损失里面为什么最小化参数？） 2.3 模型优化 一种典型的方式是最小化structural损失和meta损失之和，但是图的结构信息在训练开始阶段并没有被正确的嵌入进去，节点的表示具有一定随机性，这对小样本分类任务没有意义。因此一种比较好的优化策略是：在开始阶段针对structural模块进行优化，然后逐渐增加meta-learning模块损失的权重。 为了实现这个策略，作者引入了一个概率阈值τ\\tauτ，在每一步训练过程中分别按照τ\\tauτ和1−τ1-\\tau1−τ的概率对structural模块和meta-learning模块进行优化。阈值τ\\tauτ按照阶梯式方式逐渐从1衰减到0：τ=1/(1+γ⌊stepNdecay⌋)\\tau=1/(1+\\gamma\\lfloor\\frac{step}{N_{decay}}\\rfloor)τ=1/(1+γ⌊Ndecay​step​⌋)，其中γ\\gammaγ表示衰减率，stepstepstep表示当前的step number，NdecayN_{decay}Ndecay​表示衰减次数。时间复杂度如下： structural模块：时间复杂度为O(kd∣E∣)O(kd|\\mathcal E|)O(kd∣E∣)，k表示每次迭代过程中负类节点数，d表示节点嵌入维度，∣E∣|\\mathcal E|∣E∣表示边数； 元学习模块：时间主要花费在转换函数（自注意力模块）上，m表示查询节点数量，n表示负类或正类支持节点数量；计算query、key和value向量花费时间O(mndd′)O(mndd&#x27;)O(mndd′)，d′d&#x27;d′表示三个向量的维度；计算注意力权重和value向量之和花费时间O(mn2d′)O(mn^2d&#x27;)O(mn2d′)；计算最终输出向量花费时间O(mndd′)O(mndd&#x27;)O(mndd′)。 因此总的时间复杂度为O(kd∣E∣+mndd′+mn2d′)O(kd|\\mathcal E|+mndd&#x27;+mn^2d&#x27;)O(kd∣E∣+mndd′+mn2d′)。整个算法优化流程如下： 我们最终的目标是：给定少量标签为y∈Ynovely\\in\\mathcal Y_{novel}y∈Ynovel​的支持节点，我们能判断其他节点是否具有标签yyy，这可以看做是一个小样本节点分类任务T=(S,Q,y)\\mathcal T=(S,Q,y)T=(S,Q,y)。训练好模型后，我们可以得到task-agnostic节点表示UUU和参数为Θ\\ThetaΘ的转换函数Tr(⋅)Tr(·)Tr(⋅)。因此，如果我们要判别一个查询节点vq∈Qv_q\\in Qvq​∈Q的标签，我们只需要查询表示矩阵UUU得到其嵌入uqu_quq​，然后通过公式5和6的转换函数得到其转换后的嵌入表示u~q+\\tilde u_q^+u~q+​和u~q−\\tilde u_q^-u~q−​，再根据公式7计算其预测概率即可。算法流程如下： 3. 实验 3.1 数据集 每个数据集的标签按照6:2:2划分成训练集、验证集和测试集。训练阶段将训练标签看做known标签，并从里面采样小样本节点分类任务。将验证和测试标签看做novel标签并从中分别采样1000个任务。我们采用测试任务上的平均分类表现来比较不同方法的性能。KS,+,KS,−,KQ,+,KQ,−K_{S,+},K_{S,-},K_{Q,+},K_{Q,-}KS,+​,KS,−​,KQ,+​,KQ,−​分别表示支持集和查询集的正、负类样本数量。baseline方法采用Label Propagation，LINE，Node2Vec，GCN和Meta-GNN。 3.2 对比试验 设置KS,+=KQ,+K_{S,+}=K_{Q,+}KS,+​=KQ,+​，KS,−=KQ,−K_{S,-}=K_{Q,-}KS,−​=KQ,−​，用K∗,+K_{*,+}K∗,+​和K∗,−K_{*,-}K∗,−​简化表示正类样本和负类样本数量。考虑到负类样本数量更容易获取，作者设置K∗,+=20K_{*,+}=20K∗,+​=20，K∗,−=40K_{*,-}=40K∗,−​=40，对比结果如下表所示： 具体参数设置可以查看原始论文补充材料。 3.3 消融实验 验证不同模块的作用，提出5种变体： 没有转换函数 直接将查询节点和支持节点的表示直接喂给self-attention而不是像公式3一样将正类和负类分开 两个模块的损失的平衡因子从{10−1,10−1,...,102}\\{10^{-1},10^{-1},...,10{2}\\}{10−1,10−1,...,102}里面选取 最开始先学习节点嵌入，然后将其固定（即两个模块分开单独训练） 每个节点的表示用one-hot向量表示，节点嵌入仅仅通过meta-learning模块训练 这五种变体分别用V1,V2,V3,V4,V5V_1,V_2,V_3,V_4,V_5V1​,V2​,V3​,V4​,V5​表示，是研究结果如下表所示： 3.4 额外实验 正类和负类节点数量 在负类样本小于等于正类样本时，MetaTNE和Planetoid方法表现相当，但是当负类样本数大于正类样本数时，MetaTNE方法由于Planetoid。这证明了我们的方法优于Planetoid，因为在实际应用中负类节点数量通常多于正类节点数量。 查询节点数量 在前面试验中查询集合支持集的正负类样本数量相同，但是在实际应用中查询集正负类节点数量可能不同，因此作者进一步测试了查询及节点数对模型表现的影响。（感觉原文对这一部分实验结果的分析有点勉强） 更少的正类节点数量 设置正类样本数量为5。 节点表示可视化 如图a，未对节点嵌入做调整时，查询节点（真实类别为负类）距离正类原型更近，分类错误；对节点嵌入作调整后，查询节点（真实类别为负类）表示Query(+)到正类正类原型的距离大于Query(-)到负类原型的距离。图b也是同样地结果，说明作者提出的转换函数是有效的。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"}]},{"title":"Graph Meta Learning via Local Subgraphs","slug":"3 论文笔记/小样本图学习/7.Graph Meta Leraning via Local Subgraphs","date":"2021-06-04T07:08:10.000Z","updated":"2021-06-21T00:31:24.981Z","comments":true,"path":"84c11eb2e587/","link":"","permalink":"http://rookieyin.github.io/84c11eb2e587/","excerpt":"https://arxiv.org/pdf/2006.07889 https://github.com/mims-harvard/G-Meta Graph Meta Learning via Local Subgraphs ，NIPS，2020 总结：本文算法上没有太大的创新，将MAML拓展到图学习领域，基于度量学习判别样本标签。 在元任务上学习一个GNN参数，将其代入目标任务的GNN中进行微调 使用子图学习每个节点的嵌入，利用局部子图实现元学习（这块理论证明比较充分） 还有一点就是文章故事讲的很好，完整的定义了图上的元学习以及常见的三种类型的元学习任务，然后提出了可以同时适用这三种类型问题的模型，而其他模型通常只能解决其中一种。","text":"https://arxiv.org/pdf/2006.07889 https://github.com/mims-harvard/G-Meta Graph Meta Learning via Local Subgraphs ，NIPS，2020 总结：本文算法上没有太大的创新，将MAML拓展到图学习领域，基于度量学习判别样本标签。 在元任务上学习一个GNN参数，将其代入目标任务的GNN中进行微调 使用子图学习每个节点的嵌入，利用局部子图实现元学习（这块理论证明比较充分） 还有一点就是文章故事讲的很好，完整的定义了图上的元学习以及常见的三种类型的元学习任务，然后提出了可以同时适用这三种类型问题的模型，而其他模型通常只能解决其中一种。 1.简介 1.1 摘要 Prevailing methods for graphs require abundant label and edge information forlearning. When data for a new task are scarce, meta learning can learn fromprior experiences and form much-needed inductive biases for fast adaption to newtasks. Here, we introduceG-META, a novel meta-learning algorithm for graphs.G-METAuses local subgraphs to transfer subgraph-specific information and learntransferable knowledge faster via meta gradients.G-METAlearns how to quicklyadapt to a new task using only a handful of nodes or edges in the new task and doesso by learning from data points in other graphs or related, albeit disjoint, label sets.G-METAis theoretically justified as we show that the evidence for a prediction canbe found in the local subgraph surrounding the target node or edge. Experiments onseven datasets and nine baseline methods show thatG-METAoutperforms existingmethods by up to 16.3%. Unlike previous methods,G-METAsuccessfully learnsin challenging, few-shot learning settings that require generalization to completelynew graphs and never-before-seen labels. Finally,G-METAscales to large graphs,which we demonstrate on a new Tree-of-Life dataset comprising 1,840 graphs, atwo-orders of magnitude increase in the number of graphs used in prior work. 目前主流的图学习方法都需要大量的标签和边信息。当遇到数据稀缺的任务的时候，元学习可以从之前的经验中学习知识，形成归纳偏差使模型可以快速适应新的任务。本文，我们提出了G-META模型——一种用于图的原生元学习算法。G-META利用局部子图来迁移subgraph-specific信息，并通过meta gradients更快地学习可迁移的知识。G-META通过学习其他图或标签集（尽量不相交）中的相关数据点，来快速适应只有少量节点或边的新任务。作者证明了可以在目标节点或者边周围的局部子图中找到prediction，因此G-META理论上是合理的。7个数据集和9个baseline方法上的实验表明，G-META和现有方法相比性能提高了16.3%。和先前的方法不同，G-META成功应用于具有挑战性小样本学习场景（需要一般化到完全信的图和从未见过的标签）。最后，G-Meta可以扩展到大型图上，作者在一个包含1840个图的Tree-of-Life数据集上演示了这一点，这比之前的实验中使用的图的数量增加了两个数量级。 1.2 本文工作 1.2.1 图元学习的定义 图上的元学习通常指模型在两个层次上学习的场景：1.第一个层级上，在单个任务中快速学习，例如GNN某个特定的图上快速学习节点分类；2.第二个层级上，通过在多个任务上不断积累学习到的知识来捕捉任务结构在不同目标域中是如何变化的。 1.2.2 元学习问题 - 单个图上，不同任务使用的标签集合不同 - 多个图上，不同任务使用的标签集合相同 - 多个图上，不同任务使用的标签集合不同 目前的一些方法如Meta-Graph等只能解决上述问题中的一种，本文的方法可以同时适用于这三种问题。 1.2.3 作者方法 本文作者提出了G-Meta元学习模型，其核心思想是用一个局部子图来表示每个节点，并且用子图来训练GNNs达到元学习的目的。作者从理论上分析了可以在目标节点或者边周围的子图中找到一个合适的预测。 之前的一些小样本学习方法都是基于整个图来做的，作者从理论上分析了这些方法不可能在标签稀少且分布在多个图的小样本设定下取得成功。之前的方法虽然捕捉了整张图的结构信息，但是丢失了更精细的局部结构信息。另外，通过子图得到的结构相似度更有利于G-META通过元学习形成归纳偏置，而且局部子图可以通过GNN实现有效的特征传播和标签平滑。 1.2.4 问题定义 G={G1,...,GN}\\mathcal G=\\{G_1,...,G_N\\}G={G1​,...,GN​}表示N张图，G=(V,E,X)G=(\\mathcal V,\\mathcal E,X)G=(V,E,X)，V\\mathcal VV表示节点集合，E\\mathcal EE表示边集合，X={x1,...,xn}X=\\{x_1,...,x_n\\}X={x1​,...,xn​}表示属性向量集合，xu∈Rdx_u\\in\\mathbb R^dxu​∈Rd表示节点uuu的d维特征向量。Y={Y1,...,YM}\\mathcal Y=\\{Y_1,...,Y_M\\}Y={Y1​,...,YM​}表示M个不同的标签，用Y表示从Y\\mathcal YY中随机选取的标签集合。G-Meta的核心准则是用局部子图表示节点，然后用子图在不同任务、图和标签集合之间传递知识。用S表示节点的局部子图集合，S={S1,...,Sn}S=\\{S_1,...,S_n\\}S={S1​,...,Sn​}。节点分类的目标是训练一个GNN fθ:S→{1,...,∣Y∣}f_\\theta:\\mathcal S\\rightarrow\\{1,...,|Y|\\}fθ​:S→{1,...,∣Y∣}，只需要少量有标签节点就可以准确的将节点u对应的局部子图SuS_uSu​映射成节点对应的标签。 问题1：Single Graph and Disjoint Labels 给定图G，标签集合的分布p(Y∣G)p(Y|G)p(Y∣G)，目标是让经过其他标签集合Yi∼p(Y∣G)Y_i\\sim p(Y|G)Yi​∼p(Y∣G)训练好的模型能够快速适应unsee标签集合Y∗∼p(Y∣G)Y_*\\sim p(Y|G)Y∗​∼p(Y∣G)，其中Yi∩Y∗=∅Y_i\\cap Y_*=\\varnothingYi​∩Y∗​=∅ 问题2：Multiple Graphs and Shared Labels 给定服从分布p(G)p(G)p(G)的图集合G\\mathcal GG和一个标签集合Y，目标是让经过Gj∼p(G)G_j\\sim p(G)Gj​∼p(G)训练好的模型可以快速适应unseen graph G∗∼p(G)G_*\\sim p(G)G∗​∼p(G)，其中GjG_jGj​和G∗G_*G∗​是disjoint的。所有的任务都共享一个标签集合。 问题3：Multiple Graphs and Disjoint Labels 给定服从分布p(G)p(G)p(G)的图集合G\\mathcal GG，每个任务有自己的标签集合YiY_iYi​，但是不同图的标签集合可以相同，目标是让经过Yi∼p(Y∣G)Y_i\\sim p(Y|\\mathcal G)Yi​∼p(Y∣G)训练好的模型能够快速适应unseen标签集合Y∗∼p(Y∣G)Y_*\\sim p(Y|\\mathcal G)Y∗​∼p(Y∣G)，其中Yi∩Y∗=∅Y_i\\cap Y_*=\\varnothingYi​∩Y∗​=∅。 2. G-META 首先为每个节点构造一个局部子图（h-hop邻居），然后使用GNN encoder为每个子图生成嵌入，最后使用原型损失作为归纳偏差，使用MAML在不同的图和标签之间传递知识。 2.1 局部子图及其理论分析 首先介绍如何构造局部子图，然后从理论上分析了局部子图如何帮助G-Meta捕捉到充足的结构信息、特征以及标签，并将这些信息用于图元学习。 对于节点u，其对应的局部子图定义为Su=(Vu,Eu,Xu)S_u=(\\mathcal V^u,\\mathcal E^u, X^u)Su​=(Vu,Eu,Xu)表示一个节点集合{v∣d(u,v)≤h}\\{v|d(u,v)\\leq h\\}{v∣d(u,v)≤h}，d(u,v)d(u,v)d(u,v)表示节点u和节点v之间的最短路径，h定义了子图的邻居大小。然后用GNNs对这些局部子图进行编码（学习节点表示），但是一个直接的问题是这个子图是否会由于排除了子图外节点而丢失信息。下面作者从理论上分析了将GNN应用于子图和应用于整个图相比而言也可以保留有用的信息。 以GCN为对象，研究信息传播过程中节点之间是如何相互影响的。 2.1.2 定理1：节点影响的衰减特性 t表示节点u和节点v之间的一条路径，DGMtD_{GM}^tDGMt​表示路径t上节点度的集合平均值。令DGMt∗=mint{DGMt}D_{GM}^{t_*}=min_t\\{D_{GM}^t\\}DGMt∗​​=mint​{DGMt​}，h∗=d(u,v)h_*=d(u,v)h∗​=d(u,v)，考虑节点v到u的节点影响Iu,vI_{u,v}Iu,v​，有Iu,v≤C/(DGMt∗)h∗I_{u,v}\\leq C/(D_{GM}^{t_*})^{h_*}Iu,v​≤C/(DGMt∗​​)h∗​。 证明见原始论文Appendix C。定理1表明节点v对u的影响随着他们之间距离h∗h_*h∗​的增加指数衰减。另一个发现就是节点影响很大程度上取决于两个节点之间路径累计的节点度，换句话说，如果节点间的路径是直线（累计的节点度最小），节点影响非常高，相反，如果路径上包含大量到其他节点的连接（累计的节点度很大），那么节点影响很小。直觉上的理解就是，累计节点度较高的路径会带来更复杂的消息，从而减弱每个节点的影响，而累计节点度较低的路径上消息更简单，可以直接将消息传递给目标节点。由于现实世界中的图通常边的密度比较高，因此节点影响会非常小。下面分析在局部子图上运行GNN和在整个图上运行GNN相比，不会丢失有用的信息。 （这个我觉得还挺有意思的，通过子图是不是可以曲线救国，解决大规模图上GNN难以训练的问题？） 2.1.3 定理2：局部子图可以保留属性 SuS_uSu​表示节点u对应的邻居大小为h的局部子图，节点v定义为v=argmaxw({Iu,w∣w∈V∖Vu})v=argmax_w(\\{I_{u,w}|w\\in\\mathcal V \\setminus\\mathcal V^u\\})v=argmaxw​({Iu,w​∣w∈V∖Vu})。令tˉ\\bar ttˉ表示u和v之间的一条路径，DGMtˉD_{GM}^{\\bar t}DGMtˉ​表示路径tˉ\\bar ttˉ上节点度的几何平均，DGMtˉ∗=mint{DGMtˉ}D_{GM}^{\\bar t_*}=min_t\\{D_{GM}^{\\bar t}\\}DGMtˉ∗​​=mint​{DGMtˉ​}，则有Rh(u)≤C∖(DGMtˉ∗)t∗)h+1R_h(u)\\leq C\\setminus (D_{GM}^{\\bar t_*})^{t_*})^{h+1}Rh​(u)≤C∖(DGMtˉ∗​​)t∗​)h+1。 定理证明见原始论文Appendix D。定理2说明图的影响损失的上界受指数衰减项增长的限制（也就是公式中的DGMtˉ∗D_{GM}^{\\bar t_*}DGMtˉ∗​​），换句话说，局部子图公式就是对整图公式的一个h-th阶近似。 2.1.4 利用局部子图实现小样本元学习 下面介绍局部子图如何帮助G-Meta实现小样本元学习。上面构建的子图捕捉了：（1）结构，图结构可以作为预测的一种alternative source of strong signal，尤其在节点标签有限的情况下。GNN由于训练复杂度过高，无法捕捉大型图结构，但是可以捕捉小型图的结构信息，比如本文中的子图。（2）特征，上面的理论分析表明局部结构子图保留了有效的信息。（3）标签，当只有少量有标签节点时，标签信息难以在整个图上得到有效传播。 基于度量学习的方法学习一个task-specific度量，通过计算和支持样本之间的距离判别查询样本的标签类别，这已经被证明了是一种很好地归纳偏置。通过同时捕捉了结构和特征信息的子图表示，G-Meta使用度量学习比较查询子图嵌入和支持子图嵌入之间的类型做预测。通过这些手段就可以规避掉只有少量标签导致信息不能有效传播的问题。 2.2 具体实现 2.2.1 子图编码 在每个meta-task中，首先使用h-hops 邻居为每个节点uuu构造一个子图SuS_uSu​（也可以使用其他子图提取算法） 然后将子图SuS_uSu​喂给一个h-layer的GNN来获取子图中每个节点的embedding，这里的h表示子图领域的大小。 子图的中心节点uuu的嵌入用来表示整个子图的嵌入hu=Centroid(GNN(Su))h_u=Centroid(GNN(S_u))hu​=Centroid(GNN(Su​))。采用中心节点表示整个图的嵌入只是一种方法，也可以考虑其他的子图表示方法比如子图神经网络或者通过readout函数获取整个图的表示。 2.2.2 原型损失 得到子图表示后，作者利用表示和标签之间的归纳偏置来弥补小样本设定下标签信息不足的问题。对于每个标签k，我们用该标签下所有子图的表示的平均值作为原型ckc_kck​，即ck=1/Nk∑yj=khjc_k=1/N_k\\sum_{y_j=k}h_jck​=1/Nk​∑yj​=k​hj​作为标签k的标志。这样支持集和查询集中的所有子图对于标签k的类分布向量可以通过和支持原型之间的欧式距离计算得到：p_k=(exp(-||h_u-c_k||))/(\\sum_\\hat kexp(-||h_u-c_\\hat k||))。然后基于此优化交叉熵损失：L(p,y)=∑jyjlogpjL(p,y)=\\sum_jy_jlog p_jL(p,y)=∑j​yj​logpj​，其中y表示真实的标签one-hot向量。（这里就是度量学习常用的套路） 2.2.3 基于优化的元学习 为了在不同的图和标签之间迁移结构化知识，作者使用基于优化的元学习方法MAML。作者通过将节点划分到一个独立的局部子图来打破节点对图的依赖，这允许我们直接将子图应用到MAML，因为可以把单个子图看作传统小样本元学习设定下的单个图像。具体来说，我们首先采样一系列任务，每个任务包含一个子图集合。 元训练阶段 在元学习的inner-loop阶段，使用常规的stochastic梯度下降来由化每个任务Ti:θj=θj−1−α▽Lsupport\\mathcal T_i:\\theta_j=\\theta_{j-1}-\\alpha\\bigtriangledown\\mathcal L_{support}Ti​:θj​=θj−1​−α▽Lsupport​，更新后的参数用于query集，Ti\\mathcal T_iTi​查询集的损失记作Lqueryi\\mathcal L^i_{query}Lqueryi​。上述操作重复执行η\\etaη次。 然后将这一个batch的所有任务的最后一步得到的损失Lqueryi\\mathcal L_{query}^iLqueryi​求和，然后执行元更新操作：θ=θ−β▽∑iLqueryi\\theta=\\theta-\\beta\\bigtriangledown\\sum_i\\mathcal L_{query}^iθ=θ−β▽∑i​Lqueryi​。 然后采样新一批的任务，执行上述同样地步骤更新参数θ\\thetaθ。 元测试阶段 在meta-testing阶段，使用训练阶段最终得到的参数θ∗\\theta_*θ∗​执行训练阶段同样地流程。θ∗\\theta_*θ∗​是从多个meta-training任务中学习的的知识，是可以快速适应unseen任务的最优参数。 2.3 G-META的优点 伸缩性好：G-META在min-batch的子图上操作，子图大小和batch大小都很小，因此和之前那些在整个图上操作的方法相比，G-META计算很快，需要的内存也很小。 归纳学习：G-META的输入是GNN编码得到的不同的子图表示，强制模型在不可见子图上进行归纳推理。这种归纳学习对于小样本学习十分重要，小样本场景下模型需要适应unseen节点。归纳学习允许将知识从meta-training子图迁移到meta-testing子图上。 过平滑正则化：GNN的一个缺点就是过平滑问题，G-META不存在这个问题，因为每一轮都是单独将子图喂给GNN，并且子图的结构、大小和节点都是不一样的，这就规避了GNN的过平滑问题。 小样本学习：G-META只需要少量有标签节点就能取得不错的效果，而之前的GNN方法大多依赖于大量的有标签节点来传播信息。 应用广泛：G-META可以应用于许多图元学习问题，之前的方法通常只能解决其中一个。和之前的方法相比，G-META可以同时应用于节点分类和小样本链路预测。 作者对G-Meta的重要性做了一个总结： G-Meta advances ML research G-Meta can expedite scientific discovery G-Meta can bring economic values G-Meta can imporve equality 虽然图元学习方法性能不错，但是也存在一些潜在风险： Negative transfer，元学习其实是一种训练上的小trick，有时候迁移的知识对于目标任务可能产生负影响 Misuse，元学习并不是通用的，在标签样本很多的时候没有必要使用（这点感觉是凑数的） Adversarial attacks，由于有标签样本数量很少，每个有标签样本对于模型都很重要，因此容易受到对抗攻击（这应该是所有小样本问题的通病） 3. 实验 3.1 数据集 **两个人造数据集**：节点标签依赖于节点所处的结构，证明G-META可以捕捉局部图结构。 Cycle：使用cycle basis图，并附加上一些形状分布：房屋、信息、钻石、扇形。每个节点的标签取决于由形状定义的结构角色。在多图任务中，每个图的形状数量分布不同。 BA：为了能够在更真实的通构图中对局部结构信息建模，作者构建了一个Barabasi-Albert（BA）图，然后在图上添加不同的形状。多于多图问题，在每个图上添加不同数量分布的形状。 真实数据集：三个用于节点分类，两个用于链路预测。 3.2 实验设置 3.2.1 节点分类 5种label用于元测试，5中label用于元验证，其余的用于元训练。每个任务中，采用2-ways 1-shot设定，元训练阶段执行5步梯度更新，元测试阶段执行10次梯度更新（人造数据集）3-ways 3-shots，元训练阶段执行10步梯度更新，元测试阶段执行20次梯度更新（真实数据集） 对于多图任务（shared labels），10%的图用于测试，其余的图用于训练。 3.2.2 链路预测 10%的图用于测试，10%的图用于验证，对于每个图支持集包含30%的边，查询集包含70%的边。随机采样和正类边数目相等的负类边。每个任务采用16-shots，也就是只使用32个节点来预测unseen图上的边。元训练阶段执行10次梯度更新，元测试阶段执行20次梯度更新。每个实验重复执行5次，计算结果的标准差，超参的选择参见附件。 3.2.3 baseline Meta-Graph，Meta-GNN，FS-GIN，Few-shot SGC四个图小样本元学习方法。No-Finetune，KNN，Fintune，MAML和ProtoNet五个表现比较好的元学习模型；ProtoNet和MAML可以看做对G-META的消融实验，即分别去掉MAML和原型损失。 3.3 实验结果 人造数据集 **真实数据集** 1. G-META可以捕捉局部结构信息 Meta-GNN、FS-GIN和FS-SGC都是基于整个图来做的，和作者基于子图的方法G-META相比效果要差，证明了子图嵌入可以捕捉局部结构信息，而使用整个图无法捕捉这些信息。在单个图的disjoint label设定下，KNN取得了最好结果，这表明从训练的嵌入函数学习到的子图表示足够铺捉到结构信息，进一步证实了构造局部子图的有效性 G-META性能良好、通用的图元学习方法 G-META的性能优于MAML和ProtoNet。 局部子图对于图小样本学习十分重要 对比Meta-GNN、FS-GIN和FS-SGC这些作用在整个图上的方法，G-META性能更加优越，可以学习可迁移的知识，即使标签集是disjoint的","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"子图","slug":"子图","permalink":"http://rookieyin.github.io/tags/%E5%AD%90%E5%9B%BE/"}]},{"title":"网络嵌入综述","slug":"3.网络嵌入综述","date":"2021-06-04T07:08:10.000Z","updated":"2022-06-01T04:41:47.775Z","comments":true,"path":"2fe36ae34ad3/","link":"","permalink":"http://rookieyin.github.io/2fe36ae34ad3/","excerpt":"https://link.springer.com/article/10.1007/s00521-020-04908-5 Network representation learning: a systematic literature review 1.概述 1.1 背景 Data Representation：用一系列符号或者数字也就是特征向量来描述某个对象，它能反映所描述对象的特征、结构以及分布信息。一个好的数据表示通常能大大减小数据的体量，同时保持原始数据的基本特征以及对噪声的鲁棒性。表示学习近些年来在模式识别和机器学习领域是一个非常重要的研究热点，在很多顶级期刊会议，如TPAMI、TNNLS、TKDE、KDD、NIPS、ICML、AAAI、IJCAI以及ICLR等，都有很多相关文章。 表示学习可以直接从原始低维感知数据中学习到高维抽象特征，这更有利于后续的数据分析和处理。深度学习是表示学习的一种典型方法，它能自动提取适当的特征或者从数据中获取到对个级别的表示。深度学习技术已经成功应用在语音识别、信号处理、图像识别、对象识别等领域，尤其是在自然语言处理领域。 在表示学习的浪潮中，网络表示学习（又称网络嵌入）也在蓬勃发展。因为从网络数据中提取结构信息的传统方法通常取决于拓扑统计信息、聚合系数或者设计精良的人工特征，这带来了很多弊端。因此受成功应用在NLP领域的表示学习的启发，网络表示学习旨在从给定网络数据中学习到低维向量空间中的一些特征，但是编码了各种列结构和语义信息。获取到数据向量表示后，可以通过现成的机器学习方法直接解决网络挖掘问题。网络表示学习已经被证明可用于许多数据挖掘和机器学习任务，比如链路预测、节点分类、网络重构、推荐、可视化以及社区发现等等。下图展示了2010年~2020年网络表示相关论文数量：","text":"https://link.springer.com/article/10.1007/s00521-020-04908-5 Network representation learning: a systematic literature review 1.概述 1.1 背景 Data Representation：用一系列符号或者数字也就是特征向量来描述某个对象，它能反映所描述对象的特征、结构以及分布信息。一个好的数据表示通常能大大减小数据的体量，同时保持原始数据的基本特征以及对噪声的鲁棒性。表示学习近些年来在模式识别和机器学习领域是一个非常重要的研究热点，在很多顶级期刊会议，如TPAMI、TNNLS、TKDE、KDD、NIPS、ICML、AAAI、IJCAI以及ICLR等，都有很多相关文章。 表示学习可以直接从原始低维感知数据中学习到高维抽象特征，这更有利于后续的数据分析和处理。深度学习是表示学习的一种典型方法，它能自动提取适当的特征或者从数据中获取到对个级别的表示。深度学习技术已经成功应用在语音识别、信号处理、图像识别、对象识别等领域，尤其是在自然语言处理领域。 在表示学习的浪潮中，网络表示学习（又称网络嵌入）也在蓬勃发展。因为从网络数据中提取结构信息的传统方法通常取决于拓扑统计信息、聚合系数或者设计精良的人工特征，这带来了很多弊端。因此受成功应用在NLP领域的表示学习的启发，网络表示学习旨在从给定网络数据中学习到低维向量空间中的一些特征，但是编码了各种列结构和语义信息。获取到数据向量表示后，可以通过现成的机器学习方法直接解决网络挖掘问题。网络表示学习已经被证明可用于许多数据挖掘和机器学习任务，比如链路预测、节点分类、网络重构、推荐、可视化以及社区发现等等。下图展示了2010年~2020年网络表示相关论文数量： 下图展示了近10年来，网络表示学习领域不同子方向的论文数量： ## 1.2 图嵌入 VS 网络嵌入 1.3 分类框架 1.4 定义 1.4.1 网络中的数据 网络定义：G=(V,E)G=(V,E)G=(V,E)，V表示顶点集合，E表示顶点间边的集合。 **同构/异构网络：**给定G=(V,E)G=(V,E)G=(V,E)，ϕ:V→A\\phi:V\\rightarrow Aϕ:V→A，Ψ:E→R\\Psi:E\\rightarrow RΨ:E→R是顶点和边的映射函数，如果∣A∣&gt;1|A|&gt;1∣A∣&gt;1或者∣R∣&gt;1|R|&gt;1∣R∣&gt;1则网络为异构网络，否则为同构网络。 https://www.jiqizhixin.com/graph/technologies/9f924061-6327-40af-a9a6-b5d923f6f1c2 当代大多数信息网络分析都有一个基本假设：对象或链接的类型是独特的。也就是说，网络是同构的，包含相同类型的对象和链接。这些同构网络通常是通过简单地忽略物体和链接的异质性或仅考虑一种类型的对象之间的一种类型的关系。然而，大多数真实网络都包含多类型的交互关系，我们可以用不同类型的对象和链接将它们建模为异构信息网络（简称HIN或异构网络）。 基于这个概念之上，异构信息网络的定义为：如果对象的类型| A |&gt;1 或关系类型| R | &gt; 1，信息网络被称为异构信息网络；否则，它是一个同质的信息网络。与广泛研究的同构网络相比，异构信息网络包含更丰富的结构和语义信息，为数据挖掘提供了大量的机会和挑战。 **知识图谱：**一个知识图谱定义为有向图，图中节点表示实体，边表示subject-property-object三元组关系，表示为&lt;h,r,t&gt;&lt;h,r,t&gt;&lt;h,r,t&gt;。通常在一个知识图谱中，边和节点的类型有多种，因此知识图谱可以看做异构网络的一种。 **静态/动态网络：**动态网络随着时间会不断变化，时刻t的网络表示为Gt={Vt,Et}G^t=\\{V^t,E^t\\}Gt={Vt,Et}，其中VtV^tVt表示节点集合，EtE^tEt表示t时刻边的状态。本文中未作特殊说明，指的都是静态网络。 1.4.2 网络中的结构及其他信息 **First-order proximity：**节点uuu和vvv之间边的权重wuvw_{uv}wuv​，表示两个节点间局部成对邻近度。如果两个节点之间没有变，那么一阶邻近度为0。 **Second-order 和 High-order proximity：**假设su=(wu1,wu2,...,wu∣V∣)s_u=(w_{u1},w_{u2},...,w_{u|V|})su​=(wu1​,wu2​,...,wu∣V∣​)表示节点uuu和其他所有节点之间的一阶邻近度，那么uuu和vvv之间的二阶邻近度可以通过sus_usu​和svs_vsv​之间的余弦距离计算得到。同理，两节点之间的X-order邻近度可以通过他们之间的 X-1 order邻近度的相似度计算得到。 **Meta-path of the network：**给定异构信息网络G=(V,E)G=(V,E)G=(V,E)，一条元路径πππ表示一个节点类型序列v1,v2,...,vnv_1,v_2,...,v_nv1​,v2​,...,vn​和（或者）边类型e1,e2,...,en−1: π=v1→e1⋅⋅⋅vi→ei⋅⋅⋅→en−1vne_1,e_2,...,e_{n-1}:\\ π=v_1 \\stackrel{e_1} \\rightarrow···v_i\\stackrel{e_i}\\rightarrow···\\stackrel{e_{n-1}}\\rightarrow v_ne1​,e2​,...,en−1​: π=v1​→e1​⋅⋅⋅vi​→ei​⋅⋅⋅→en−1​vn​。 1.4.3 网络嵌入的问题定义 **问题1：（同构网络嵌入）**给定输入图G，同构网络嵌入旨在将节点或者子图或者整个网络映射到一个低维空间Rd(d≪∣V∣)R^d(d\\ll|V|)Rd(d≪∣V∣)。我们希望嵌入向量能够尽可能多的保留网络的各种特征。 **问题2：（异构网络嵌入）**给定网络G，异构网络嵌入旨在将不同类型的实体或者关系映射到一个低维空间Rd(d≪∣V∣)R^d(d\\ll|V|)Rd(d≪∣V∣)。我们希望嵌入向量能够尽可能丰富的保留G中的结构和语义信息。 **问题3：（动态网络嵌入）**给定一系列动态网络G1,G2,...,GT{G^1,G^2,...,G^T}G1,G2,...,GT，动态同构或异构网络嵌入希望学习到一个映射函数ft:vi→Rdf^t:v_i\\rightarrow R^dft:vi​→Rd。随着时间的推进，该目标函数保留了viv_ivi​和vjv_jvj​之间的结构和语义信息。 2. 同构网络嵌入 将原始网络数据喂给网络嵌入算法，得到低维向量后，利用现成的机器学习模型完成各类图分析任务。 2.1 节点嵌入 2.1.1 基于随机游走 一、方法 随机游走被广泛应用于网络数据分析中，来捕捉拓扑结构信息。随机游走会在图中选取某个节点然后沿着图中的边随机移动，形成一条移动路径。我们可以把得到的路径类比成NLP中的语料库中的句子，网络中的顶点当成文本语料库中的单词。然后利用NLP中的技术比如word2vec，我们可以将节点映射到低维向量空间中。学术界基于节点序列和文本序列之间的相似性提出了一些方法，比较具有代表性的有： DeepWalk 受word2vec的启发而提出的一种方法。Deepwalk算法通过在图上随机游走生成节点序列，每一条游走路径相当于NLP语料库中的一个句子，而一个节点相当于一个一个单词。然后，在路径上应用skip-gram模型，在节点嵌入条件下，来最大化观测到节点邻居的概率。 Node2vec 但是DeepWalk有一些缺陷，首先就是研究人员发现不同的游走策略会产生不同的节点表示。Node2vec通过广度优先采样（BFS）和深度优先采样（DFS）的有偏策略改进了DeepWalk方法。通过调整搜索偏置参数，模型可以获得良好的节点特征向量。 DDRW DeepWalk的第二个问题就是对于某些特定的节点分类任务，模型无法得到具有判别力的特征表示。DDRW旨在学习一个潜在表示空间，可以很好地捕捉到网络的拓扑结构，同时在网络分类任务中具有很好地判别力。该模型通过对分类目标和隐藏空间中的嵌入实体目标进行联合优化，扩展了DeepWalk。 TriDNR DeepWalk的第三个问题就是没有对节点标签信息进行建模。TriDNR模型从三方面学习网络表示：节点结构，节点内容和节点标签。 Struct2vec DeepWalk还有一个问题：在结构等价的任务中表现比较差。Struct2vec使用层次结构在不同尺度下测量相似性来估计结构相似性，并构造了一个多层图，通过非对称随机游走对节点的结构相似性进行编码并生成结构上下文。然后，应用skip-gram模型来学习节点的潜在表示，最大化节点上下文在序列中的可能性。 二、讨论 虽然基于随机游走的方法取得了不错的效果，但是其随机性带来的弊端是不能忽略的。 2.1.2 基于优化的方法 一、方法 基于优化的方法旨在设计一个合适的目标函数来对图的结构和语义信息进行建模，然后通过各种优化方法来最大化或最小化目标函数得到节点的向量表示。比如LINE使用负采样+ASGD，APP使用负采样+SGD。 Line Line模型设计了一阶邻近度和二阶邻近度两个损失函数。作者建议优化联合概率分布和经验概率分布的KL散度。为了得到顶点的嵌入，提出了一种边采样策略来最小化一阶或者二阶邻近度。 APP APP模型同时捕捉节点对之间的非对称邻近和高阶相似度。为了保留非对称邻近，顶点v需要同时担任两个角色：source role和target role，分别用sv→\\mathop{s_v}\\limits^{\\rightarrow}sv​→​和tv→\\mathop{t_v}\\limits^{\\rightarrow}tv​→​表示。全局目标函数被设计成sus_usu​和tvt_vtv​的内积，表示节点对(u,v)(u,v)(u,v)之间的相似度。 二、讨论 Line模型复杂度和边的数量线性相关，可以轻松应用到大型网络中去。而且，这类模型的性能主要依赖于目标函数的建模能力。因此如果能设计出更准确的目标函数，基于优化的模型性能会得到进一步的提高。 2.1.3 基于矩阵分解 一、方法 网络或者图通常可以表示成矩阵形式，比如邻接矩阵或者拉普拉斯矩阵。因此，很容易想到用矩阵分解的方法来获取节点嵌入。矩阵分解，比如奇异值分解（SVD），特征值分解，是数学里一种重要方法，已经成功应用在很多领域。 基于矩阵分解的模型主要有：GraRep，HOPE和M-NMF。GraRep通过分解全局结构信息矩阵来获取节点嵌入，它整合了各种k-step关系信息。HOPE使用SVD分解高阶邻近度矩阵来获取高阶邻近嵌入。M-NMF提出了一种模块化的非负矩阵分解模型，同时保留了一阶微观结构，二阶邻近度以及宏观的团体结构的特征。 需要注意的时，现实世界的网络除了结构外还包含了其他丰富的信息。因此，为了对这些辅助信息建模，TADW将顶点的文本特征引入到矩阵分解框架中。MMDW基于矩阵分解，在一个统一的学习框架中，将标签信息整合到了顶点表示中。 二、讨论 GraRep方法仅仅通过SVD进行线性降维，导致更多地非线性信息的损失。因为矩阵分解十分灵活，TADW、MMDW和M-NMF很容易进行扩展，整合其他信息。HOPE也可以通过设计新的高阶邻近度矩阵进行扩展。 2.1.4 基于深度学习方法 近年来，深度学习技术在许多领域都展现了强大的数据建模能力，网络数据也不例外。自编码器、各种卷积神经网络、注意力机制、对抗学习等都被应用到网络数据中。 2.1.4.1 基于自编码器的方法 这种类型方法主要分为两类：基于传统自编码器和基于图自编码器。前者的典型算法有SDNE和DNGR ，后者的典型算法有GAE和ARGA。 SDNE SDNE提出了一种改进的卷积自编码器模型，同时优化一阶和二阶邻近度来获取网络的局部和全局结构特征。一阶邻近度利用拉普拉斯矩阵保留下来，二阶邻近度通过深度自编码器保留下来。最后，将深度自编码器的中间层作为最终的节点表示。 DNGR DNGR通过positive pointwise mutual information(PPMI)矩阵来获取图的结构信息，学习堆叠式的降噪自编码器来获取节点嵌入。需要注意的时，DNGR是task-agnostic的，无法保证对于某个特定任务有好的表现。 DNNNC DNNNC是对DNGR的一个拓展，是一种有效的classification-oriented的节点嵌入方法，可以提高节点分类的表现。 GAE GAE可以看做基于图自编码器的pioneering work。该模型设计了一个卷积神经网络作为编码器，一个简单的内积解码器，用于图结构数据上的无监督学习。但是这种模型有三个弊端： 模型无法得到稳定的图表示——ARGA模型，提出了对抗训练模式来对GAE的隐藏编码进行正则化。 不是为了某个特定的图分析任务而设计的——DAEGC提出clustering-oriented节点嵌入模型，通过联合优化来同时获取图嵌入和图聚类结果。 解码器太简单，丢失了太多的结构信息——TGA模型提出了一种triad解码器，通过对三元闭包属性（现实世界网络的基础）进行建模。 2.1.4.2 基于GCN的方法 Semi-supervised classification withgraph convolutional network这篇文章提出的GCN模型可以看做是最具代表性的工作，它采用了CNN在图结构数据上的一种有效的变体。主要的卷积架构是通过谱图卷积的一个局部一阶近似。研究者发现这个模型也有一些代表性的弊端： GCN无法对网络的全局信息进行建模——DGCN模型采用双重图卷积网络，基于邻接矩阵的卷积ConvA和基于PPMI的卷积ConvP。这样模型能同时保留局部和全局信息。 节点数量很大时，GCN占用的内存和计算资源很大——LGCL通过可学习的卷积层和一种有效的子图训练策略，提出了一种适用于大规模网络的可学习GCN。 GCN太浅了，无法捕捉更多信息——HesGCN提出了一种更有效的卷积规则，对一阶谱图Hessian卷积（Hessian矩阵和谱图卷积的结合）进行优化。 2.1.4.3 基于图注意力的方法 2018年，Velickovic在Graph attention network一文中提出了GATs模型，用于节点分类的一种基于注意力的架构。它的主要思想是按照自注意力策略，通过节点的邻居，计算每个节点的隐藏表示。 2.1.4.4 基于GAN的方法 这一类方法中比较有代表性的有：ANE、GraphGAN和ProGAN。 ANE ANE主要包含两部分：一个是结构保留组件，另一个是对抗学习组件。具体来说，用DeepWalk来保留结构信息，对抗学习组件包含一个生成器和一个判别器。 GraphGAN GraphGAN是另一个比较创新的基于GAN的图表示学习框架。给定一个顶点，生成模型旨在拟合它和其他所有顶点之间的连接分布，并且生成fake样本来迷惑判别器。 ProGAN ProGAN提出在不同节点之间生成邻近度，这有助于发现复杂的潜在的邻近性，有利于网络嵌入。 2.1.5 其他 GraphWave和上面所有方法不同，它基于以该节点为中心的频谱图小波扩散，为每一个节点学习一个不同维度的结构嵌入。该方法使得通过谱图小波来学习节点的结构嵌入成为可能，关键是将小波系数看做概率分布，通过经验特征函数对分布进行描述。 2.1.6 总结 对于基于自编码器和GAN的模型，它们都是无监督模型。学习到的表示可以完成节点聚类、链路预测等任务。值得注意的是，由于网络数据的特殊性，在网络数据中应用自编码器，其学习能力是有限的。因此，设计一个面向图的自编码器是一个非常紧急的研究问题。虽然上面提到了一些这方面的工作，但是还有很大的发展空间。因为大多数自编码器及其变体都是使用KL散度来计算两个分布之间的相似度，这不是一个真实的度量。因此，最近提出的Wasserstein autoencoders为下一代图自编码器提供了一个研究方向。 基于GAN的模型也有一些弊端，比如稳定性差，这可能是GAN本身的特性导致的。将GAN应用在图数据上仍然有很大发展空间。 对于基于GCN和GAN的模型，它们主要应用于半监督节点分类任务。对于GCN，其时间复杂度和图的边数量线性相关，GAT的时间复杂度和GCN相当。因此，这两类方法都能使用与大规模网络。 2.2 子图嵌入 子图嵌入即将部分节点和边构成的集合映射成一个低维向量。比较有代表性的方法是Subgraph2vec，它在一个连续向量空间中对语义子结构依赖进行编码。首先，它利用WL重新标记策略提取给定图中每个节点周围的根子图，然后通过radial skip-gram模型学习它的嵌入。 2.3 整图嵌入 整图嵌入就是将整个图映射成一个向量，下面主要介绍目前效果最好的基于Graph kernel和基于深度学习的两类方法。 2.3.1 基于Graph kernel的方法 这一类方法中比较典型的有两种：graph kernel和deep graph kernel（DGK）。Graph kernel定义了两个子图之间距离的度量函数。DGK提出利用子结构之间独立的信息来学习它们的潜在表示。DGK是这一类方法中表现最好的方法之一，已经被证明了优于其他三种比较流行的图核方法Graphlet kernel、Weisfeiler-Lehman kernel和shortest-path graph kernel。 这一类方法的主要缺点是需要精心提取的特征。另外，这些模型的相似度是直接基于全局图结构计算到的，并且计算图之间的距离代价很大。预测规则也难以解释，因为图特征很多且都是隐藏的。而且它们不能捕捉一些重要的子结构，这对图分类很重要。 2.3.2 基于深度学习的方法 2.3.2.1 基于CNN 这一类方法主要有两种：基于传统CNN和基于普卷积。 基于传统CNN PSCN 具有代表性的模型是PSCN，它可以看做是第一个用CNN来进行任意图分类的工作。该模型设计了一种通用的方法，可以通过对基于图像的卷积网络进行模拟，从图上提取局部连接区域，然后在输入的局部连接区域上进行卷积操作。PSCN的最终架构包含节点序列选择、邻居图构造、图正则化和卷积模块四部分。 NgramCNN 但是PSCN模型存在一些缺点：（1）邻居的选择；（2）丢失了复杂的子图特征；（3）特别的打标签方法。最近提出的NgramCNN模型解决了上述问题。它包含三个核心组件：（1）n-gram正则化，对邻接矩阵中的节点进行排序，输出n-gram正则化的邻接矩阵；（2）一个特别的卷积层，称为diagonal卷积，它可以提取通用的子图模式；（3）一个堆叠的卷积结构，由若干卷积层和一个池化层构成。 DGCNN PSCN还有一个问题就是数据预处理复杂度高，为了解决这个问题，研究人员提出了DGCNN——一个纯神经网络架构，实现了端到端的图分类。 基于谱卷积 Spectral networks and locally connected networks on graphs这篇文章最先提出谱图CNN模型，然后 Convolutional neural networks on graphs with fast localized spectral filtering这篇文章对其进行了拓展。 但是这两个模型复杂度较高，无法应用到大规模网络中。为了解决这个问题，将GCN和其他有效的机制相结合很有吸引力。比如最近将differentiable pooling和self-attention pooling引入到GCN中来从节点嵌入中获取图嵌入，在图分类任务中取得了很好地表现。 2.3.2.2 基于注意力 基于注意力的方法中具有代表性的一个模型是GAM——一个原生的RNN模型，它关注图中比较小但是信息量丰富的部分，避免了图中其余部分的噪声。注意力机制主要用来指导模型向信息更丰富的部分移动。 2.3.2.3 总结 许多图分类算法都是基于传统CNN模型的，比如NgramCNN和DGCNN，它们的本质还是通过传统的CNN来指导特征处理和转换。尽管这些模型取得了不错的效果，但是它们捕捉复杂结构的能力天生不足。为了更好地辨别网络中的复杂结构，最近提出的模型CapSGNN，利用CapsNet在图像处理领域的强大能力来进行图分类，取得了不错的效果。因此，如何从复杂结构空间学习到最具有判别力的信息是解决图分类问题的关键。 2.4 动态同构网络嵌入 现有的大部分网络嵌入工作都是针对静态网络的，忽略了网络的动态性。因此，正对动态网络的网络嵌入是一个开放性问题，它也逐渐得到了相关研究人员的关注。考虑网络在时间上的动态性，设计一个有效的动态网络嵌入算法是十分重要的。比较有代表性的工作有：DHPE、DynamicTriad和动态GCN，前两个不是基于深度学习的方法。 DHPE DHPE提出了一种动态网络嵌入方法，首次采用GSVD来保留高阶邻近度。然后研究人员提出了一种广义本征摄动方法来逐步更新GSVD的结果。这样，我们就将动态问题转换成了特征值更新问题。 DynamicTriad DynamicTriad通过对三元闭包过程进行建模来设计动态网络嵌入算法，它可以让我们的模型捕捉到网络的动态性 Dynamic GCN Dynamic GCN结合了长短期记忆网络和GCN来图结构之间的学习长短期依赖。改模型的效果已经被证明了其在基于顶点和基于图的半监督分类任务中的优越性。 总之，如何对网络动态特征和节点嵌入更新进行建模是解决动态网络嵌入问题的关键。随着深度学习的发展，基于神经网络的动态网络嵌入方法取得了很大的进展。 3. 异构网络嵌入 和同构网络相似，现实世界中广泛存在着大量异构网络，知识图谱就是一种典型的异构网络。以在线社交网络为例，它可能包含不同类型的跨模态节点（比如用户、图片、文本、视频等）和复杂的关系。因此，和同构网络嵌入相比，由于异构网络的异质性和高复杂性，异构网络嵌入是一个更具挑战性的问题。异构社交网络表示学习的架构如下图所示： 异构网络嵌入可以将网络中的不同的异构对象映射到统一的潜在空间，这样来自不同空间的对象就可以直接进行比较。下面主要从KG和HIIN两个方面介绍异构网络嵌入。 3.1 知识图谱嵌入 3.1.1 常用方法及数据集 代表性方法： 常用数据集： ### 3.1.2 基于Translation 基于translation的模型的核心是translation距离。早期，研究人员使用经验距离模型，比如SE。但是这种模型丢失了太多的信息，导致模型效果较差。后来，人们大多采用本文下面介绍的translation模型。 **一、方法** TransE TransE是第一个基于translation的模型，也是最具代表性的translational距离模型。它将实体和关系在同一个空间中表示成向量。TransE受skip-gram模型启发，认为词嵌入之间的不同点代表着它们的关系。对于一个三元组&lt;h,r,t&gt;&lt;h,r,t&gt;&lt;h,r,t&gt;，TransE将从实体h到实体t的转换看成它们之间的关系r。因此，(h+r)(h+r)(h+r)会和(t)(t)(t)很接近，最终的得分函数定义为：fr(h,t)=∣∣h+r−t∣∣22f_r(h,t)=||h+r-t||^2_2fr​(h,t)=∣∣h+r−t∣∣22​。需要注意的时TransE只适用于1-to-1的关系。 TransH TransH是为了解决1-to-N、N-to-1以及N−to−NN-to-NN−to−N问题的。TransH提出一种模型叫“translation on a hyperplane”。在不同关系的超平面上，一个实体会有不同的表示。TransH通过一个正则向量wrw_rwr​将实体嵌入hhh和ttt投影到一个具体关系的超平面上，h′=h−wrThwrh&#x27;=h-w_r^Thw_rh′=h−wrT​hwr​，t′=t−wrTtwrt&#x27;=t-w_r^Ttw_rt′=t−wrT​twr​。最终的目标函数定义为：fr(h,t)=∣∣(h−wrThwr)+r−(t−wrTtwr)∣∣22f_r(h,t)=||(h-w_r^Thw_r)+r-(t-w_r^Ttw_r)||_2^2fr​(h,t)=∣∣(h−wrT​hwr​)+r−(t−wrT​twr​)∣∣22​。 TransR TransE和TransH都是假设实体和关系在同一个向量空间，但是关系和实体都是不同类型的对象，它们不应该在同一个向量空间。TransR模型就是基于这一思想被提出的。TransR将TransE和TransH中的单个向量空间拓展到了多个向量空间。具体地，对于每一个关系rrr，通过映射矩阵MrM_rMr​将实体映射到关系向量空间，h′=Mrhh&#x27;=M_rhh′=Mr​h，t′=Mrtt&#x27;=M_rtt′=Mr​t。得分函数定义为：fr(h,t)=∣∣Mrh+r−Mrt∣∣22f_r(h,t)=||M_rh+r-M_rt||_2^2fr​(h,t)=∣∣Mr​h+r−Mr​t∣∣22​。 TransD TransR也有一些缺点：（1）对于关系r，所有的实体都共享同一个映射矩阵MrM_rMr​。但事实上，该关系链接的实体的类型和属性都不尽相同。（2）投影操作是实体和关系之间交互的过程，仅仅通过关系来确定关系映射矩阵是不合理的。（3）矩阵和向量的乘法操作计算开销大，当关系数量很多时，TransE和TransH的参数量巨大。 因此，为了提升TransR，一个更好的模型TransD被提出来了。对于每个实体和关系都定义了两个向量，一个表示实体或者关系的含义，另一个表示如何将实体投影到关系向量空间，用于构造投影矩阵。这样，每个emtity-relation对都有一个自己独特的映射矩阵。最终的得分函数定义为：fr(h,t)=∣∣Mrhh+r−Mrtt∣∣22f_r(h,t)=||M_{rh}h+r-M_{rt}t||_2^2fr​(h,t)=∣∣Mrh​h+r−Mrt​t∣∣22​。 TranSparse 尽管上面的模型效果已经很好了，但是知识图谱中的实体和关系是异构、不均衡的，因此还存在很多挑战。为了解决异构和不均衡的问题，研究人员提出了TransSparse模型。M(θ)M(\\theta)M(θ)表示矩阵MMM的sparse degree为θ\\thetaθ。TranSparse得分函数定义为：fr(h,t)=∣∣Mrh(θrh)h+r−Mrt(θrt)t∣∣l1/22f_r(h,t)=||M_r^h(\\theta_r^h)h+r-M_r^t(\\theta_r^t)t||_{l1/2}^2fr​(h,t)=∣∣Mrh​(θrh​)h+r−Mrt​(θrt​)t∣∣l1/22​。 TransA 为了解决优化函数对某些特定图的局限性，TransA更具知识图谱的结构，自适应性地找到了最优的损失函数，因此不需要事先封闭候选集。它不仅使得基于Translation的嵌入在实践中更容易处理，还提高了模型的表现。它的得分函数定义为：fr(h,t)=∣∣h+r−t∣∣f_r(h,t)=||h+r-t||fr​(h,t)=∣∣h+r−t∣∣。 MTransE 考虑到大多数知识图谱嵌入方法都是用于单语言知识图谱，相关研究人员提出了一种用于多语言知识图谱嵌入模型MTransE。通过在单独的嵌入空间中对每种语言的实体和关系进行编码，MTransE为每个嵌入向量提供了其在其他空间中跨语言版本对应的转换，同时保留了单语言嵌入的功能。其得分函数定义和TransA模型相同。 TorusE 最近，研究人员注意到TransE的正则问题。TorusE采用和TransE相同的原理，但是希望通过改变嵌入空间来解决正则化问题。首先考虑嵌入空间的要求。然后引入一个lie group作为候选空间。最后改模型无需进行任何正则化即可得到实体和关系的嵌入。它的得分函数定义为：min(x,y)∈([h]+[r])×[t]\\mathop{min}\\limits_{(x,y)\\in([h]+[r])\\times[t]}(x,y)∈([h]+[r])×[t]min​。 二、讨论 上面的大多数方法都是基于TransE的，直觉上，通过对最近算法进行改进可以进一步提高模型性能。 3.1.3 基于语义匹配 一、方法 RESCAL 用一个向量捕捉每个实体的潜在语义，用一个n-by-n的矩阵表示每个关系。它最终的得分函数定义为：fr(h,t)=hTMrtf_r(h,t)=h^TM_rtfr​(h,t)=hTMr​t。 NTN NTN基于RESCAL进行拓展，提出了一个标准线性神经网络和双线性张量结构。 DistMult DistMult通过将表示关系的矩阵严格限制为对角矩阵，简化了RESCAL。但是存在一个问题：(h,r,t)(h,r,t)(h,r,t)和(t,r,h)(t,r,h)(t,r,h)的得分相同。 ComplEx ComplEx为了解决DistMult的问题，使用复数代替原来的实数，在计算双线性映射前先求尾实体的共轭，从而扩展了双线性映射。 HOLE HOLE提供了一种全息嵌入方法，通过结合RESCAL中使用的张量积的表达能力和TransE的简单性，学习整个知识图谱的向量空间表示。 Analogy Analogy拓展了RESCAL模型来对类比属性进行建模，这对知识库的不全十分有用。例如，如果系统A类似于系统B，则可以通过镜像A中的对象来推断B中未观察到的三元组。它采用和RESCAL相同的得分函数，并添加了对矩阵MrM_rMr​的约束。 二、讨论 双线性模型比基于Translation的模型具有更多地冗余，因此很容易过拟合。 3.1.4 基于信息混合 一、方法 DKRL 为了吸收更多地信息来提高模型表现，DKRL提出了基于描述的实体表示。它通过CBOW或者CNN，从实体描述中构建实体的表示。 TKRL 层次实体类型中也蕴含大量对知识图谱有用的信息，TKRL是第一个借助层次结构，显示的将类型信息编码为多种表示形式的方法。 二、讨论 如已在DKRL和TKRL中反映的那样，多种信息（如文本信息和类型信息）被视为嵌入三元组的结构化信息的补充，对于知识图谱的表示学习意义重大。也就是，包含更多信息的模型将更接近实际问题，可以极大的推动相关实际应用的发展。 3.1.5 基于GNN和GCN 图神经网络包括GCN和GAT已经证明了对图数据的强大建模能力，知识图谱也是其应用场景之一。 一、方法 R-GCNs R-GCNs将GCN拓展应用到了知识图谱中，模型对每个实体的邻居进行卷积操作，并赋予它们一个权重。 基于GAT Nathani等人在“ (2019) Learningattention-based embeddings for relation prediction in knowledgegraphs ”一文中提出了一种基于图注意力的特征嵌入方法，给定一个实体，可以在其多条邻居中同时捕捉实体和关系特征。 ConvE 除了GNN外，研究人员也尝试着用多层CNN网络来学习深度特征表示，典型的工作就是ConvE。改模型在embedding上使用2D卷积，并且使用多个非线性特征层来对知识图谱进行建模。 二、讨论 近些年来随着深度学习的发展，尤其是GNN和CNN，讲这些先进方法应用到知识图谱领域逐渐变得流行起来。 3.1.6 其他 除了上述方法，ManifoldE将基于manifold的原理M(h,r,t)=Dr2M(h,r,t)=D_r^2M(h,r,t)=Dr2​应用到一个三元组&lt;h,t,t&gt;&lt;h,t,t&gt;&lt;h,t,t&gt;上。在给定头实体和关系的时候，将尾实体置于高维流形中。直觉上，改模型的得分函数应该是三元组和流行之间的距离：fr(h,t)=∣∣∣∣h+r−t∣∣22−Dr2∣∣2f_r(h,t)=\\big|\\big|||h+r-t||_2^2-D_r^2\\big|\\big|^2fr​(h,t)=∣∣∣​∣∣∣​∣∣h+r−t∣∣22​−Dr2​∣∣∣​∣∣∣​2，其中DrD_rDr​是关系rrr的流形参数。 3.2 异构信息网络嵌入 3.2.1 基于优化 一、方法 这里比较有代表性的方法有：LSHM、PTE和Hebe。 LSHM LSHM是一个潜在空间异构模型，是这类方法的初始工作之一。改模型假设网络中相连的两个检点倾向于共享一些相似的表示，尽管它们的类型可能不同。通过结合分类和回归损失来学习节点的潜在表示。不同类型节点的标签通过它们的表示计算得到。 PTE PTE同时利用有标签和无标签数据来学习异构文本网络中的文本嵌入。首先将标签信息和不同几倍的单词贡献信息表示成大规模异构文本网络。然后，异构文本网络可以有三个双向网络组成：单词-单词，单词-文档以及单词-标签网络。为了学习到异构文本网络的嵌入，一个直觉上的方法就是通过最小化三个网络中的节点对之间的条件概率来同时嵌入这三个双向网络。 Hebe Hebe捕捉了整个异构信息网络中的多个交互。形成了一致且语义完整的单元的一组对象称之为超边，并将其视为一个事件。因此，这种方法保留了更多地网络中的语义信息。研究人员基于超边提出了两种模型：HEBE-PO和HEBE-PE。前者对同一超边中参与对象自身之间的邻近度进行建模，后者对超边与参与对象之间的邻近度进行建模。 二、讨论 上述模型对异构网络的建模能力有限，导致丢失了很多信息，比如节点类型信息。由于异构网络的复杂性，设计更准确的目标函数是实现这类方法的关键。 3.2.2 基于深度学习 和同构网络嵌入相似，深度学习模型也可以用于异构网络表示学习中，可以捕捉异构网络组件间的复交互。这些方法大体上可以分为两类：基于传统神经网络和基于CNN。 3.2.2.1 基于传统神经网络 传统的神经网络包括CNN、自编码器等等，在图像处理、cv以及其他很多领域取得了很好地效果。但是，考虑到异构网络中通常包含多种类型的信息和复杂的结构，让传统神经网络在这种类型数据上表现良好很具有挑战性。HNE和DHNE是两种比较具有代表性的方法。 HNE HNE通过深度架构共同建模异构网络中的内容和拓扑结构。改模型将特征学习过程分解成多个非线性层构成的深度结构，包括图像-图像，图像-文本以及文本-文本三个模块。HNE利用CNN网络学习图像特征，用全连接层提取具有判别李的文本表示。最后，它将异构网络中的不同对象转换成统一的向量表示。 DHNE 尽管HNE已经取得了很好地效果，但是它忽略了异构网络中普遍存在不可分解的超边的问题。因此DHNE提出通过深度模型将对含有超边的hypernetwork进行嵌入。DHNE从理论上证明了现有方法中常用的嵌入空间中的任何线性相似度量都无法维持超网络中不可分解性。DHNE通过设计一个带有自编码器的新的深层模型来实现非线性元组的相似性函数，同时在形成的嵌入空间中保留局部和全局的邻近度。 3.2.2.2 基于GNN 受GNN在同构网络中成功应用的影响，GNN逐渐也被用于异构网络，具有代表性的方法有HetGNN和HAN。 HetGNN HetGNN有效地同时考虑了网络的结构信息和节点内容信息。首先，改模型通过RWR为每个节点采样固定大小的邻居，并基于节点类型对它们进行分组。然后，改模型设计了一个包含两个模块的神经网络架构来聚合采样到的邻居节点的信息。最后，改模型利用一个graph context loss和mini-batch梯度下降来端到端的训练模型。 HAN HetGNN没有考虑到异构网络中的重要信息，因此HAN基于层级注意力提出了一种异构图神经网络，包含节点级和语义级注意力。具体来说，节点级注意力旨在了解节点和其基于元路径的邻居之间的重要性，而语义级的注意力则用来学习不同原路径的重要性。 3.2.2.3 讨论 和同构网络相比，异构网络中基于深度学习的算法比较少，因为在异构网络中学习网络表示更具有挑战性。除了深度学习外，broad learning已经被引入到网络嵌入中来了，基于broad learning来做网络嵌入具有很大潜力。 3.2.3 基于元路径 一、方法 该类型具有代表性的算法主要有：Metapath2vec、metapath2vec和HIN2Vec两种。 Metapath2vec和metapath2vec++ 前者同时保留了异构图中的结构和语义之间的关联性。该模型设计了一个基于元路径的随机游走，用于为各种类型的节点生成具有网络语义的异构领域，构建了执行节点嵌入的异构skip-gram模型。后者探索了将元路径应用于异构网络中的表示学习。 HIN2Vec 和Metapath2vec不同，HIN2Vec还学习元路径的表示。具体来说，改模型首先采用随机游走和负采样来准备训练数据。然后，训练一个逻辑二元分类器来预测两个输入节点是否有某种特定关系，来有效学习节点向量和元路径向量。 二、讨论 虽然基于元路径的方法取得了不错的效果，但是仅仅通过元路径来获取异构网络中的信息是不够的。因此，设计一个更好的语义信息采样策略可以显著提高异构网络嵌入算法的性能。最近提出的MetaGraph2vec和HERec对这个方向进行了一些探索并成功应用于节点分类和推荐任务中。 3.2.4 其他 ASPEM ASPEM分别单独封装了每个角度的信息，而不是在一个语义空间中保留网络信息。模型提出了角度选择方法，证明了可以使用网络统计信息从任何异构信息网络中选择一组具有代表新的角度，而无需额外的监督。为了给某个角度设计算法，作者拓展了skip-gram模型。因此对于节点u的嵌入，最终是通过涉及到u的所有角度学习到的向量联合得到的。 Tree2Vector 树形数据可以看作成一个特殊的异构网络。例如一个表示作者的树状数据可以由作者信息节点、写的书节点以及书的评论节点构成。在这种情况下，研究人员设计了有效的方法将树状结构的数据转换成向量表示。Tree2Vector是一个具有代表性的工作，它主要通过使用无监督聚类技术通过节点分配过程以及局部敏感的重建方法对重建过程进行建模来实现的。但是，这是一个无监督模型，无法直接应用的监督学习中。因此为树状数据设计一个端到端的有监督学习模型是另一个值得探讨的问题。 4. 网络嵌入的应用 节点分类、节点聚类、链路预测、可视化、推荐、图分类、知识图谱中的应用以及其他一些场景(图像分类、强化学习、跨模态检索等等) 5. 总结及未来方向 虽然面向网络数据的表示学习已经取得了很大的进展，但是在未来工作中任然面临着巨大的挑战。下面主要从两个理论和应用两个方面来介绍未来可能的研究方向。 5.1 算法和理论 当前几乎所有网络嵌入算法都嘉定网络数据被嵌入到欧几里得空间中，在非欧空间中设计网络嵌入算法仍然是一个充满挑战和希望的研究方向。 现实中的大部分网络无疑都是动态、异构的，设计一个有效的动态、异构网络嵌入算法将是下一个研究话题。 现有的基于深度学习的算法仍存在一些问题：比如大数据集上的不稳定性、复杂的训练、鲁棒性较差等等，因此这些方法仍有巨大发展空间。 如何直接测量数据表示的质量是长期存在于表示学习领域的一个问题。提出或者设计用于表示学习的新评估或度量方法是一个紧迫的问题。另外，当前图嵌入算法缺乏解释性，从直觉上看，模型的解释性和数据表示的度量方法可能会相互促进者发展。 当前深度学习无法完成因果推理任务，设计有效的图神经网络以支持组合泛化和关系推理是一个非常有希望的方向。 5.2 应用 考虑到网络数据的普遍性，许多跨学科问题都可以抽象成图挖掘和分析问题。尽管已经有了一些成功的应用，例如蛋白质网络、脑网络、分子网络、药物发现等等，但是网络嵌入算法仍具有广阔的应用前景。","categories":[{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"表示学习","slug":"表示学习","permalink":"http://rookieyin.github.io/tags/%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"}]},{"title":"SpringBoot常用注解总结","slug":"2 后端/SpringBoot/SpringBoot常用注解总结","date":"2021-03-23T14:34:49.000Z","updated":"2022-06-12T14:07:23.937Z","comments":true,"path":"18a7f78f6409/","link":"","permalink":"http://rookieyin.github.io/18a7f78f6409/","excerpt":"文章主要搬运自这里","text":"文章主要搬运自这里 @SpringBootApplication 这里先单独拎出@SpringBootApplication 注解说一下，虽然我们一般不会主动去使用它。这个注解是 Spring Boot 项目的基石，创建 SpringBoot 项目之后会默认在主类加上。 123456@SpringBootApplicationpublic class SpringSecurityJwtGuideApplication &#123; public static void main(java.lang.String[] args) &#123; SpringApplication.run(SpringSecurityJwtGuideApplication.class, args); &#125;&#125; 我们可以把 @SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。 12345678910111213141516171819202122package org.springframework.boot.autoconfigure;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; ......&#125;package org.springframework.boot;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; 根据 SpringBoot 官网，这三个注解的作用分别是： @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @ComponentScan：扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描该类所在的包下所有的类。 @Configuration：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类 Spring Bean相关 @Autowired 自动导入对象到类中，被注入进的类同样要被 Spring 容器管理比如：Service 类注入到 Controller 类中。 123456789101112@Servicepublic class UserService &#123; ......&#125;@RestController@RequestMapping(&quot;/users&quot;)public class UserController &#123; @Autowired private UserService userService; ......&#125; @Component,@Repository,@Service, @Controller 我们一般使用 @Autowired 注解让 Spring 容器帮我们自动装配 bean。要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,可以采用以下注解实现： @Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。 @RestController @RestController注解是@Controller和@ResponseBody的合集,表示这是个控制器 bean,并且是将函数的返回值直 接填入 HTTP 响应体中,是 REST 风格的控制器。 单独使用 @Controller 不加 @ResponseBody的话一般使用在要返回一个视图的情况，这种情况属于比较传统的 Spring MVC 的应用，对应于前后端不分离的情况。@Controller +@ResponseBody 返回 JSON 或 XML 形式数据 @Scope 声明 Spring Bean 的作用域，使用方法: 12345@Bean@Scope(&quot;singleton&quot;)public Person personSingleton() &#123; return new Person();&#125; 四种常见的 Spring Bean 的作用域： singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 @Configuration 一般用来声明配置类，可以使用 @Component注解替代，不过使用Configuration注解声明配置类更加语义化。 12345678@Configurationpublic class AppConfig &#123; @Bean public TransferService transferService() &#123; return new TransferServiceImpl(); &#125;&#125; 处理HTTP请求 常见的HTTP请求，包含下面5种： GET ：请求从服务器获取特定资源。举个例子：GET /users（获取所有学生） POST ：在服务器上创建一个新的资源。举个例子：POST /users（创建学生） PUT ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：PUT /users/12（更新编号为 12 的学生） DELETE ：从服务器删除特定的资源。举个例子：DELETE /users/12（删除编号为 12 的学生） PATCH ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少，这里就不举例子了。 GET请求 @GetMapping(“users”) 等价于@RequestMapping(value=&quot;/users&quot;,method=RequestMethod.GET) 1234@GetMapping(&quot;/users&quot;)public ResponseEntity&lt;List&lt;User&gt;&gt; getAllUsers() &#123; return userRepository.findAll();&#125; POST请求 @PostMapping(“users”) 等价于@RequestMapping(value=&quot;/users&quot;,method=RequestMethod.POST) 关于@RequestBody注解的使用，在下面的“前后端传值”这块会讲到。 1234@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;User&gt; createUser(@Valid @RequestBody UserCreateRequest userCreateRequest) &#123; return userRespository.save(user);&#125; PUT请求 @PutMapping(&quot;/users/{userId}&quot;) 等价于@RequestMapping(value=&quot;/users/{userId}&quot;,method=RequestMethod.PUT) 12345@PutMapping(&quot;/users/&#123;userId&#125;&quot;)public ResponseEntity&lt;User&gt; updateUser(@PathVariable(value = &quot;userId&quot;) Long userId, @Valid @RequestBody UserUpdateRequest userUpdateRequest) &#123; ......&#125; DELETE请求 @DeleteMapping(&quot;/users/{userId}&quot;)等价于@RequestMapping(value=&quot;/users/{userId}&quot;,method=RequestMethod.DELETE) 12345@DeleteMapping(&quot;/users/&#123;userId&#125;&quot;)public ResponseEntity deleteUser(@PathVariable(value = &quot;userId&quot;) Long userId)&#123; ......&#125; PATCH请求 一般实际项目中，我们都是 PUT 不够用了之后才用 PATCH 请求去更新数据。 123456@PatchMapping(&quot;/profile&quot;)public ResponseEntity updateStudent(@RequestBody StudentUpdateRequest studentUpdateRequest) &#123; studentRepository.updateDetail(studentUpdateRequest); return ResponseEntity.ok().build();&#125; 前后端传值 @PathVariable和@RequestParam @PathVariable用于获取路径参数，@RequestParam用于获取查询参数。 举个简单的例子： 1234567@GetMapping(&quot;/klasses/&#123;klassId&#125;/teachers&quot;)public List&lt;Teacher&gt; getKlassRelatedTeachers( @PathVariable(&quot;klassId&quot;) Long klassId, @RequestParam(value = &quot;type&quot;, required = false) String type ) &#123;...&#125; 如果我们请求的 url 是：/klasses/{123456}/teachers?type=web。 那么我们服务获取到的数据就是：klassId=123456,type=web。 @RequestBody 用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且Content-Type 为 application/json 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。系统会使用HttpMessageConverter或者自定义的HttpMessageConverter将请求的 body 中的 json 字符串转换为 java 对象。 我用一个简单的例子来给演示一下基本使用！ 我们有一个注册的接口： 123456@PostMapping(&quot;/sign-up&quot;)public ResponseEntity signUp(@RequestBody @Valid UserRegisterRequest userRegisterRequest) &#123; userService.save(userRegisterRequest); return ResponseEntity.ok().build();&#125; UserRegisterRequest对象： 12345678910111213@Data@AllArgsConstructor@NoArgsConstructorpublic class UserRegisterRequest &#123; @NotBlank private String userName; @NotBlank private String password; @FullName @NotBlank private String fullName;&#125; 我们发送 post 请求到这个接口，并且 body 携带 JSON 数据： 12&#123;&quot;userName&quot;:&quot;coder&quot;,&quot;fullName&quot;:&quot;shuangkou&quot;,&quot;password&quot;:&quot;123456&quot;&#125; 这样我们的后端就可以直接把 json 格式的数据映射到我们的 UserRegisterRequest 类上。 需要注意的是：一个请求方法只可以有一个@RequestBody，但是可以有多个@RequestParam和@PathVariable。如果你的方法必须要用两个 @RequestBody来接受数据的话，大概率是你的数据库设计或者系统设计出问题了！ 读取配置信息 很多时候我们需要将一些常用的配置信息比如阿里云 oss、发送短信、微信认证的相关配置信息等等放到配置文件中。 下面我们来看一下 Spring 为我们提供了哪些方式帮助我们从配置文件中读取这些配置信息。 我们的数据源application.yml内容如下： 123456789101112wuhan2020: 2020年初武汉爆发了新型冠状病毒，疫情严重，但是，我相信一切都会过去！武汉加油！中国加油！library: location: 湖北武汉加油中国加油 books: - name: 天才基本法 description: 二十二岁的林朝夕在父亲确诊阿尔茨海默病这天，得知自己暗恋多年的校园男神裴之即将出国深造的消息——对方考取的学校，恰是父亲当年为她放弃的那所。 - name: 时间的秩序 description: 为什么我们记得过去，而非未来？时间“流逝”意味着什么？是我们存在于时间之内，还是时间存在于我们之中？卡洛·罗韦利用诗意的文字，邀请我们思考这一亘古难题——时间的本质。 - name: 了不起的我 description: 如何养成一个新习惯？如何让心智变得更成熟？如何拥有高质量的关系？ 如何走出人生的艰难时刻？ @Value 使用 @Value(&quot;${property}&quot;) 读取比较简单的配置信息： 123@Value(&quot;$&#123;wuhan2020&#125;&quot;)String wuhan2020; @ConfigurationProperties 通过@ConfigurationProperties读取配置信息并与 bean 绑定： 123456789101112131415161718@Component@ConfigurationProperties(prefix = &quot;library&quot;)class LibraryProperties &#123; @NotEmpty private String location; private List&lt;Book&gt; books; @Setter @Getter @ToString static class Book &#123; String name; String description; &#125; 省略getter/setter ......&#125; @PropertySource @PropertySource读取指定 properties 文件 1234567891011@Component@PropertySource(&quot;classpath:website.properties&quot;)class WebSite &#123; @Value(&quot;$&#123;url&#125;&quot;) private String url; 省略getter/setter ......&#125; 参数校验 数据的校验的重要性就不用说了，即使在前端对数据进行校验的情况下，我们还是要对传入后端的数据再进行一遍校验，避免用户绕过浏览器直接通过一些 HTTP 工具直接向后端请求一些违法数据。 JSR(Java Specification Requests） 是一套 JavaBean 参数校验的标准，它定义了很多常用的校验注解，我们可以直接将这些注解加在我们 JavaBean 的属性上面，这样就可以在需要校验的时候进行校验了，非常方便！ 校验的时候我们实际用的是 Hibernate Validator 框架。Hibernate Validator 是 Hibernate 团队最初的数据校验框架，Hibernate Validator 4.x 是 Bean Validation 1.0（JSR 303）的参考实现，Hibernate Validator 5.x 是 Bean Validation 1.1（JSR 349）的参考实现，目前最新版的 Hibernate Validator 6.x 是 Bean Validation 2.0（JSR 380）的参考实现。 SpringBoot 项目的 spring-boot-starter-web 依赖中已经有 hibernate-validator 包，不需要引用相关依赖。 需要注意的是：所有的注解，推荐使用 JSR 注解，即javax.validation.constraints，而不是org.hibernate.validator.constraints。 一些常用的字段验证注解 @NotEmpty 被注释的字符串的不能为 null 也不能为空 @NotBlank 被注释的字符串非 null，并且必须包含一个非空白字符 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Pattern(regex=,flag=)被注释的元素必须符合指定的正则表达式 @Email 被注释的元素必须是 Email 格式。 @Min(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value)被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=)被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction)被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 验证请求体（RequestBody） 12345678910111213141516171819202122@Data@AllArgsConstructor@NoArgsConstructorpublic class Person &#123; @NotNull(message = &quot;classId 不能为空&quot;) private String classId; @Size(max = 33) @NotNull(message = &quot;name 不能为空&quot;) private String name; @Pattern(regexp = &quot;((^Man$|^Woman$|^UGM$))&quot;, message = &quot;sex 值不在可选范围&quot;) @NotNull(message = &quot;sex 不能为空&quot;) private String sex; @Email(message = &quot;email 格式不正确&quot;) @NotNull(message = &quot;email 不能为空&quot;) private String email;&#125; 我们在需要验证的参数上加上了@Valid注解，如果验证失败，它将抛出MethodArgumentNotValidException。 12345678910@RestController@RequestMapping(&quot;/api&quot;)public class PersonController &#123; @PostMapping(&quot;/person&quot;) public ResponseEntity&lt;Person&gt; getPerson(@RequestBody @Valid Person person) &#123; return ResponseEntity.ok().body(person); &#125;&#125; 验证请求参数(Path Variables 和 Request Parameters) 一定一定不要忘记在类上加上 Validated 注解了，这个参数可以告诉 Spring 去校验方法参数。 1234567891011@RestController@RequestMapping(&quot;/api&quot;)@Validatedpublic class PersonController &#123; @GetMapping(&quot;/person/&#123;id&#125;&quot;) public ResponseEntity&lt;Integer&gt; getPersonByID(@Valid @PathVariable(&quot;id&quot;) @Max(value = 5,message = &quot;超过 id 的范围了&quot;) Integer id) &#123; return ResponseEntity.ok().body(id); &#125;&#125; 全局处理Controller异常 常用的注解有两个： @ControllerAdvice :注解定义全局异常处理类 @ExceptionHandler :注解声明异常处理方法 如何使用呢？拿我们在第 5 节参数校验这块来举例子。如果方法参数不对的话就会抛出MethodArgumentNotValidException，我们来处理这个异常。 12345678910111213@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler &#123; /** * 请求参数异常处理 */ @ExceptionHandler(MethodArgumentNotValidException.class) public ResponseEntity&lt;?&gt; handleMethodArgumentNotValidException(MethodArgumentNotValidException ex, HttpServletRequest request) &#123; ...... &#125;&#125; JPA相关 创建表 @Entity声明一个类对应一个数据库实体。 @Table 设置表明 1234567891011@Entity@Table(name = &quot;role&quot;)public class Role &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private String description; 省略getter/setter......&#125; 创建主键 @Id ：声明一个字段为主键。 使用@Id声明之后，我们还需要定义主键的生成策略。我们可以使用 @GeneratedValue 指定主键生成策略。 通过 @GeneratedValue直接使用 JPA 内置提供的四种主键生成策略来指定主键生成策略。 1234@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id; JPA 使用枚举定义了 4 中常见的主键生成策略，如下： 12345678910111213141516171819202122232425public enum GenerationType &#123; /** * 使用一个特定的数据库表格来保存主键 * 持久化引擎通过关系数据库的一张特定的表格来生成主键, */ TABLE, /** *在某些数据库中,不支持主键自增长,比如Oracle、PostgreSQL其提供了一种叫做&quot;序列(sequence)&quot;的机制生成主键 */ SEQUENCE, /** * 主键自增长 */ IDENTITY, /** *把主键生成策略交给持久化引擎(persistence engine), *持久化引擎会根据数据库在以上三种主键生成 策略中选择其中一种 */ AUTO&#125; @GeneratedValue注解默认使用的策略是GenerationType.AUTO 123456public @interface GeneratedValue &#123; GenerationType strategy() default AUTO; String generator() default &quot;&quot;;&#125; 一般使用 MySQL 数据库的话，使用GenerationType.IDENTITY策略比较普遍一点（分布式系统的话需要另外考虑使用分布式 ID）。 通过 @GenericGenerator声明一个主键策略，然后 @GeneratedValue使用这个策略 12345@Id@GeneratedValue(generator = &quot;IdentityIdGenerator&quot;)@GenericGenerator(name = &quot;IdentityIdGenerator&quot;, strategy = &quot;identity&quot;)private Long id; 等价于： 1234@Id@GeneratedValue(strategy = GenerationType.IDENTITY)private Long id; jpa 提供的主键生成策略有如下几种： 12345678910111213141516171819202122232425262728293031public class DefaultIdentifierGeneratorFactory implements MutableIdentifierGeneratorFactory, Serializable, ServiceRegistryAwareService &#123; @SuppressWarnings(&quot;deprecation&quot;) public DefaultIdentifierGeneratorFactory() &#123; register( &quot;uuid2&quot;, UUIDGenerator.class ); register( &quot;guid&quot;, GUIDGenerator.class ); // can be done with UUIDGenerator + strategy register( &quot;uuid&quot;, UUIDHexGenerator.class ); // &quot;deprecated&quot; for new use register( &quot;uuid.hex&quot;, UUIDHexGenerator.class ); // uuid.hex is deprecated register( &quot;assigned&quot;, Assigned.class ); register( &quot;identity&quot;, IdentityGenerator.class ); register( &quot;select&quot;, SelectGenerator.class ); register( &quot;sequence&quot;, SequenceStyleGenerator.class ); register( &quot;seqhilo&quot;, SequenceHiLoGenerator.class ); register( &quot;increment&quot;, IncrementGenerator.class ); register( &quot;foreign&quot;, ForeignGenerator.class ); register( &quot;sequence-identity&quot;, SequenceIdentityGenerator.class ); register( &quot;enhanced-sequence&quot;, SequenceStyleGenerator.class ); register( &quot;enhanced-table&quot;, TableGenerator.class ); &#125; public void register(String strategy, Class generatorClass) &#123; LOG.debugf( &quot;Registering IdentifierGenerator strategy [%s] -&gt; [%s]&quot;, strategy, generatorClass.getName() ); final Class previous = generatorStrategyToClassNameMap.put( strategy, generatorClass ); if ( previous != null ) &#123; LOG.debugf( &quot; - overriding [%s]&quot;, previous.getName() ); &#125; &#125;&#125; 设置字段类型 @Column 声明字段。 示例： 设置属性 userName 对应的数据库字段名为 user_name，长度为 32，非空 123@Column(name = &quot;user_name&quot;, nullable = false, length=32)private String userName; 设置字段类型并且加默认值，这个还是挺常用的。 123Column(columnDefinition = &quot;tinyint(1) default 1&quot;)private Boolean enabled; 指定不持久化特定字段 @Transient ：声明不需要与数据库映射的字段，在保存的时候不需要保存进数据库 。 如果我们想让secrect 这个字段不被持久化，可以使用 @Transient关键字声明。 123456789Entity(name=&quot;USER&quot;)public class User &#123; ...... @Transient private String secrect; // not persistent because of @Transient&#125; 除了 @Transient关键字声明， 还可以采用下面几种方法： 1234static String secrect; // not persistent because of staticfinal String secrect = “Satish”; // not persistent because of finaltransient String secrect; // not persistent because of transient 声明大字段 @Lob:声明某个字段为大字段。 123@Lobprivate String content; 更详细的声明： 1234567@Lob//指定 Lob 类型数据的获取策略， FetchType.EAGER 表示非延迟 加载，而 FetchType. LAZY 表示延迟加载 ；@Basic(fetch = FetchType.EAGER)//columnDefinition 属性指定数据表对应的 Lob 字段类型@Column(name = &quot;content&quot;, columnDefinition = &quot;LONGTEXT NOT NULL&quot;)private String content; 创建枚举类型的字段 可以使用枚举类型的字段，不过枚举字段要用@Enumerated注解修饰。 12345678910public enum Gender &#123; MALE(&quot;男性&quot;), FEMALE(&quot;女性&quot;); private String value; Gender(String str)&#123; value=str; &#125;&#125; 12345678910111213@Entity@Table(name = &quot;role&quot;)public class Role &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String name; private String description; @Enumerated(EnumType.STRING) private Gender gender; 省略getter/setter......&#125; 数据库里面对应存储的是 MAIL/FEMAIL。 增加审计功能 只要继承了 AbstractAuditBase的类都会默认加上下面四个字段。 1234567891011121314151617181920212223242526@Data@AllArgsConstructor@NoArgsConstructor@MappedSuperclass@EntityListeners(value = AuditingEntityListener.class)public abstract class AbstractAuditBase &#123; @CreatedDate @Column(updatable = false) @JsonIgnore private Instant createdAt; @LastModifiedDate @JsonIgnore private Instant updatedAt; @CreatedBy @Column(updatable = false) @JsonIgnore private String createdBy; @LastModifiedBy @JsonIgnore private String updatedBy;&#125; 我们对应的审计功能对应地配置类可能是下面这样的（Spring Security 项目）: 123456789101112@Configuration@EnableJpaAuditingpublic class AuditSecurityConfiguration &#123; @Bean AuditorAware&lt;String&gt; auditorAware() &#123; return () -&gt; Optional.ofNullable(SecurityContextHolder.getContext()) .map(SecurityContext::getAuthentication) .filter(Authentication::isAuthenticated) .map(Authentication::getName); &#125;&#125; 删除/修改数据 @Modifying 注解提示 JPA 该操作是修改操作,注意还要配合@Transactional注解使用。 12345678@Repositorypublic interface UserRepository extends JpaRepository&lt;User, Integer&gt; &#123; @Modifying @Transactional(rollbackFor = Exception.class) void deleteByUserName(String userName);&#125; 关联关系 @OneToOne 声明一对一关系 @OneToMany 声明一对多关系 @ManyToOne声明多对一关系 @MangToMang声明多对多关系 事务@Transactional 在要开启事务的方法上使用@Transactional注解即可! 12345@Transactional(rollbackFor = Exception.class)public void save() &#123; ......&#125; 我们知道 Exception 分为运行时异常 RuntimeException 和非运行时异常。在@Transactional注解中如果不配置rollbackFor属性,那么事物只会在遇到RuntimeException的时候才会回滚,加上rollbackFor=Exception.class,可以让事物在遇到非运行时异常时也回滚。@Transactional 注解一般用在可以作用在类或者方法上： 作用于类：当把@Transactional 注解放在类上时，表示所有该类的public 方法都配置相同的事务属性信息。 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。 JSON数据处理 过滤JSON数据 @JsonIgnoreProperties 作用在类上用于过滤掉特定字段不返回或者不解析。 1234567891011//生成json时将userRoles属性过滤@JsonIgnoreProperties(&#123;&quot;userRoles&quot;&#125;)public class User &#123; private String userName; private String fullName; private String password; @JsonIgnore private List&lt;UserRole&gt; userRoles = new ArrayList&lt;&gt;();&#125; @JsonIgnore一般用于类的属性上，作用和上面的@JsonIgnoreProperties 一样。 12345678910public class User &#123; private String userName; private String fullName; private String password; //生成json时将userRoles属性过滤 @JsonIgnore private List&lt;UserRole&gt; userRoles = new ArrayList&lt;&gt;();&#125; 格式化JSON数据 @JsonFormat一般用来格式化 json 数据。 123@JsonFormat(shape=JsonFormat.Shape.STRING, pattern=&quot;yyyy-MM-dd&#x27;T&#x27;HH:mm:ss.SSS&#x27;Z&#x27;&quot;, timezone=&quot;GMT&quot;)private Date date; 扁平化对象 12345678910111213141516171819202122232425@Getter@Setter@ToStringpublic class Account &#123; @JsonUnwrapped private Location location; @JsonUnwrapped private PersonInfo personInfo; @Getter @Setter @ToString public static class Location &#123; private String provinceName; private String countyName; &#125; @Getter @Setter @ToString public static class PersonInfo &#123; private String userName; private String fullName; &#125;&#125; 未扁平化之前： 1234567891011&#123; &quot;location&quot;: &#123; &quot;provinceName&quot;:&quot;湖北&quot;, &quot;countyName&quot;:&quot;武汉&quot; &#125;, &quot;personInfo&quot;: &#123; &quot;userName&quot;: &quot;coder1234&quot;, &quot;fullName&quot;: &quot;shaungkou&quot; &#125;&#125; 使用@JsonUnwrapped 扁平对象之后： 1234567&#123; &quot;provinceName&quot;:&quot;湖北&quot;, &quot;countyName&quot;:&quot;武汉&quot;, &quot;userName&quot;: &quot;coder1234&quot;, &quot;fullName&quot;: &quot;shaungkou&quot;&#125; 测试相关 @ActiveProfiles一般作用于测试类上， 用于声明生效的 Spring 配置文件。 1234567@SpringBootTest(webEnvironment = RANDOM_PORT)@ActiveProfiles(&quot;test&quot;)@Slf4jpublic abstract class TestBase &#123; ......&#125; @Test声明一个方法为测试方法 @Transactional被声明的测试方法的数据会回滚，避免污染测试数据。 @WithMockUser Spring Security 提供的，用来模拟一个真实用户，并且可以赋予权限。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"SpringBoot","slug":"后端/SpringBoot","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/SpringBoot/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://rookieyin.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot自动配置原理","slug":"2 后端/SpringBoot/SpringBoot自动配置原理","date":"2021-03-22T14:34:49.000Z","updated":"2022-06-12T14:08:32.453Z","comments":true,"path":"b3fc5b6d6095/","link":"","permalink":"http://rookieyin.github.io/b3fc5b6d6095/","excerpt":"我们知道SpringBoot是Spring的一种便携式使用方式，可以达到开箱即用的效果，避免了原生Spring中那些繁杂的配置工作。那么SpringBoot是如何实现自动配置功能的呢？ 这还要从启动类注解@SpringBootApplication说起。 我们知道@SpringBootApplication是一个组合注解，主要由三个注解组成： SpringBootConfiguration注解 表示这是SpringBoot的配置类 @ComponentScan 开启组件扫描 @EnableAutoConfiguration这个注解的作用就是让SpringBoot开启自动配置","text":"我们知道SpringBoot是Spring的一种便携式使用方式，可以达到开箱即用的效果，避免了原生Spring中那些繁杂的配置工作。那么SpringBoot是如何实现自动配置功能的呢？ 这还要从启动类注解@SpringBootApplication说起。 我们知道@SpringBootApplication是一个组合注解，主要由三个注解组成： SpringBootConfiguration注解 表示这是SpringBoot的配置类 @ComponentScan 开启组件扫描 @EnableAutoConfiguration这个注解的作用就是让SpringBoot开启自动配置 @EnableAutoConfiguration @EnableAutoConfiguration定义在 org.springframework.boot:spring-boot-autoconfigure:xxxx 包中，其源码如下： 12345678910111213@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 如上我们可以看到EnableAutoConfiguration注解上有两个注解 @AutoConfigurationPackage 注解，从字面意思上来看就是自动配置包。点进去可以看到就是⼀个 @Import 注解： @Import(AutoConfigurationPackages.Registrar.class) ，导⼊了⼀个Registrar 的组件，这个注解的作用就是将主配置类（@SpringBootConfiguration标注的类）所在的包及其下面所有子包里面所有的组件扫描到IOC容器中。所以说，默认情况下主配置类所在包及其子包以外的组件，Spring IOC容器是扫描不到的。 @Import(AutoConfigurationImportSelector.class)通过@Import导入AutoConfigurationImportSelector类，而这个类的selectImports方法会通过SpringFactoriesLoader得到大量的配置类。而每个配置类则根据条件化配置类做出决策，以实现自动配置的功能。下面就让我们来看看selectImports方法。 AutoConfigurationImportSelector的selectImports方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; ... ... //这一行是核心 AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(annotationMetadata); ... ...&#125;protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; ... ... //这一行获取spring.factories中所有对象 List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); ... ...&#125;protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; //调用loadFactoryNames List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); ... ...&#125;public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());&#125;private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; ... ... try &#123; //FACTORIES_RESOURCE_LOCATION的值是META-INF/spring.factories Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryTypeName, factoryImplementationName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; ... ...&#125; 简单梳理一下思路： FACTORIES_RESOURCE_LOCATION的值是META-INF/spring.factories Spring启动的时候会扫描所有jar路径下的META-INF/spring.factories，将其文件包装成Properties对象 从Properties对象获取到key值为EnableAutoConfiguration的数据，然后添加到容器里边。 @ConditionOnXXX注解 打开org.springframework.boot:spring-boot-autoconfigure:xxxx jar包，META-INF目录下的spring.factories文件，我们发现其中定义了多大130个配置类。 难道SpringBoot在启动的时候都要将这些类里的@Bean实例化到Spring容器中吗？ 当然不用！ 那么 SpringBoot是如何确定哪些配置类该使用，哪些该忽略呢？答案就是使用各种 ConditionalOnXXX 注解，也就是说当符合某些条件时才自动装配。下图总结了SpringBoot中常用条件注解： 总结 SpringBoot启动时会扫描项目所依赖的JAR包，寻找包含spring.factories文件的JAR包。 根据spring.factories配置加载EnableAutoConfiguration，其中给容器中自动配置添加组件的时候，会从propeties类中获取配置文件中指定这些属性的值。xxxAutoConfiguration：⾃动配置类给容器中添加组件。xxxProperties：封装配置⽂件中相关属性。 根据@Conditional注解的条件，进行自动配置并将Bean注入Spring容器。","categories":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"SpringBoot","slug":"后端/SpringBoot","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/SpringBoot/"}],"tags":[{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://rookieyin.github.io/tags/SpringBoot/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"MySQL","slug":"后端/MySQL","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/MySQL/"},{"name":"论文笔记","slug":"论文笔记","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图学习","slug":"论文笔记/图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"论文笔记/图学习/对比学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"其他","slug":"后端/其他","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%85%B6%E4%BB%96/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"操作系统","slug":"计算机基础/操作系统","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Redis/"},{"name":"Spring","slug":"后端/Spring","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Spring/"},{"name":"Java","slug":"后端/Java","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/"},{"name":"JVM","slug":"后端/Java/JVM","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/JVM/"},{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Java并发","slug":"后端/Java/Java并发","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%B9%B6%E5%8F%91/"},{"name":"Java容器","slug":"后端/Java/Java容器","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%AE%B9%E5%99%A8/"},{"name":"Java基础知识","slug":"后端/Java/Java基础知识","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"小样本学习","slug":"论文笔记/小样本学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"name":"异构网络","slug":"论文笔记/图学习/异构网络","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%AD%A6%E4%B9%A0/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"小样本图学习","slug":"论文笔记/小样本图学习","permalink":"http://rookieyin.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"前端","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"CSS","slug":"前端/CSS","permalink":"http://rookieyin.github.io/categories/%E5%89%8D%E7%AB%AF/CSS/"},{"name":"其他","slug":"其他","permalink":"http://rookieyin.github.io/categories/%E5%85%B6%E4%BB%96/"},{"name":"SpringBoot","slug":"后端/SpringBoot","permalink":"http://rookieyin.github.io/categories/%E5%90%8E%E7%AB%AF/SpringBoot/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://rookieyin.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://rookieyin.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"后端","slug":"后端","permalink":"http://rookieyin.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"数据库","slug":"数据库","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://rookieyin.github.io/tags/MySQL/"},{"name":"统计","slug":"统计","permalink":"http://rookieyin.github.io/tags/%E7%BB%9F%E8%AE%A1/"},{"name":"图学习","slug":"图学习","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"对比学习","slug":"对比学习","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://rookieyin.github.io/tags/ElasticSearch/"},{"name":"内存屏障","slug":"内存屏障","permalink":"http://rookieyin.github.io/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"},{"name":"定时任务","slug":"定时任务","permalink":"http://rookieyin.github.io/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"name":"分布式","slug":"分布式","permalink":"http://rookieyin.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Redis","slug":"Redis","permalink":"http://rookieyin.github.io/tags/Redis/"},{"name":"锁","slug":"锁","permalink":"http://rookieyin.github.io/tags/%E9%94%81/"},{"name":"操作系统","slug":"操作系统","permalink":"http://rookieyin.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内存","slug":"内存","permalink":"http://rookieyin.github.io/tags/%E5%86%85%E5%AD%98/"},{"name":"进程","slug":"进程","permalink":"http://rookieyin.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"http://rookieyin.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://rookieyin.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"http://rookieyin.github.io/tags/TCP/"},{"name":"HTTP","slug":"HTTP","permalink":"http://rookieyin.github.io/tags/HTTP/"},{"name":"redis","slug":"redis","permalink":"http://rookieyin.github.io/tags/redis/"},{"name":"随机化","slug":"随机化","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E5%8C%96/"},{"name":"树","slug":"树","permalink":"http://rookieyin.github.io/tags/%E6%A0%91/"},{"name":"图","slug":"图","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE/"},{"name":"二叉树","slug":"二叉树","permalink":"http://rookieyin.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"并查集","slug":"并查集","permalink":"http://rookieyin.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"链表","slug":"链表","permalink":"http://rookieyin.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"动态规划","slug":"动态规划","permalink":"http://rookieyin.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"01背包","slug":"01背包","permalink":"http://rookieyin.github.io/tags/01%E8%83%8C%E5%8C%85/"},{"name":"Java","slug":"Java","permalink":"http://rookieyin.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://rookieyin.github.io/tags/Spring/"},{"name":"JVM","slug":"JVM","permalink":"http://rookieyin.github.io/tags/JVM/"},{"name":"设计模式","slug":"设计模式","permalink":"http://rookieyin.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"数据结构","slug":"数据结构","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"多线程","slug":"多线程","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"容器","slug":"容器","permalink":"http://rookieyin.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"抽象类","slug":"抽象类","permalink":"http://rookieyin.github.io/tags/%E6%8A%BD%E8%B1%A1%E7%B1%BB/"},{"name":"接口","slug":"接口","permalink":"http://rookieyin.github.io/tags/%E6%8E%A5%E5%8F%A3/"},{"name":"泛型","slug":"泛型","permalink":"http://rookieyin.github.io/tags/%E6%B3%9B%E5%9E%8B/"},{"name":"数据类型","slug":"数据类型","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"日期","slug":"日期","permalink":"http://rookieyin.github.io/tags/%E6%97%A5%E6%9C%9F/"},{"name":"String","slug":"String","permalink":"http://rookieyin.github.io/tags/String/"},{"name":"综述","slug":"综述","permalink":"http://rookieyin.github.io/tags/%E7%BB%BC%E8%BF%B0/"},{"name":"自适应","slug":"自适应","permalink":"http://rookieyin.github.io/tags/%E8%87%AA%E9%80%82%E5%BA%94/"},{"name":"自监督学习","slug":"自监督学习","permalink":"http://rookieyin.github.io/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"对抗攻击","slug":"对抗攻击","permalink":"http://rookieyin.github.io/tags/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"},{"name":"半监督学习","slug":"半监督学习","permalink":"http://rookieyin.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"预训练","slug":"预训练","permalink":"http://rookieyin.github.io/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/"},{"name":"子图学习","slug":"子图学习","permalink":"http://rookieyin.github.io/tags/%E5%AD%90%E5%9B%BE%E5%AD%A6%E4%B9%A0/"},{"name":"多视角","slug":"多视角","permalink":"http://rookieyin.github.io/tags/%E5%A4%9A%E8%A7%86%E8%A7%92/"},{"name":"数据增强","slug":"数据增强","permalink":"http://rookieyin.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"},{"name":"图像分类","slug":"图像分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"小样本学习","slug":"小样本学习","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"name":"元学习","slug":"元学习","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"},{"name":"MAML","slug":"MAML","permalink":"http://rookieyin.github.io/tags/MAML/"},{"name":"GNN","slug":"GNN","permalink":"http://rookieyin.github.io/tags/GNN/"},{"name":"异构网络","slug":"异构网络","permalink":"http://rookieyin.github.io/tags/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/"},{"name":"知识图谱","slug":"知识图谱","permalink":"http://rookieyin.github.io/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"小样本","slug":"小样本","permalink":"http://rookieyin.github.io/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC/"},{"name":"CSS","slug":"CSS","permalink":"http://rookieyin.github.io/tags/CSS/"},{"name":"Git","slug":"Git","permalink":"http://rookieyin.github.io/tags/Git/"},{"name":"前端","slug":"前端","permalink":"http://rookieyin.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"定位","slug":"定位","permalink":"http://rookieyin.github.io/tags/%E5%AE%9A%E4%BD%8D/"},{"name":"深度学习","slug":"深度学习","permalink":"http://rookieyin.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"http://rookieyin.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"WL测试","slug":"WL测试","permalink":"http://rookieyin.github.io/tags/WL%E6%B5%8B%E8%AF%95/"},{"name":"图嵌入","slug":"图嵌入","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%B5%8C%E5%85%A5/"},{"name":"随机游走","slug":"随机游走","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0/"},{"name":"标签传播","slug":"标签传播","permalink":"http://rookieyin.github.io/tags/%E6%A0%87%E7%AD%BE%E4%BC%A0%E6%92%AD/"},{"name":"GCN","slug":"GCN","permalink":"http://rookieyin.github.io/tags/GCN/"},{"name":"图分类","slug":"图分类","permalink":"http://rookieyin.github.io/tags/%E5%9B%BE%E5%88%86%E7%B1%BB/"},{"name":"原型网络","slug":"原型网络","permalink":"http://rookieyin.github.io/tags/%E5%8E%9F%E5%9E%8B%E7%BD%91%E7%BB%9C/"},{"name":"迁移学习","slug":"迁移学习","permalink":"http://rookieyin.github.io/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"},{"name":"样本生成","slug":"样本生成","permalink":"http://rookieyin.github.io/tags/%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90/"},{"name":"随机采样","slug":"随机采样","permalink":"http://rookieyin.github.io/tags/%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7/"},{"name":"元路径","slug":"元路径","permalink":"http://rookieyin.github.io/tags/%E5%85%83%E8%B7%AF%E5%BE%84/"},{"name":"动态网络","slug":"动态网络","permalink":"http://rookieyin.github.io/tags/%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C/"},{"name":"拉普拉斯","slug":"拉普拉斯","permalink":"http://rookieyin.github.io/tags/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/"},{"name":"谱聚类","slug":"谱聚类","permalink":"http://rookieyin.github.io/tags/%E8%B0%B1%E8%81%9A%E7%B1%BB/"},{"name":"Softmax","slug":"Softmax","permalink":"http://rookieyin.github.io/tags/Softmax/"},{"name":"过平滑","slug":"过平滑","permalink":"http://rookieyin.github.io/tags/%E8%BF%87%E5%B9%B3%E6%BB%91/"},{"name":"子图","slug":"子图","permalink":"http://rookieyin.github.io/tags/%E5%AD%90%E5%9B%BE/"},{"name":"表示学习","slug":"表示学习","permalink":"http://rookieyin.github.io/tags/%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://rookieyin.github.io/tags/SpringBoot/"}]}